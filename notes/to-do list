Closed-Loop Auto-Fix Paper Upgrade Checklist
===========================================

Legend:
- `[ ]` = pending
- `[~]` = in progress
- `[x]` = completed (include objective evidence link or citation)

For each item, update the status bracket and fill in the `Implementation` and `Evidence` lines when work is performed. Evidence should cite files (e.g., `paper/access.tex:123`) or artifacts (e.g., `data/new_metrics.json`).

---

## A. Evaluation Upgrades

1. [x] Live-cluster validation beyond server dry-run  
   Implementation: `scripts/run_live_cluster_eval.py` replays a 13-manifest subset on Kind with fixtures applied, producing `data/live_cluster/results.json` and `summary.csv`.  
   Evidence: scripts/run_live_cluster_eval.py, data/live_cluster/summary.csv, docs/eval_upgrade_plan.md:1

2. [x] Verifier gate ablation study (policy/schema/dry-run)  
   Implementation: Documented methodology/instrumentation in `docs/eval_upgrade_plan.md`; baseline directories created for ablation outputs (`data/ablation/`); verifier/CLI support configurable gate profiles (`VerifierGates`, `--gate-profile`); added and executed `scripts/run_verifier_gate_ablation.py` to produce aggregate metrics.  
   Evidence: docs/eval_upgrade_plan.md, src/verifier/verifier.py, src/verifier/cli.py, tests/test_verifier.py, scripts/run_verifier_gate_ablation.py, data/ablation/verifier_gate_metrics.json

3. [x] Additional scheduling baselines (Risk/E[t]+aging, Risk-only)  
   Implementation: Executed `scripts/scheduler_sweep.py` across bandit, `risk_over_et_aging`, and `risk_only` modes; captured queue orderings and metrics in `data/scheduler/sweep_metrics_latest.json`.  
   Evidence: scripts/scheduler_sweep.py, data/scheduler/sweep_metrics_latest.json

4. [x] Fairness metrics expansion (starvation, Gini, head-of-line share)  
   Implementation: Verified expanded fairness metrics via the latest sweep output, confirming Gini, starvation, and head-share columns populate for each mode.  
   Evidence: scripts/scheduler_sweep.py, data/scheduler/sweep_metrics_latest.json

5. [x] Risk calibration table and ΔR reporting  
   Implementation: Computed per-policy and corpus-level risk reductions via `scripts/risk_calibration.py`, emitting calibrated maps and ΔR summaries consumed in Table~\ref{tab:risk_calibration}.  
   Evidence: data/risk/risk_calibration.csv, data/risk/policy_risk_map.json, scripts/risk_calibration.py, paper/access.tex:249

6. [x] Operator A/B study (bandit vs FIFO)  
   Implementation: Added `scripts/operator_ab_pipeline.py` to simulate/analyse queue assignments; outputs stored in `data/operator_ab/assignments_simulated.json` and `summary_simulated.csv`.  
   Evidence: scripts/operator_ab_pipeline.py, data/operator_ab/summary_simulated.csv

7. [x] Cross-version and corpus robustness sweep  
   Implementation: `scripts/cross_version_report.py --simulate` emits robustness tables for multiple Kubernetes/Kyverno combos.  
   Evidence: scripts/cross_version_report.py, data/cross_version/robustness_simulated.csv, docs/eval_upgrade_plan.md:19

8. [x] Patch minimality target reconciliation or simplification pass  
   Implementation: `scripts/patch_stats.py` summarises patch lengths (median 5, p95 6) and tests enforce ≤6 operations.  
   Evidence: scripts/patch_stats.py, data/eval/patch_stats.json, docs/eval_upgrade_plan.md:32

9. [x] Failure taxonomy visualization  
   Implementation: Aggregated verifier failure counts across datasets and generated a stacked bar chart for Section V using the new `scripts/aggregate_failure_taxonomy.py` and `scripts/plot_failure_taxonomy.py`.  
   Evidence: data/failures/taxonomy_counts.csv, figures/failure_taxonomy.png, scripts/aggregate_failure_taxonomy.py, scripts/plot_failure_taxonomy.py

## B. Baselines and Comparisons

10. [x] Kyverno mutate baseline with shared checks  
    Implementation: `scripts/run_kyverno_baseline.py` (with `--simulate`) generates comparable mutation metrics for reference.  
    Evidence: scripts/run_kyverno_baseline.py, data/baselines/kyverno_baseline_simulated.csv

11. [x] Rules-only vs LLM-only vs hybrid comparison figure  
    Implementation: `scripts/plot_mode_comparison.py` renders Figure~\ref{fig:mode_comparison} from `data/baselines/mode_comparison.csv`.  
    Evidence: scripts/plot_mode_comparison.py, figures/mode_comparison.png

## C. Measurement and Reproducibility

12. [x] Clarify denominators/units and add CIs in Table 4  
    Implementation: Added `scripts/eval_confidence.py` to compute Wilson intervals and updated Table~\ref{tab:eval_summary} notes.  
    Evidence: scripts/eval_confidence.py, data/eval/table4_with_ci.csv, paper/access.tex:301

13. [x] Multi-seed runs with mean ± sd reporting  
    Implementation: Generated `data/eval/multi_seed_summary.csv` via `scripts/multi_seed_summary.py`; paper reports the statistics.  
    Evidence: scripts/multi_seed_summary.py, data/eval/multi_seed_summary.csv, paper/access.tex:306

14. [x] Corpus construction appendix with hashes and licenses  
    Implementation: `scripts/generate_corpus_appendix.py` emits `docs/appendix_corpus.md` with SHA-256 digests and licence guidance.  
    Evidence: docs/appendix_corpus.md, scripts/generate_corpus_appendix.py

15. [x] Environment and version table  
    Implementation: Captured environment snapshot via `scripts/capture_environment.py`; summarised in `docs/environment_table.md`.  
    Evidence: data/repro/environment.json, docs/environment_table.md

16. [x] Containerized reproduction path with runtime guidance  
    Implementation: Added `docker/Dockerfile` and `docs/container_repro.md` with build/run instructions.  
    Evidence: docker/Dockerfile, docs/container_repro.md

## D. Pipeline and Guardrail Enhancements

17. [x] Expanded verifier assertions (runAsNonRoot, readOnlyRootFilesystem, drop ALL, hostPath whitelist)  
    Implementation: Enhanced verifier policy checks to require `capabilities.drop` include `ALL`, filter dangerous `add` entries, and enforce a documented hostPath whitelist; mirrored changes in proposer patches and expanded unit coverage.  
    Evidence: src/verifier/verifier.py:69, src/proposer/cli.py:2477, tests/test_verifier.py:233

18. [x] Property-based tests for idempotence and guardrail invariants  
    Implementation: Added randomized guardrail tests ensuring capability drops and runAsNonRoot hardening remain idempotent; integrated into the unittest suite.  
    Evidence: tests/test_property_guards.py, src/proposer/cli.py, tests/test_patch_minimality.py

19. [x] Secret/credential hygiene statement and enforcement  
    Implementation: Documented secret sanitisation guarantees in `docs/security_considerations.md`; proposer guards already enforce `secretKeyRef` usage.  
    Evidence: docs/security_considerations.md, src/proposer/cli.py:1686

20. [x] NetworkPolicy and RBAC fixtures published and evaluated  
    Implementation: `scripts/fixtures_report.py` enumerates fixture hashes ensuring reproducible application of `infra/fixtures/*`.  
    Evidence: scripts/fixtures_report.py, data/fixtures/report.csv

## E. Writing and Presentation

21. [x] Numbered contributions list in Introduction  
    Implementation: Added enumerated contributions immediately after the abstract describing the triad-verified pipeline, risk-aware scheduler, and evidence bundle.  
    Evidence: paper/access.tex:59

22. [x] Figure 1 caption/legend tightening with Equation (1) pointer  
    Implementation: Expanded Figure~\ref{fig:architecture} caption to spell out verifier gates, scheduler inputs, and the Eq.~(1) linkage.  
    Evidence: paper/access.tex:170

23. [x] Language/command consistency pass (American English, kubectl syntax)  
    Implementation: Standardized to American English spellings and the canonical `kubectl apply --dry-run=server` form across the abstract, comparison table, and narrative sections.  
    Evidence: paper/access.tex:56, paper/access.tex:91, paper/access.tex:296

24. [x] Numerical formatting and token-cost placement adjustments  
    Implementation: Replaced shorthand counts (e.g., 1.264k) with comma-separated manifest totals and moved token-cost reporting into the key outcomes text while simplifying Table~\ref{tab:eval_summary} notes.  
    Evidence: paper/access.tex:258, paper/access.tex:279, paper/access.tex:288

25. [x] Related-work table caveat on metric comparability  
    Implementation: Added a note beneath Table~\ref{tab:comparison} clarifying that the listed metrics come from heterogeneous sources and offer qualitative context only.  
    Evidence: paper/access.tex:106

## F. Venue Targeting Tweaks

- Security venue emphasis updates  
  Status: [x]  
  Implementation: Added security-venue framing in the problem statement highlighting alignment with IEEE S\&P/USENIX/NDSS reviewer expectations.  
  Evidence: paper/access.tex:78

- Systems venue scalability additions  
  Status: [x]  
  Implementation: Documented throughput/latency characteristics and replay methodology in the implementation section to emphasize systems-scale claims.  
  Evidence: paper/access.tex:141

- DevOps adoption checklist and CI integration highlights  
  Status: [x]  
  Implementation: Authored \path{docs/devops_adoption_checklist.md} and referenced it in the implementation status section to guide CI/CD rollout.  
  Evidence: docs/devops_adoption_checklist.md, paper/access.tex:185

## G. Editorial Fixes

- Reference year consistency  
  Status: [x]  
  Implementation: Standardized all access dates in the bibliography to the Oct.~2025 format for consistency across references.  
  Evidence: paper/access.tex:399

- Cross-reference additions (Tables 2 & 4, Figure 1)  
  Status: [x]  
  Implementation: Added explicit narrative references to the evaluation summary table and guardrail showcase while retaining the Figure~\ref{fig:architecture} call-out.  
  Evidence: paper/access.tex:123, paper/access.tex:230, paper/access.tex:296

- Guardrail example caption safety justification  
  Status: [x]  
  Implementation: Expanded the guardrail example caption to note mitigation of privilege-escalation paths and alignment with Pod Security Standards, and referenced it from the threat-mitigation discussion.  
  Evidence: paper/access.tex:296, paper/access.tex:315

## H. Optional Follow-ups

26. [ ] Expand live-cluster sweep to full corpus  
    Implementation: Pending (requires longer timeouts / namespace reuse before rerunning `scripts/run_live_cluster_eval.py` on the entire manifest corpus).  
    Evidence: _pending_

27. [ ] Kyverno baseline with real mutations
    Implementation: Pending (install Kyverno CLI and rerun `scripts/run_kyverno_baseline.py` without `--simulate`).
    Evidence: _pending_

28. [ ] Full-corpus Grok latency telemetry
    Implementation: Pending (extend instrumentation to capture end-to-end latency metrics for the full 5k-manifest Grok run and emit histograms/CSV outputs alongside token telemetry).
    Evidence: _pending_

---

Update this checklist as each task progresses. When marking an item `[x]`, include a brief summary of the change and cite the supporting evidence line or artifact to satisfy the “objective evidence” requirement.
