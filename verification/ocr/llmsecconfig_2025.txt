
# LLMSecConfig: An LLM-Based Approach for Fixing Software Container Misconfigurations  


Ziyang \(\mathrm{Ye}^{*\dagger}\) , Triet Huynh Minh \(\mathrm{Le}^{*\dagger}\) and M. Ali Babar\*†  \*CREST - The Centre for Research on Engineering Software Technologies, Adelaide, Australia  †School of Computer and Mathematical Sciences, The University of Adelaide, Adelaide, Australia  ziyang.ye@student.adelaide.edu.au, triet.h.le@adelaide.edu.au, ali.babar@adelaide.edu.au  


Abstract—Security misconfigurations in Container Orchestrators (COs) can pose serious threats to software systems. While Static Analysis Tools (SATs) can effectively detect these security vulnerabilities, the industry currently lacks automated solutions capable of fixing these misconfigurations. The emergence of Large Language Models (LLMs), with their proven capabilities in code understanding and generation, presents an opportunity to address this limitation. This study introduces LLMSecConfig, an innovative framework that bridges this gap by combining SATs with LLMs. Our approach leverages advanced prompting techniques and Retrieval- Augmented Generation (RAG) to automatically repair security misconfigurations while preserving operational functionality. Evaluation of 1,000 real- world Kubernetes configurations achieved a \(94\%\) success rate while maintaining a low rate of introducing new misconfigurations.  


Our work makes a promising step towards automated container security management, reducing the manual effort required for configuration maintenance.  


Index Terms—Container, Container Orchestrator, Configuration, Security, Large Language Models, Prompt Template, Retrieval- Augmented Generation  


## I. INTRODUCTION  


Container Orchestrators (COs) have become integral to modern cloud infrastructure, enabling scalable and efficient deployment of applications. However, their widespread adoption has also highlighted a critical security challenge: the prevalence of security misconfigurations. These misconfigurations are the leading cause of vulnerabilities in container- - - - - - - - - - - - - - - - - - - - - ised environments, posing significant risks to system integrity and data confidentiality [1], [2]. While Static Analysis Tools (SATs) are proficient at detecting these vulnerabilities through pattern matching and rule- based analysis [3], there remains a substantial gap in automated remediation solutions. This gap necessitates manual intervention by security administrators, a process that is not only time- consuming and labour- intensive but also prone to human error, especially as the scale and complexity of deployments grow [4]- [6].  


The manual process of fixing misconfigurations involves meticulous examination and correction of numerous configuration files, often requiring deep domain expertise and an in- depth understanding of interdependent settings. This complexity is exacerbated in dynamic environments where configurations frequently change due to scaling operations and Continuous Integration and Continuous Deployment (CI/CD) practices [7]. There are numerous changes in adding, removing, and modifying different services, along with a large num  


ber of corresponding configuration files in CI/CD pipelines. Consequently, organizations usually face significant operational bottlenecks and increased vulnerability exposure due to the lag between the detection and remediation of security issues (misconfigurations) in COs.  


Advancements in Deep Learning and, recently, Large Language Models (LLMs) in Software Engineering offer a promising avenue to bridge this gap [8], [9]. LLMs have demonstrated remarkable capabilities in understanding and generating complex technical content [10]- [12], making them suitable candidates for automating the remediation of security misconfigurations. By leveraging LLMs in conjunction with Retrieval- Augmented Generation (RAG) techniques, it is possible to not only identify but also generate accurate and context- aware fixes for misconfigurations, thereby significantly reducing the manual effort and minimising the risk of introducing new vulnerabilities.  


This study introduces LLMSecConfig, a novel framework designed to automate the repair of security misconfigurations in COs, ensuring that configurations adhere to security best practices while maintaining operational functionality.  


This paper makes the following key contributions:  


1) Novel Framework for Automated Security Configuration Repair: An innovative framework that integrates SATs with LLMs for automated security configuration repair in COs. Our approach uniquely combines LLMs with RAG techniques to generate precise fixes while maintaining operational functionality. 
2) Demonstrated Effectiveness with Real-world Evaluation: Comprehensive evaluation using 1,000 real-world Kubernetes configurations, demonstrating superior performance with a 94.3% repair success rate and minimal error introduction (0.024). Our approach significantly outperforms baseline models, including GPT-4o-mini, which achieved only a 40.2% success rate. 
3) Open-source Dataset and Implementation: To facilitate reproducibility and future research in container security, we provide our complete implementation, including the collected dataset of Kubernetes misconfiguration, source code of the framework, and evaluation scripts at https://figshare.com/s/2a9be8ccfbec9d8ba199.

<--- Page Split --->



<center>Fig. 1: Comparison of misconfigured (left) versus properly configured (right) Kubernetes security contexts. The misconfigured configuration allows privilege escalation, enabling container processes to gain elevated privileges beyond their parent processes. In contrast, the secure configuration explicitly disables this capability. </center>  


## II. BACKGROUND AND MOTIVATION  


### A. Container Security Landscape  


The rise of Infrastructure as Code (IaC) has transformed IT infrastructure management, enabling automated and scalable deployment of applications. Container technologies like Kubernetes offer significant benefits in terms of portability and resource efficiency, but they also present unique security challenges that span multiple layers of the system. These challenges range from kernel vulnerabilities to intricate orchestration misconfigurations [13]- [15].  


Fig. 1 illustrates a common security misconfiguration in container orchestration, where incorrectly enabled privilege escalation could compromise system security. However, security fixes in container orchestrators are often complex and go beyond simple value correction. For instance, setting a Pod's allowPrivilegeEscalation to false becomes challenging when multiple security configurations interact across namespaces.  


Users must analyse configuration dependencies and prevent privilege overrides by considering three main factors. Primarily, CAP_SYS_ADMIN will override allowPrivilegeEscalation to true, invalidating the previous setting. Consequently, any predefined CAP_SYS_ADMIN must be removed to ensure that allowPrivilegeEscalation remains false. This behaviour is notably different from the scenario shown in Fig. 1.  


Additionally, security contexts in Kubernetes operate at different levels. PodSecurityContext manages pod- level security and shared container settings, while container- level SecurityContext controls individual container security and takes precedence when both specify the same field. This complexity is further compounded by varying behaviours between Linux and Windows containers.  


Moreover, security configuration complexity scales significantly with the architectural hierarchy of Kubernetes clusters. At the highest level, a cluster encompasses multiple nodes. Each node, in turn, hosts numerous Pods, while individual Pods can run multiple applications. Throughout this hierarchy, components maintain their own security settings and network policies, creating an intricate web of security configurations.  


This hierarchical structure makes manually defining and fixing rules extremely challenging. More importantly, incomplete fixes can introduce new issues, such as incompatible values between interdependent configurations. Therefore, addressing these intricate security challenges requires automated and systematic approaches rather than manual intervention.   


Modern COs provide an extensive array of configuration options to support diverse deployment scenarios and security requirements. While this flexibility is beneficial, it significantly increases the complexity of maintaining secure settings across all components [16]. The dynamic nature of container environments, characterised by frequent updates and scaling operations, further complicates the security landscape by potentially introducing vulnerabilities through configuration changes [1].  


Multi- tenancy environments present additional security challenges, where shared resources and namespaces require careful management to prevent unauthorised access and resource contention [15]. Supply chain security is equally critical, as container images and their dependencies can introduce vulnerabilities that demand continuous monitoring [14]. The rapid evolution of security threats, including side- channel attacks and container- specific exploits, necessitates robust and adaptable security measures [15], [17].  


### B. The Need for Automated Fixing of Software Container Misconfigurations  


The complexity of container security configurations, combined with the rapid pace of modern development practices, creates a compelling need for automated remediation solutions. In large- scale deployments, the number of configuration files can reach into thousands, making manual corrections time- consuming and prone to errors [4]- [6]. Security administrators must address each misconfiguration meticulously to ensure consistency and compliance across the entire infrastructure. As deployments grow, the operational burden and response times increase, rendering manual approaches impractical.  


Currently, it is challenging to address misconfigurations in COs like Kubernetes. Firstly, understanding the intricate relationships between different settings and ensuring that fixes do not conflict with existing configurations requires significant expertise and domain knowledge [18]. This complexity makes effective manual remediation challenging, especially in environments lacking specialised security personnel.  


The rapid pace of modern development practices, such as CI/CD, also demands swift and reliable configuration updates to keep up with agile development cycles and frequent deployments. Manual remediation cannot meet the speed and effi

<--- Page Split --->


ciency required by these practices, leading to security risks and deployment delays [4]- [6]. Furthermore, regulatory standards often mandate stringent security configurations and require detailed audit trails of configuration changes. Automated fixing can ensure consistent adherence to compliance requirements and provide comprehensive logs for auditing purposes [19].  


Despite the clear need for automated remediation solutions, current research and industry practices have not adequately addressed the automation of security misconfiguration fixes in container environments. While significant progress has been made in automated detection through SATs and validation frameworks, the critical step of actually implementing corrections remains largely manual [3]. Existing approaches primarily focus on providing guidance and recommendations, leaving the complex task of modification and validation to human operators [20]- [23]. This limitation is further exacerbated by the heterogeneous nature of COs and SATs; their diverse design philosophies, programming languages, and technical implementations make it challenging to develop a universal framework for automated detection and repair. Consequently, this gap between detection and remediation represents a significant bottleneck in container security management, particularly as organizations scale their deployments. Our work addresses this fundamental limitation by proposing one of the first automated solutions for fixing container security misconfigurations.  


## III. LLMSEcConfig: AN AUTOMATED FRAMEWORK FOR FIXING SOFTWARE CONTAINER MISCONFIGURATIONS  


### A. Framework Overview  


LLMSeConfig presents an end- to- end pipeline designed to detect and rectify misconfigurations in COs by synergizing SATs with LLMs. The framework operates through three interconnected phases: (i) SAT Integration and (ii) Context Retrieval for detecting and understanding misconfigurations, and then (iii) Repair Generation and Validation, as illustrated in Fig. 2. This modular architecture ensures flexibility and scalability, allowing each component to function independently while contributing to the overall system's effectiveness.  


### B. Static Analysis Tools Integration for Misconfiguration Detection  


SATs are instrumental in the identification of security vulnerabilities and misconfigurations within software systems [21], [24]. Among the various SATs available for COs, such as Checkov, Trivy, Terrascan, and KubeSec [25]- [28], our framework selects Checkov as the primary tool due to its strategic advantages. Checkov offers a comprehensive collection of over 1,000 built- in security policies, ensuring extensive coverage of potential vulnerabilities [25]. Its implementation in pure Python facilitates seamless integration with our framework, allowing direct access to policy definitions and enhancing flexibility. Additionally, Checkov provides rich contextual information through integration with Prisma Cloud documentation and receives regular updates that incorporate the latest security best practices and emerging vulnerability patterns [29].  


### C. Context Retrieval for Misconfiguration Understanding  


The context retrieval module is a critical component of LLMSeConfig, where RAG, with its efficient retrieval capability, has the characteristics of knowledge augmentation and the performance of context- aware generation [30], which enables us to enhance the repair generation process. This module integrates corrective feedback mechanisms to elevate the quality and reliability of the fixes produced by the LLMs [31]. For every detected misconfiguration, the system aggregates three essential types of information to provide a comprehensive context for repair.  


Firstly, the SAT output serves as the foundational context, offering detailed error messages from Checkov scans, specific policy violation identifiers (e.g., CKV_K8S_20), resource type and location information, links to relevant documentation, and severity levels within the framework context, as illustrated in Fig. 3. This information provides a precise understanding of the nature and location of each misconfiguration.  


Secondly, the policy implementation source code, exemplified in Fig. 4, offers in- depth insights into the validation logic and conditions underpinning each security policy, including the complete Python implementation of security checks, key configuration parameters being evaluated, and expected values. Access to the source code allows the framework to comprehend the specific criteria used to determine compliance, enabling more accurate and context- aware repairs. For each ready- to- fix configuration, we first scan it with the Checkov tool to identify security issues and obtain detailed information. Each security issue has a unique ID in Checkov, and by examining its GitHub repository [25], we can locate the corresponding Python file for that ID, which includes the implementation of the security- related checking policy. To facilitate fast indexing, we created a CSV file to map each ID to its source code file.  


Thirdly, comprehensive security documentation from Prisma Cloud, depicted in Fig. 5, supplements the context with detailed analysis of security implications, specific fix recommendations, example configurations demonstrating correct implementations, and framework- specific guidance and best practices. This documentation provides additional layers of information that guide the LLMs in generating precise and effective fixes.  


The context module efficiently retrieves and maintains the relationships between these information sources by extracting policy identifiers and error details from Checkov's output, locating the corresponding Python implementations, and fetching the associated Prisma Cloud documentation. The merge of these elements ensures that the LLMs can get all the necessary information to generate accurate and contextually appropriate repairs. More details about the prompt templates can be found in the Appendix at https://figshare.com/s/2a9be8ccfbec9d8ba199.  


### D. Misconfiguration Repair Generation and Validation  


The repair generation component leverages LLMs to produce context- aware fixes for the identified misconfigurations.

<--- Page Split --->



<center>Fig. 2: Architecture overview of the LLMSecConfig framework for automated Kubernetes security configuration repair. The pipeline comprises three main stages: (1) configuration analysis using SATs, (2) context retrieval through RAG, and (3 & 4) repair generation using Large Language Models (LLMs). The system iteratively processes configurations until all security issues are resolved or the maximum number of attempts is reached. </center>  

<center>Fig. 3: Example output from the Checkov security scanner, indicating a detected privilege escalation vulnerability in a Kubernetes configuration. </center>  

<center>Fig. 4: Python implementation of the Checkov security check for container privilege escalation. </center>  


## Policy Details  

<table><tr><td>Prisma Cloud Policy ID</td><td>3aa8f043-3853-4c9e-ae3a-8d3a70d69d4b</td></tr><tr><td>Checkov ID</td><td>CKV_K8S_20</td></tr><tr><td>Severity</td><td>MEDIUM</td></tr><tr><td>Subtype</td><td>Build</td></tr><tr><td>Frameworks</td><td>Kubernetes, Terraform, Helm, Kustomize</td></tr></table>  


## Description  


The AllowPrivilegeEscalation Pod Security Policy controls whether or not a user is allowed to set the security context of a container to True. Setting it to False ensures that no child process of a container can gain more privileges than its parent. We recommend you to set AllowPrivilegeEscalation to False, to ensure RunAsUser commands cannot bypass their existing sets of permissions.  


## Fix - Buildtime  


## Kubernetes  


- Resource: Container- Arguments: allowPrivilegeEscalation (Optional) If false, the pod can not request to allow privilege escalation. Default to true.  

<center>Fig. 5: Prisma Cloud security policy documentation for CKV_K8S_20: Containers Run with AllowPrivilegeEscalation. </center>  


This process involves carefully designed prompt templates that incorporate error information, policy implementation details, and security documentation. By providing the LLM with this rich context, we enable it to generate precise and effective

<--- Page Split --->


repairs. The system supports multiple LLM backends, offering flexibility in model selection based on specific requirements.  


Upon receiving the context, the LLM generates proposed configuration changes to resolve the identified security issues. To ensure that these generated fixes are valid and effective, LLMSecConfig incorporates a validation process. This process begins with using SAT to verify valid syntax, ensuring that the generated output maintains a valid YAML structure. If the syntax is valid, the system proceeds to security validation, confirming that the repairs address the identified vulnerabilities without introducing new issues.  


To enhance system robustness, we implement two stages of retry mechanisms. An outer loop manages the overall repair attempts, limiting the total number of fixes attempted for each configuration to prevent endless loops. An inner loop handles potential parsing failures of LLM outputs, ensuring that only valid YAML configurations proceed to the security validation stage.  


During each repair iteration, the system performs SAT analysis to identify any remaining security issues. If issues persist, the context is updated, and the LLM generates a new fix. To conform to specific SAT's security best practices, this iterative process continues until all issues are resolved, the maximum number of repair attempts is reached, or an unrecoverable error is encountered.  


Additionally, LLMSecConfig maintains comprehensive control mechanisms and detailed logging. Each repair attempt is logged with information about the original configuration state, identified security issues, generated fixes, and validation results.  


By combining automated repair generation with stringent validation protocols, LLMSecConfig provides a reliable approach to addressing security misconfigurations in COs. The integration of SATs and LLMs, coupled with effective context management and validation, ensures that the framework can effectively repair misconfigurations while preserving the operational functionality of the containerised applications.  


## IV. EXPERIMENTAL SETUP AND DESIGN  


### A. Kubernetes as a Case Study Container Orchestrator  


Kubernetes was selected as our experimental platform due to its position as the de facto standard for container orchestration, with over \(92\%\) of organizations either using or evaluating it according to the CNCF survey [32], [33]. Its extensive security- related settings and well- documented configuration patterns provide an ideal testing ground for our automated repair approach, making our research findings immediately applicable to a large user base [34].  


### B. Dataset  


The need for a custom dataset stems from several key factors. First, there is an absence of public datasets specifically designed for container misconfiguration remediation [35], [36]. Moreover, even if such datasets existed, they would require constant updates due to the evolving nature of COs and their security configurations [37]. As API specifications  


change, security configuration requirements must adapt accordingly.  


We selected ArtifactHub as our primary data source due to its repository of high- quality, vetted Kubernetes configurations that accurately represent real- world usage patterns. As the official CNCF artifact hub [38], [39], ArtifactHub provides a standardised and open format, facilitating straightforward data collection and validation processes. ArtifactHub ensures that the configurations are well- maintained and regularly updated, capturing current configuration trends and security challenges.  


The data collection process was executed through a systematic multi- step approach. Initially, we accessed ArtifactHub's API to identify the top 1,000 most popular projects based on their internal ranking system, ensuring that our dataset encompassed configurations widely used and representative of common industry practices. Each selected project, managed using Helm, required conversion of Helm charts into raw Kubernetes configuration files. This step was crucial as Helm charts typically generate multiple YAML files, each representing distinct Kubernetes resources or components.  


Subsequently, the exported YAML files were parsed to isolate individual sub- configurations. Each sub- configuration was treated as a separate entity corresponding to a specific Kubernetes resource, such as Pods, Services, or Deployments. These isolated configurations were then subjected to analysis using SATs to identify security misconfigurations. Only those files that triggered security issues were retained to increase the vulnerability label quality [40], [41], culminating in a robust test dataset of 1,000 configuration files with detected misconfigurations. The distribution of different types of security misconfigurations within this dataset is illustrated in Fig. 6, highlighting the prevalence of various vulnerability patterns in real- world container configurations.  


### C. LLMs Selection for Repair Generation  


Our evaluation utilised two distinct LLMs: Mistral Large 2 and GPT- 4o- mini [42], [43], strategically selected to compare both open- source and closed- source approaches while considering practical deployment factors.  


Mistral Large 2 was chosen as our primary open- source model not only for its strong performance characteristics but also for its exceptional cost- effectiveness. Its open- source nature enables complete transparency in deployment and modification, allowing organizations to implement our framework without dependency on external API services. The model's efficient architecture makes it particularly suitable for production deployment, offering high performance at significantly lower computational costs compared to other open- source alternatives [42].  


GPT- 4o- mini was selected as our closed- source baseline for several practical reasons. As OpenAI's most cost- effective model [43], it offers a good balance between performance and operational costs. Its widespread adoption and extensive usage history in the developer community provide valuable benchmarking opportunities. The model's optimisation for speed makes it particularly suitable for rapid configuration analysis

<--- Page Split --->



<center>Fig. 6: Distribution of security misconfiguration types in our dataset collected from ArtifactHub. The chart illustrates the relative frequency of different security issues detected by SATs across 1,000 configuration files, highlighting the prevalence of specific vulnerability patterns in real-world container configurations. </center>  


and repair tasks, while still maintaining competitive accuracy levels. Although newer models are available, GPT- 4o- mini's established track record and substantial community feedback make it reliable for evaluating our framework's performance with commercial solutions.  


### D. Evaluation Metrics  


We adopted two primary evaluation metrics, i.e., the Parse Success Rate (PSR) and the Pass Rate (PR). The PSR measures the ability of LLMs to generate syntactically valid YAML configurations, while the PR indicates the proportion of repaired YAML configurations that successfully pass all security checks without errors.  


Let \(\mathcal{D} = \{d_1,\ldots ,d_N\}\) denotes our test dataset, consisting of \(N\) configurations.  


\[\mathrm{Parse~Success~Rate} = \frac{1}{N}\sum_{i = 1}^{N}\mathbb{I}_{\mathrm{parse}}(d_i)\times 100\% \quad (1)\]  


\[\mathrm{Pass~Rate} = \frac{1}{N}\sum_{i = 1}^{N}\mathbb{I}_{\mathrm{pass}}(d_i)\times 100\% \quad (2)\]  


where \(\mathbb{I}_{\mathrm{parse}}(d_i)\) and \(\mathbb{I}_{\mathrm{pass}}(d_i)\) are indicator functions that equal 1 if the YAML parsing of configuration \(d_i\) succeeds and if configuration \(d_i\) passes all security checks, respectively, and 0 otherwise. Higher values are preferred for both metrics.  


To evaluate repair efficiency, we measured the Average Pass Steps (APS):  


\[\mathrm{Average~Pass~Steps} = \frac{\sum_{i = 1}^{N}s(d_i)\cdot\mathbb{I}_{\mathrm{pass}}(d_i)}{\sum_{i = 1}^{N}\mathbb{I}_{\mathrm{pass}}(d_i)} \quad (3)\]  


where \(s(d_i)\) is the number of steps required for configuration \(d_i\) to pass all security checks. Lower values are preferred.  


For step- wise analysis, we computed the Area Under Curve (AUC) metrics for both Pass Rate over Steps (AUC \(\mathrm{PRS}\) ) and Average Pass Steps over Steps (AUC \(\mathrm{APSS}\) ):  


\[\mathrm{AUC}_{\mathrm{PRS}} = \frac{1}{T}\sum_{t = 1}^{T}\mathrm{PR}_t \quad (4)\]  


\[\mathrm{AUC}_{\mathrm{APSS}} = \frac{1}{T}\sum_{t = 1}^{T}\mathrm{APS}_t \quad (5)\]  


where \(T\) is the maximum number of allowed repair steps, \(\mathrm{PR}_t\) is the pass rate achieved within \(t\) steps, and \(\mathrm{APS}_t\) is the average number of steps needed for passing configurations when limited to \(t\) steps. Higher values are preferred for \(\mathrm{AUC}_{\mathrm{PRS}}\) , while lower values are preferred for \(\mathrm{AUC}_{\mathrm{APSS}}\) .  


Finally, we assessed repair quality through the Security Improvement and Average Introduced Errors metrics:  


\[\mathrm{Security~Improvement} = \frac{\sum_{i = 1}^{N}(e_{\mathrm{init}}(d_i) - e_{\mathrm{final}}(d_i))}{\sum_{i = 1}^{N}e_{\mathrm{init}}(d_i)} \quad (6)\]  


where \(e_{\mathrm{init}}(d_i)\) represents the number of security issues in configuration \(d_i\) before repair, and \(e_{\mathrm{final}}(d_i)\) represents the

<--- Page Split --->


number of security issues in configuration \(d_{i}\) after repair. Higher values are preferred.  


\[\mathrm{Average~Introduced~Errors} = \frac{1}{N}\sum_{i = 1}^{N}e_{\mathrm{new}}(d_{i}) \quad (7)\]  


where \(e_{\mathrm{new}}(d_{i})\) represents the number of new security issues introduced during the repair of configuration \(d_{i}\) . Lower values are preferred.  


## V. RESEARCH QUESTIONS AND EXPERIMENTAL RESULTS  


### A. RQ1: To what extent are LLMs effective to correct misconfigurations?  


Motivation: Our primary research question aims to evaluate the fundamental capability of LLMs in automating configuration error correction. While SATs excel at detecting misconfigurations, their inability to automatically correct them creates a significant operational gap. This question quantitatively assesses whether LLMs can effectively bridge this gap by examining several key aspects. We aim to evaluate correction accuracy rates across different LLMs and analyse the syntax validity of the generated corrections.  


Method: We conducted the experiments using the GPT- 4o- mini [43] and mistral- large- 2407 [42] models on a dataset of 1,000 Kubernetes configurations as described in Section IV- B. For both models, we set the temperature to 0.5 and used the default values for all other hyperparameters. Additionally, we configured the maximum parser retry time and the maximum retry value to 10 and 5, respectively. The key parameters in our framework, namely temperature and max retry, were selected as follows:  


- temperature: This parameter controls the randomness of the model's output. A value of 0 results in deterministic outputs, while higher values increase variability. We set the temperature to 0.5, as it provides a balance between diversity and stability, based on findings from prior research [44].- max retry: To account for the non-deterministic nature of LLMs, we introduced a retry mechanism. A non-zero max retry value increases the likelihood of generating correct outputs, but excessive values can lead to higher computational costs. Through experimentation, we determined that a maximum parser retry time of 10 and a maximum retry value of 5 offer a practical balance between performance and efficiency.  


For each sample, we logged the input file's Checkov output and the output file's scanning result, so we could obtain all the metrics we designed and the stopping step.  


Results: The results, presented in Table I and visualised in Fig. 7, demonstrate both the potential and current limitations of LLM- based configuration repair.  


GPT- 4o- mini exhibited considerable limitations in its ability to correct misconfigurations effectively, achieving only a \(40.2\%\) PR and \(99.8\%\) PSR. This relatively low success rate was accompanied by decreasing efficiency over time,  

<center>Fig. 7: Step-wise performance metrics comparing GPT-4o-mini and Mistral Large 2 models. (a) Pass Rate over Steps illustrates the cumulative success rate in fixing misconfigurations across repair attempts. (b) Average Pass Steps over Steps indicates the efficiency of repair processes, where lower values represent more efficient repairs. </center>  


as indicated by an increasing APS that reached 4.38 steps. The model showed a concerning tendency to introduce new errors, with an error introduction rate of 0.029. In contrast, Mistral Large 2 demonstrated remarkably strong capabilities, achieving a \(94.3\%\) PR and \(100\%\) PSR. This high success rate was complemented by consistent efficiency, maintaining 3.06 APS, whilst demonstrating strong security improvement (0.986) with a low rate of introduced errors (0.024), suggesting its potential suitability for production environments.  


The step- wise analysis can be better understood through the curves in Fig. 7. The Pass Rate over Steps curve in Fig. 7(a) shows the cumulative success rate as repair attempts progress, with the Area Under Curve (AUCPRs) quantifying the overall repair effectiveness, a higher value indicates better overall success (Mistral: 0.696 vs GPT- 4o- mini: 0.241). Conversely, Fig. 7(b) displays the Average Pass Steps required at each step limit, where the Area Under Curve (AUCAPSS) measures repair efficiency, lower values indicate more efficient repairs (Mistral: 2.249 vs GPT- 4o- mini: 2.495), demonstrating Mistral Large 2's superior performance in both dimensions.  


RQ1 Summary. LLMs are promising for automated configuration repair. Mistral Large 2 achieved superior performance (94.3% PR, 100% PSR, 3.06 APS) compared to GPT- 4o- mini (40.2% PR, 99.8% PSR, 4.38 APS). Both models maintained low error rates (<0.03), demonstrating viability for production use.  


### B. RQ2: What misconfiguration types are hard to correct?  


Motivation: Understanding the limitations of LLM- based correction is essential for both practical implementation and future research directions. We analyse patterns in failed correction attempts and identify categories of misconfigurations that consistently challenge LLM- based correction. By examining the relationships between configuration complexity and correction success, we can identify edge cases that require

<--- Page Split --->



TABLE I: Comprehensive performance comparison of different Large Language Models (LLMs) in security configuration repair tasks. Metrics include Pass Rate (PR), Parse Success Rate (PSR), Average Pass Steps (APS), Area Under the Curve metrics (AUCpRs and AUCapsS), Security Improvement (Sec Imp), and Average Introduced Errors (Avg. Introduced Err).   

<table><tr><td>LLM</td><td>PR(%)</td><td>PSR(%)</td><td>APS</td><td>AUCpRs</td><td>AUCapsS</td><td>Sec Imp</td><td>Avg. Introduced Err</td></tr><tr><td>GPT-4o-mini</td><td>40.2</td><td>99.8</td><td>4.38</td><td>0.241</td><td>2.495</td><td>0.906</td><td>0.029</td></tr><tr><td>Mistral Large 2</td><td>94.3</td><td>100</td><td>3.06</td><td>0.696</td><td>2.249</td><td>0.986</td><td>0.024</td></tr></table>  


additional mechanisms or human intervention. This analysis of challenging cases can provide valuable insights for future improvements in automated configuration correction systems and help establish realistic expectations for their capabilities.  


Method: According to the intermediate and final results we logged in RQ1, after counting all errors' categories of input files and output files, we obtained and analysed each category's change (fixed or not for each category).  


Results: Our analysis across different security policy types revealed distinct patterns in the difficulty of correcting various misconfigurations. As shown in Fig. 8, the success rates varied significantly depending on both the type of security policy and the model's capabilities.  


Basic security configurations, particularly those involving resource limits and simple networking policies, consistently showed high success rates across all models. These configurations typically involve straightforward parameter adjustments and have clear, well- defined correction paths. The high success rates in these cases suggest that LLMs can effectively handle routine security configuration tasks that form the bulk of day- to- day security maintenance.  


However, our analysis identified several categories of misconfigurations that proved consistently challenging to correct. Complex security contexts, particularly those involving privilege- related configurations, posed significant challenges for GPT- 4o- mini, with Pass Rates falling below \(50\%\) . These cases often involve intricate interdependencies between different security parameters and require a deeper understanding of security implications.  


While Mistral Large 2 showed better performance across all categories, it still encountered occasional difficulties with advanced security policies, particularly those involving complex network configurations. These configuration types usually have limited data in the wild (see Fig. 6), and such data imbalance has been shown to impede the performance of vulnerability prediction models [45]. We have also shown that even advanced models may require additional support mechanisms when handling such highly specialised security configurations.  


RQ2 Summary. Basic security configurations showed consistently high PR across models. Complex security contexts, especially privilege- related configurations, proved challenging for GPT- 4o- mini with \(< 50\%\) PR. While Mistral Large 2 demonstrated a better performance across different policy types, network configurations remained challenging for this model.  


### C. RQ3: What context types are most useful for correction?  


Motivation: Given our framework's integration of RAG and prompting techniques, understanding the impact of different contextual information is crucial. We plan to explore the relative importance of various context sources in the correction process, including error messages from SATs, security documentation and best practices, and configuration file structure and metadata. This investigation helps establish optimal approaches for combining domain- specific knowledge with LLMs' capabilities in security- critical applications.  


Method: Our ablation study was conducted using Mistral Large 2 due to its strong performance demonstrated in RQ1. While all parameters and settings remained identical with RQ1, we only varied the context retrieval method. There are three types of contexts in Checkov: scanning results, source code and Prisma documents from URL. The raw scanning results are mandatory for each run, so we tested four variants: scanning results only, scanning results with source code, scanning results with Prisma document content, and full context combining all three sources as used in RQ1.  


Results: The results, detailed in Table II and visualised in Fig. 9, provide important insights into the relative value of different context types in the repair process.  


The base configuration, utilising only Checkov output (ckvout), demonstrated balanced performance with a PSR of \(95.9\%\) and a PR of \(88.0\%\) . This relatively strong performance suggests that basic error messages provide essential information for many repairs without introducing excessive complexity. The AUCpRs value of 0.598 indicates consistent performance across multiple repair attempts.  


When enhanced with source code context (ckvout + code), the system showed improvement in several metrics. The PR increased to \(90.3\%\) , while the AUCpRs improved to 0.701, indicating both higher success rates and more consistent performance. Most notably, the APS decreased to 2.68, suggesting that source code context enables more efficient repairs. This improvement likely stems from the precise validation logic and expected values provided by the source code.  


Interestingly, the addition of Prisma documentation alone (ckvout + prisma) produced lower performance compared to other configurations. While achieving a high PSR at \(98.4\%\) , the overall PR dropped significantly to \(65.2\%\) , with reduced efficiency (APS: 4.29). However, when combined with both Checkov output, source code and Prisma documentation (full context as used in RQ1), the framework achieved its best overall performance refer to RQ1. This suggests that while documentation alone may introduce noise, its combination with precise technical context creates a complementary effect,

<--- Page Split --->



<center>Fig. 8: Performance comparison of different Large Language Models (LLMs) (GPT-4o-mini and Mistral Large 2) in fixing Kubernetes security misconfigurations, categorised by policy type. The results demonstrate varying success rates across different security policy categories, with Mistral Large 2 consistently showing higher performance across most categories. </center>  


providing both the detailed technical requirements from source code and the broader security context from the documentation. The full context configuration achieved superior performance across all metrics, demonstrating that the combination of all three context types provides the most robust foundation for  


repair generation when properly integrated.

<--- Page Split --->



TABLE II: Comprehensive performance comparison of different context types in security configuration repair tasks. Metrics include Pass Rate (PR), Parse Success Rate (PSR), Average Pass Steps (APS), Area Under the Curve metrics (AUCps and AUCaps), Security Improvement (Sec Imp), and Average Introduced Errors (Avg. Introduced Err).   

<table><tr><td>Context Type</td><td>PR(%)</td><td>PSR(%)</td><td>APS</td><td>AUCps</td><td>AUCaps</td><td>Sec Imp</td><td>Avg. Introduced Err</td></tr><tr><td>ckv_out</td><td>88.0</td><td>95.9</td><td>3.64</td><td>0.598</td><td>2.531</td><td>0.9926</td><td>0</td></tr><tr><td>ckv_out + code</td><td>90.3</td><td>92.2</td><td>2.68</td><td>0.701</td><td>2.105</td><td>0.9946</td><td>0.0134</td></tr><tr><td>ckv_out + prisma</td><td>65.2</td><td>98.4</td><td>4.29</td><td>0.399</td><td>2.582</td><td>0.9675</td><td>0.0031</td></tr><tr><td>ckv_out + code + prisma (RQ1)</td><td>94.3</td><td>100</td><td>3.06</td><td>0.696</td><td>2.249</td><td>0.986</td><td>0.024</td></tr></table>  

<center>Fig. 9: Ablation study results comparing different context types in the repair process. The graphs display (a) Pass Rate progression and (b) Average Pass Steps across repair iterations for three context configurations: base configuration, source code-enhanced, and Prisma documentation-enhanced. Results demonstrate the superior performance of the source code-enhanced context in both repair success rate and efficiency. </center>  


RQ3 Summary. Source code context provided the most effective guidance \((90.3\%)\) PR), while basic Checkov output alone achieved \(88.0\%\) PR. Adding Prisma documentation decreased performance \((65.2\%)\) PR), indicating that precise, technical context outperforms comprehensive documentation for repairs.  


## VI. DISCUSSION  


### A. LLMSecConfig and Beyond  


Our experimental results reveal important insights about automated security configuration repair in container environments, while also highlighting areas for further development.  


The significant performance gap between Mistral Large 2 and GPT- 4o- mini demonstrates that advanced model architectures are crucial for processing complex security contexts with interdependent settings. This difference is particularly evident in the models' ability to maintain consistency across diverse policy types while preserving existing configuration intent.  


Our ablation study reveals insights about context utilisation in repair generation for container misconfigurations. Source code context consistently provides the most effective guidance, achieving a \(90.3\%\) PR. While comprehensive, documentation can add noise that reduces repair efficiency. This suggests that future implementations should prioritise precise, structured context over verbose documentation, particularly for models with limited processing capacity.  


Organizations adopting automated configuration repair should carefully consider their model selection strategy based on our experimental results. The demonstrated success of open- source models like Mistral Large 2, achieving a \(94.3\%\) pass rate while maintaining a low error introduction rate of 0.024, suggests their viability for production environments. However, the complexity of certain configuration types, particularly in advanced network policies, indicates that human oversight remains valuable for high- risk scenarios.  


The strong performance of source code- based context retrieval, evidenced by its \(90.3\%\) PR compared to documentation- based approaches at \(65.2\%\) , emphasises the importance of maintaining well- structured policy implementations. Organizations should focus on establishing clear mappings between security checks and their underlying validation logic to maximise repair effectiveness. Furthermore, our successful implementation of multi- stage validation, achieving a \(100\%\) PSR while maintaining security compliance, demonstrates the necessity of comprehensive validation pipelines in production deployments. These findings collectively provide a practical foundation for implementing automated security configuration repair while highlighting specific areas that require careful consideration during deployment.  


### B. Threats to Validity  


A primary internal validity threat lies in the potential suboptimal configuration of our framework and baseline models. While it is impractical to explore all, we mitigated this by evaluating multiple parameter settings and adapting best practices from relevant literature for LLM- based repair tasks. We also conducted extensive sensitivity analysis to understand the impact of key parameters on repair performance. We choose 0.5 as LLMs Temperature after experiments to find a balance between stabilisation and usability of retry mechanism.  


For external validity, our findings may not generalise to all CO platforms and security scenarios as it was impractical to identify all security issues in the wild [46]. We addressed this threat by evaluating our approach on 1,000 real- world Kubernetes configurations from ArtifactHub, covering diverse project scales and security requirements. While focusing on Kubernetes, our dataset spans various deployment patterns and security policies commonly found in production environments.  


## VII. RELATED WORK  


### A. Configuration Analysis and Management  


Recent research has made significant progress in understanding and addressing container security challenges through

<--- Page Split --->


various methodological approaches. Static analysis techniques have been a commonly used approach, with studies by Smith et al. [21] and Johnson et al. [20] developing tools for analysing container configurations without execution. These approaches primarily focus on identifying potential security issues through pattern matching and semantic analysis, providing early detection of vulnerabilities in configuration specifications.  


Complementing static analysis, dynamic analysis methods have been developed to provide runtime security monitoring and enforcement. Sultan et al. [15] proposed a comprehensive framework for detecting and preventing security violations during container execution, enabling real- time protection against emerging threats. Their work demonstrates the importance of runtime monitoring in maintaining container security, particularly in dynamic deployment environments.  


The application of Machine Learning (ML) techniques to configuration security represents a more recent development in the field. Studies by Bandari [47] and Farkouh et al. [48] have demonstrated the potential of ML approaches in identifying patterns within secure and vulnerable configurations. These data- driven approaches offer promising capabilities for automating security analysis, though they often require substantial training data and careful feature engineering.  


KGSeConfig [18] introduced a structured approach to configuration security, which leverages knowledge graphs and ontologies to represent and reason about security configurations. This semantic approach enables a more sophisticated analysis of configuration relationships and dependencies, though it requires careful knowledge of engineering and maintenance.  


While these approaches have advanced our understanding of container security analysis, they primarily focus on detection rather than automated repair. Our work extends beyond detection by introducing an end- to- end framework that not only identifies misconfigurations but also automatically generates and validates fixes, addressing a critical gap in existing container security management solutions.  


### B. Source Code Vulnerability Detection and Fixing  


The domain of automated vulnerability detection and repair in source code provides valuable insights for configuration security management. Traditional approaches have relied heavily on SATs and pattern matching. For example, Fabian et al. [49] introduced a code property graph for vulnerability detection, combining abstract syntax trees, control flow graphs, and program dependence graphs to identify complex vulnerability patterns. Building on this foundation, there have been major advances in AI (Machine Learning, Deep Learning, and recently LLMs) for detecting and addressing vulnerabilities in source code [50]- [59]. These prior studies have established key principles about context utilisation and fix validation that parallel our approach to configuration repair.  


While code and configuration vulnerabilities present distinct challenges, the underlying principles of combining traditional analysis tools with AI capabilities remain valuable. Our work adapts these lessons to the specific requirements of container configurations, addressing unique challenges such as security parameter interdependencies and the need to maintain operational stability while enhancing security posture.   


## VIII. CONCLUSION  


This paper presents a novel framework that combines SATs with LLMs for automated security configuration repair in COs. The framework's success \((\approx 94\%)\) repair accuracy), particularly with context- aware repair generation, shows the potential of integrating traditional static analysis with modern AI techniques. This work represents a significant step toward automated, secure container deployment management.  


## IX. DATA AVAILABILITY  


The data and code of this study are available at https://figshare.com/s/2a9be8ccfbec9d8ba199.  


## REFERENCES  


[1] E. Casalicchio, "Container orchestration: A survey," Systems Modeling: Methodologies and Tools, pp. 221- 235, 2019.  [2] M. S. I. Shamim, F. A. Bhuiyan, and A. Rahman, "Xi commandments of kubernetes security: A systematization of knowledge related to kubernetes security practices," 2020 IEEE Secure Development (SecDev), pp. 58- 64, 2020.  [3] M. Pistoia, S. Chandra, S. J. Fink, and E. Yahav, "A survey of static analysis methods for identifying security vulnerabilities in software systems," IBM systems journal, vol. 46, no. 2, pp. 265- 288, 2007.  [4] A. Zerouali, R. Opdebeeck, and C. De Roover, "Helm charts for kubernetes applications: Evolution, outdatedness and security risks," in 2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR), 2023, pp. 523- 533.  [5] D. B. Bose, A. Rahman, and S. I. Shamim, "under- reported' security defects in kubernetes manifests," in 2021 IEEE/ACM 2nd International Workshop on Engineering and Cybersecurity of Critical Systems (EnCyCriS), 2021, pp. 9- 12.  [6] E. Russell and K. Dev, "Centralized defense: Logging and mitigation of kubernetes misconfigurations with open source tools," 2024. [Online]. Available: https://arxiv.org/abs/2408.03714  [7] A. K. Arani, T. H. M. Le, M. Zahedi, and M. A. Babar, "Systematic literature review on application of learning- based approaches in continuous integration," IEEE Access, 2024.  [8] T. H. M. Le, H. Chen, and M. A. Babar, "Deep learning for source code modeling and generation: Models, applications, and challenges," ACM Computing Surveys (CSUR), vol. 53, no. 3, pp. 1- 38, 2020.  [9] X. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo, D. Lo, J. Grundy, and H. Wang, "Large language models for software engineering: A systematic literature review," ACM Transactions on Software Engineering and Methodology, vol. 33, no. 8, pp. 1- 79, 2024.  [10] M. Bhatt, S. Chennabasappa, C. Nikolaidis, S. Wan, I. Evtimov, D. Gabi, D. Song, F. Ahmad, C. Aschermann, L. Fontana, S. Frolov, R. P. Giri, D. Kapil, Y. Kozyrakis, D. LeBlanc, J. Milazzo, A. Straumann, G. Synnaeve, V. Vontimitta, S. Whitman, and J. Saxe, "Purple llama cybersecave: A secure coding benchmark for language models," 2023. [Online]. Available: https://arxiv.org/abs/2312.04724  [11] M. Bhatt, S. Chennabasappa, Y. Li, C. Nikolaidis, D. Song, S. Wan, F. Ahmad, C. Aschermann, Y. Chen, D. Kapil, D. Molnar, S. Whitman, and J. Saxe, "Cybersecave 2: A wide- ranging cybersecurity evaluation suite for large language models," 2024. [Online]. Available: https://arxiv.org/abs/2404.13161  [12] S. Wan, C. Nikolaidis, D. Song, D. Molnar, J. Crnkovich, J. Grace, M. Bhatt, S. Chennabasappa, S. Whitman, S. Ding, V. Ionescu, Y. Li, and J. Saxe, "Cybersecave 3: Advancing the evaluation of cybersecurity risks and capabilities in large language models," 2024. [Online]. Available: https://arxiv.org/abs/2408.01605  [13] E. Casalicchio and S. Iannucci, "The state- of- the- art in container technologies: Application, orchestration and security," Concurr. Comput. Pract. Exp., vol. 32, 2020. [Online]. Available: https://api.semanticscholar.org/CorpusID:211264375

<--- Page Split --->


[14] Y. Yang, W. Shen, B. Ruan, W. Liu, and K. Ren, "Security challenges in the container cloud," in 2021 Third IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS- ISA). IEEE, 2021, pp. 137- 145. [15] S. Sultan, I. Ahmad, and T. Dimitriou, "Container security: Issues, challenges, and the road ahead," IEEE access, vol. 7, pp. 52 976- 52 996, 2019. [16] E. Truyen, D. Van Landuyt, D. Preuveneers, B. Lagaisse, and W. Joosen, "A comprehensive feature comparison study of open- source container orchestration frameworks," Applied Sciences, vol. 9, no. 5, p. 931, 2019. [17] D. B. Bose, A. Rahman, and S. I. Shamim, "Under- reported security defects in kubernetes manifests," in 2021 IEEE/ACM 2nd International Workshop on Engineering and Cybersecurity of Critical Systems (EnCyCriS). IEEE, 2021, pp. 9- 12. [18] M. U. Haque, M. M. Kholoosi, and M. A. Babar, "Kgscconfig: a knowledge graph based approach for secured container orchestrator configuration," in 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, 2022, pp. 420- 431. [19] R. Shevchuk, M. P. Karpinski, M. Kasianchuk, I. Yakymenko, A. Melnyk, and R. Tykhyi, "Software for improve the security of kubernetes- based ci/cd pipeline," 2023 13th International Conference on Advanced Computer Information Technologies (ACIT), pp. 420- 425, 2023. [Online]. Available: https://api.semanticscholar.org/CorpusID: 264294763 [20] D. N. Kleidermacher, "Integrating static analysis into a secure software development process," in 2008 IEEE Conference on Technologies for Homeland Security, 2008, pp. 367- 371. [21] H. H. AlBreiki and Q. H. Mahmoud, "Evaluation of static analysis tools for software security," in 2014 10th International Conference on Innovations in Information Technology (IIT), 2014, pp. 93- 98. [22] Z. Moric, V. Dakic, and M. Kulic, "Implementing a security framework for container orchestration," in 2024 IEEE 11th International Conference on Cyber Security and Cloud Computing (CSCloud), 2024, pp. 200- 206. [23] L. Al Mashta, "Containers: Security challenges and mitigation strategies: A systematic literature review," 2024. [24] T. H. M. Le, R. Croft, D. Hin, and M. A. Babar, "A large- scale study of security vulnerability support on developer q&a websites," in Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering, 2021, pp. 109- 118. [25] Bridgecrew. (2024) Checkov. Prisma Cloud. Accessed: 2024- 05. [Online]. Available: https://www.checkov.io/ [26] Aqua Security. (2024) Trivy. Aqua Security. Accessed: 2024- 05. [Online]. Available: https://github.com/aquasecurity/trivy [27] Tenable. (2024) Terrascan. Tenable. Accessed: 2024- 05. [Online]. Available: https://runterrascan.io/ [28] controlplane. (2024) Kubesec. controlplane. Accessed: 2024- 05. [Online]. Available: https://kubesec.io/ [29] Palo Alto Networks. (2024) Prisma cloud. Palo Alto Networks. Accessed: 2024- 11- 09. [Online]. Available: https://www.paloaltonetworks.com/prisma/cloud [30] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and H. Wang, "Retrieval- augmented generation for large language models: A survey," arXiv preprint arXiv:2312.10997, 2023. [31] S.- Q. Yan, J.- C. Gu, Y. Zhu, and Z.- H. Ling, "Corrective retrieval augmented generation," arXiv preprint arXiv:2401.15884, 2024. [32] Cloud Native Computing Foundation, "CncF survey report 2020," The Linux Foundation, Tech. Rep., 11 2020, accessed: 2024- 11- 09. [Online]. Available: https://www.cncf.io/wp- content/uploads/2020/11/CNCF_Survey_Report_2020. pdf [33] EdgeDelta. (2023) Kubernetes adoption statistics. EdgeDelta. Accessed: 2024- 11- 09. [Online]. Available: https://edgeDelta.com/company/blog/kubernetes- adoption- statistics [34] The Kubernetes Authors. (2024) Kubernetes. The Linux Foundation. Accessed: 2024- 05. [Online]. Available: https://kubernetes.io/ [35] A. Khraisat and A. Alazab, "A critical review of intrusion detection systems in the internet of things: techniques, deployment strategy, validation strategy, attacks, public datasets and challenges," Cybersecurity, vol. 4, 2021. [Online]. Available: https://api.semanticscholar.org/CorpusID:232145452 [36] V. Mahajan and S. B. Mane, "Detection, analysis and countermeasures for container based misconfiguration using docker and kubernetes," 2022 International Conference on Computing, Communication, Security  


and Intelligent Systems (ICSIS), pp. 1- 6, 2022. [Online]. Available: https://api.semanticscholar.org/CorpusID:252311879 [37] T. H. M. Le, B. Sabir, and M. A. Babar, "Automated software vulnerability assessment with concept drift," in 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR). IEEE, 2019, pp. 371- 382. [38] Cloud Native Computing Foundation. (2023) Artifact hub. The Linux Foundation. Accessed: 2024- 11- 09. [Online]. Available: https://artifacthub.io/ [39] (2023) CncF projects: Artifact hub. The Linux Foundation. Accessed: 2024- 11- 09. [Online]. Available: https://www.cncf.io/projects/ artifact- hub/ [40] R. Croft, M. A. Babar, and M. M. Kholoosi, "Data quality for software vulnerability datasets," in 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE). IEEE, 2023, pp. 121- 133. [41] T. H. M. Le and M. A. Babar, "Automatic data labeling for software vulnerability prediction models: How far are we?" in Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, 2024, pp. 131- 142. [42] Mistral AI Team. (2023) Large enough. Mistral AI. Accessed: 2024- 11- 09. [Online]. Available: https://mistral.ai/news/mistral- large- 2407/ [43] OpenAI. (2023) Gpt- 4o mini: Advancing cost- efficient intelligence. OpenAI. Accessed: 2024- 11- 09. [Online]. Available: https://openai. com/index/gpt- 4o- mini- advancing- cost- efficient- intelligence/ [44] Y. Wang, Z. Zhang, H. Chen, and H. Shen, "Reasoning with large language models on graph tasks: The influence of temperature," in 2024 5th International Conference on Computer Engineering and Application (ICCEA), 2024, pp. 630- 634. [45] T. H. M. Le and M. Ali Babar, "Mitigating data imbalance for software vulnerability assessment: Does data augmentation help?" in Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, 2024, pp. 119- 130. [46] T. H. M. Le, X. Du, and M. A. Babar, "Are latent vulnerabilities hidden gems for software vulnerability prediction? an empirical study," in 2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR). IEEE, 2024, pp. 716- 727. [47] V. Bandari, "A comprehensive review of ai applications in automated container orchestration, predictive maintenance, security and compliance, resource optimization, and continuous deployment and testing," International Journal of Intelligent Automation and Computing, vol. 4, no. 1, pp. 1- 19, 2021. [48] J. Farkouh, A. A. Donwoung, and A. Nazim, "Intelligent orchestration of containerized applications in cloud infrastructures," in 10th International Workshop on ADVANCES in ICT Infrastructures and Services (ADVANCE 2023), 2023. [49] F. Yamaguchi, N. Golde, D. Arp, and K. Rieck, "Modeling and discovering vulnerabilities with code property graphs," in 2014 IEEE symposium on security and privacy. IEEE, 2014, pp. 590- 604. [50] J. A. Harer, L. Y. Kim, R. L. Russell, O. Ozdemir, L. Kosta, A. Rangamani, L. H. Hamilton, G. I. Centeno, J. R. Key, P. M. Ellingwood, M. W. McConley, J. M. Opper, P. Chin, and T. Lazovich, "Automated software vulnerability detection with machine learning," ArXiv, vol. abs/1803.04497, 2018. [Online]. Available: https://api.semanticscholar.org/CorpusID:3880688 [51] T. H. M. Le, D. Hin, R. Croft, and M. A. Babar, "Deepcva: Automated commit- level vulnerability assessment with deep multi- task learning," in 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2021, pp. 717- 729. [52] S. Chakraborty, R. Krishna, Y. Ding, and B. Ray, "Deep learning based vulnerability detection: Are we there yet?" IEEE Transactions on Software Engineering, vol. 48, no. 9, pp. 3280- 3296, 2021. [53] T. H. M. Le, H. Chen, and M. A. Babar, "A survey on data- driven software vulnerability assessment and prioritization," ACM Computing Surveys, vol. 55, no. 5, pp. 1- 39, 2022. [54] T. H. Le, "Towards an improved understanding of software vulnerability assessment using data- driven approaches," arXiv preprint arXiv:2207.11708, 2022. [55] M. Fu and C. Tantithamthavorn, "Linevul: A transformer- based line- level vulnerability prediction," in Proceedings of the 19th International Conference on Mining Software Repositories, 2022, pp. 608- 620. [56] T. H. M. Le and M. A. Babar, "On the use of fine- grained vulnerable code statements for software vulnerability assessment models," in Proceedings of the 19th International Conference on Mining Software Repositories, 2022, pp. 621- 633.

<--- Page Split --->


[57] M. Fu, C. Tantithamthavorn, T. Le, V. Nguyen, and D. Phung, "Vulre- pair: a t5- based automated software vulnerability repair," in Proceedings of the 30th ACM joint european software engineering conference and symposium on the foundations of software engineering, 2022, pp. 935- 947. [58] A. T. Nguyen, T. H. M. Le, and M. A. Babar, "Automated code- centric software vulnerability assessment: How far are we? an empirical study in clc++, in Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, 2024, pp. 72- 83. [59] T. H. M. Le, M. A. Babar, and T. H. Thai, "Software vulnerability prediction in low- resource languages: An empirical study of codebert and chatgpt," in Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering, 2024, pp. 679- 685.