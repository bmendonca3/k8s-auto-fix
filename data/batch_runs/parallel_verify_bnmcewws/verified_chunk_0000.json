[
  {
    "id": "001",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-latest\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    ports:\n    - containerPort: 80\n",
    "errors": []
  },
  {
    "id": "002",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-latest\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    ports:\n    - containerPort: 80\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n",
    "errors": []
  },
  {
    "id": "003",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-latest\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    ports:\n    - containerPort: 80\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n",
    "errors": []
  },
  {
    "id": "004",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-latest\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n",
    "errors": []
  },
  {
    "id": "005",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-latest\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n",
    "errors": []
  },
  {
    "id": "006",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged-pod\n  namespace: default\nspec:\n  containers:\n  - name: ubuntu\n    image: ubuntu:22.04\n    securityContext:\n      privileged: false\n      readOnlyRootFilesystem: true\n    command:\n    - sleep\n    - '3600'\n",
    "errors": []
  },
  {
    "id": "007",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged-pod\n  namespace: default\nspec:\n  containers:\n  - name: ubuntu\n    image: ubuntu:22.04\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n    command:\n    - sleep\n    - '3600'\n",
    "errors": []
  },
  {
    "id": "008",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged-pod\n  namespace: default\nspec:\n  containers:\n  - name: ubuntu\n    image: ubuntu:22.04\n    securityContext:\n      privileged: false\n    command:\n    - sleep\n    - '3600'\n",
    "errors": []
  },
  {
    "id": "009",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged-pod\n  namespace: default\nspec:\n  containers:\n  - name: ubuntu\n    image: ubuntu:22.04\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n    command:\n    - sleep\n    - '3600'\n",
    "errors": []
  },
  {
    "id": "010",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged-pod\n  namespace: default\nspec:\n  containers:\n  - name: ubuntu\n    image: ubuntu:22.04\n    securityContext:\n      privileged: false\n    command:\n    - sleep\n    - '3600'\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "011",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged-pod\n  namespace: default\nspec:\n  containers:\n  - name: ubuntu\n    image: ubuntu:22.04\n    securityContext:\n      privileged: false\n    command:\n    - sleep\n    - '3600'\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "012",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-risk\n  namespace: default\nspec:\n  containers:\n  - name: web\n    image: nginx:latest\n    ports:\n    - containerPort: 8080\n      hostPort: 30080\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n  volumes:\n  - name: host-data\n    hostPath:\n      path: /var/lib/data\n",
    "errors": []
  },
  {
    "id": "013",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-risk\n  namespace: default\nspec:\n  containers:\n  - name: web\n    image: nginx:latest\n    ports:\n    - containerPort: 8080\n      hostPort: 30080\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n  volumes:\n  - name: host-data\n    hostPath:\n      path: /var/lib/data\n",
    "errors": []
  },
  {
    "id": "014",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-risk\n  namespace: default\nspec:\n  containers:\n  - name: web\n    image: nginx:stable\n    ports:\n    - containerPort: 8080\n      hostPort: 30080\n    securityContext:\n      capabilities:\n        add:\n        - NET_RAW\n        - SYS_ADMIN\n  volumes:\n  - name: host-data\n    hostPath:\n      path: /var/lib/data\n",
    "errors": []
  },
  {
    "id": "015",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-risk\n  namespace: default\nspec:\n  containers:\n  - name: web\n    image: nginx:latest\n    ports:\n    - containerPort: 8080\n      hostPort: 30080\n    securityContext:\n      capabilities:\n        add:\n        - NET_RAW\n        - SYS_ADMIN\n      readOnlyRootFilesystem: true\n      privileged: false\n  volumes:\n  - name: host-data\n    hostPath:\n      path: /var/lib/data\n",
    "errors": []
  },
  {
    "id": "016",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-risk\n  namespace: default\nspec:\n  containers:\n  - name: web\n    image: nginx:latest\n    ports:\n    - containerPort: 8080\n      hostPort: 30080\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n  volumes:\n  - name: host-data\n    hostPath:\n      path: /var/lib/data\n",
    "errors": []
  },
  {
    "id": "017",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-risk\n  namespace: default\nspec:\n  containers:\n  - name: web\n    image: nginx:latest\n    ports:\n    - containerPort: 8080\n      hostPort: 30080\n    securityContext:\n      capabilities:\n        add:\n        - NET_RAW\n        - SYS_ADMIN\n      runAsNonRoot: true\n      privileged: false\n  volumes:\n  - name: host-data\n    hostPath:\n      path: /var/lib/data\n",
    "errors": []
  },
  {
    "id": "018",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-risk\n  namespace: default\nspec:\n  containers:\n  - name: web\n    image: nginx:latest\n    ports:\n    - containerPort: 8080\n      hostPort: 30080\n    securityContext:\n      capabilities:\n        add:\n        - NET_RAW\n        - SYS_ADMIN\n      privileged: false\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: host-data\n    hostPath:\n      path: /var/lib/data\n",
    "errors": []
  },
  {
    "id": "019",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-risk\n  namespace: default\nspec:\n  containers:\n  - name: web\n    image: nginx:latest\n    ports:\n    - containerPort: 8080\n      hostPort: 30080\n    securityContext:\n      capabilities:\n        add:\n        - NET_RAW\n        - SYS_ADMIN\n      privileged: false\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: host-data\n    hostPath:\n      path: /var/lib/data\n",
    "errors": []
  },
  {
    "id": "020",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-postgresql-hl\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 16.1.0\n    helm.sh/chart: postgresql-13.2.24\n    app.kubernetes.io/component: primary\n  annotations:\n    service.alpha.kubernetes.io/tolerate-unready-endpoints: 'true'\nspec:\n  type: ExternalName\n  publishNotReadyAddresses: true\n  externalName: release-name-postgresql-hl.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "021",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 16.1.0\n    helm.sh/chart: postgresql-13.2.24\n    app.kubernetes.io/component: primary\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-postgresql.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "022",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-api-server\n  labels:\n    tier: airflow\n    component: api-server\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  type: ExternalName\n  externalName: release-name-api-server.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "023",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-redis\n  labels:\n    tier: airflow\n    component: redis\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  type: ExternalName\n  externalName: release-name-redis.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "024",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-statsd\n  labels:\n    tier: airflow\n    component: statsd\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    prometheus.io/scrape: 'true'\n    prometheus.io/port: '9102'\nspec:\n  type: ExternalName\n  externalName: release-name-statsd.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "025",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  type: ExternalName\n  externalName: release-name-triggerer.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "026",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  type: ExternalName\n  externalName: release-name-worker.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "027",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-api-server\n  labels:\n    tier: airflow\n    component: api-server\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      tier: airflow\n      component: api-server\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: api-server\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n    spec:\n      serviceAccountName: release-name-airflow-api-server\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: api-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: api-server\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow api-server\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        ports:\n        - name: api-server\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        startupProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "028",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-api-server\n  labels:\n    tier: airflow\n    component: api-server\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      tier: airflow\n      component: api-server\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: api-server\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n    spec:\n      serviceAccountName: release-name-airflow-api-server\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: api-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: api-server\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow api-server\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        ports:\n        - name: api-server\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        startupProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "029",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-api-server\n  labels:\n    tier: airflow\n    component: api-server\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      tier: airflow\n      component: api-server\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: api-server\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n    spec:\n      serviceAccountName: default\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: api-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: api-server\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - -c\n        - exec airflow api-server\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        ports:\n        - name: api-server\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        startupProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "030",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-api-server\n  labels:\n    tier: airflow\n    component: api-server\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      tier: airflow\n      component: api-server\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: api-server\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n    spec:\n      serviceAccountName: release-name-airflow-api-server\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: api-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: api-server\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow api-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        ports:\n        - name: api-server\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        startupProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "031",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-api-server\n  labels:\n    tier: airflow\n    component: api-server\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      tier: airflow\n      component: api-server\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: api-server\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n    spec:\n      serviceAccountName: release-name-airflow-api-server\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: api-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: api-server\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow api-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        ports:\n        - name: api-server\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        startupProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "032",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-api-server\n  labels:\n    tier: airflow\n    component: api-server\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      tier: airflow\n      component: api-server\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: api-server\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n    spec:\n      serviceAccountName: release-name-airflow-api-server\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: api-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: api-server\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow api-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        ports:\n        - name: api-server\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        startupProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "033",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-api-server\n  labels:\n    tier: airflow\n    component: api-server\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      tier: airflow\n      component: api-server\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: api-server\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n    spec:\n      serviceAccountName: release-name-airflow-api-server\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: api-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: api-server\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow api-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        ports:\n        - name: api-server\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          failureThreshold: 5\n          periodSeconds: 10\n        startupProbe:\n          httpGet:\n            path: /api/v2/version\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "034",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "035",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "036",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "037",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: default\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "038",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "039",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "040",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "041",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "042",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "043",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-dag-processor\n  labels:\n    tier: airflow\n    component: dag-processor\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: dag-processor\n      release: release-name\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 50%\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: dag-processor\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: dag-processor\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-dag-processor\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: dag-processor\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow dag-processor\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --local --job-type DagProcessorJob\n\n              '\n      - name: dag-processor-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "044",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "045",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "046",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "047",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: default\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "048",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "049",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "050",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "051",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "052",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "053",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-scheduler\n  labels:\n    tier: airflow\n    component: scheduler\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n    executor: CeleryExecutor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: scheduler\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: scheduler\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: scheduler\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 10\n      serviceAccountName: release-name-airflow-scheduler\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: scheduler\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow scheduler\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        startupProbe:\n          initialDelaySeconds: 0\n          timeoutSeconds: 20\n          failureThreshold: 6\n          periodSeconds: 10\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type SchedulerJob --local\n\n              '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/pod_templates/pod_template_file.yaml\n          subPath: pod_template_file.yaml\n          readOnly: true\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      - name: scheduler-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n      - name: logs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "054",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-statsd\n  labels:\n    tier: airflow\n    component: statsd\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: statsd\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: statsd\n        release: release-name\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: release-name-airflow-statsd\n      securityContext:\n        runAsUser: 65534\n      restartPolicy: Always\n      containers:\n      - name: statsd\n        image: quay.io/prometheus/statsd-exporter:v0.28.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - --statsd.mapping-config=/etc/statsd-exporter/mappings.yml\n        resources: {}\n        ports:\n        - name: statsd-ingest\n          protocol: UDP\n          containerPort: 9125\n        - name: statsd-scrape\n          containerPort: 9102\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 9102\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /metrics\n            port: 9102\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: config\n          mountPath: /etc/statsd-exporter/mappings.yml\n          subPath: mappings.yml\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-statsd\n",
    "errors": []
  },
  {
    "id": "055",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-statsd\n  labels:\n    tier: airflow\n    component: statsd\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: statsd\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: statsd\n        release: release-name\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      securityContext:\n        runAsUser: 65534\n      restartPolicy: Always\n      containers:\n      - name: statsd\n        image: quay.io/prometheus/statsd-exporter:v0.28.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - --statsd.mapping-config=/etc/statsd-exporter/mappings.yml\n        resources: {}\n        ports:\n        - name: statsd-ingest\n          protocol: UDP\n          containerPort: 9125\n        - name: statsd-scrape\n          containerPort: 9102\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 9102\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /metrics\n            port: 9102\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: config\n          mountPath: /etc/statsd-exporter/mappings.yml\n          subPath: mappings.yml\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-statsd\n",
    "errors": []
  },
  {
    "id": "056",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-statsd\n  labels:\n    tier: airflow\n    component: statsd\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: statsd\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: statsd\n        release: release-name\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: release-name-airflow-statsd\n      securityContext:\n        runAsUser: 65534\n      restartPolicy: Always\n      containers:\n      - name: statsd\n        image: quay.io/prometheus/statsd-exporter:v0.28.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - --statsd.mapping-config=/etc/statsd-exporter/mappings.yml\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - name: statsd-ingest\n          protocol: UDP\n          containerPort: 9125\n        - name: statsd-scrape\n          containerPort: 9102\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 9102\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /metrics\n            port: 9102\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: config\n          mountPath: /etc/statsd-exporter/mappings.yml\n          subPath: mappings.yml\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-statsd\n",
    "errors": []
  },
  {
    "id": "057",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-statsd\n  labels:\n    tier: airflow\n    component: statsd\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: statsd\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: statsd\n        release: release-name\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: release-name-airflow-statsd\n      securityContext:\n        runAsUser: 65534\n      restartPolicy: Always\n      containers:\n      - name: statsd\n        image: quay.io/prometheus/statsd-exporter:v0.28.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - --statsd.mapping-config=/etc/statsd-exporter/mappings.yml\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - name: statsd-ingest\n          protocol: UDP\n          containerPort: 9125\n        - name: statsd-scrape\n          containerPort: 9102\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 9102\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /metrics\n            port: 9102\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: config\n          mountPath: /etc/statsd-exporter/mappings.yml\n          subPath: mappings.yml\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-statsd\n",
    "errors": []
  },
  {
    "id": "058",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 16.1.0\n    helm.sh/chart: postgresql-13.2.24\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  serviceName: release-name-postgresql-hl\n  updateStrategy:\n    rollingUpdate: {}\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: postgresql\n      app.kubernetes.io/component: primary\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: postgresql\n        app.kubernetes.io/version: 16.1.0\n        helm.sh/chart: postgresql-13.2.24\n        app.kubernetes.io/component: primary\n    spec:\n      serviceAccountName: default\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: postgresql\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n      hostNetwork: false\n      hostIPC: false\n      containers:\n      - name: postgresql\n        image: docker.io/bitnami/postgresql:16.1.0-debian-11-r15\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 1001\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /bitnami/postgresql\n        - name: PGDATA\n          value: /bitnami/postgresql/data\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-postgresql\n              key: postgres-password\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        - name: POSTGRESQL_ENABLE_TLS\n          value: 'no'\n        - name: POSTGRESQL_LOG_HOSTNAME\n          value: 'false'\n        - name: POSTGRESQL_LOG_CONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_LOG_DISCONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_PGAUDIT_LOG_CATALOG\n          value: 'off'\n        - name: POSTGRESQL_CLIENT_MIN_MESSAGES\n          value: error\n        - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES\n          value: pgaudit\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -h 127.0.0.1 -p 5432\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -h 127.0.0.1 -p 5432\n\n              [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized\n              ]\n\n              '\n        resources:\n          limits: {}\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /bitnami/postgresql\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "059",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 16.1.0\n    helm.sh/chart: postgresql-13.2.24\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  serviceName: release-name-postgresql-hl\n  updateStrategy:\n    rollingUpdate: {}\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: postgresql\n      app.kubernetes.io/component: primary\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: postgresql\n        app.kubernetes.io/version: 16.1.0\n        helm.sh/chart: postgresql-13.2.24\n        app.kubernetes.io/component: primary\n    spec:\n      serviceAccountName: default\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: postgresql\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n      hostNetwork: false\n      hostIPC: false\n      containers:\n      - name: postgresql\n        image: docker.io/bitnami/postgresql:16.1.0-debian-11-r15\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: false\n          runAsNonRoot: true\n          runAsUser: 1001\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /bitnami/postgresql\n        - name: PGDATA\n          value: /bitnami/postgresql/data\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-postgresql\n              key: postgres-password\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        - name: POSTGRESQL_ENABLE_TLS\n          value: 'no'\n        - name: POSTGRESQL_LOG_HOSTNAME\n          value: 'false'\n        - name: POSTGRESQL_LOG_CONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_LOG_DISCONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_PGAUDIT_LOG_CATALOG\n          value: 'off'\n        - name: POSTGRESQL_CLIENT_MIN_MESSAGES\n          value: error\n        - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES\n          value: pgaudit\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -h 127.0.0.1 -p 5432\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -h 127.0.0.1 -p 5432\n\n              [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized\n              ]\n\n              '\n        resources:\n          limits:\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /bitnami/postgresql\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "060",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis\n  labels:\n    tier: airflow\n    component: redis\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-redis\n  selector:\n    matchLabels:\n      tier: airflow\n      component: redis\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: redis\n        release: release-name\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      serviceAccountName: release-name-airflow-redis\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: redis\n        image: redis:7.2-bookworm\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        command:\n        - /bin/sh\n        resources: {}\n        args:\n        - -c\n        - redis-server --requirepass ${REDIS_PASSWORD}\n        ports:\n        - name: redis-db\n          containerPort: 6379\n        volumeMounts:\n        - name: redis-db\n          mountPath: /data\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-redis-password\n              key: password\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-db\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "errors": []
  },
  {
    "id": "061",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis\n  labels:\n    tier: airflow\n    component: redis\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-redis\n  selector:\n    matchLabels:\n      tier: airflow\n      component: redis\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: redis\n        release: release-name\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      serviceAccountName: default\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: redis\n        image: redis:7.2-bookworm\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        command:\n        - /bin/sh\n        resources: {}\n        args:\n        - -c\n        - redis-server --requirepass ${REDIS_PASSWORD}\n        ports:\n        - name: redis-db\n          containerPort: 6379\n        volumeMounts:\n        - name: redis-db\n          mountPath: /data\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-redis-password\n              key: password\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-db\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "errors": []
  },
  {
    "id": "062",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis\n  labels:\n    tier: airflow\n    component: redis\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-redis\n  selector:\n    matchLabels:\n      tier: airflow\n      component: redis\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: redis\n        release: release-name\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      serviceAccountName: release-name-airflow-redis\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: redis\n        image: redis:7.2-bookworm\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        command:\n        - /bin/sh\n        resources: {}\n        args:\n        - -c\n        - redis-server --requirepass ${REDIS_PASSWORD}\n        ports:\n        - name: redis-db\n          containerPort: 6379\n        volumeMounts:\n        - name: redis-db\n          mountPath: /data\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-redis-password\n              key: password\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-db\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "errors": []
  },
  {
    "id": "063",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis\n  labels:\n    tier: airflow\n    component: redis\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-redis\n  selector:\n    matchLabels:\n      tier: airflow\n      component: redis\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: redis\n        release: release-name\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      serviceAccountName: release-name-airflow-redis\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: redis\n        image: redis:7.2-bookworm\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        command:\n        - /bin/sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        args:\n        - -c\n        - redis-server --requirepass ${REDIS_PASSWORD}\n        ports:\n        - name: redis-db\n          containerPort: 6379\n        volumeMounts:\n        - name: redis-db\n          mountPath: /data\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-redis-password\n              key: password\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-db\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "errors": []
  },
  {
    "id": "064",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis\n  labels:\n    tier: airflow\n    component: redis\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-redis\n  selector:\n    matchLabels:\n      tier: airflow\n      component: redis\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: redis\n        release: release-name\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      serviceAccountName: release-name-airflow-redis\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: redis\n        image: redis:7.2-bookworm\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        command:\n        - /bin/sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        args:\n        - -c\n        - redis-server --requirepass ${REDIS_PASSWORD}\n        ports:\n        - name: redis-db\n          containerPort: 6379\n        volumeMounts:\n        - name: redis-db\n          mountPath: /data\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-redis-password\n              key: password\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-db\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "errors": []
  },
  {
    "id": "065",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "066",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "067",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "068",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: default\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "069",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "070",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "071",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "072",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "073",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "074",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-triggerer\n  labels:\n    tier: airflow\n    component: triggerer\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-triggerer\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: triggerer\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: triggerer\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: triggerer\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 60\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-triggerer\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: triggerer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - exec airflow triggerer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - 'CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR\n              exec /entrypoint \\\n\n              airflow jobs check --job-type TriggererJob --local\n\n              '\n        ports:\n        - name: triggerer-logs\n          containerPort: 8794\n      - name: triggerer-log-groomer\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "075",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources: {}\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "076",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources: {}\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "077",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources: {}\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "078",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: default\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources: {}\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources: {}\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources: {}\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "079",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "080",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "081",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "082",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "083",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "084",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-worker\n  labels:\n    tier: airflow\n    component: worker\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\nspec:\n  serviceName: release-name-worker\n  replicas: 1\n  selector:\n    matchLabels:\n      tier: airflow\n      component: worker\n      release: release-name\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: worker\n        release: release-name\n      annotations:\n        checksum/metadata-secret: 327e091234a14bd54fe663b0f2eb6d8f7b817c2dcfa8b6fc2311334f6a68faf1\n        checksum/result-backend-secret: 98a68f230007cfa8f5d3792e1aff843a76b0686409e4a46ab2f092f6865a1b71\n        checksum/pgbouncer-config-secret: 1dae2adc757473469686d37449d076b0c82404f61413b58ae68b3c5e99527688\n        checksum/webserver-secret-key: 97ccb485bcb4d6b5d625617645f8cda75f82731afbd1fa58b643a3bd927c7026\n        checksum/kerberos-keytab: 80979996aa3c1f48c95dfbe9bb27191e71f12442a08c0ed834413da9d430fd0e\n        checksum/airflow-config: 8280f1a548335eb4fa2dadaae8a78f009bb408ea8725a2363cc9533a176ec5db\n        checksum/extra-configmaps: e862ea47e13e634cf17d476323784fa27dac20015550c230953b526182f5cac8\n        checksum/extra-secrets: e9582fdd622296c976cbc10a5ba7d6702c28a24fe80795ea5b84ba443a56c827\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n    spec:\n      nodeSelector: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  component: worker\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      tolerations: []\n      topologySpreadConstraints: []\n      terminationGracePeriodSeconds: 600\n      restartPolicy: Always\n      serviceAccountName: release-name-airflow-worker\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      initContainers:\n      - name: wait-for-airflow-migrations\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        args:\n        - airflow\n        - db\n        - check-migrations\n        - --migration-wait-timeout=60\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      containers:\n      - name: worker\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow celery worker'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          failureThreshold: 5\n          periodSeconds: 60\n          exec:\n            command:\n            - sh\n            - -c\n            - CONNECTION_CHECK_MAX_COUNT=0 exec /entrypoint python -m celery --app\n              airflow.providers.celery.executors.celery_executor.app inspect ping\n              -d celery@$(hostname)\n        ports:\n        - name: worker-logs\n          containerPort: 8793\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n        envFrom: []\n        env:\n        - name: DUMB_INIT_SETSID\n          value: '0'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n      - name: worker-log-groomer\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - /clean-logs\n        env:\n        - name: AIRFLOW__LOG_RETENTION_DAYS\n          value: '15'\n        - name: AIRFLOW__LOG_CLEANUP_FREQUENCY_MINUTES\n          value: '15'\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: logs\n          mountPath: /opt/airflow/logs\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: logs\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n",
    "errors": []
  },
  {
    "id": "085",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-create-user\n  labels:\n    tier: airflow\n    component: create-user-job\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    helm.sh/hook: post-install,post-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '2'\nspec:\n  ttlSecondsAfterFinished: 300\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: create-user-job\n        release: release-name\n    spec:\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      restartPolicy: OnFailure\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      serviceAccountName: release-name-airflow-create-user-job\n      containers:\n      - name: create-user\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow users create \"$@\"'\n        - --\n        - -r\n        - Admin\n        - -u\n        - admin\n        - -e\n        - admin@example.com\n        - -f\n        - admin\n        - -l\n        - user\n        - -p\n        - admin\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "086",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-create-user\n  labels:\n    tier: airflow\n    component: create-user-job\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    helm.sh/hook: post-install,post-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '2'\nspec:\n  ttlSecondsAfterFinished: 300\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: create-user-job\n        release: release-name\n    spec:\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      restartPolicy: OnFailure\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      serviceAccountName: default\n      containers:\n      - name: create-user\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow users create \"$@\"'\n        - --\n        - -r\n        - Admin\n        - -u\n        - admin\n        - -e\n        - admin@example.com\n        - -f\n        - admin\n        - -l\n        - user\n        - -p\n        - admin\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "087",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-create-user\n  labels:\n    tier: airflow\n    component: create-user-job\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    helm.sh/hook: post-install,post-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '2'\nspec:\n  ttlSecondsAfterFinished: 300\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: create-user-job\n        release: release-name\n    spec:\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      restartPolicy: OnFailure\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      serviceAccountName: release-name-airflow-create-user-job\n      containers:\n      - name: create-user\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow users create \"$@\"'\n        - --\n        - -r\n        - Admin\n        - -u\n        - admin\n        - -e\n        - admin@example.com\n        - -f\n        - admin\n        - -l\n        - user\n        - -p\n        - admin\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "088",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-create-user\n  labels:\n    tier: airflow\n    component: create-user-job\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    helm.sh/hook: post-install,post-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '2'\nspec:\n  ttlSecondsAfterFinished: 300\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: create-user-job\n        release: release-name\n    spec:\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      restartPolicy: OnFailure\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      serviceAccountName: release-name-airflow-create-user-job\n      containers:\n      - name: create-user\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow users create \"$@\"'\n        - --\n        - -r\n        - Admin\n        - -u\n        - admin\n        - -e\n        - admin@example.com\n        - -f\n        - admin\n        - -l\n        - user\n        - -p\n        - admin\n        envFrom: []\n        env:\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "089",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-run-airflow-migrations\n  labels:\n    tier: airflow\n    component: run-airflow-migrations\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    helm.sh/hook: post-install,post-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '1'\nspec:\n  ttlSecondsAfterFinished: 300\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: run-airflow-migrations\n        release: release-name\n    spec:\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      restartPolicy: OnFailure\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      serviceAccountName: release-name-airflow-migrate-database-job\n      containers:\n      - name: run-airflow-migrations\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow db migrate'\n        envFrom: []\n        env:\n        - name: PYTHONUNBUFFERED\n          value: '1'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "090",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-run-airflow-migrations\n  labels:\n    tier: airflow\n    component: run-airflow-migrations\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    helm.sh/hook: post-install,post-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '1'\nspec:\n  ttlSecondsAfterFinished: 300\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: run-airflow-migrations\n        release: release-name\n    spec:\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      restartPolicy: OnFailure\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      serviceAccountName: default\n      containers:\n      - name: run-airflow-migrations\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow db migrate'\n        envFrom: []\n        env:\n        - name: PYTHONUNBUFFERED\n          value: '1'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "091",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-run-airflow-migrations\n  labels:\n    tier: airflow\n    component: run-airflow-migrations\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    helm.sh/hook: post-install,post-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '1'\nspec:\n  ttlSecondsAfterFinished: 300\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: run-airflow-migrations\n        release: release-name\n    spec:\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      restartPolicy: OnFailure\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      serviceAccountName: release-name-airflow-migrate-database-job\n      containers:\n      - name: run-airflow-migrations\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow db migrate'\n        envFrom: []\n        env:\n        - name: PYTHONUNBUFFERED\n          value: '1'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "092",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-run-airflow-migrations\n  labels:\n    tier: airflow\n    component: run-airflow-migrations\n    release: release-name\n    chart: airflow-1.18.0\n    heritage: Helm\n  annotations:\n    helm.sh/hook: post-install,post-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '1'\nspec:\n  ttlSecondsAfterFinished: 300\n  template:\n    metadata:\n      labels:\n        tier: airflow\n        component: run-airflow-migrations\n        release: release-name\n    spec:\n      securityContext:\n        runAsUser: 50000\n        fsGroup: 0\n      restartPolicy: OnFailure\n      nodeSelector: {}\n      affinity: {}\n      tolerations: []\n      topologySpreadConstraints: []\n      serviceAccountName: release-name-airflow-migrate-database-job\n      containers:\n      - name: run-airflow-migrations\n        image: apache/airflow:3.0.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        args:\n        - bash\n        - -c\n        - 'exec \\\n\n          airflow db migrate'\n        envFrom: []\n        env:\n        - name: PYTHONUNBUFFERED\n          value: '1'\n        - name: AIRFLOW__CORE__FERNET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-fernet-key\n              key: fernet-key\n        - name: AIRFLOW_HOME\n          value: /opt/airflow\n        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW_CONN_AIRFLOW_DB\n          valueFrom:\n            secretKeyRef:\n              name: release-name-metadata\n              key: connection\n        - name: AIRFLOW__API__SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: release-name-api-secret-key\n              key: api-secret-key\n        - name: AIRFLOW__API_AUTH__JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-jwt-secret\n              key: jwt-secret\n        - name: AIRFLOW__CELERY__BROKER_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-broker-url\n              key: connection\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: config\n          mountPath: /opt/airflow/airflow.cfg\n          subPath: airflow.cfg\n          readOnly: true\n        - name: config\n          mountPath: /opt/airflow/config/airflow_local_settings.py\n          subPath: airflow_local_settings.py\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-config\n",
    "errors": []
  },
  {
    "id": "093",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-argocd-applicationset-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  type: ExternalName\n  externalName: release-name-argocd-applicationset-controller.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "094",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\n  name: release-name-argocd-repo-server\n  namespace: default\nspec:\n  type: ExternalName\n  externalName: release-name-argocd-repo-server.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "095",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-argocd-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-argocd-server.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "096",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-argocd-dex-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  type: ExternalName\n  externalName: release-name-argocd-dex-server.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "097",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-argocd-redis\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-redis\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  type: ExternalName\n  externalName: release-name-argocd-redis.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "098",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-applicationset-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-applicationset-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: applicationset-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      containers:\n      - name: applicationset-controller\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-applicationset-controller\n        - --metrics-addr=:8080\n        - --probe-addr=:8081\n        - --webhook-addr=:7000\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.allowed.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_GITHUB_API_METRICS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.github.api.metrics\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.webhook.parallelism.limit\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_MAX_RESOURCES_STATUS_COUNT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.status.max.resources.count\n              optional: true\n        ports:\n        - name: metrics\n          containerPort: 8080\n          protocol: TCP\n        - name: probe\n          containerPort: 8081\n          protocol: TCP\n        - name: webhook\n          containerPort: 7000\n          protocol: TCP\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-applicationset-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "099",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-applicationset-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-applicationset-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: applicationset-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-applicationset-controller\n      automountServiceAccountToken: true\n      containers:\n      - name: applicationset-controller\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-applicationset-controller\n        - --metrics-addr=:8080\n        - --probe-addr=:8081\n        - --webhook-addr=:7000\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.allowed.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_GITHUB_API_METRICS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.github.api.metrics\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.webhook.parallelism.limit\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_MAX_RESOURCES_STATUS_COUNT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.status.max.resources.count\n              optional: true\n        ports:\n        - name: metrics\n          containerPort: 8080\n          protocol: TCP\n        - name: probe\n          containerPort: 8081\n          protocol: TCP\n        - name: webhook\n          containerPort: 7000\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-applicationset-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "100",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-applicationset-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-applicationset-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: applicationset-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-applicationset-controller\n      automountServiceAccountToken: true\n      containers:\n      - name: applicationset-controller\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-applicationset-controller\n        - --metrics-addr=:8080\n        - --probe-addr=:8081\n        - --webhook-addr=:7000\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.allowed.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_GITHUB_API_METRICS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.github.api.metrics\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.webhook.parallelism.limit\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_MAX_RESOURCES_STATUS_COUNT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.status.max.resources.count\n              optional: true\n        ports:\n        - name: metrics\n          containerPort: 8080\n          protocol: TCP\n        - name: probe\n          containerPort: 8081\n          protocol: TCP\n        - name: webhook\n          containerPort: 7000\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-applicationset-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "101",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-notifications-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-notifications-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: notifications-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      containers:\n      - name: notifications-controller\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-notifications\n        - --metrics-port=9001\n        - --namespace=default\n        - --argocd-repo-server=release-name-argocd-repo-server:8081\n        - --secret-name=argocd-notifications-secret\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        ports:\n        - name: metrics\n          containerPort: 9001\n          protocol: TCP\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        workingDir: /app\n        volumeMounts:\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: argocd-repo-server-tls\n          mountPath: /app/config/reposerver/tls\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-notifications-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "102",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-notifications-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-notifications-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: notifications-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-notifications-controller\n      automountServiceAccountToken: true\n      containers:\n      - name: notifications-controller\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-notifications\n        - --metrics-port=9001\n        - --namespace=default\n        - --argocd-repo-server=release-name-argocd-repo-server:8081\n        - --secret-name=argocd-notifications-secret\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        ports:\n        - name: metrics\n          containerPort: 9001\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        workingDir: /app\n        volumeMounts:\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: argocd-repo-server-tls\n          mountPath: /app/config/reposerver/tls\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-notifications-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "103",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-notifications-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-notifications-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: notifications-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-notifications-controller\n      automountServiceAccountToken: true\n      containers:\n      - name: notifications-controller\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-notifications\n        - --metrics-port=9001\n        - --namespace=default\n        - --argocd-repo-server=release-name-argocd-repo-server:8081\n        - --secret-name=argocd-notifications-secret\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        ports:\n        - name: metrics\n          containerPort: 9001\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        workingDir: /app\n        volumeMounts:\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: argocd-repo-server-tls\n          mountPath: /app/config/reposerver/tls\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-notifications-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "104",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-repo-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-repo-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: repo-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      containers:\n      - name: repo-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-repo-server\n        - --port=8081\n        - --metrics-port=8084\n        env:\n        - name: ARGOCD_REPO_SERVER_NAME\n          value: release-name-argocd-repo-server\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.format\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.level\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.parallelism.limit\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.metrics.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.ciphers\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.repo.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.default.cache.expiration\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.max.combined.directory.manifests.size\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.plugin.tar.exclusions\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_LAYER_MEDIA_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.layer.media.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n        - mountPath: /tmp\n          name: tmp\n        ports:\n        - name: repo-server\n          containerPort: 8081\n          protocol: TCP\n        - name: metrics\n          containerPort: 8084\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: copyutil\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: helm-working-dir\n        emptyDir: {}\n      - name: plugins\n        emptyDir: {}\n      - name: var-files\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "105",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-repo-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-repo-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: repo-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: release-name-argocd-repo-server\n      automountServiceAccountToken: true\n      containers:\n      - name: repo-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-repo-server\n        - --port=8081\n        - --metrics-port=8084\n        env:\n        - name: ARGOCD_REPO_SERVER_NAME\n          value: release-name-argocd-repo-server\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.format\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.level\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.parallelism.limit\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.metrics.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.ciphers\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.repo.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.default.cache.expiration\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.max.combined.directory.manifests.size\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.plugin.tar.exclusions\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_LAYER_MEDIA_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.layer.media.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n        - mountPath: /tmp\n          name: tmp\n        ports:\n        - name: repo-server\n          containerPort: 8081\n          protocol: TCP\n        - name: metrics\n          containerPort: 8084\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: copyutil\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: helm-working-dir\n        emptyDir: {}\n      - name: plugins\n        emptyDir: {}\n      - name: var-files\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "106",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-repo-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-repo-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: repo-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: release-name-argocd-repo-server\n      automountServiceAccountToken: true\n      containers:\n      - name: repo-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-repo-server\n        - --port=8081\n        - --metrics-port=8084\n        env:\n        - name: ARGOCD_REPO_SERVER_NAME\n          value: release-name-argocd-repo-server\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.format\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.level\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.parallelism.limit\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.metrics.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.ciphers\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.repo.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.default.cache.expiration\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.max.combined.directory.manifests.size\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.plugin.tar.exclusions\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_LAYER_MEDIA_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.layer.media.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n        - mountPath: /tmp\n          name: tmp\n        ports:\n        - name: repo-server\n          containerPort: 8081\n          protocol: TCP\n        - name: metrics\n          containerPort: 8084\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: copyutil\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: helm-working-dir\n        emptyDir: {}\n      - name: plugins\n        emptyDir: {}\n      - name: var-files\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "107",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-repo-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-repo-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: repo-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: release-name-argocd-repo-server\n      automountServiceAccountToken: true\n      containers:\n      - name: repo-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-repo-server\n        - --port=8081\n        - --metrics-port=8084\n        env:\n        - name: ARGOCD_REPO_SERVER_NAME\n          value: release-name-argocd-repo-server\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.format\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.level\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.parallelism.limit\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.metrics.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.ciphers\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.repo.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.default.cache.expiration\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.max.combined.directory.manifests.size\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.plugin.tar.exclusions\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_LAYER_MEDIA_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.layer.media.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n        - mountPath: /tmp\n          name: tmp\n        ports:\n        - name: repo-server\n          containerPort: 8081\n          protocol: TCP\n        - name: metrics\n          containerPort: 8084\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: copyutil\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: helm-working-dir\n        emptyDir: {}\n      - name: plugins\n        emptyDir: {}\n      - name: var-files\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "108",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-repo-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-repo-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: repo-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: release-name-argocd-repo-server\n      automountServiceAccountToken: true\n      containers:\n      - name: repo-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-repo-server\n        - --port=8081\n        - --metrics-port=8084\n        env:\n        - name: ARGOCD_REPO_SERVER_NAME\n          value: release-name-argocd-repo-server\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.format\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.level\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.parallelism.limit\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.metrics.listen.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.ciphers\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.repo.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.default.cache.expiration\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.max.combined.directory.manifests.size\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.plugin.tar.exclusions\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_OCI_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.oci.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OCI_LAYER_MEDIA_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.oci.layer.media.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n        - mountPath: /tmp\n          name: tmp\n        ports:\n        - name: repo-server\n          containerPort: 8081\n          protocol: TCP\n        - name: metrics\n          containerPort: 8084\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: copyutil\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: helm-working-dir\n        emptyDir: {}\n      - name: plugins\n        emptyDir: {}\n      - name: var-files\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "109",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      containers:\n      - name: server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-server\n        - --port=8080\n        - --metrics-port=8083\n        env:\n        - name: ARGOCD_SERVER_NAME\n          value: release-name-argocd-server\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.insecure\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.basehref\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.rootpath\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.log.format\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.log.level\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: repo.server\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.disable.auth\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.enable.gzip\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.x.frame.options\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.content.security.policy\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server.plaintext\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server.strict.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.ciphers\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.connection.status.cache.expiration\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.oidc.cache.expiration\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.staticassets\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.app.state.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.default.cache.expiration\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.http.cookie.maxnumber\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.listen.address\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.metrics.listen.address\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: application.namespaces\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.enable.proxy.extension\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.k8sclient.retry.max\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.k8sclient.retry.base.backoff\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.api.content.types\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.webhook.parallelism.limit\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.allowed.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_GITHUB_API_METRICS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.github.api.metrics\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: hydrator.enabled\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.sync.replace.allowed\n              optional: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /shared/app/custom\n          name: styles\n        - mountPath: /tmp\n          name: tmp\n        - name: argocd-cmd-params-cm\n          mountPath: /home/argocd/params\n        ports:\n        - name: server\n          containerPort: 8080\n          protocol: TCP\n        - name: metrics\n          containerPort: 8083\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: server\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: server\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: plugins-home\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: styles\n        configMap:\n          name: argocd-styles-cm\n          optional: true\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-dex-server-tls\n        secret:\n          secretName: argocd-dex-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-cmd-params-cm\n        configMap:\n          optional: true\n          name: argocd-cmd-params-cm\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "110",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-server\n      automountServiceAccountToken: true\n      containers:\n      - name: server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-server\n        - --port=8080\n        - --metrics-port=8083\n        env:\n        - name: ARGOCD_SERVER_NAME\n          value: release-name-argocd-server\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.insecure\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.basehref\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.rootpath\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.log.format\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.log.level\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: repo.server\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.disable.auth\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.enable.gzip\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.x.frame.options\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.content.security.policy\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server.plaintext\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server.strict.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.ciphers\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.connection.status.cache.expiration\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.oidc.cache.expiration\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.staticassets\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.app.state.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.default.cache.expiration\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.http.cookie.maxnumber\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.listen.address\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.metrics.listen.address\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: application.namespaces\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.enable.proxy.extension\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.k8sclient.retry.max\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.k8sclient.retry.base.backoff\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.api.content.types\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.webhook.parallelism.limit\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.allowed.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_GITHUB_API_METRICS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.github.api.metrics\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: hydrator.enabled\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.sync.replace.allowed\n              optional: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /shared/app/custom\n          name: styles\n        - mountPath: /tmp\n          name: tmp\n        - name: argocd-cmd-params-cm\n          mountPath: /home/argocd/params\n        ports:\n        - name: server\n          containerPort: 8080\n          protocol: TCP\n        - name: metrics\n          containerPort: 8083\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: server\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: server\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: plugins-home\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: styles\n        configMap:\n          name: argocd-styles-cm\n          optional: true\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-dex-server-tls\n        secret:\n          secretName: argocd-dex-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-cmd-params-cm\n        configMap:\n          optional: true\n          name: argocd-cmd-params-cm\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "111",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-server\n      automountServiceAccountToken: true\n      containers:\n      - name: server\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        args:\n        - /usr/local/bin/argocd-server\n        - --port=8080\n        - --metrics-port=8083\n        env:\n        - name: ARGOCD_SERVER_NAME\n          value: release-name-argocd-server\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.insecure\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.basehref\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.rootpath\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.log.format\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.log.level\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: repo.server\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.disable.auth\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.enable.gzip\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.x.frame.options\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.content.security.policy\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server.plaintext\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.dex.server.strict.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.tls.ciphers\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.connection.status.cache.expiration\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.oidc.cache.expiration\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.staticassets\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.app.state.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.default.cache.expiration\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.http.cookie.maxnumber\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.listen.address\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.metrics.listen.address\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: application.namespaces\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.enable.proxy.extension\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.k8sclient.retry.max\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.k8sclient.retry.base.backoff\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.api.content.types\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.webhook.parallelism.limit\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.allowed.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.scm.providers\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_GITHUB_API_METRICS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: applicationsetcontroller.enable.github.api.metrics\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: hydrator.enabled\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: server.sync.replace.allowed\n              optional: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /shared/app/custom\n          name: styles\n        - mountPath: /tmp\n          name: tmp\n        - name: argocd-cmd-params-cm\n          mountPath: /home/argocd/params\n        ports:\n        - name: server\n          containerPort: 8080\n          protocol: TCP\n        - name: metrics\n          containerPort: 8083\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: server\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: server\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: plugins-home\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: styles\n        configMap:\n          name: argocd-styles-cm\n          optional: true\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-dex-server-tls\n        secret:\n          secretName: argocd-dex-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-cmd-params-cm\n        configMap:\n          optional: true\n          name: argocd-cmd-params-cm\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "112",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-dex-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-dex-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: dex-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      containers:\n      - name: dex-server\n        image: ghcr.io/dexidp/dex:v2.44.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /shared/argocd-dex\n        args:\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: dexserver.disable.tls\n              optional: true\n        ports:\n        - name: http\n          containerPort: 5556\n          protocol: TCP\n        - name: grpc\n          containerPort: 5557\n          protocol: TCP\n        - name: metrics\n          containerPort: 5558\n          protocol: TCP\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - name: static-files\n          mountPath: /shared\n        - name: dexconfig\n          mountPath: /tmp\n        - name: argocd-dex-server-tls\n          mountPath: /tls\n      initContainers:\n      - name: copyutil\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-dex-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: static-files\n        emptyDir: {}\n      - name: dexconfig\n        emptyDir: {}\n      - name: argocd-dex-server-tls\n        secret:\n          secretName: argocd-dex-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "113",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-dex-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-dex-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: dex-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-dex-server\n      automountServiceAccountToken: true\n      containers:\n      - name: dex-server\n        image: ghcr.io/dexidp/dex:v2.44.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /shared/argocd-dex\n        args:\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: dexserver.disable.tls\n              optional: true\n        ports:\n        - name: http\n          containerPort: 5556\n          protocol: TCP\n        - name: grpc\n          containerPort: 5557\n          protocol: TCP\n        - name: metrics\n          containerPort: 5558\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - name: static-files\n          mountPath: /shared\n        - name: dexconfig\n          mountPath: /tmp\n        - name: argocd-dex-server-tls\n          mountPath: /tls\n      initContainers:\n      - name: copyutil\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-dex-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: static-files\n        emptyDir: {}\n      - name: dexconfig\n        emptyDir: {}\n      - name: argocd-dex-server-tls\n        secret:\n          secretName: argocd-dex-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "114",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-dex-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-dex-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: dex-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-dex-server\n      automountServiceAccountToken: true\n      containers:\n      - name: dex-server\n        image: ghcr.io/dexidp/dex:v2.44.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /shared/argocd-dex\n        args:\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: dexserver.disable.tls\n              optional: true\n        ports:\n        - name: http\n          containerPort: 5556\n          protocol: TCP\n        - name: grpc\n          containerPort: 5557\n          protocol: TCP\n        - name: metrics\n          containerPort: 5558\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - name: static-files\n          mountPath: /shared\n        - name: dexconfig\n          mountPath: /tmp\n        - name: argocd-dex-server-tls\n          mountPath: /tls\n      initContainers:\n      - name: copyutil\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-dex-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: static-files\n        emptyDir: {}\n      - name: dexconfig\n        emptyDir: {}\n      - name: argocd-dex-server-tls\n        secret:\n          secretName: argocd-dex-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "115",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-dex-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-dex-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: dex-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-dex-server\n      automountServiceAccountToken: true\n      containers:\n      - name: dex-server\n        image: ghcr.io/dexidp/dex:v2.44.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /shared/argocd-dex\n        args:\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: dexserver.disable.tls\n              optional: true\n        ports:\n        - name: http\n          containerPort: 5556\n          protocol: TCP\n        - name: grpc\n          containerPort: 5557\n          protocol: TCP\n        - name: metrics\n          containerPort: 5558\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - name: static-files\n          mountPath: /shared\n        - name: dexconfig\n          mountPath: /tmp\n        - name: argocd-dex-server-tls\n          mountPath: /tls\n      initContainers:\n      - name: copyutil\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-dex-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: static-files\n        emptyDir: {}\n      - name: dexconfig\n        emptyDir: {}\n      - name: argocd-dex-server-tls\n        secret:\n          secretName: argocd-dex-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "116",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-dex-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-dex-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: dex-server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-dex-server\n      automountServiceAccountToken: true\n      containers:\n      - name: dex-server\n        image: ghcr.io/dexidp/dex:v2.44.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /shared/argocd-dex\n        args:\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: dexserver.disable.tls\n              optional: true\n        ports:\n        - name: http\n          containerPort: 5556\n          protocol: TCP\n        - name: grpc\n          containerPort: 5557\n          protocol: TCP\n        - name: metrics\n          containerPort: 5558\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        volumeMounts:\n        - name: static-files\n          mountPath: /shared\n        - name: dexconfig\n          mountPath: /tmp\n        - name: argocd-dex-server-tls\n          mountPath: /tls\n      initContainers:\n      - name: copyutil\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-dex-server\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: static-files\n        emptyDir: {}\n      - name: dexconfig\n        emptyDir: {}\n      - name: argocd-dex-server-tls\n        secret:\n          secretName: argocd-dex-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "117",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-redis\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-redis\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-redis\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: redis\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 999\n        seccompProfile:\n          type: RuntimeDefault\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      containers:\n      - name: redis\n        image: ecr-public.aws.com/docker/library/redis:7.2.8-alpine\n        imagePullPolicy: IfNotPresent\n        args:\n        - --save\n        - ''\n        - --appendonly\n        - 'no'\n        - --requirepass $(REDIS_PASSWORD)\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        ports:\n        - name: redis\n          containerPort: 6379\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - mountPath: /health\n          name: health\n      nodeSelector:\n        kubernetes.io/os: linux\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-redis\n              topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: health\n        configMap:\n          name: release-name-argocd-redis-health-configmap\n          defaultMode: 493\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "118",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argocd-redis\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-redis\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-redis\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: redis\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 999\n        seccompProfile:\n          type: RuntimeDefault\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      containers:\n      - name: redis\n        image: ecr-public.aws.com/docker/library/redis:7.2.8-alpine\n        imagePullPolicy: IfNotPresent\n        args:\n        - --save\n        - ''\n        - --appendonly\n        - 'no'\n        - --requirepass $(REDIS_PASSWORD)\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        ports:\n        - name: redis\n          containerPort: 6379\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - mountPath: /health\n          name: health\n      nodeSelector:\n        kubernetes.io/os: linux\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-redis\n              topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: health\n        configMap:\n          name: release-name-argocd-redis-health-configmap\n          defaultMode: 493\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "119",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-argocd-application-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 5\n  serviceName: release-name-argocd-application-controller\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-application-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: application-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        - --metrics-port=8082\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: application-controller\n        env:\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_APPLICATION_CONTROLLER_NAME\n          value: release-name-argocd-application-controller\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.hard.reconciliation\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.error.grace.period.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: repo.server\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.status.processors\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.operation.processors\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.log.format\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.log.level\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.metrics.cache.expiration\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.factor\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.cap.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_COOLDOWN_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.cooldown.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.sync.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.resource.health.persist\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.app.state.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.default.cache.expiration\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: application.namespaces\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.sharding.algorithm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.kubectl.parallelism.limit\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.k8sclient.retry.max\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.k8sclient.retry.base.backoff\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.diff.server.side\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.ignore.normalizer.jq.timeout\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: hydrator.enabled\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.cluster.cache.batch.events.processing\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.cluster.cache.events.processing.interval\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_COMMIT_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: commit.server\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        ports:\n        - name: metrics\n          containerPort: 8082\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        workingDir: /home/argocd\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - name: argocd-cmd-params-cm\n          mountPath: /home/argocd/params\n        - name: argocd-application-controller-tmp\n          mountPath: /tmp\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: argocd-home\n        emptyDir: {}\n      - name: argocd-application-controller-tmp\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-cmd-params-cm\n        configMap:\n          optional: true\n          name: argocd-cmd-params-cm\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "120",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-argocd-application-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 5\n  serviceName: release-name-argocd-application-controller\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-application-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: application-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-application-controller\n      automountServiceAccountToken: true\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        - --metrics-port=8082\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: application-controller\n        env:\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_APPLICATION_CONTROLLER_NAME\n          value: release-name-argocd-application-controller\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.hard.reconciliation\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.error.grace.period.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: repo.server\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.status.processors\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.operation.processors\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.log.format\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.log.level\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.metrics.cache.expiration\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.factor\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.cap.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_COOLDOWN_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.cooldown.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.sync.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.resource.health.persist\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.app.state.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.default.cache.expiration\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: application.namespaces\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.sharding.algorithm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.kubectl.parallelism.limit\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.k8sclient.retry.max\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.k8sclient.retry.base.backoff\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.diff.server.side\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.ignore.normalizer.jq.timeout\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: hydrator.enabled\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.cluster.cache.batch.events.processing\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.cluster.cache.events.processing.interval\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_COMMIT_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: commit.server\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        ports:\n        - name: metrics\n          containerPort: 8082\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        workingDir: /home/argocd\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - name: argocd-cmd-params-cm\n          mountPath: /home/argocd/params\n        - name: argocd-application-controller-tmp\n          mountPath: /tmp\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: argocd-home\n        emptyDir: {}\n      - name: argocd-application-controller-tmp\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-cmd-params-cm\n        configMap:\n          optional: true\n          name: argocd-cmd-params-cm\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "121",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-argocd-application-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  replicas: 1\n  revisionHistoryLimit: 5\n  serviceName: release-name-argocd-application-controller\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        checksum/cmd-params: 2668ced57bd7b8a4198bc09a7505497f26b422d12a957a08b048317dda050991\n        checksum/cm: 96ecfb88b6c2d1b7b1b033e1c466cb5b41411e6d7280e8c87ae5a02343d5079a\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-application-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: application-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      terminationGracePeriodSeconds: 30\n      serviceAccountName: argocd-application-controller\n      automountServiceAccountToken: true\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        - --metrics-port=8082\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: application-controller\n        env:\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_APPLICATION_CONTROLLER_NAME\n          value: release-name-argocd-application-controller\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.hard.reconciliation\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.error.grace.period.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: repo.server\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.status.processors\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.operation.processors\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.log.format\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.log.level\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: log.format.timestamp\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.metrics.cache.expiration\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.factor\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.cap.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_COOLDOWN_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.self.heal.backoff.cooldown.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.sync.timeout.seconds\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.plaintext\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.repo.server.strict.tls\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.resource.health.persist\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.app.state.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.compression\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: REDIS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: redis-username\n              optional: true\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n              optional: false\n        - name: REDIS_SENTINEL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-username\n              optional: true\n        - name: REDIS_SENTINEL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-argocd-redis\n              key: redis-sentinel-password\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.default.cache.expiration\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.address\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.insecure\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.headers\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: otlp.attrs\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: application.namespaces\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.sharding.algorithm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.kubectl.parallelism.limit\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.k8sclient.retry.max\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.k8sclient.retry.base.backoff\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.diff.server.side\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.ignore.normalizer.jq.timeout\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: hydrator.enabled\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.cluster.cache.batch.events.processing\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: controller.cluster.cache.events.processing.interval\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_COMMIT_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: commit.server\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        ports:\n        - name: metrics\n          containerPort: 8082\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n        workingDir: /home/argocd\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - name: argocd-cmd-params-cm\n          mountPath: /home/argocd/params\n        - name: argocd-application-controller-tmp\n          mountPath: /tmp\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      volumes:\n      - name: argocd-home\n        emptyDir: {}\n      - name: argocd-application-controller-tmp\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      - name: argocd-cmd-params-cm\n        configMap:\n          optional: true\n          name: argocd-cmd-params-cm\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n      dnsPolicy: ClusterFirst\n",
    "errors": []
  },
  {
    "id": "122",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-argocd-redis-secret-init\n  namespace: default\n  annotations:\n    helm.sh/hook: pre-install,pre-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-redis-secret-init\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: redis-secret-init\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  ttlSecondsAfterFinished: 60\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-redis-secret-init\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: redis-secret-init\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      containers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      restartPolicy: OnFailure\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-redis-secret-init\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: default\n",
    "errors": []
  },
  {
    "id": "123",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-argocd-redis-secret-init\n  namespace: default\n  annotations:\n    helm.sh/hook: pre-install,pre-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-redis-secret-init\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: redis-secret-init\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  ttlSecondsAfterFinished: 60\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-redis-secret-init\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: redis-secret-init\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      containers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      restartPolicy: OnFailure\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-redis-secret-init\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: release-name-argocd-redis-secret-init\n",
    "errors": []
  },
  {
    "id": "124",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-argocd-redis-secret-init\n  namespace: default\n  annotations:\n    helm.sh/hook: pre-install,pre-upgrade\n    helm.sh/hook-delete-policy: before-hook-creation\n  labels:\n    helm.sh/chart: argo-cd-8.5.9\n    app.kubernetes.io/name: argocd-redis-secret-init\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: redis-secret-init\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/version: v3.1.8\nspec:\n  ttlSecondsAfterFinished: 60\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-cd-8.5.9\n        app.kubernetes.io/name: argocd-redis-secret-init\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: redis-secret-init\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argocd\n        app.kubernetes.io/version: v3.1.8\n    spec:\n      containers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:v3.1.8\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: false\n      restartPolicy: OnFailure\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-redis-secret-init\n              topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: release-name-argocd-redis-secret-init\n",
    "errors": []
  },
  {
    "id": "125",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-argo-workflows-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-workflows-0.45.26\n    app.kubernetes.io/name: argo-workflows-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argo-workflows\n    app.kubernetes.io/version: v3.7.2\nspec:\n  sessionAffinity: None\n  type: ExternalName\n  externalName: release-name-argo-workflows-server.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "126",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argo-workflows-workflow-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-workflows-0.45.26\n    app.kubernetes.io/name: argo-workflows-workflow-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: workflow-controller\n    app: workflow-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argo-workflows\n    app.kubernetes.io/version: v3.7.2\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argo-workflows-workflow-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-workflows-0.45.26\n        app.kubernetes.io/name: argo-workflows-workflow-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: workflow-controller\n        app: workflow-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argo-workflows\n        app.kubernetes.io/version: v3.7.2\n    spec:\n      serviceAccountName: default\n      containers:\n      - name: controller\n        image: quay.io/argoproj/workflow-controller:v3.7.2\n        imagePullPolicy: Always\n        command:\n        - workflow-controller\n        args:\n        - --configmap\n        - release-name-argo-workflows-workflow-controller-configmap\n        - --executor-image\n        - quay.io/argoproj/argoexec:v3.7.2\n        - --loglevel\n        - info\n        - --gloglevel\n        - '0'\n        - --log-format\n        - text\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        env:\n        - name: ARGO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: LEADER_ELECTION_IDENTITY\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.name\n        - name: LEADER_ELECTION_DISABLE\n          value: 'true'\n        resources: {}\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - containerPort: 6060\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 6060\n          initialDelaySeconds: 90\n          periodSeconds: 60\n          timeoutSeconds: 30\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "127",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argo-workflows-workflow-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-workflows-0.45.26\n    app.kubernetes.io/name: argo-workflows-workflow-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: workflow-controller\n    app: workflow-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argo-workflows\n    app.kubernetes.io/version: v3.7.2\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argo-workflows-workflow-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-workflows-0.45.26\n        app.kubernetes.io/name: argo-workflows-workflow-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: workflow-controller\n        app: workflow-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argo-workflows\n        app.kubernetes.io/version: v3.7.2\n    spec:\n      serviceAccountName: release-name-argo-workflows-workflow-controller\n      containers:\n      - name: controller\n        image: quay.io/argoproj/workflow-controller:v3.7.2\n        imagePullPolicy: Always\n        command:\n        - workflow-controller\n        args:\n        - --configmap\n        - release-name-argo-workflows-workflow-controller-configmap\n        - --executor-image\n        - quay.io/argoproj/argoexec:v3.7.2\n        - --loglevel\n        - info\n        - --gloglevel\n        - '0'\n        - --log-format\n        - text\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          privileged: false\n        env:\n        - name: ARGO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: LEADER_ELECTION_IDENTITY\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.name\n        - name: LEADER_ELECTION_DISABLE\n          value: 'true'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - containerPort: 6060\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 6060\n          initialDelaySeconds: 90\n          periodSeconds: 60\n          timeoutSeconds: 30\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "128",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argo-workflows-workflow-controller\n  namespace: default\n  labels:\n    helm.sh/chart: argo-workflows-0.45.26\n    app.kubernetes.io/name: argo-workflows-workflow-controller\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: workflow-controller\n    app: workflow-controller\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argo-workflows\n    app.kubernetes.io/version: v3.7.2\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argo-workflows-workflow-controller\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-workflows-0.45.26\n        app.kubernetes.io/name: argo-workflows-workflow-controller\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: workflow-controller\n        app: workflow-controller\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argo-workflows\n        app.kubernetes.io/version: v3.7.2\n    spec:\n      serviceAccountName: release-name-argo-workflows-workflow-controller\n      containers:\n      - name: controller\n        image: quay.io/argoproj/workflow-controller:v3.7.2\n        imagePullPolicy: Always\n        command:\n        - workflow-controller\n        args:\n        - --configmap\n        - release-name-argo-workflows-workflow-controller-configmap\n        - --executor-image\n        - quay.io/argoproj/argoexec:v3.7.2\n        - --loglevel\n        - info\n        - --gloglevel\n        - '0'\n        - --log-format\n        - text\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          privileged: false\n        env:\n        - name: ARGO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: LEADER_ELECTION_IDENTITY\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.name\n        - name: LEADER_ELECTION_DISABLE\n          value: 'true'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - containerPort: 6060\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 6060\n          initialDelaySeconds: 90\n          periodSeconds: 60\n          timeoutSeconds: 30\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "129",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argo-workflows-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-workflows-0.45.26\n    app.kubernetes.io/name: argo-workflows-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argo-workflows\n    app.kubernetes.io/version: v3.7.2\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argo-workflows-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-workflows-0.45.26\n        app.kubernetes.io/name: argo-workflows-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: server\n        app: server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argo-workflows\n        app.kubernetes.io/version: v3.7.2\n      annotations:\n        checksum/cm: bfd06978cb1b4ebca21cb5b49988153e6e6824da4db346a3a9b3ed6b802bb083\n    spec:\n      serviceAccountName: release-name-argo-workflows-server\n      containers:\n      - name: argo-server\n        image: quay.io/argoproj/argocli:v3.7.2\n        imagePullPolicy: Always\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          privileged: false\n        args:\n        - server\n        - --configmap=release-name-argo-workflows-workflow-controller-configmap\n        - --secure=false\n        - --loglevel\n        - info\n        - --gloglevel\n        - '0'\n        - --log-format\n        - text\n        ports:\n        - name: web\n          containerPort: 2746\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 2746\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 20\n        env:\n        - name: IN_CLUSTER\n          value: 'true'\n        - name: ARGO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: ARGO_BASE_HREF\n          value: /\n        resources: {}\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "130",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argo-workflows-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-workflows-0.45.26\n    app.kubernetes.io/name: argo-workflows-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argo-workflows\n    app.kubernetes.io/version: v3.7.2\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argo-workflows-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-workflows-0.45.26\n        app.kubernetes.io/name: argo-workflows-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: server\n        app: server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argo-workflows\n        app.kubernetes.io/version: v3.7.2\n      annotations:\n        checksum/cm: bfd06978cb1b4ebca21cb5b49988153e6e6824da4db346a3a9b3ed6b802bb083\n    spec:\n      serviceAccountName: default\n      containers:\n      - name: argo-server\n        image: quay.io/argoproj/argocli:v3.7.2\n        imagePullPolicy: Always\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: false\n          runAsNonRoot: true\n        args:\n        - server\n        - --configmap=release-name-argo-workflows-workflow-controller-configmap\n        - --secure=false\n        - --loglevel\n        - info\n        - --gloglevel\n        - '0'\n        - --log-format\n        - text\n        ports:\n        - name: web\n          containerPort: 2746\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 2746\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 20\n        env:\n        - name: IN_CLUSTER\n          value: 'true'\n        - name: ARGO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: ARGO_BASE_HREF\n          value: /\n        resources: {}\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "131",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argo-workflows-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-workflows-0.45.26\n    app.kubernetes.io/name: argo-workflows-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argo-workflows\n    app.kubernetes.io/version: v3.7.2\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argo-workflows-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-workflows-0.45.26\n        app.kubernetes.io/name: argo-workflows-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: server\n        app: server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argo-workflows\n        app.kubernetes.io/version: v3.7.2\n      annotations:\n        checksum/cm: bfd06978cb1b4ebca21cb5b49988153e6e6824da4db346a3a9b3ed6b802bb083\n    spec:\n      serviceAccountName: release-name-argo-workflows-server\n      containers:\n      - name: argo-server\n        image: quay.io/argoproj/argocli:v3.7.2\n        imagePullPolicy: Always\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: false\n          runAsNonRoot: true\n          privileged: false\n        args:\n        - server\n        - --configmap=release-name-argo-workflows-workflow-controller-configmap\n        - --secure=false\n        - --loglevel\n        - info\n        - --gloglevel\n        - '0'\n        - --log-format\n        - text\n        ports:\n        - name: web\n          containerPort: 2746\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 2746\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 20\n        env:\n        - name: IN_CLUSTER\n          value: 'true'\n        - name: ARGO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: ARGO_BASE_HREF\n          value: /\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "132",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-argo-workflows-server\n  namespace: default\n  labels:\n    helm.sh/chart: argo-workflows-0.45.26\n    app.kubernetes.io/name: argo-workflows-server\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: server\n    app: server\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: argo-workflows\n    app.kubernetes.io/version: v3.7.2\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argo-workflows-server\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: argo-workflows-0.45.26\n        app.kubernetes.io/name: argo-workflows-server\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: server\n        app: server\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: argo-workflows\n        app.kubernetes.io/version: v3.7.2\n      annotations:\n        checksum/cm: bfd06978cb1b4ebca21cb5b49988153e6e6824da4db346a3a9b3ed6b802bb083\n    spec:\n      serviceAccountName: release-name-argo-workflows-server\n      containers:\n      - name: argo-server\n        image: quay.io/argoproj/argocli:v3.7.2\n        imagePullPolicy: Always\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: false\n          runAsNonRoot: true\n          privileged: false\n        args:\n        - server\n        - --configmap=release-name-argo-workflows-workflow-controller-configmap\n        - --secure=false\n        - --loglevel\n        - info\n        - --gloglevel\n        - '0'\n        - --log-format\n        - text\n        ports:\n        - name: web\n          containerPort: 2746\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 2746\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 20\n        env:\n        - name: IN_CLUSTER\n          value: 'true'\n        - name: ARGO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: ARGO_BASE_HREF\n          value: /\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "133",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-postgresql-headless\n  labels:\n    app: postgresql\n    chart: postgresql-8.2.1\n    release: release-name\n    heritage: Helm\nspec:\n  type: ExternalName\n  externalName: release-name-postgresql-headless.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "134",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-postgresql\n  labels:\n    app: postgresql\n    chart: postgresql-8.2.1\n    release: release-name\n    heritage: Helm\nspec:\n  type: ExternalName\n  externalName: release-name-postgresql.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "135",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  type: ExternalName\n  externalName: hub.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "136",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: trivy\n  labels:\n    app.kubernetes.io/component: trivy\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  type: ExternalName\n  externalName: trivy.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "137",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "138",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "139",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "140",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "141",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: default\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "142",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "143",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "144",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "145",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "146",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "147",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "148",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "149",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "150",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hub\n  labels:\n    app.kubernetes.io/component: hub\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: hub\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        prometheus.io/port: '8001'\n      labels:\n        app.kubernetes.io/component: hub\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      serviceAccountName: hub\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      - name: check-db-migrator-run\n        image: bitnami/kubectl:1.34\n        imagePullPolicy: IfNotPresent\n        command:\n        - kubectl\n        - wait\n        - --namespace=default\n        - --for=condition=complete\n        - job/db-migrator-install\n        - --timeout=60s\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: hub\n        image: artifacthub/hub:v1.21.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: hub-config\n          mountPath: /home/hub/.cfg\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: hub-config\n        secret:\n          secretName: hub-config\n",
    "errors": []
  },
  {
    "id": "151",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: trivy\n  labels:\n    app.kubernetes.io/component: trivy\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: trivy\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: trivy\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      containers:\n      - name: trivy\n        image: aquasec/trivy:0.56.1\n        command:\n        - trivy\n        - --debug\n        - --cache-dir\n        - /trivy\n        - server\n        - --listen\n        - 0.0.0.0:8081\n        volumeMounts:\n        - name: trivy\n          mountPath: /trivy\n        ports:\n        - name: http\n          containerPort: 8081\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      volumes:\n      - name: trivy\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "152",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: trivy\n  labels:\n    app.kubernetes.io/component: trivy\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: trivy\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: trivy\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      containers:\n      - name: trivy\n        image: aquasec/trivy:0.56.1\n        command:\n        - trivy\n        - --debug\n        - --cache-dir\n        - /trivy\n        - server\n        - --listen\n        - 0.0.0.0:8081\n        volumeMounts:\n        - name: trivy\n          mountPath: /trivy\n        ports:\n        - name: http\n          containerPort: 8081\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      volumes:\n      - name: trivy\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "153",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: trivy\n  labels:\n    app.kubernetes.io/component: trivy\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: trivy\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: trivy\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      containers:\n      - name: trivy\n        image: aquasec/trivy:0.56.1\n        command:\n        - trivy\n        - --debug\n        - --cache-dir\n        - /trivy\n        - server\n        - --listen\n        - 0.0.0.0:8081\n        volumeMounts:\n        - name: trivy\n          mountPath: /trivy\n        ports:\n        - name: http\n          containerPort: 8081\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: trivy\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "154",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: trivy\n  labels:\n    app.kubernetes.io/component: trivy\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: trivy\n      app.kubernetes.io/name: artifact-hub\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: trivy\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n    spec:\n      containers:\n      - name: trivy\n        image: aquasec/trivy:0.56.1\n        command:\n        - trivy\n        - --debug\n        - --cache-dir\n        - /trivy\n        - server\n        - --listen\n        - 0.0.0.0:8081\n        volumeMounts:\n        - name: trivy\n          mountPath: /trivy\n        ports:\n        - name: http\n          containerPort: 8081\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: trivy\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "155",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  labels:\n    app: postgresql\n    chart: postgresql-8.2.1\n    release: release-name\n    heritage: Helm\nspec:\n  serviceName: release-name-postgresql-headless\n  replicas: 1\n  updateStrategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: postgresql\n      release: release-name\n      role: master\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app: postgresql\n        chart: postgresql-8.2.1\n        release: release-name\n        heritage: Helm\n        role: master\n    spec:\n      securityContext:\n        fsGroup: 1001\n      initContainers:\n      - name: init-chmod-data\n        image: docker.io/bitnami/minideb:stretch\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"mkdir -p /data/data\\nchmod 700 /data/data\\nfind /data -mindepth 0 -maxdepth\\\n          \\ 1 -not -name \\\".snapshot\\\" -not -name \\\"lost+found\\\" | \\\\\\n  xargs chown\\\n          \\ -R 1001:1001\\nchmod -R 777 /dev/shm\\n\"\n        securityContext:\n          runAsUser: 0\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: null\n        - name: dshm\n          mountPath: /dev/shm\n      containers:\n      - name: release-name-postgresql\n        image: docker.io/artifacthub/postgres:stable\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        securityContext:\n          runAsUser: 1001\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /data\n        - name: PGDATA\n          value: /data/pgdata\n        - name: POSTGRES_USER\n          value: postgres\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-postgresql\n              key: postgresql-password\n        - name: POSTGRES_DB\n          value: hub\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n\n              '\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /data\n          subPath: null\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Gi\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "156",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  labels:\n    app: postgresql\n    chart: postgresql-8.2.1\n    release: release-name\n    heritage: Helm\nspec:\n  serviceName: release-name-postgresql-headless\n  replicas: 1\n  updateStrategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: postgresql\n      release: release-name\n      role: master\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app: postgresql\n        chart: postgresql-8.2.1\n        release: release-name\n        heritage: Helm\n        role: master\n    spec:\n      securityContext:\n        fsGroup: 1001\n      initContainers:\n      - name: init-chmod-data\n        image: docker.io/bitnami/minideb:stretch\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"mkdir -p /data/data\\nchmod 700 /data/data\\nfind /data -mindepth 0 -maxdepth\\\n          \\ 1 -not -name \\\".snapshot\\\" -not -name \\\"lost+found\\\" | \\\\\\n  xargs chown\\\n          \\ -R 1001:1001\\nchmod -R 777 /dev/shm\\n\"\n        securityContext:\n          runAsUser: 0\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: null\n        - name: dshm\n          mountPath: /dev/shm\n      containers:\n      - name: release-name-postgresql\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        securityContext:\n          runAsUser: 1001\n          readOnlyRootFilesystem: true\n          privileged: false\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /data\n        - name: PGDATA\n          value: /data/pgdata\n        - name: POSTGRES_USER\n          value: postgres\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-postgresql\n              key: postgresql-password\n        - name: POSTGRES_DB\n          value: hub\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n\n              '\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /data\n          subPath: null\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Gi\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "157",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  labels:\n    app: postgresql\n    chart: postgresql-8.2.1\n    release: release-name\n    heritage: Helm\nspec:\n  serviceName: release-name-postgresql-headless\n  replicas: 1\n  updateStrategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: postgresql\n      release: release-name\n      role: master\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app: postgresql\n        chart: postgresql-8.2.1\n        release: release-name\n        heritage: Helm\n        role: master\n    spec:\n      securityContext:\n        fsGroup: 1001\n      initContainers:\n      - name: init-chmod-data\n        image: docker.io/bitnami/minideb:stretch\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"mkdir -p /data/data\\nchmod 700 /data/data\\nfind /data -mindepth 0 -maxdepth\\\n          \\ 1 -not -name \\\".snapshot\\\" -not -name \\\"lost+found\\\" | \\\\\\n  xargs chown\\\n          \\ -R 1001:1001\\nchmod -R 777 /dev/shm\\n\"\n        securityContext:\n          runAsUser: 0\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: null\n        - name: dshm\n          mountPath: /dev/shm\n      containers:\n      - name: release-name-postgresql\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        securityContext:\n          runAsUser: 1001\n          readOnlyRootFilesystem: true\n          privileged: false\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /data\n        - name: PGDATA\n          value: /data/pgdata\n        - name: POSTGRES_USER\n          value: postgres\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-postgresql\n              key: postgresql-password\n        - name: POSTGRES_DB\n          value: hub\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n\n              '\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /data\n          subPath: null\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Gi\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "158",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  labels:\n    app: postgresql\n    chart: postgresql-8.2.1\n    release: release-name\n    heritage: Helm\nspec:\n  serviceName: release-name-postgresql-headless\n  replicas: 1\n  updateStrategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: postgresql\n      release: release-name\n      role: master\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app: postgresql\n        chart: postgresql-8.2.1\n        release: release-name\n        heritage: Helm\n        role: master\n    spec:\n      securityContext:\n        fsGroup: 1001\n      initContainers:\n      - name: init-chmod-data\n        image: docker.io/bitnami/minideb:stretch\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"mkdir -p /data/data\\nchmod 700 /data/data\\nfind /data -mindepth 0 -maxdepth\\\n          \\ 1 -not -name \\\".snapshot\\\" -not -name \\\"lost+found\\\" | \\\\\\n  xargs chown\\\n          \\ -R 1001:1001\\nchmod -R 777 /dev/shm\\n\"\n        securityContext:\n          runAsUser: 0\n          runAsNonRoot: true\n          privileged: false\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: null\n        - name: dshm\n          mountPath: /dev/shm\n      containers:\n      - name: release-name-postgresql\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n        securityContext:\n          runAsUser: 1001\n          runAsNonRoot: true\n          privileged: false\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /data\n        - name: PGDATA\n          value: /data/pgdata\n        - name: POSTGRES_USER\n          value: postgres\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-postgresql\n              key: postgresql-password\n        - name: POSTGRES_DB\n          value: hub\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n\n              '\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /data\n          subPath: null\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Gi\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "159",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  labels:\n    app: postgresql\n    chart: postgresql-8.2.1\n    release: release-name\n    heritage: Helm\nspec:\n  serviceName: release-name-postgresql-headless\n  replicas: 1\n  updateStrategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: postgresql\n      release: release-name\n      role: master\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app: postgresql\n        chart: postgresql-8.2.1\n        release: release-name\n        heritage: Helm\n        role: master\n    spec:\n      securityContext:\n        fsGroup: 1001\n      initContainers:\n      - name: init-chmod-data\n        image: docker.io/bitnami/minideb:stretch\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"mkdir -p /data/data\\nchmod 700 /data/data\\nfind /data -mindepth 0 -maxdepth\\\n          \\ 1 -not -name \\\".snapshot\\\" -not -name \\\"lost+found\\\" | \\\\\\n  xargs chown\\\n          \\ -R 1001:1001\\nchmod -R 777 /dev/shm\\n\"\n        securityContext:\n          runAsUser: 0\n          privileged: false\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: null\n        - name: dshm\n          mountPath: /dev/shm\n      containers:\n      - name: release-name-postgresql\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsUser: 1001\n          privileged: false\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /data\n        - name: PGDATA\n          value: /data/pgdata\n        - name: POSTGRES_USER\n          value: postgres\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-postgresql\n              key: postgresql-password\n        - name: POSTGRES_DB\n          value: hub\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n\n              '\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /data\n          subPath: null\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Gi\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "160",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  labels:\n    app: postgresql\n    chart: postgresql-8.2.1\n    release: release-name\n    heritage: Helm\nspec:\n  serviceName: release-name-postgresql-headless\n  replicas: 1\n  updateStrategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app: postgresql\n      release: release-name\n      role: master\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app: postgresql\n        chart: postgresql-8.2.1\n        release: release-name\n        heritage: Helm\n        role: master\n    spec:\n      securityContext:\n        fsGroup: 1001\n      initContainers:\n      - name: init-chmod-data\n        image: docker.io/bitnami/minideb:stretch\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"mkdir -p /data/data\\nchmod 700 /data/data\\nfind /data -mindepth 0 -maxdepth\\\n          \\ 1 -not -name \\\".snapshot\\\" -not -name \\\"lost+found\\\" | \\\\\\n  xargs chown\\\n          \\ -R 1001:1001\\nchmod -R 777 /dev/shm\\n\"\n        securityContext:\n          runAsUser: 0\n          privileged: false\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: null\n        - name: dshm\n          mountPath: /dev/shm\n      containers:\n      - name: release-name-postgresql\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 250m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsUser: 1001\n          privileged: false\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /data\n        - name: PGDATA\n          value: /data/pgdata\n        - name: POSTGRES_USER\n          value: postgres\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: release-name-postgresql\n              key: postgresql-password\n        - name: POSTGRES_DB\n          value: hub\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -d \"hub\" -h 127.0.0.1 -p 5432\n\n              '\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /data\n          subPath: null\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Gi\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "161",
    "policy_id": "job_ttl_after_finished",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: 3600\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "162",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "163",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "164",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "165",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "166",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "167",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "168",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "169",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "170",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrator-install\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  ttlSecondsAfterFinished: null\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: artifact-hub-1.21.0\n        app.kubernetes.io/name: artifact-hub\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/version: 1.21.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      restartPolicy: Never\n      initContainers:\n      - name: check-db-ready\n        image: docker.io/artifacthub/postgres:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: PGHOST\n          value: release-name-postgresql.default\n        - name: PGPORT\n          value: '5432'\n        - name: PGUSER\n          value: postgres\n        command:\n        - sh\n        - -c\n        - until pg_isready; do echo waiting for database; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      containers:\n      - name: db-migrator\n        image: artifacthub/db-migrator:v1.21.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: TERN_CONF\n          value: /home/db-migrator/.cfg/tern.conf\n        volumeMounts:\n        - name: db-migrator-config\n          mountPath: /home/db-migrator/.cfg\n          readOnly: true\n        command:\n        - ./migrate.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n      volumes:\n      - name: db-migrator-config\n        secret:\n          secretName: db-migrator-config\n",
    "errors": []
  },
  {
    "id": "171",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:stable\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "172",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "173",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "174",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "175",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "176",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "177",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "178",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "179",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: scanner\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 15,45 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          containers:\n          - name: scanner\n            image: artifacthub/scanner:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: scanner-config\n              mountPath: /home/scanner/.cfg\n              readOnly: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          volumes:\n          - name: scanner-config\n            secret:\n              secretName: scanner-config\n",
    "errors": []
  },
  {
    "id": "180",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:stable\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "181",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "182",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "183",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "184",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "185",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "186",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "187",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "188",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tracker\n  labels:\n    helm.sh/chart: artifact-hub-1.21.0\n    app.kubernetes.io/name: artifact-hub\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 1.21.0\n    app.kubernetes.io/managed-by: Helm\nspec:\n  schedule: 1,30 * * * *\n  successfulJobsHistoryLimit: 1\n  failedJobsHistoryLimit: 1\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          labels:\n            helm.sh/chart: artifact-hub-1.21.0\n            app.kubernetes.io/name: artifact-hub\n            app.kubernetes.io/instance: release-name\n            app.kubernetes.io/version: 1.21.0\n            app.kubernetes.io/managed-by: Helm\n        spec:\n          serviceAccountName: default\n          restartPolicy: Never\n          initContainers:\n          - name: check-db-ready\n            image: docker.io/artifacthub/postgres:latest\n            imagePullPolicy: IfNotPresent\n            env:\n            - name: PGHOST\n              value: release-name-postgresql.default\n            - name: PGPORT\n              value: '5432'\n            - name: PGUSER\n              value: postgres\n            command:\n            - sh\n            - -c\n            - until pg_isready; do echo waiting for database; sleep 2; done;\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          containers:\n          - name: tracker\n            image: artifacthub/tracker:v1.21.0\n            imagePullPolicy: IfNotPresent\n            volumeMounts:\n            - name: tracker-config\n              mountPath: /home/tracker/.cfg\n              readOnly: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n          volumes:\n          - name: tracker-config\n            secret:\n              secretName: tracker-config\n",
    "errors": []
  },
  {
    "id": "189",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-sealed-secrets\n  namespace: default\n  labels:\n    app.kubernetes.io/name: sealed-secrets\n    helm.sh/chart: sealed-secrets-2.17.7\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/version: 0.32.2\n    app.kubernetes.io/part-of: sealed-secrets\nspec:\n  type: ExternalName\n  externalName: release-name-sealed-secrets.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "190",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-sealed-secrets-metrics\n  namespace: default\n  labels:\n    app.kubernetes.io/name: sealed-secrets\n    helm.sh/chart: sealed-secrets-2.17.7\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/version: 0.32.2\n    app.kubernetes.io/part-of: sealed-secrets\n    app.kubernetes.io/component: metrics\nspec:\n  type: ExternalName\n  externalName: release-name-sealed-secrets-metrics.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "191",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-sealed-secrets\n  namespace: default\n  labels:\n    app.kubernetes.io/name: sealed-secrets\n    helm.sh/chart: sealed-secrets-2.17.7\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/version: 0.32.2\n    app.kubernetes.io/part-of: sealed-secrets\n  annotations: null\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sealed-secrets\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sealed-secrets\n        app.kubernetes.io/instance: release-name\n    spec:\n      securityContext:\n        fsGroup: 65534\n      serviceAccountName: default\n      containers:\n      - name: controller\n        command:\n        - controller\n        args:\n        - --update-status\n        - --key-prefix\n        - sealed-secrets-key\n        - --listen-addr\n        - :8080\n        - --listen-metrics-addr\n        - :8081\n        image: docker.io/bitnami/sealed-secrets-controller:0.32.2\n        imagePullPolicy: IfNotPresent\n        env: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 8081\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          httpGet:\n            path: /healthz\n            port: http\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          httpGet:\n            path: /healthz\n            port: http\n        resources:\n          limits: {}\n          requests: {}\n        securityContext:\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 1001\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "192",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-sealed-secrets\n  namespace: default\n  labels:\n    app.kubernetes.io/name: sealed-secrets\n    helm.sh/chart: sealed-secrets-2.17.7\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/version: 0.32.2\n    app.kubernetes.io/part-of: sealed-secrets\n  annotations: null\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sealed-secrets\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sealed-secrets\n        app.kubernetes.io/instance: release-name\n    spec:\n      securityContext:\n        fsGroup: 65534\n      serviceAccountName: release-name-sealed-secrets\n      containers:\n      - name: controller\n        command:\n        - controller\n        args:\n        - --update-status\n        - --key-prefix\n        - sealed-secrets-key\n        - --listen-addr\n        - :8080\n        - --listen-metrics-addr\n        - :8081\n        image: docker.io/bitnami/sealed-secrets-controller:0.32.2\n        imagePullPolicy: IfNotPresent\n        env: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 8081\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          httpGet:\n            path: /healthz\n            port: http\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          httpGet:\n            path: /healthz\n            port: http\n        resources:\n          limits:\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 1001\n          privileged: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "193",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-sealed-secrets\n  namespace: default\n  labels:\n    app.kubernetes.io/name: sealed-secrets\n    helm.sh/chart: sealed-secrets-2.17.7\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/version: 0.32.2\n    app.kubernetes.io/part-of: sealed-secrets\n  annotations: null\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sealed-secrets\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sealed-secrets\n        app.kubernetes.io/instance: release-name\n    spec:\n      securityContext:\n        fsGroup: 65534\n      serviceAccountName: release-name-sealed-secrets\n      containers:\n      - name: controller\n        command:\n        - controller\n        args:\n        - --update-status\n        - --key-prefix\n        - sealed-secrets-key\n        - --listen-addr\n        - :8080\n        - --listen-metrics-addr\n        - :8081\n        image: docker.io/bitnami/sealed-secrets-controller:0.32.2\n        imagePullPolicy: IfNotPresent\n        env: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 8081\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          httpGet:\n            path: /healthz\n            port: http\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          httpGet:\n            path: /healthz\n            port: http\n        resources:\n          limits:\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 1001\n          privileged: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "194",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-external-dns\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: external-dns\n    app.kubernetes.io/version: 0.18.0\n    helm.sh/chart: external-dns-9.0.3\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: external-dns\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "195",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-external-dns\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: external-dns\n    app.kubernetes.io/version: 0.18.0\n    helm.sh/chart: external-dns-9.0.3\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-external-dns.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "196",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-external-dns\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: external-dns\n    app.kubernetes.io/version: 0.18.0\n    helm.sh/chart: external-dns-9.0.3\nspec:\n  revisionHistoryLimit: 10\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: external-dns\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: external-dns\n        app.kubernetes.io/version: 0.18.0\n        helm.sh/chart: external-dns-9.0.3\n    spec:\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: external-dns\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      automountServiceAccountToken: true\n      serviceAccountName: default\n      containers:\n      - name: external-dns\n        image: docker.io/bitnami/external-dns:0.18.0-debian-12-r4\n        imagePullPolicy: IfNotPresent\n        args:\n        - --metrics-address=:7979\n        - --log-level=info\n        - --log-format=text\n        - --policy=upsert-only\n        - --provider=aws\n        - --registry=txt\n        - --interval=1m\n        - --source=service\n        - --source=ingress\n        - --aws-api-retries=3\n        - --aws-zone-type=\n        - --aws-batch-change-size=1000\n        env:\n        - name: AWS_DEFAULT_REGION\n          value: us-east-1\n        envFrom: null\n        ports:\n        - name: http\n          containerPort: 7979\n        livenessProbe:\n          tcpSocket:\n            port: http\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 2\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 6\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "197",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-kafka-broker\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: kafka\n    app.kubernetes.io/version: 4.0.0\n    helm.sh/chart: kafka-32.4.3\n    app.kubernetes.io/component: broker\n    app.kubernetes.io/part-of: kafka\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: kafka\n      app.kubernetes.io/component: broker\n      app.kubernetes.io/part-of: kafka\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "198",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-kafka-controller\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: kafka\n    app.kubernetes.io/version: 4.0.0\n    helm.sh/chart: kafka-32.4.3\n    app.kubernetes.io/component: controller-eligible\n    app.kubernetes.io/part-of: kafka\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: kafka\n      app.kubernetes.io/component: controller-eligible\n      app.kubernetes.io/part-of: kafka\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "199",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-kafka-controller-headless\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: kafka\n    app.kubernetes.io/version: 4.0.0\n    helm.sh/chart: kafka-32.4.3\n    app.kubernetes.io/component: controller-eligible\n    app.kubernetes.io/part-of: kafka\nspec:\n  type: ExternalName\n  publishNotReadyAddresses: true\n  externalName: release-name-kafka-controller-headless.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "200",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-kafka\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: kafka\n    app.kubernetes.io/version: 4.0.0\n    helm.sh/chart: kafka-32.4.3\n    app.kubernetes.io/component: kafka\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-kafka.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "201",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-kafka-controller\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: kafka\n    app.kubernetes.io/version: 4.0.0\n    helm.sh/chart: kafka-32.4.3\n    app.kubernetes.io/component: controller-eligible\n    app.kubernetes.io/part-of: kafka\nspec:\n  podManagementPolicy: Parallel\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: kafka\n      app.kubernetes.io/component: controller-eligible\n      app.kubernetes.io/part-of: kafka\n  serviceName: release-name-kafka-controller-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: kafka\n        app.kubernetes.io/version: 4.0.0\n        helm.sh/chart: kafka-32.4.3\n        app.kubernetes.io/component: controller-eligible\n        app.kubernetes.io/part-of: kafka\n      annotations:\n        checksum/configuration: d96601aff02b0e88a9bc5c8593a6d0446462e05650b1eb84af185e551160d1c8\n        checksum/secret: dba2cdb043e84e63d768aad3292379237050a24915b1b3e70c1f2408e8cd76e8\n    spec:\n      automountServiceAccountToken: false\n      hostNetwork: false\n      hostIPC: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: kafka\n                  app.kubernetes.io/component: controller-eligible\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        seccompProfile:\n          type: RuntimeDefault\n        supplementalGroups: []\n        sysctls: []\n      serviceAccountName: default\n      enableServiceLinks: true\n      initContainers:\n      - name: prepare-config\n        image: docker.io/bitnami/kafka:4.0.0-debian-12-r10\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add: []\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \". /opt/bitnami/scripts/libkafka.sh\\nconfigure_kafka_sasl() {\\n    # Replace\\\n          \\ placeholders with passwords\\n    replace_in_file \\\"$KAFKA_CONF_FILE\\\"\\\n          \\ \\\"interbroker-password-placeholder\\\" \\\"$KAFKA_INTER_BROKER_PASSWORD\\\"\\n\\\n          \\    replace_in_file \\\"$KAFKA_CONF_FILE\\\" \\\"controller-password-placeholder\\\"\\\n          \\ \\\"$KAFKA_CONTROLLER_PASSWORD\\\"\\n    read -r -a passwords <<< \\\"$(tr ',;'\\\n          \\ ' ' <<<\\\"${KAFKA_CLIENT_PASSWORDS:-}\\\")\\\"\\n    for ((i = 0; i < ${#passwords[@]};\\\n          \\ i++)); do\\n        replace_in_file \\\"$KAFKA_CONF_FILE\\\" \\\"password-placeholder-${i}\\\\\\\n          \\\"\\\" \\\"${passwords[i]}\\\\\\\"\\\"\\n    done\\n}\\n\\ncp /configmaps/server.properties\\\n          \\ $KAFKA_CONF_FILE\\n\\n# Get pod ID and role, last and second last fields\\\n          \\ in the pod name respectively\\nPOD_ID=\\\"${MY_POD_NAME##*-}\\\"\\nPOD_ROLE=\\\"\\\n          ${MY_POD_NAME%-*}\\\"; POD_ROLE=\\\"${POD_ROLE##*-}\\\"\\n\\n# Configure node.id\\n\\\n          ID=$((POD_ID + KAFKA_MIN_ID))\\n[[ -f \\\"/bitnami/kafka/data/meta.properties\\\"\\\n          \\ ]] && ID=\\\"$(grep \\\"node.id\\\" /bitnami/kafka/data/meta.properties | awk\\\n          \\ -F '=' '{print $2}')\\\"\\nkafka_server_conf_set \\\"node.id\\\" \\\"$ID\\\"\\n# Configure\\\n          \\ initial controllers\\nif [[ \\\"controller\\\" =~ \\\"$POD_ROLE\\\" ]]; then\\n\\\n          \\    INITIAL_CONTROLLERS=()\\n    for ((i = 0; i < 3; i++)); do\\n       \\\n          \\ var=\\\"KAFKA_CONTROLLER_${i}_DIR_ID\\\"; DIR_ID=\\\"${!var}\\\"\\n        [[ $i\\\n          \\ -eq $POD_ID ]] && [[ -f \\\"/bitnami/kafka/data/meta.properties\\\" ]] &&\\\n          \\ DIR_ID=\\\"$(grep \\\"directory.id\\\" /bitnami/kafka/data/meta.properties |\\\n          \\ awk -F '=' '{print $2}')\\\"\\n        INITIAL_CONTROLLERS+=(\\\"${i}@${KAFKA_FULLNAME}-${POD_ROLE}-${i}.${KAFKA_CONTROLLER_SVC_NAME}.${MY_POD_NAMESPACE}.svc.${CLUSTER_DOMAIN}:${KAFKA_CONTROLLER_PORT}:${DIR_ID}\\\"\\\n          )\\n    done\\n    echo \\\"${INITIAL_CONTROLLERS[*]}\\\" | awk -v OFS=',' '{$1=$1}1'\\\n          \\ > /shared/initial-controllers.txt\\nfi\\nreplace_in_file \\\"$KAFKA_CONF_FILE\\\"\\\n          \\ \\\"advertised-address-placeholder\\\" \\\"${MY_POD_NAME}.${KAFKA_FULLNAME}-${POD_ROLE}-headless.${MY_POD_NAMESPACE}.svc.${CLUSTER_DOMAIN}\\\"\\\n          \\nsasl_env_vars=(\\n  KAFKA_CLIENT_PASSWORDS\\n  KAFKA_INTER_BROKER_PASSWORD\\n\\\n          \\  KAFKA_INTER_BROKER_CLIENT_SECRET\\n  KAFKA_CONTROLLER_PASSWORD\\n  KAFKA_CONTROLLER_CLIENT_SECRET\\n\\\n          )\\nfor env_var in \\\"${sasl_env_vars[@]}\\\"; do\\n    file_env_var=\\\"${env_var}_FILE\\\"\\\n          \\n    if [[ -n \\\"${!file_env_var:-}\\\" ]]; then\\n        if [[ -r \\\"${!file_env_var:-}\\\"\\\n          \\ ]]; then\\n            export \\\"${env_var}=$(< \\\"${!file_env_var}\\\")\\\"\\n\\\n          \\            unset \\\"${file_env_var}\\\"\\n        else\\n            warn \\\"\\\n          Skipping export of '${env_var}'. '${!file_env_var:-}' is not readable.\\\"\\\n          \\n        fi\\n    fi\\ndone\\nconfigure_kafka_sasl\\nif [[ -f /secret-config/server-secret.properties\\\n          \\ ]]; then\\n    cat /secret-config/server-secret.properties >> $KAFKA_CONF_FILE\\n\\\n          fi\\n\"\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: KAFKA_FULLNAME\n          value: release-name-kafka\n        - name: CLUSTER_DOMAIN\n          value: cluster.local\n        - name: KAFKA_VOLUME_DIR\n          value: /bitnami/kafka\n        - name: KAFKA_CONF_FILE\n          value: /config/server.properties\n        - name: KAFKA_MIN_ID\n          value: '0'\n        - name: KAFKA_CONTROLLER_SVC_NAME\n          value: release-name-kafka-controller-headless\n        - name: KAFKA_CONTROLLER_PORT\n          value: '9093'\n        - name: KAFKA_CONTROLLER_0_DIR_ID\n          valueFrom:\n            secretKeyRef:\n              name: release-name-kafka-kraft\n              key: controller-0-id\n        - name: KAFKA_CONTROLLER_1_DIR_ID\n          valueFrom:\n            secretKeyRef:\n              name: release-name-kafka-kraft\n              key: controller-1-id\n        - name: KAFKA_CONTROLLER_2_DIR_ID\n          valueFrom:\n            secretKeyRef:\n              name: release-name-kafka-kraft\n              key: controller-2-id\n        - name: KAFKA_CLIENT_USERS\n          value: user1\n        - name: KAFKA_CLIENT_PASSWORDS_FILE\n          value: /opt/bitnami/kafka/config/secrets/client-passwords\n        - name: KAFKA_INTER_BROKER_USER\n          value: inter_broker_user\n        - name: KAFKA_INTER_BROKER_PASSWORD_FILE\n          value: /opt/bitnami/kafka/config/secrets/inter-broker-password\n        - name: KAFKA_CONTROLLER_USER\n          value: controller_user\n        - name: KAFKA_CONTROLLER_PASSWORD_FILE\n          value: /opt/bitnami/kafka/config/secrets/controller-password\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/kafka\n        - name: kafka-config\n          mountPath: /config\n        - name: kafka-configmaps\n          mountPath: /configmaps\n        - name: kafka-secret-config\n          mountPath: /secret-config\n        - name: tmp\n          mountPath: /tmp\n        - name: init-shared\n          mountPath: /shared\n        - name: kafka-sasl\n          mountPath: /opt/bitnami/kafka/config/secrets\n          readOnly: true\n      containers:\n      - name: kafka\n        image: docker.io/bitnami/kafka:4.0.0-debian-12-r10\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n        env:\n        - name: KAFKA_HEAP_OPTS\n          value: -XX:InitialRAMPercentage=75 -XX:MaxRAMPercentage=75\n        - name: KAFKA_CFG_PROCESS_ROLES\n          value: controller,broker\n        - name: KAFKA_INITIAL_CONTROLLERS_FILE\n          value: /shared/initial-controllers.txt\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: KAFKA_KRAFT_CLUSTER_ID\n          valueFrom:\n            secretKeyRef:\n              name: release-name-kafka-kraft\n              key: cluster-id\n        - name: KAFKA_KRAFT_BOOTSTRAP_SCRAM_USERS\n          value: 'true'\n        - name: KAFKA_CLIENT_USERS\n          value: user1\n        - name: KAFKA_CLIENT_PASSWORDS_FILE\n          value: /opt/bitnami/kafka/config/secrets/client-passwords\n        - name: KAFKA_INTER_BROKER_USER\n          value: inter_broker_user\n        - name: KAFKA_INTER_BROKER_PASSWORD_FILE\n          value: /opt/bitnami/kafka/config/secrets/inter-broker-password\n        - name: KAFKA_CONTROLLER_USER\n          value: controller_user\n        - name: KAFKA_CONTROLLER_PASSWORD_FILE\n          value: /opt/bitnami/kafka/config/secrets/controller-password\n        ports:\n        - name: controller\n          containerPort: 9093\n        - name: client\n          containerPort: 9092\n        - name: interbroker\n          containerPort: 9094\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - pgrep\n            - -f\n            - kafka\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          tcpSocket:\n            port: controller\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/kafka\n        - name: logs\n          mountPath: /opt/bitnami/kafka/logs\n        - name: kafka-config\n          mountPath: /opt/bitnami/kafka/config/server.properties\n          subPath: server.properties\n        - name: tmp\n          mountPath: /tmp\n        - name: init-shared\n          mountPath: /shared\n        - name: kafka-sasl\n          mountPath: /opt/bitnami/kafka/config/secrets\n          readOnly: true\n      volumes:\n      - name: kafka-configmaps\n        configMap:\n          name: release-name-kafka-controller-configuration\n      - name: kafka-secret-config\n        emptyDir: {}\n      - name: kafka-config\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: init-shared\n        emptyDir: {}\n      - name: kafka-sasl\n        projected:\n          sources:\n          - secret:\n              name: release-name-kafka-user-passwords\n      - name: logs\n        emptyDir: {}\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "202",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 17.6.0\n    helm.sh/chart: postgresql-16.7.26\n    app.kubernetes.io/component: primary\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: postgresql\n      app.kubernetes.io/component: primary\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "203",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-keycloak\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: keycloak\n    app.kubernetes.io/version: 26.3.3\n    helm.sh/chart: keycloak-25.2.0\n    app.kubernetes.io/component: keycloak\n    app.kubernetes.io/part-of: keycloak\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: keycloak\n      app.kubernetes.io/component: keycloak\n      app.kubernetes.io/part-of: keycloak\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "204",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-postgresql-hl\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 17.6.0\n    helm.sh/chart: postgresql-16.7.26\n    app.kubernetes.io/component: primary\n  annotations: null\nspec:\n  type: ExternalName\n  publishNotReadyAddresses: true\n  externalName: release-name-postgresql-hl.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "205",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 17.6.0\n    helm.sh/chart: postgresql-16.7.26\n    app.kubernetes.io/component: primary\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-postgresql.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "206",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-keycloak-headless\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: keycloak\n    app.kubernetes.io/version: 26.3.3\n    helm.sh/chart: keycloak-25.2.0\n    app.kubernetes.io/component: keycloak\n    app.kubernetes.io/part-of: keycloak\nspec:\n  type: ExternalName\n  publishNotReadyAddresses: true\n  externalName: release-name-keycloak-headless.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "207",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-keycloak\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: keycloak\n    app.kubernetes.io/version: 26.3.3\n    helm.sh/chart: keycloak-25.2.0\n    app.kubernetes.io/component: keycloak\n    app.kubernetes.io/part-of: keycloak\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-keycloak.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "208",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 17.6.0\n    helm.sh/chart: postgresql-16.7.26\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  serviceName: release-name-postgresql-hl\n  updateStrategy:\n    rollingUpdate: {}\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: postgresql\n      app.kubernetes.io/component: primary\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: postgresql\n        app.kubernetes.io/version: 17.6.0\n        helm.sh/chart: postgresql-16.7.26\n        app.kubernetes.io/component: primary\n    spec:\n      serviceAccountName: default\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: postgresql\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      hostNetwork: false\n      hostIPC: false\n      containers:\n      - name: postgresql\n        image: docker.io/bitnami/postgresql:17.6.0-debian-12-r0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /bitnami/postgresql\n        - name: PGDATA\n          value: /bitnami/postgresql/data\n        - name: POSTGRES_USER\n          value: bn_keycloak\n        - name: POSTGRES_PASSWORD_FILE\n          value: /opt/bitnami/postgresql/secrets/password\n        - name: POSTGRES_POSTGRES_PASSWORD_FILE\n          value: /opt/bitnami/postgresql/secrets/postgres-password\n        - name: POSTGRES_DATABASE\n          value: bitnami_keycloak\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        - name: POSTGRESQL_ENABLE_TLS\n          value: 'no'\n        - name: POSTGRESQL_LOG_HOSTNAME\n          value: 'false'\n        - name: POSTGRESQL_LOG_CONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_LOG_DISCONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_PGAUDIT_LOG_CATALOG\n          value: 'off'\n        - name: POSTGRESQL_CLIENT_MIN_MESSAGES\n          value: error\n        - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES\n          value: pgaudit\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"bn_keycloak\" -d \"dbname=bitnami_keycloak\" -h 127.0.0.1\n              -p 5432\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"bn_keycloak\" -d \"dbname=bitnami_keycloak\" -h 127.0.0.1\n              -p 5432\n\n              [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized\n              ]\n\n              '\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/postgresql/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/postgresql/tmp\n          subPath: app-tmp-dir\n        - name: postgresql-password\n          mountPath: /opt/bitnami/postgresql/secrets/\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /bitnami/postgresql\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: postgresql-password\n        secret:\n          secretName: release-name-postgresql\n      - name: dshm\n        emptyDir:\n          medium: Memory\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "209",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-keycloak\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: keycloak\n    app.kubernetes.io/version: 26.3.3\n    helm.sh/chart: keycloak-25.2.0\n    app.kubernetes.io/component: keycloak\n    app.kubernetes.io/part-of: keycloak\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  podManagementPolicy: Parallel\n  serviceName: release-name-keycloak-headless\n  updateStrategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: keycloak\n      app.kubernetes.io/component: keycloak\n      app.kubernetes.io/part-of: keycloak\n  template:\n    metadata:\n      annotations:\n        checksum/configmap-env-vars: 32b97b2f95a4b4c37d1e7ba71916ca4c1f73d024fd8a3e077f2c86fba821b469\n        checksum/secrets: 04a6ccee11f98c05bad75a87ca3f46ce99e265b4b5d35d83a1a541641c64d855\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: keycloak\n        app.kubernetes.io/version: 26.3.3\n        helm.sh/chart: keycloak-25.2.0\n        app.kubernetes.io/component: keycloak\n        app.kubernetes.io/part-of: keycloak\n    spec:\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: keycloak\n                  app.kubernetes.io/component: keycloak\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      enableServiceLinks: true\n      initContainers:\n      - name: prepare-write-dirs\n        image: docker.io/bitnami/keycloak:26.3.3-debian-12-r0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - '. /opt/bitnami/scripts/liblog.sh\n\n\n          info \"Copying writable dirs to empty dir\"\n\n          # In order to not break the application functionality we need to make some\n\n          # directories writable, so we need to copy it to an empty dir volume\n\n          cp -r --preserve=mode,timestamps /opt/bitnami/keycloak/lib/quarkus /emptydir/app-quarkus-dir\n\n          cp -r --preserve=mode,timestamps /opt/bitnami/keycloak/data /emptydir/app-data-dir\n\n          cp -r --preserve=mode,timestamps /opt/bitnami/keycloak/providers /emptydir/app-providers-dir\n\n          cp -r --preserve=mode,timestamps /opt/bitnami/keycloak/themes /emptydir/app-themes-dir\n\n          info \"Copy operation completed\"\n\n          '\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: keycloak\n        image: docker.io/bitnami/keycloak:26.3.3-debian-12-r0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: KUBERNETES_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: release-name-keycloak-env-vars\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        - name: discovery\n          containerPort: 7800\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 120\n          periodSeconds: 1\n          successThreshold: 1\n          timeoutSeconds: 5\n          tcpSocket:\n            port: http\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          httpGet:\n            path: /realms/master\n            port: http\n            scheme: HTTP\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /bitnami/keycloak\n          subPath: app-volume-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/keycloak/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/keycloak/lib/quarkus\n          subPath: app-quarkus-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/keycloak/data\n          subPath: app-data-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/keycloak/providers\n          subPath: app-providers-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/keycloak/themes\n          subPath: app-themes-dir\n        - name: keycloak-secrets\n          mountPath: /opt/bitnami/keycloak/secrets\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: keycloak-secrets\n        projected:\n          sources:\n          - secret:\n              name: release-name-keycloak\n          - secret:\n              name: release-name-postgresql\n              items:\n              - key: password\n                path: db-password\n",
    "errors": []
  },
  {
    "id": "210",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-23.0.4\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mariadb\n      app.kubernetes.io/component: primary\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "211",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-mariadb-headless\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-23.0.4\n    app.kubernetes.io/part-of: mariadb\nspec:\n  type: ExternalName\n  publishNotReadyAddresses: true\n  externalName: release-name-mariadb-headless.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "212",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-23.0.4\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\n  annotations: null\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-mariadb.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "213",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-23.0.4\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mariadb\n      app.kubernetes.io/part-of: mariadb\n      app.kubernetes.io/component: primary\n  serviceName: release-name-mariadb-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/configuration: a73d0da9839c0886aa9e36d38eecc9587f379829e4b835933fcf64c0eba3b1f5\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/version: 12.0.2\n        helm.sh/chart: mariadb-23.0.4\n        app.kubernetes.io/part-of: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: release-name-mariadb\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mariadb\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/mariadb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/mariadb/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/mariadb/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: mariadb\n        image: registry-1.docker.io/bitnami/mariadb:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MARIADB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-root-password\n        - name: MARIADB_DATABASE\n          value: my_database\n        - name: MARIADB_ENABLE_SSL\n          value: 'no'\n        ports:\n        - name: mysql\n          containerPort: 3306\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin status -uroot -p\\\"${password_aux}\\\"\\n\"\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin ping -uroot -p\\\"${password_aux}\\\"\\n\"\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/mariadb\n        - name: config\n          mountPath: /opt/bitnami/mariadb/conf/my.cnf\n          subPath: my.cnf\n        - name: mariadb-credentials\n          mountPath: /opt/bitnami/mariadb/secrets/\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/logs\n          subPath: app-logs-dir\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: config\n        configMap:\n          name: release-name-mariadb\n      - name: mariadb-credentials\n        secret:\n          secretName: release-name-mariadb\n          items:\n          - key: mariadb-root-password\n            path: mariadb-root-password\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "214",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-23.0.4\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mariadb\n      app.kubernetes.io/part-of: mariadb\n      app.kubernetes.io/component: primary\n  serviceName: release-name-mariadb-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/configuration: a73d0da9839c0886aa9e36d38eecc9587f379829e4b835933fcf64c0eba3b1f5\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/version: 12.0.2\n        helm.sh/chart: mariadb-23.0.4\n        app.kubernetes.io/part-of: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: release-name-mariadb\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mariadb\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/mariadb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/mariadb/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/mariadb/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: mariadb\n        image: registry-1.docker.io/bitnami/mariadb:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MARIADB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-root-password\n        - name: MARIADB_DATABASE\n          value: my_database\n        - name: MARIADB_ENABLE_SSL\n          value: 'no'\n        ports:\n        - name: mysql\n          containerPort: 3306\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin status -uroot -p\\\"${password_aux}\\\"\\n\"\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin ping -uroot -p\\\"${password_aux}\\\"\\n\"\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/mariadb\n        - name: config\n          mountPath: /opt/bitnami/mariadb/conf/my.cnf\n          subPath: my.cnf\n        - name: mariadb-credentials\n          mountPath: /opt/bitnami/mariadb/secrets/\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/logs\n          subPath: app-logs-dir\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: config\n        configMap:\n          name: release-name-mariadb\n      - name: mariadb-credentials\n        secret:\n          secretName: release-name-mariadb\n          items:\n          - key: mariadb-root-password\n            path: mariadb-root-password\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "215",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-23.0.4\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mariadb\n      app.kubernetes.io/part-of: mariadb\n      app.kubernetes.io/component: primary\n  serviceName: release-name-mariadb-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/configuration: a73d0da9839c0886aa9e36d38eecc9587f379829e4b835933fcf64c0eba3b1f5\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/version: 12.0.2\n        helm.sh/chart: mariadb-23.0.4\n        app.kubernetes.io/part-of: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: default\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mariadb\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/mariadb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/mariadb/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/mariadb/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: mariadb\n        image: registry-1.docker.io/bitnami/mariadb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MARIADB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-root-password\n        - name: MARIADB_DATABASE\n          value: my_database\n        - name: MARIADB_ENABLE_SSL\n          value: 'no'\n        ports:\n        - name: mysql\n          containerPort: 3306\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin status -uroot -p\\\"${password_aux}\\\"\\n\"\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin ping -uroot -p\\\"${password_aux}\\\"\\n\"\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/mariadb\n        - name: config\n          mountPath: /opt/bitnami/mariadb/conf/my.cnf\n          subPath: my.cnf\n        - name: mariadb-credentials\n          mountPath: /opt/bitnami/mariadb/secrets/\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/logs\n          subPath: app-logs-dir\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: config\n        configMap:\n          name: release-name-mariadb\n      - name: mariadb-credentials\n        secret:\n          secretName: release-name-mariadb\n          items:\n          - key: mariadb-root-password\n            path: mariadb-root-password\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "216",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-minio-console\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: minio\n    app.kubernetes.io/version: 2.0.2\n    helm.sh/chart: minio-17.0.21\n    app.kubernetes.io/component: console\n    app.kubernetes.io/part-of: minio\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: minio\n      app.kubernetes.io/component: console\n      app.kubernetes.io/part-of: minio\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "217",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-minio\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: minio\n    app.kubernetes.io/version: 2025.7.23\n    helm.sh/chart: minio-17.0.21\n    app.kubernetes.io/component: minio\n    app.kubernetes.io/part-of: minio\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: minio\n      app.kubernetes.io/component: minio\n      app.kubernetes.io/part-of: minio\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "218",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-minio-console\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: minio\n    app.kubernetes.io/version: 2.0.2\n    helm.sh/chart: minio-17.0.21\n    app.kubernetes.io/component: console\n    app.kubernetes.io/part-of: minio\nspec:\n  type: ExternalName\n  externalName: release-name-minio-console.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "219",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-minio\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: minio\n    app.kubernetes.io/version: 2025.7.23\n    helm.sh/chart: minio-17.0.21\n    app.kubernetes.io/component: minio\n    app.kubernetes.io/part-of: minio\nspec:\n  type: ExternalName\n  externalName: release-name-minio.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "220",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-minio\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: minio\n    app.kubernetes.io/version: 2025.7.23\n    helm.sh/chart: minio-17.0.21\n    app.kubernetes.io/component: minio\n    app.kubernetes.io/part-of: minio\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: minio\n      app.kubernetes.io/component: minio\n      app.kubernetes.io/part-of: minio\n  strategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: minio\n        app.kubernetes.io/version: 2025.7.23\n        helm.sh/chart: minio-17.0.21\n        app.kubernetes.io/component: minio\n        app.kubernetes.io/part-of: minio\n      annotations:\n        checksum/credentials-secret: d7f9b363039fe1a5911ad90a3de83dbcfe0eba441592f6815c91be1861016459\n    spec:\n      serviceAccountName: default\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: minio\n                  app.kubernetes.io/component: minio\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      automountServiceAccountToken: false\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: OnRootMismatch\n        supplementalGroups: []\n        sysctls: []\n      initContainers: null\n      containers:\n      - name: minio\n        image: docker.io/bitnami/minio:2025.7.23-debian-12-r3\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MINIO_DISTRIBUTED_MODE_ENABLED\n          value: 'no'\n        - name: MINIO_SCHEME\n          value: http\n        - name: MINIO_FORCE_NEW_KEYS\n          value: 'no'\n        - name: MINIO_ROOT_USER_FILE\n          value: /opt/bitnami/minio/secrets/root-user\n        - name: MINIO_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/minio/secrets/root-password\n        - name: MINIO_SKIP_CLIENT\n          value: 'yes'\n        - name: MINIO_API_PORT_NUMBER\n          value: '9000'\n        - name: MINIO_BROWSER\n          value: 'off'\n        - name: MINIO_PROMETHEUS_AUTH_TYPE\n          value: public\n        - name: MINIO_DATA_DIR\n          value: /bitnami/minio/data\n        ports:\n        - name: api\n          containerPort: 9000\n        livenessProbe:\n          httpGet:\n            path: /minio/health/live\n            port: api\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          tcpSocket:\n            port: api\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 5\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/minio/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /.mc\n          subPath: app-mc-dir\n        - name: minio-credentials\n          mountPath: /opt/bitnami/minio/secrets/\n        - name: data\n          mountPath: /bitnami/minio/data\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: minio-credentials\n        secret:\n          secretName: release-name-minio\n      - name: data\n        persistentVolumeClaim:\n          claimName: release-name-minio\n",
    "errors": []
  },
  {
    "id": "221",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-minio-console\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: minio\n    app.kubernetes.io/version: 2.0.2\n    helm.sh/chart: minio-17.0.21\n    app.kubernetes.io/component: console\n    app.kubernetes.io/part-of: minio\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: minio\n      app.kubernetes.io/component: console\n      app.kubernetes.io/part-of: minio\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: minio\n        app.kubernetes.io/version: 2025.7.23\n        helm.sh/chart: minio-17.0.21\n        app.kubernetes.io/component: console\n        app.kubernetes.io/part-of: minio\n    spec:\n      serviceAccountName: default\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: minio\n                  app.kubernetes.io/component: console\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      containers:\n      - name: console\n        image: docker.io/bitnami/minio-object-browser:2.0.2-debian-12-r3\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        args:\n        - server\n        - --host\n        - 0.0.0.0\n        - --port\n        - '9090'\n        env:\n        - name: CONSOLE_MINIO_SERVER\n          value: http://release-name-minio:9000\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        ports:\n        - name: http\n          containerPort: 9090\n        livenessProbe:\n          failureThreshold: 5\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 5\n          tcpSocket:\n            port: http\n        readinessProbe:\n          failureThreshold: 5\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 5\n          httpGet:\n            path: /minio\n            port: http\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /.console\n          subPath: app-console-dir\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "222",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-mongodb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mongodb\n    app.kubernetes.io/version: 8.2.1\n    helm.sh/chart: mongodb-18.0.5\n    app.kubernetes.io/component: mongodb\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mongodb\n      app.kubernetes.io/component: mongodb\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "223",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-mongodb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mongodb\n    app.kubernetes.io/version: 8.2.1\n    helm.sh/chart: mongodb-18.0.5\n    app.kubernetes.io/component: mongodb\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  publishNotReadyAddresses: false\n  externalName: release-name-mongodb.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "224",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-mongodb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mongodb\n    app.kubernetes.io/version: 8.2.1\n    helm.sh/chart: mongodb-18.0.5\n    app.kubernetes.io/component: mongodb\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mongodb\n      app.kubernetes.io/component: mongodb\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mongodb\n        app.kubernetes.io/version: 8.2.1\n        helm.sh/chart: mongodb-18.0.5\n        app.kubernetes.io/component: mongodb\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: release-name-mongodb\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mongodb\n                  app.kubernetes.io/component: mongodb\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      enableServiceLinks: true\n      initContainers:\n      - name: log-dir\n        image: registry-1.docker.io/bitnami/mongodb:latest\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - 'ln -sf /dev/stdout \"/opt/bitnami/mongodb/logs/mongodb.log\"\n\n          '\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/logs\n          subPath: app-logs-dir\n      containers:\n      - name: mongodb\n        image: registry-1.docker.io/bitnami/mongodb:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MONGODB_ROOT_USER\n          value: root\n        - name: MONGODB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mongodb/secrets/mongodb-root-password\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'no'\n        - name: MONGODB_SYSTEM_LOG_VERBOSITY\n          value: '0'\n        - name: MONGODB_DISABLE_SYSTEM_LOG\n          value: 'no'\n        - name: MONGODB_DISABLE_JAVASCRIPT\n          value: 'no'\n        - name: MONGODB_ENABLE_JOURNAL\n          value: 'yes'\n        - name: MONGODB_PORT_NUMBER\n          value: '27017'\n        - name: MONGODB_ENABLE_IPV6\n          value: 'no'\n        - name: MONGODB_ENABLE_DIRECTORY_PER_DB\n          value: 'no'\n        ports:\n        - name: mongodb\n          containerPort: 27017\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 20\n          successThreshold: 1\n          timeoutSeconds: 10\n          exec:\n            command:\n            - /bitnami/scripts/ping-mongodb.sh\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bitnami/scripts/readiness-probe.sh\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/logs\n          subPath: app-logs-dir\n        - name: empty-dir\n          mountPath: /.mongodb\n          subPath: mongosh-home\n        - name: datadir\n          mountPath: /bitnami/mongodb\n          subPath: null\n        - name: common-scripts\n          mountPath: /bitnami/scripts\n        - name: mongodb-secrets\n          mountPath: /opt/bitnami/mongodb/secrets\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: common-scripts\n        configMap:\n          name: release-name-mongodb-common-scripts\n          defaultMode: 360\n      - name: mongodb-secrets\n        secret:\n          secretName: release-name-mongodb\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: release-name-mongodb\n",
    "errors": []
  },
  {
    "id": "225",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-mongodb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mongodb\n    app.kubernetes.io/version: 8.2.1\n    helm.sh/chart: mongodb-18.0.5\n    app.kubernetes.io/component: mongodb\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mongodb\n      app.kubernetes.io/component: mongodb\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mongodb\n        app.kubernetes.io/version: 8.2.1\n        helm.sh/chart: mongodb-18.0.5\n        app.kubernetes.io/component: mongodb\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: release-name-mongodb\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mongodb\n                  app.kubernetes.io/component: mongodb\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      enableServiceLinks: true\n      initContainers:\n      - name: log-dir\n        image: registry-1.docker.io/bitnami/mongodb:latest\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - 'ln -sf /dev/stdout \"/opt/bitnami/mongodb/logs/mongodb.log\"\n\n          '\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/logs\n          subPath: app-logs-dir\n      containers:\n      - name: mongodb\n        image: registry-1.docker.io/bitnami/mongodb:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MONGODB_ROOT_USER\n          value: root\n        - name: MONGODB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mongodb/secrets/mongodb-root-password\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'no'\n        - name: MONGODB_SYSTEM_LOG_VERBOSITY\n          value: '0'\n        - name: MONGODB_DISABLE_SYSTEM_LOG\n          value: 'no'\n        - name: MONGODB_DISABLE_JAVASCRIPT\n          value: 'no'\n        - name: MONGODB_ENABLE_JOURNAL\n          value: 'yes'\n        - name: MONGODB_PORT_NUMBER\n          value: '27017'\n        - name: MONGODB_ENABLE_IPV6\n          value: 'no'\n        - name: MONGODB_ENABLE_DIRECTORY_PER_DB\n          value: 'no'\n        ports:\n        - name: mongodb\n          containerPort: 27017\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 20\n          successThreshold: 1\n          timeoutSeconds: 10\n          exec:\n            command:\n            - /bitnami/scripts/ping-mongodb.sh\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bitnami/scripts/readiness-probe.sh\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/logs\n          subPath: app-logs-dir\n        - name: empty-dir\n          mountPath: /.mongodb\n          subPath: mongosh-home\n        - name: datadir\n          mountPath: /bitnami/mongodb\n          subPath: null\n        - name: common-scripts\n          mountPath: /bitnami/scripts\n        - name: mongodb-secrets\n          mountPath: /opt/bitnami/mongodb/secrets\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: common-scripts\n        configMap:\n          name: release-name-mongodb-common-scripts\n          defaultMode: 360\n      - name: mongodb-secrets\n        secret:\n          secretName: release-name-mongodb\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: release-name-mongodb\n",
    "errors": []
  },
  {
    "id": "226",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-mongodb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mongodb\n    app.kubernetes.io/version: 8.2.1\n    helm.sh/chart: mongodb-18.0.5\n    app.kubernetes.io/component: mongodb\nspec:\n  replicas: 1\n  strategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mongodb\n      app.kubernetes.io/component: mongodb\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mongodb\n        app.kubernetes.io/version: 8.2.1\n        helm.sh/chart: mongodb-18.0.5\n        app.kubernetes.io/component: mongodb\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: default\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mongodb\n                  app.kubernetes.io/component: mongodb\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      enableServiceLinks: true\n      initContainers:\n      - name: log-dir\n        image: registry-1.docker.io/bitnami/mongodb:latest\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - 'ln -sf /dev/stdout \"/opt/bitnami/mongodb/logs/mongodb.log\"\n\n          '\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/logs\n          subPath: app-logs-dir\n      containers:\n      - name: mongodb\n        image: registry-1.docker.io/bitnami/mongodb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MONGODB_ROOT_USER\n          value: root\n        - name: MONGODB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mongodb/secrets/mongodb-root-password\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'no'\n        - name: MONGODB_SYSTEM_LOG_VERBOSITY\n          value: '0'\n        - name: MONGODB_DISABLE_SYSTEM_LOG\n          value: 'no'\n        - name: MONGODB_DISABLE_JAVASCRIPT\n          value: 'no'\n        - name: MONGODB_ENABLE_JOURNAL\n          value: 'yes'\n        - name: MONGODB_PORT_NUMBER\n          value: '27017'\n        - name: MONGODB_ENABLE_IPV6\n          value: 'no'\n        - name: MONGODB_ENABLE_DIRECTORY_PER_DB\n          value: 'no'\n        ports:\n        - name: mongodb\n          containerPort: 27017\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 20\n          successThreshold: 1\n          timeoutSeconds: 10\n          exec:\n            command:\n            - /bitnami/scripts/ping-mongodb.sh\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bitnami/scripts/readiness-probe.sh\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mongodb/logs\n          subPath: app-logs-dir\n        - name: empty-dir\n          mountPath: /.mongodb\n          subPath: mongosh-home\n        - name: datadir\n          mountPath: /bitnami/mongodb\n          subPath: null\n        - name: common-scripts\n          mountPath: /bitnami/scripts\n        - name: mongodb-secrets\n          mountPath: /opt/bitnami/mongodb/secrets\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: common-scripts\n        configMap:\n          name: release-name-mongodb-common-scripts\n          defaultMode: 360\n      - name: mongodb-secrets\n        secret:\n          secretName: release-name-mongodb\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: release-name-mongodb\n",
    "errors": []
  },
  {
    "id": "227",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-mysql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mysql\n    app.kubernetes.io/version: 9.4.0\n    helm.sh/chart: mysql-14.0.3\n    app.kubernetes.io/part-of: mysql\n    app.kubernetes.io/component: primary\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mysql\n      app.kubernetes.io/part-of: mysql\n      app.kubernetes.io/component: primary\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "228",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-mysql-headless\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mysql\n    app.kubernetes.io/version: 9.4.0\n    helm.sh/chart: mysql-14.0.3\n    app.kubernetes.io/part-of: mysql\n    app.kubernetes.io/component: primary\nspec:\n  type: ExternalName\n  publishNotReadyAddresses: true\n  externalName: release-name-mysql-headless.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "229",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-mysql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mysql\n    app.kubernetes.io/version: 9.4.0\n    helm.sh/chart: mysql-14.0.3\n    app.kubernetes.io/part-of: mysql\n    app.kubernetes.io/component: primary\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-mysql.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "230",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-mysql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mysql\n    app.kubernetes.io/version: 9.4.0\n    helm.sh/chart: mysql-14.0.3\n    app.kubernetes.io/part-of: mysql\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  podManagementPolicy: ''\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mysql\n      app.kubernetes.io/part-of: mysql\n      app.kubernetes.io/component: primary\n  serviceName: release-name-mysql-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/configuration: 0aa4c7bb029f4871ca0cdece35adf5a5caaf6f2e016ef25c8cae18901c047e48\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mysql\n        app.kubernetes.io/version: 9.4.0\n        helm.sh/chart: mysql-14.0.3\n        app.kubernetes.io/part-of: mysql\n        app.kubernetes.io/component: primary\n    spec:\n      serviceAccountName: default\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mysql\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: docker.io/bitnami/mysql:9.4.0-debian-12-r1\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/mysql/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/mysql/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: mysql\n        image: docker.io/bitnami/mysql:9.4.0-debian-12-r1\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MYSQL_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mysql/secrets/mysql-root-password\n        - name: MYSQL_ENABLE_SSL\n          value: 'no'\n        - name: MYSQL_PORT\n          value: '3306'\n        - name: MYSQL_DATABASE\n          value: my_database\n        envFrom: null\n        ports:\n        - name: mysql\n          containerPort: 3306\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MYSQL_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MYSQL_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MYSQL_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmysqladmin status -uroot -p\\\"${password_aux}\\\"\\n\"\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MYSQL_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MYSQL_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MYSQL_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmysqladmin ping -uroot -p\\\"${password_aux}\\\" | grep \\\"mysqld is\\\n              \\ alive\\\"\\n\"\n        startupProbe:\n          failureThreshold: 10\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MYSQL_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MYSQL_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MYSQL_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmysqladmin ping -uroot -p\\\"${password_aux}\\\" | grep \\\"mysqld is\\\n              \\ alive\\\"\\n\"\n        resources:\n          limits:\n            cpu: 750m\n            ephemeral-storage: 2Gi\n            memory: 768Mi\n          requests:\n            cpu: 500m\n            ephemeral-storage: 50Mi\n            memory: 512Mi\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/mysql\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mysql/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mysql/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mysql/logs\n          subPath: app-logs-dir\n        - name: config\n          mountPath: /opt/bitnami/mysql/conf/my.cnf\n          subPath: my.cnf\n        - name: mysql-credentials\n          mountPath: /opt/bitnami/mysql/secrets/\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-mysql\n      - name: mysql-credentials\n        secret:\n          secretName: release-name-mysql\n          items:\n          - key: mysql-root-password\n            path: mysql-root-password\n          - key: mysql-password\n            path: mysql-password\n      - name: empty-dir\n        emptyDir: {}\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: mysql\n        app.kubernetes.io/component: primary\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "231",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-nginx\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: nginx\n    app.kubernetes.io/version: 1.29.1\n    helm.sh/chart: nginx-22.0.7\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: nginx\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "232",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-nginx\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: nginx\n    app.kubernetes.io/version: 1.29.1\n    helm.sh/chart: nginx-22.0.7\n  annotations: null\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalTrafficPolicy: Cluster\n  externalName: release-name-nginx.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "233",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-nginx\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: nginx\n    app.kubernetes.io/version: 1.29.1\n    helm.sh/chart: nginx-22.0.7\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  strategy:\n    rollingUpdate: {}\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: nginx\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: nginx\n        app.kubernetes.io/version: 1.29.1\n        helm.sh/chart: nginx-22.0.7\n      annotations: null\n    spec:\n      shareProcessNamespace: false\n      serviceAccountName: release-name-nginx\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: nginx\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      hostNetwork: false\n      hostIPC: false\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/nginx:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/nginx/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/nginx/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: nginx\n        image: registry-1.docker.io/bitnami/nginx:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: NGINX_HTTP_PORT_NUMBER\n          value: '8080'\n        - name: NGINX_HTTPS_PORT_NUMBER\n          value: '8443'\n        envFrom: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          tcpSocket:\n            port: http\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 3\n          httpGet:\n            path: /\n            port: http\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/logs\n          subPath: app-logs-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/tmp\n          subPath: app-tmp-dir\n        - name: certificate\n          mountPath: /certs\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: certificate\n        secret:\n          secretName: release-name-nginx-tls\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n",
    "errors": []
  },
  {
    "id": "234",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-nginx\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: nginx\n    app.kubernetes.io/version: 1.29.1\n    helm.sh/chart: nginx-22.0.7\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  strategy:\n    rollingUpdate: {}\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: nginx\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: nginx\n        app.kubernetes.io/version: 1.29.1\n        helm.sh/chart: nginx-22.0.7\n      annotations: null\n    spec:\n      shareProcessNamespace: false\n      serviceAccountName: release-name-nginx\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: nginx\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      hostNetwork: false\n      hostIPC: false\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/nginx:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/nginx/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/nginx/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: nginx\n        image: registry-1.docker.io/bitnami/nginx:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: NGINX_HTTP_PORT_NUMBER\n          value: '8080'\n        - name: NGINX_HTTPS_PORT_NUMBER\n          value: '8443'\n        envFrom: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          tcpSocket:\n            port: http\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 3\n          httpGet:\n            path: /\n            port: http\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/logs\n          subPath: app-logs-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/tmp\n          subPath: app-tmp-dir\n        - name: certificate\n          mountPath: /certs\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: certificate\n        secret:\n          secretName: release-name-nginx-tls\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n",
    "errors": []
  },
  {
    "id": "235",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-nginx\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: nginx\n    app.kubernetes.io/version: 1.29.1\n    helm.sh/chart: nginx-22.0.7\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  strategy:\n    rollingUpdate: {}\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: nginx\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: nginx\n        app.kubernetes.io/version: 1.29.1\n        helm.sh/chart: nginx-22.0.7\n      annotations: null\n    spec:\n      shareProcessNamespace: false\n      serviceAccountName: default\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: nginx\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      hostNetwork: false\n      hostIPC: false\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/nginx:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/nginx/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/nginx/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: nginx\n        image: registry-1.docker.io/bitnami/nginx:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: NGINX_HTTP_PORT_NUMBER\n          value: '8080'\n        - name: NGINX_HTTPS_PORT_NUMBER\n          value: '8443'\n        envFrom: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          tcpSocket:\n            port: http\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 3\n          httpGet:\n            path: /\n            port: http\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/logs\n          subPath: app-logs-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/nginx/tmp\n          subPath: app-tmp-dir\n        - name: certificate\n          mountPath: /certs\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: certificate\n        secret:\n          secretName: release-name-nginx-tls\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n",
    "errors": []
  },
  {
    "id": "236",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 18.0.0\n    helm.sh/chart: postgresql-18.0.8\n    app.kubernetes.io/component: primary\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: postgresql\n      app.kubernetes.io/component: primary\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "237",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-postgresql-hl\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 18.0.0\n    helm.sh/chart: postgresql-18.0.8\n    app.kubernetes.io/component: primary\n  annotations: null\nspec:\n  type: ExternalName\n  publishNotReadyAddresses: true\n  externalName: release-name-postgresql-hl.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "238",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 18.0.0\n    helm.sh/chart: postgresql-18.0.8\n    app.kubernetes.io/component: primary\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-postgresql.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "239",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 18.0.0\n    helm.sh/chart: postgresql-18.0.8\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  serviceName: release-name-postgresql-hl\n  updateStrategy:\n    rollingUpdate: {}\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: postgresql\n      app.kubernetes.io/component: primary\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: postgresql\n        app.kubernetes.io/version: 18.0.0\n        helm.sh/chart: postgresql-18.0.8\n        app.kubernetes.io/component: primary\n    spec:\n      serviceAccountName: release-name-postgresql\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: postgresql\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      hostNetwork: false\n      hostIPC: false\n      containers:\n      - name: postgresql\n        image: registry-1.docker.io/bitnami/postgresql:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /bitnami/postgresql\n        - name: PGDATA\n          value: /bitnami/postgresql/data\n        - name: POSTGRES_PASSWORD_FILE\n          value: /opt/bitnami/postgresql/secrets/postgres-password\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        - name: POSTGRESQL_ENABLE_TLS\n          value: 'no'\n        - name: POSTGRESQL_LOG_HOSTNAME\n          value: 'false'\n        - name: POSTGRESQL_LOG_CONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_LOG_DISCONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_PGAUDIT_LOG_CATALOG\n          value: 'off'\n        - name: POSTGRESQL_CLIENT_MIN_MESSAGES\n          value: error\n        - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES\n          value: pgaudit\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -h 127.0.0.1 -p 5432\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -h 127.0.0.1 -p 5432\n\n              [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized\n              ]\n\n              '\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/postgresql/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/postgresql/tmp\n          subPath: app-tmp-dir\n        - name: postgresql-password\n          mountPath: /opt/bitnami/postgresql/secrets/\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /bitnami/postgresql\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: postgresql-password\n        secret:\n          secretName: release-name-postgresql\n      - name: dshm\n        emptyDir:\n          medium: Memory\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "240",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-postgresql\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: postgresql\n    app.kubernetes.io/version: 18.0.0\n    helm.sh/chart: postgresql-18.0.8\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  serviceName: release-name-postgresql-hl\n  updateStrategy:\n    rollingUpdate: {}\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: postgresql\n      app.kubernetes.io/component: primary\n  template:\n    metadata:\n      name: release-name-postgresql\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: postgresql\n        app.kubernetes.io/version: 18.0.0\n        helm.sh/chart: postgresql-18.0.8\n        app.kubernetes.io/component: primary\n    spec:\n      serviceAccountName: default\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: postgresql\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      hostNetwork: false\n      hostIPC: false\n      containers:\n      - name: postgresql\n        image: registry-1.docker.io/bitnami/postgresql:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: POSTGRESQL_PORT_NUMBER\n          value: '5432'\n        - name: POSTGRESQL_VOLUME_DIR\n          value: /bitnami/postgresql\n        - name: PGDATA\n          value: /bitnami/postgresql/data\n        - name: POSTGRES_PASSWORD_FILE\n          value: /opt/bitnami/postgresql/secrets/postgres-password\n        - name: POSTGRESQL_ENABLE_LDAP\n          value: 'no'\n        - name: POSTGRESQL_ENABLE_TLS\n          value: 'no'\n        - name: POSTGRESQL_LOG_HOSTNAME\n          value: 'false'\n        - name: POSTGRESQL_LOG_CONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_LOG_DISCONNECTIONS\n          value: 'false'\n        - name: POSTGRESQL_PGAUDIT_LOG_CATALOG\n          value: 'off'\n        - name: POSTGRESQL_CLIENT_MIN_MESSAGES\n          value: error\n        - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES\n          value: pgaudit\n        ports:\n        - name: tcp-postgresql\n          containerPort: 5432\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - exec pg_isready -U \"postgres\" -h 127.0.0.1 -p 5432\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          exec:\n            command:\n            - /bin/sh\n            - -c\n            - -e\n            - 'exec pg_isready -U \"postgres\" -h 127.0.0.1 -p 5432\n\n              [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized\n              ]\n\n              '\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/postgresql/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/postgresql/tmp\n          subPath: app-tmp-dir\n        - name: postgresql-password\n          mountPath: /opt/bitnami/postgresql/secrets/\n        - name: dshm\n          mountPath: /dev/shm\n        - name: data\n          mountPath: /bitnami/postgresql\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: postgresql-password\n        secret:\n          secretName: release-name-postgresql\n      - name: dshm\n        emptyDir:\n          medium: Memory\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "241",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-rabbitmq\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: rabbitmq\n    app.kubernetes.io/version: 4.1.3\n    helm.sh/chart: rabbitmq-16.0.14\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: rabbitmq\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "242",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-rabbitmq-headless\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: rabbitmq\n    app.kubernetes.io/version: 4.1.3\n    helm.sh/chart: rabbitmq-16.0.14\nspec:\n  publishNotReadyAddresses: true\n  trafficDistribution: PreferClose\n  type: ExternalName\n  externalName: release-name-rabbitmq-headless.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "243",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-rabbitmq\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: rabbitmq\n    app.kubernetes.io/version: 4.1.3\n    helm.sh/chart: rabbitmq-16.0.14\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-rabbitmq.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "244",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-rabbitmq\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: rabbitmq\n    app.kubernetes.io/version: 4.1.3\n    helm.sh/chart: rabbitmq-16.0.14\nspec:\n  serviceName: release-name-rabbitmq-headless\n  podManagementPolicy: OrderedReady\n  replicas: 1\n  updateStrategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: rabbitmq\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: rabbitmq\n        app.kubernetes.io/version: 4.1.3\n        helm.sh/chart: rabbitmq-16.0.14\n      annotations:\n        checksum/config: 81f24711d28981f706e1ae5b2e3ae075d7014b462120496ce6f50d5053194f5e\n        checksum/secret: 0db9412a28617166460cac5333a5cf8ebbc34cfe87087e0f09b593395c5fa678\n    spec:\n      serviceAccountName: default\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: rabbitmq\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      automountServiceAccountToken: true\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      terminationGracePeriodSeconds: 120\n      enableServiceLinks: true\n      initContainers:\n      - name: prepare-plugins-dir\n        image: docker.io/bitnami/rabbitmq:4.1.3-debian-12-r1\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - '#!/bin/bash\n\n\n          . /opt/bitnami/scripts/liblog.sh\n\n\n          info \"Copying plugins dir to empty dir\"\n\n          # In order to not break the possibility of installing custom plugins, we\n          need\n\n          # to make the plugins directory writable, so we need to copy it to an empty\n          dir volume\n\n          cp -r --preserve=mode /opt/bitnami/rabbitmq/plugins/ /emptydir/app-plugins-dir\n\n          '\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: rabbitmq\n        image: docker.io/bitnami/rabbitmq:4.1.3-debian-12-r1\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/bash\n              - -ec\n              - \"if [[ -f /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh ]]; then\\n\\\n                \\    /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh -t \\\"120\\\" -d \\\"\\\n                false\\\"\\nelse\\n    rabbitmqctl stop_app\\nfi\\n\"\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: RABBITMQ_FORCE_BOOT\n          value: 'no'\n        - name: RABBITMQ_NODE_NAME\n          value: rabbit@$(MY_POD_NAME).release-name-rabbitmq-headless.$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: RABBITMQ_UPDATE_PASSWORD\n          value: 'no'\n        - name: RABBITMQ_MNESIA_DIR\n          value: /opt/bitnami/rabbitmq/.rabbitmq/mnesia/$(RABBITMQ_NODE_NAME)\n        - name: RABBITMQ_LDAP_ENABLE\n          value: 'no'\n        - name: RABBITMQ_LOGS\n          value: '-'\n        - name: RABBITMQ_ULIMIT_NOFILES\n          value: '65535'\n        - name: RABBITMQ_USE_LONGNAME\n          value: 'true'\n        - name: RABBITMQ_ERL_COOKIE_FILE\n          value: /opt/bitnami/rabbitmq/secrets/rabbitmq-erlang-cookie\n        - name: RABBITMQ_LOAD_DEFINITIONS\n          value: 'no'\n        - name: RABBITMQ_DEFINITIONS_FILE\n          value: /app/load_definition.json\n        - name: RABBITMQ_SECURE_PASSWORD\n          value: 'yes'\n        - name: RABBITMQ_USERNAME\n          value: user\n        - name: RABBITMQ_PASSWORD_FILE\n          value: /opt/bitnami/rabbitmq/secrets/rabbitmq-password\n        - name: RABBITMQ_PLUGINS\n          value: rabbitmq_management, rabbitmq_peer_discovery_k8s, rabbitmq_auth_backend_ldap\n        envFrom: null\n        ports:\n        - name: amqp\n          containerPort: 5672\n        - name: dist\n          containerPort: 25672\n        - name: stats\n          containerPort: 15672\n        - name: epmd\n          containerPort: 4369\n        - name: metrics\n          containerPort: 9419\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 20\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - curl -f --user user:$(< $RABBITMQ_PASSWORD_FILE) 127.0.0.1:15672/api/health/checks/virtual-hosts\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 10\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 20\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - curl -f --user user:$(< $RABBITMQ_PASSWORD_FILE) 127.0.0.1:15672/api/health/checks/local-alarms\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        volumeMounts:\n        - name: configuration\n          mountPath: /bitnami/rabbitmq/conf\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/rabbitmq/etc/rabbitmq\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/rabbitmq/var/lib/rabbitmq\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/rabbitmq/.rabbitmq/\n          subPath: app-erlang-cookie\n        - name: empty-dir\n          mountPath: /opt/bitnami/rabbitmq/var/log/rabbitmq\n          subPath: app-logs-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/rabbitmq/plugins\n          subPath: app-plugins-dir\n        - name: data\n          mountPath: /opt/bitnami/rabbitmq/.rabbitmq/mnesia\n        - name: rabbitmq-secrets\n          mountPath: /opt/bitnami/rabbitmq/secrets\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: configuration\n        projected:\n          sources:\n          - secret:\n              name: release-name-rabbitmq-config\n      - name: rabbitmq-secrets\n        projected:\n          sources:\n          - secret:\n              name: release-name-rabbitmq\n          - secret:\n              name: release-name-rabbitmq\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: rabbitmq\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "245",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-redis-master\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\n    app.kubernetes.io/component: master\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: redis\n      app.kubernetes.io/component: master\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "246",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-redis-replicas\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\n    app.kubernetes.io/component: replica\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: redis\n      app.kubernetes.io/component: replica\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "247",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-redis-headless\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\nspec:\n  type: ExternalName\n  externalName: release-name-redis-headless.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "248",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-redis-master\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\n    app.kubernetes.io/component: master\nspec:\n  type: ExternalName\n  internalTrafficPolicy: Cluster\n  sessionAffinity: None\n  externalName: release-name-redis-master.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "249",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-redis-replicas\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\n    app.kubernetes.io/component: replica\nspec:\n  type: ExternalName\n  internalTrafficPolicy: Cluster\n  sessionAffinity: None\n  externalName: release-name-redis-replicas.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "250",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis-master\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\n    app.kubernetes.io/component: master\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: redis\n      app.kubernetes.io/component: master\n  serviceName: release-name-redis-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: redis\n        app.kubernetes.io/version: 8.2.2\n        helm.sh/chart: redis-23.1.1\n        app.kubernetes.io/component: master\n      annotations:\n        checksum/configmap: 95944ee35a19af37cefd156f19d93e157e578c1dc63ac01ce735ae93090b7580\n        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9\n        checksum/scripts: 796326939380261bbef30ebf93cef0ad202f8440491c7bfce6ca532637bd0271\n        checksum/secret: e604af60410e66fdbde895aaa50ef67a9838938e9197616eab6627edea05bc2a\n    spec:\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      serviceAccountName: release-name-redis-master\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: redis\n                  app.kubernetes.io/component: master\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      enableServiceLinks: true\n      terminationGracePeriodSeconds: 30\n      containers:\n      - name: redis\n        image: registry-1.docker.io/bitnami/redis:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - /opt/bitnami/scripts/start-scripts/start-master.sh\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: REDIS_REPLICATION_MODE\n          value: master\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'no'\n        - name: REDIS_PASSWORD_FILE\n          value: /opt/bitnami/redis/secrets/redis-password\n        - name: REDIS_TLS_ENABLED\n          value: 'no'\n        - name: REDIS_PORT\n          value: '6379'\n        ports:\n        - name: redis\n          containerPort: 6379\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          timeoutSeconds: 6\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - /health/ping_liveness_local.sh 5\n        readinessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          timeoutSeconds: 2\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - /health/ping_readiness_local.sh 1\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: start-scripts\n          mountPath: /opt/bitnami/scripts/start-scripts\n        - name: health\n          mountPath: /health\n        - name: redis-password\n          mountPath: /opt/bitnami/redis/secrets/\n        - name: redis-data\n          mountPath: /data\n        - name: config\n          mountPath: /opt/bitnami/redis/mounted-etc\n        - name: empty-dir\n          mountPath: /opt/bitnami/redis/etc/\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n      volumes:\n      - name: start-scripts\n        configMap:\n          name: release-name-redis-scripts\n          defaultMode: 493\n      - name: health\n        configMap:\n          name: release-name-redis-health\n          defaultMode: 493\n      - name: redis-password\n        secret:\n          secretName: release-name-redis\n          items:\n          - key: redis-password\n            path: redis-password\n      - name: config\n        configMap:\n          name: release-name-redis-configuration\n      - name: empty-dir\n        emptyDir: {}\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: redis\n        app.kubernetes.io/component: master\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "251",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis-master\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\n    app.kubernetes.io/component: master\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: redis\n      app.kubernetes.io/component: master\n  serviceName: release-name-redis-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: redis\n        app.kubernetes.io/version: 8.2.2\n        helm.sh/chart: redis-23.1.1\n        app.kubernetes.io/component: master\n      annotations:\n        checksum/configmap: 95944ee35a19af37cefd156f19d93e157e578c1dc63ac01ce735ae93090b7580\n        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9\n        checksum/scripts: 796326939380261bbef30ebf93cef0ad202f8440491c7bfce6ca532637bd0271\n        checksum/secret: e604af60410e66fdbde895aaa50ef67a9838938e9197616eab6627edea05bc2a\n    spec:\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      serviceAccountName: default\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: redis\n                  app.kubernetes.io/component: master\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      enableServiceLinks: true\n      terminationGracePeriodSeconds: 30\n      containers:\n      - name: redis\n        image: registry-1.docker.io/bitnami/redis:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - /opt/bitnami/scripts/start-scripts/start-master.sh\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: REDIS_REPLICATION_MODE\n          value: master\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'no'\n        - name: REDIS_PASSWORD_FILE\n          value: /opt/bitnami/redis/secrets/redis-password\n        - name: REDIS_TLS_ENABLED\n          value: 'no'\n        - name: REDIS_PORT\n          value: '6379'\n        ports:\n        - name: redis\n          containerPort: 6379\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          timeoutSeconds: 6\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - /health/ping_liveness_local.sh 5\n        readinessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          timeoutSeconds: 2\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - /health/ping_readiness_local.sh 1\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: start-scripts\n          mountPath: /opt/bitnami/scripts/start-scripts\n        - name: health\n          mountPath: /health\n        - name: redis-password\n          mountPath: /opt/bitnami/redis/secrets/\n        - name: redis-data\n          mountPath: /data\n        - name: config\n          mountPath: /opt/bitnami/redis/mounted-etc\n        - name: empty-dir\n          mountPath: /opt/bitnami/redis/etc/\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n      volumes:\n      - name: start-scripts\n        configMap:\n          name: release-name-redis-scripts\n          defaultMode: 493\n      - name: health\n        configMap:\n          name: release-name-redis-health\n          defaultMode: 493\n      - name: redis-password\n        secret:\n          secretName: release-name-redis\n          items:\n          - key: redis-password\n            path: redis-password\n      - name: config\n        configMap:\n          name: release-name-redis-configuration\n      - name: empty-dir\n        emptyDir: {}\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: redis\n        app.kubernetes.io/component: master\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "252",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis-replicas\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\n    app.kubernetes.io/component: replica\nspec:\n  replicas: 3\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: redis\n      app.kubernetes.io/component: replica\n  serviceName: release-name-redis-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: redis\n        app.kubernetes.io/version: 8.2.2\n        helm.sh/chart: redis-23.1.1\n        app.kubernetes.io/component: replica\n      annotations:\n        checksum/configmap: 95944ee35a19af37cefd156f19d93e157e578c1dc63ac01ce735ae93090b7580\n        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9\n        checksum/scripts: 796326939380261bbef30ebf93cef0ad202f8440491c7bfce6ca532637bd0271\n        checksum/secret: e604af60410e66fdbde895aaa50ef67a9838938e9197616eab6627edea05bc2a\n    spec:\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      serviceAccountName: release-name-redis-replica\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: redis\n                  app.kubernetes.io/component: replica\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      enableServiceLinks: true\n      terminationGracePeriodSeconds: 30\n      containers:\n      - name: redis\n        image: registry-1.docker.io/bitnami/redis:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - /opt/bitnami/scripts/start-scripts/start-replica.sh\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: REDIS_REPLICATION_MODE\n          value: replica\n        - name: REDIS_MASTER_HOST\n          value: release-name-redis-master-0.release-name-redis-headless.default.svc.cluster.local\n        - name: REDIS_MASTER_PORT_NUMBER\n          value: '6379'\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'no'\n        - name: REDIS_PASSWORD_FILE\n          value: /opt/bitnami/redis/secrets/redis-password\n        - name: REDIS_MASTER_PASSWORD_FILE\n          value: /opt/bitnami/redis/secrets/redis-password\n        - name: REDIS_TLS_ENABLED\n          value: 'no'\n        - name: REDIS_PORT\n          value: '6379'\n        ports:\n        - name: redis\n          containerPort: 6379\n        startupProbe:\n          failureThreshold: 22\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          tcpSocket:\n            port: redis\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          timeoutSeconds: 6\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - /health/ping_liveness_local_and_master.sh 5\n        readinessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          timeoutSeconds: 2\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - /health/ping_readiness_local_and_master.sh 1\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: start-scripts\n          mountPath: /opt/bitnami/scripts/start-scripts\n        - name: health\n          mountPath: /health\n        - name: redis-password\n          mountPath: /opt/bitnami/redis/secrets/\n        - name: redis-data\n          mountPath: /data\n        - name: config\n          mountPath: /opt/bitnami/redis/mounted-etc\n        - name: empty-dir\n          mountPath: /opt/bitnami/redis/etc\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n      volumes:\n      - name: start-scripts\n        configMap:\n          name: release-name-redis-scripts\n          defaultMode: 493\n      - name: health\n        configMap:\n          name: release-name-redis-health\n          defaultMode: 493\n      - name: redis-password\n        secret:\n          secretName: release-name-redis\n          items:\n          - key: redis-password\n            path: redis-password\n      - name: config\n        configMap:\n          name: release-name-redis-configuration\n      - name: empty-dir\n        emptyDir: {}\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: redis\n        app.kubernetes.io/component: replica\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "253",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-redis-replicas\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: redis\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: redis-23.1.1\n    app.kubernetes.io/component: replica\nspec:\n  replicas: 3\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: redis\n      app.kubernetes.io/component: replica\n  serviceName: release-name-redis-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: redis\n        app.kubernetes.io/version: 8.2.2\n        helm.sh/chart: redis-23.1.1\n        app.kubernetes.io/component: replica\n      annotations:\n        checksum/configmap: 95944ee35a19af37cefd156f19d93e157e578c1dc63ac01ce735ae93090b7580\n        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9\n        checksum/scripts: 796326939380261bbef30ebf93cef0ad202f8440491c7bfce6ca532637bd0271\n        checksum/secret: e604af60410e66fdbde895aaa50ef67a9838938e9197616eab6627edea05bc2a\n    spec:\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      serviceAccountName: default\n      automountServiceAccountToken: false\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: redis\n                  app.kubernetes.io/component: replica\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      enableServiceLinks: true\n      terminationGracePeriodSeconds: 30\n      containers:\n      - name: redis\n        image: registry-1.docker.io/bitnami/redis:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - /opt/bitnami/scripts/start-scripts/start-replica.sh\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: REDIS_REPLICATION_MODE\n          value: replica\n        - name: REDIS_MASTER_HOST\n          value: release-name-redis-master-0.release-name-redis-headless.default.svc.cluster.local\n        - name: REDIS_MASTER_PORT_NUMBER\n          value: '6379'\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'no'\n        - name: REDIS_PASSWORD_FILE\n          value: /opt/bitnami/redis/secrets/redis-password\n        - name: REDIS_MASTER_PASSWORD_FILE\n          value: /opt/bitnami/redis/secrets/redis-password\n        - name: REDIS_TLS_ENABLED\n          value: 'no'\n        - name: REDIS_PORT\n          value: '6379'\n        ports:\n        - name: redis\n          containerPort: 6379\n        startupProbe:\n          failureThreshold: 22\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n          tcpSocket:\n            port: redis\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          timeoutSeconds: 6\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - /health/ping_liveness_local_and_master.sh 5\n        readinessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          timeoutSeconds: 2\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - /health/ping_readiness_local_and_master.sh 1\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts:\n        - name: start-scripts\n          mountPath: /opt/bitnami/scripts/start-scripts\n        - name: health\n          mountPath: /health\n        - name: redis-password\n          mountPath: /opt/bitnami/redis/secrets/\n        - name: redis-data\n          mountPath: /data\n        - name: config\n          mountPath: /opt/bitnami/redis/mounted-etc\n        - name: empty-dir\n          mountPath: /opt/bitnami/redis/etc\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n      volumes:\n      - name: start-scripts\n        configMap:\n          name: release-name-redis-scripts\n          defaultMode: 493\n      - name: health\n        configMap:\n          name: release-name-redis-health\n          defaultMode: 493\n      - name: redis-password\n        secret:\n          secretName: release-name-redis\n          items:\n          - key: redis-password\n            path: redis-password\n      - name: config\n        configMap:\n          name: release-name-redis-configuration\n      - name: empty-dir\n        emptyDir: {}\n  volumeClaimTemplates:\n  - apiVersion: v1\n    kind: PersistentVolumeClaim\n    metadata:\n      name: redis-data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: redis\n        app.kubernetes.io/component: replica\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "254",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-thanos-query-frontend\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: thanos\n    app.kubernetes.io/version: 0.39.2\n    helm.sh/chart: thanos-17.3.1\n    app.kubernetes.io/component: query-frontend\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: thanos\n      app.kubernetes.io/component: query-frontend\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "255",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-thanos-query\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: thanos\n    app.kubernetes.io/version: 0.39.2\n    helm.sh/chart: thanos-17.3.1\n    app.kubernetes.io/component: query\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: thanos\n      app.kubernetes.io/component: query\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "256",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-thanos-query-frontend\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: thanos\n    app.kubernetes.io/version: 0.39.2\n    helm.sh/chart: thanos-17.3.1\n    app.kubernetes.io/component: query-frontend\nspec:\n  type: ExternalName\n  externalName: release-name-thanos-query-frontend.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "257",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-thanos-query-grpc\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: thanos\n    app.kubernetes.io/version: 0.39.2\n    helm.sh/chart: thanos-17.3.1\n    app.kubernetes.io/component: query\nspec:\n  type: ExternalName\n  externalName: release-name-thanos-query-grpc.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "258",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-thanos-query\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: thanos\n    app.kubernetes.io/version: 0.39.2\n    helm.sh/chart: thanos-17.3.1\n    app.kubernetes.io/component: query\nspec:\n  type: ExternalName\n  externalName: release-name-thanos-query.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "259",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-thanos-query-frontend\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: thanos\n    app.kubernetes.io/version: 0.39.2\n    helm.sh/chart: thanos-17.3.1\n    app.kubernetes.io/component: query-frontend\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  strategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: thanos\n      app.kubernetes.io/component: query-frontend\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: thanos\n        app.kubernetes.io/version: 0.39.2\n        helm.sh/chart: thanos-17.3.1\n        app.kubernetes.io/component: query-frontend\n    spec:\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: thanos\n                  app.kubernetes.io/component: query-frontend\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      containers:\n      - name: query-frontend\n        image: docker.io/bitnami/thanos:0.39.2-debian-12-r2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        args:\n        - query-frontend\n        - --log.level=info\n        - --log.format=logfmt\n        - --http-address=0.0.0.0:9090\n        - --query-frontend.downstream-url=http://release-name-thanos-query:9090\n        ports:\n        - name: http\n          containerPort: 9090\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 30\n          httpGet:\n            path: /-/healthy\n            port: http\n            scheme: HTTP\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 30\n          httpGet:\n            path: /-/ready\n            port: http\n            scheme: HTTP\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts: null\n      volumes: null\n",
    "errors": []
  },
  {
    "id": "260",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-thanos-query\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: thanos\n    app.kubernetes.io/version: 0.39.2\n    helm.sh/chart: thanos-17.3.1\n    app.kubernetes.io/component: query\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  strategy:\n    type: RollingUpdate\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: thanos\n      app.kubernetes.io/component: query\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: thanos\n        app.kubernetes.io/version: 0.39.2\n        helm.sh/chart: thanos-17.3.1\n        app.kubernetes.io/component: query\n    spec:\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: thanos\n                  app.kubernetes.io/component: query\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      containers:\n      - name: query\n        image: docker.io/bitnami/thanos:0.39.2-debian-12-r2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        args:\n        - query\n        - --log.level=info\n        - --log.format=logfmt\n        - --grpc-address=0.0.0.0:10901\n        - --http-address=0.0.0.0:10902\n        - --query.replica-label=replica\n        - --alert.query-url=http://release-name-thanos-query.default.svc.cluster.local:9090\n        ports:\n        - name: http\n          containerPort: 10902\n          protocol: TCP\n        - name: grpc\n          containerPort: 10901\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 30\n          httpGet:\n            path: /-/healthy\n            port: http\n            scheme: HTTP\n        readinessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 30\n          httpGet:\n            path: /-/ready\n            port: http\n            scheme: HTTP\n        resources:\n          limits:\n            cpu: 150m\n            ephemeral-storage: 2Gi\n            memory: 192Mi\n          requests:\n            cpu: 100m\n            ephemeral-storage: 50Mi\n            memory: 128Mi\n        volumeMounts: null\n      volumes: null\n",
    "errors": []
  },
  {
    "id": "261",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-22.0.2\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mariadb\n      app.kubernetes.io/component: primary\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "262",
    "policy_id": "pdb_unhealthy_eviction_policy",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: release-name-wordpress\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: wordpress\n    app.kubernetes.io/version: 6.8.3\n    helm.sh/chart: wordpress-27.0.7\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: wordpress\n  unhealthyPodEvictionPolicy: AlwaysAllow\n",
    "errors": []
  },
  {
    "id": "263",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-mariadb-headless\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-22.0.2\n    app.kubernetes.io/part-of: mariadb\nspec:\n  type: ExternalName\n  publishNotReadyAddresses: true\n  externalName: release-name-mariadb-headless.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "264",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-22.0.2\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\n  annotations: null\nspec:\n  type: ExternalName\n  sessionAffinity: None\n  externalName: release-name-mariadb.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "265",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-wordpress\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: wordpress\n    app.kubernetes.io/version: 6.8.3\n    helm.sh/chart: wordpress-27.0.7\nspec:\n  type: ExternalName\n  externalTrafficPolicy: Cluster\n  sessionAffinity: None\n  externalName: release-name-wordpress.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "266",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-wordpress\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: wordpress\n    app.kubernetes.io/version: 6.8.3\n    helm.sh/chart: wordpress-27.0.7\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: wordpress\n  strategy:\n    type: RollingUpdate\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: wordpress\n        app.kubernetes.io/version: 6.8.3\n        helm.sh/chart: wordpress-27.0.7\n    spec:\n      automountServiceAccountToken: false\n      hostAliases:\n      - hostnames:\n        - status.localhost\n        ip: 127.0.0.1\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: wordpress\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      serviceAccountName: release-name-wordpress\n      initContainers:\n      - name: prepare-base-dir\n        image: registry-1.docker.io/bitnami/wordpress:latest\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/liblog.sh\\n. /opt/bitnami/scripts/libfs.sh\\n\\\n          \\ninfo \\\"Copying base dir to empty dir\\\"\\n# In order to not break the application\\\n          \\ functionality (such as upgrades or plugins) we need\\n# to make the base\\\n          \\ directory writable, so we need to copy it to an empty dir volume\\ncp -r\\\n          \\ --preserve=mode /opt/bitnami/wordpress /emptydir/app-base-dir\\n\\ninfo\\\n          \\ \\\"Copying symlinks to stdout/stderr\\\"\\n# We copy the logs folder because\\\n          \\ it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/apache/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/apache/logs /emptydir/apache-logs-dir\\nfi\\n\\\n          \\ninfo \\\"Copying default PHP config\\\"\\ncp -r --preserve=mode /opt/bitnami/php/etc\\\n          \\ /emptydir/php-conf-dir\\n\\ninfo \\\"Copying php var directory\\\"\\nif ! is_dir_empty\\\n          \\ /opt/bitnami/php/var; then\\n  cp -r /opt/bitnami/php/var /emptydir/php-var-dir\\n\\\n          fi\\n\\ninfo \\\"Copy operation completed\\\"\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: wordpress\n        image: registry-1.docker.io/bitnami/wordpress:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'yes'\n        - name: WORDPRESS_SKIP_BOOTSTRAP\n          value: 'no'\n        - name: MARIADB_HOST\n          value: release-name-mariadb\n        - name: MARIADB_PORT_NUMBER\n          value: '3306'\n        - name: WORDPRESS_DATABASE_NAME\n          value: bitnami_wordpress\n        - name: WORDPRESS_DATABASE_USER\n          value: bn_wordpress\n        - name: WORDPRESS_DATABASE_PASSWORD_FILE\n          value: /secrets/mariadb-password\n        - name: WORDPRESS_USERNAME\n          value: user\n        - name: WORDPRESS_PASSWORD_FILE\n          value: /secrets/wordpress-password\n        - name: WORDPRESS_EMAIL\n          value: user@example.com\n        - name: WORDPRESS_FIRST_NAME\n          value: FirstName\n        - name: WORDPRESS_LAST_NAME\n          value: LastName\n        - name: WORDPRESS_HTACCESS_OVERRIDE_NONE\n          value: 'no'\n        - name: WORDPRESS_ENABLE_HTACCESS_PERSISTENCE\n          value: 'no'\n        - name: WORDPRESS_BLOG_NAME\n          value: User's Blog!\n        - name: WORDPRESS_TABLE_PREFIX\n          value: wp_\n        - name: WORDPRESS_SCHEME\n          value: http\n        - name: WORDPRESS_EXTRA_WP_CONFIG_CONTENT\n          value: ''\n        - name: WORDPRESS_PLUGINS\n          value: none\n        - name: WORDPRESS_OVERRIDE_DATABASE_SETTINGS\n          value: 'no'\n        - name: APACHE_HTTP_PORT_NUMBER\n          value: '8080'\n        - name: APACHE_HTTPS_PORT_NUMBER\n          value: '8443'\n        envFrom: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          tcpSocket:\n            port: http\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 6\n          httpGet:\n            httpHeaders: []\n            path: /wp-login.php\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/conf\n          subPath: apache-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/logs\n          subPath: apache-logs-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/var/run\n          subPath: apache-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/etc\n          subPath: php-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/tmp\n          subPath: php-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/var\n          subPath: php-var-dir\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/wordpress\n          subPath: app-base-dir\n        - mountPath: /bitnami/wordpress\n          name: wordpress-data\n          subPath: wordpress\n        - name: wordpress-secrets\n          mountPath: /secrets\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: wordpress-secrets\n        projected:\n          sources:\n          - secret:\n              name: release-name-wordpress\n          - secret:\n              name: release-name-mariadb\n      - name: wordpress-data\n        persistentVolumeClaim:\n          claimName: release-name-wordpress\n",
    "errors": []
  },
  {
    "id": "267",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-wordpress\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: wordpress\n    app.kubernetes.io/version: 6.8.3\n    helm.sh/chart: wordpress-27.0.7\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: wordpress\n  strategy:\n    type: RollingUpdate\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: wordpress\n        app.kubernetes.io/version: 6.8.3\n        helm.sh/chart: wordpress-27.0.7\n    spec:\n      automountServiceAccountToken: false\n      hostAliases:\n      - hostnames:\n        - status.localhost\n        ip: 127.0.0.1\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: wordpress\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      serviceAccountName: release-name-wordpress\n      initContainers:\n      - name: prepare-base-dir\n        image: registry-1.docker.io/bitnami/wordpress:latest\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/liblog.sh\\n. /opt/bitnami/scripts/libfs.sh\\n\\\n          \\ninfo \\\"Copying base dir to empty dir\\\"\\n# In order to not break the application\\\n          \\ functionality (such as upgrades or plugins) we need\\n# to make the base\\\n          \\ directory writable, so we need to copy it to an empty dir volume\\ncp -r\\\n          \\ --preserve=mode /opt/bitnami/wordpress /emptydir/app-base-dir\\n\\ninfo\\\n          \\ \\\"Copying symlinks to stdout/stderr\\\"\\n# We copy the logs folder because\\\n          \\ it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/apache/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/apache/logs /emptydir/apache-logs-dir\\nfi\\n\\\n          \\ninfo \\\"Copying default PHP config\\\"\\ncp -r --preserve=mode /opt/bitnami/php/etc\\\n          \\ /emptydir/php-conf-dir\\n\\ninfo \\\"Copying php var directory\\\"\\nif ! is_dir_empty\\\n          \\ /opt/bitnami/php/var; then\\n  cp -r /opt/bitnami/php/var /emptydir/php-var-dir\\n\\\n          fi\\n\\ninfo \\\"Copy operation completed\\\"\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: wordpress\n        image: registry-1.docker.io/bitnami/wordpress:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'yes'\n        - name: WORDPRESS_SKIP_BOOTSTRAP\n          value: 'no'\n        - name: MARIADB_HOST\n          value: release-name-mariadb\n        - name: MARIADB_PORT_NUMBER\n          value: '3306'\n        - name: WORDPRESS_DATABASE_NAME\n          value: bitnami_wordpress\n        - name: WORDPRESS_DATABASE_USER\n          value: bn_wordpress\n        - name: WORDPRESS_DATABASE_PASSWORD_FILE\n          value: /secrets/mariadb-password\n        - name: WORDPRESS_USERNAME\n          value: user\n        - name: WORDPRESS_PASSWORD_FILE\n          value: /secrets/wordpress-password\n        - name: WORDPRESS_EMAIL\n          value: user@example.com\n        - name: WORDPRESS_FIRST_NAME\n          value: FirstName\n        - name: WORDPRESS_LAST_NAME\n          value: LastName\n        - name: WORDPRESS_HTACCESS_OVERRIDE_NONE\n          value: 'no'\n        - name: WORDPRESS_ENABLE_HTACCESS_PERSISTENCE\n          value: 'no'\n        - name: WORDPRESS_BLOG_NAME\n          value: User's Blog!\n        - name: WORDPRESS_TABLE_PREFIX\n          value: wp_\n        - name: WORDPRESS_SCHEME\n          value: http\n        - name: WORDPRESS_EXTRA_WP_CONFIG_CONTENT\n          value: ''\n        - name: WORDPRESS_PLUGINS\n          value: none\n        - name: WORDPRESS_OVERRIDE_DATABASE_SETTINGS\n          value: 'no'\n        - name: APACHE_HTTP_PORT_NUMBER\n          value: '8080'\n        - name: APACHE_HTTPS_PORT_NUMBER\n          value: '8443'\n        envFrom: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          tcpSocket:\n            port: http\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 6\n          httpGet:\n            httpHeaders: []\n            path: /wp-login.php\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/conf\n          subPath: apache-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/logs\n          subPath: apache-logs-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/var/run\n          subPath: apache-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/etc\n          subPath: php-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/tmp\n          subPath: php-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/var\n          subPath: php-var-dir\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/wordpress\n          subPath: app-base-dir\n        - mountPath: /bitnami/wordpress\n          name: wordpress-data\n          subPath: wordpress\n        - name: wordpress-secrets\n          mountPath: /secrets\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: wordpress-secrets\n        projected:\n          sources:\n          - secret:\n              name: release-name-wordpress\n          - secret:\n              name: release-name-mariadb\n      - name: wordpress-data\n        persistentVolumeClaim:\n          claimName: release-name-wordpress\n",
    "errors": []
  },
  {
    "id": "268",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-wordpress\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: wordpress\n    app.kubernetes.io/version: 6.8.3\n    helm.sh/chart: wordpress-27.0.7\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: wordpress\n  strategy:\n    type: RollingUpdate\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: wordpress\n        app.kubernetes.io/version: 6.8.3\n        helm.sh/chart: wordpress-27.0.7\n    spec:\n      automountServiceAccountToken: false\n      hostAliases:\n      - hostnames:\n        - status.localhost\n        ip: 127.0.0.1\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: wordpress\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      serviceAccountName: default\n      initContainers:\n      - name: prepare-base-dir\n        image: registry-1.docker.io/bitnami/wordpress:latest\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/liblog.sh\\n. /opt/bitnami/scripts/libfs.sh\\n\\\n          \\ninfo \\\"Copying base dir to empty dir\\\"\\n# In order to not break the application\\\n          \\ functionality (such as upgrades or plugins) we need\\n# to make the base\\\n          \\ directory writable, so we need to copy it to an empty dir volume\\ncp -r\\\n          \\ --preserve=mode /opt/bitnami/wordpress /emptydir/app-base-dir\\n\\ninfo\\\n          \\ \\\"Copying symlinks to stdout/stderr\\\"\\n# We copy the logs folder because\\\n          \\ it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/apache/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/apache/logs /emptydir/apache-logs-dir\\nfi\\n\\\n          \\ninfo \\\"Copying default PHP config\\\"\\ncp -r --preserve=mode /opt/bitnami/php/etc\\\n          \\ /emptydir/php-conf-dir\\n\\ninfo \\\"Copying php var directory\\\"\\nif ! is_dir_empty\\\n          \\ /opt/bitnami/php/var; then\\n  cp -r /opt/bitnami/php/var /emptydir/php-var-dir\\n\\\n          fi\\n\\ninfo \\\"Copy operation completed\\\"\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: wordpress\n        image: registry-1.docker.io/bitnami/wordpress:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: ALLOW_EMPTY_PASSWORD\n          value: 'yes'\n        - name: WORDPRESS_SKIP_BOOTSTRAP\n          value: 'no'\n        - name: MARIADB_HOST\n          value: release-name-mariadb\n        - name: MARIADB_PORT_NUMBER\n          value: '3306'\n        - name: WORDPRESS_DATABASE_NAME\n          value: bitnami_wordpress\n        - name: WORDPRESS_DATABASE_USER\n          value: bn_wordpress\n        - name: WORDPRESS_DATABASE_PASSWORD_FILE\n          value: /secrets/mariadb-password\n        - name: WORDPRESS_USERNAME\n          value: user\n        - name: WORDPRESS_PASSWORD_FILE\n          value: /secrets/wordpress-password\n        - name: WORDPRESS_EMAIL\n          value: user@example.com\n        - name: WORDPRESS_FIRST_NAME\n          value: FirstName\n        - name: WORDPRESS_LAST_NAME\n          value: LastName\n        - name: WORDPRESS_HTACCESS_OVERRIDE_NONE\n          value: 'no'\n        - name: WORDPRESS_ENABLE_HTACCESS_PERSISTENCE\n          value: 'no'\n        - name: WORDPRESS_BLOG_NAME\n          value: User's Blog!\n        - name: WORDPRESS_TABLE_PREFIX\n          value: wp_\n        - name: WORDPRESS_SCHEME\n          value: http\n        - name: WORDPRESS_EXTRA_WP_CONFIG_CONTENT\n          value: ''\n        - name: WORDPRESS_PLUGINS\n          value: none\n        - name: WORDPRESS_OVERRIDE_DATABASE_SETTINGS\n          value: 'no'\n        - name: APACHE_HTTP_PORT_NUMBER\n          value: '8080'\n        - name: APACHE_HTTPS_PORT_NUMBER\n          value: '8443'\n        envFrom: null\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: https\n          containerPort: 8443\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          tcpSocket:\n            port: http\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 6\n          httpGet:\n            httpHeaders: []\n            path: /wp-login.php\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/conf\n          subPath: apache-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/logs\n          subPath: apache-logs-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/apache/var/run\n          subPath: apache-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/etc\n          subPath: php-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/tmp\n          subPath: php-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/php/var\n          subPath: php-var-dir\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/wordpress\n          subPath: app-base-dir\n        - mountPath: /bitnami/wordpress\n          name: wordpress-data\n          subPath: wordpress\n        - name: wordpress-secrets\n          mountPath: /secrets\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: wordpress-secrets\n        projected:\n          sources:\n          - secret:\n              name: release-name-wordpress\n          - secret:\n              name: release-name-mariadb\n      - name: wordpress-data\n        persistentVolumeClaim:\n          claimName: release-name-wordpress\n",
    "errors": []
  },
  {
    "id": "269",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-22.0.2\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mariadb\n      app.kubernetes.io/part-of: mariadb\n      app.kubernetes.io/component: primary\n  serviceName: release-name-mariadb-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/configuration: 99c5698089cb2d501d6285e8a852fa828778b04554e408ae7b3b77a77a839d84\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/version: 12.0.2\n        helm.sh/chart: mariadb-22.0.2\n        app.kubernetes.io/part-of: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: release-name-mariadb\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mariadb\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/mariadb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/mariadb/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/mariadb/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: mariadb\n        image: registry-1.docker.io/bitnami/mariadb:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MARIADB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-root-password\n        - name: MARIADB_USER\n          value: bn_wordpress\n        - name: MARIADB_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-password\n        - name: MARIADB_DATABASE\n          value: bitnami_wordpress\n        - name: MARIADB_ENABLE_SSL\n          value: 'no'\n        ports:\n        - name: mysql\n          containerPort: 3306\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin status -uroot -p\\\"${password_aux}\\\"\\n\"\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin ping -uroot -p\\\"${password_aux}\\\"\\n\"\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/mariadb\n        - name: config\n          mountPath: /opt/bitnami/mariadb/conf/my.cnf\n          subPath: my.cnf\n        - name: mariadb-credentials\n          mountPath: /opt/bitnami/mariadb/secrets/\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/logs\n          subPath: app-logs-dir\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: config\n        configMap:\n          name: release-name-mariadb\n      - name: mariadb-credentials\n        secret:\n          secretName: release-name-mariadb\n          items:\n          - key: mariadb-root-password\n            path: mariadb-root-password\n          - key: mariadb-password\n            path: mariadb-password\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "270",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-22.0.2\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mariadb\n      app.kubernetes.io/part-of: mariadb\n      app.kubernetes.io/component: primary\n  serviceName: release-name-mariadb-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/configuration: 99c5698089cb2d501d6285e8a852fa828778b04554e408ae7b3b77a77a839d84\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/version: 12.0.2\n        helm.sh/chart: mariadb-22.0.2\n        app.kubernetes.io/part-of: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: release-name-mariadb\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mariadb\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/mariadb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/mariadb/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/mariadb/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: mariadb\n        image: registry-1.docker.io/bitnami/mariadb:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MARIADB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-root-password\n        - name: MARIADB_USER\n          value: bn_wordpress\n        - name: MARIADB_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-password\n        - name: MARIADB_DATABASE\n          value: bitnami_wordpress\n        - name: MARIADB_ENABLE_SSL\n          value: 'no'\n        ports:\n        - name: mysql\n          containerPort: 3306\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin status -uroot -p\\\"${password_aux}\\\"\\n\"\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin ping -uroot -p\\\"${password_aux}\\\"\\n\"\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/mariadb\n        - name: config\n          mountPath: /opt/bitnami/mariadb/conf/my.cnf\n          subPath: my.cnf\n        - name: mariadb-credentials\n          mountPath: /opt/bitnami/mariadb/secrets/\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/logs\n          subPath: app-logs-dir\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: config\n        configMap:\n          name: release-name-mariadb\n      - name: mariadb-credentials\n        secret:\n          secretName: release-name-mariadb\n          items:\n          - key: mariadb-root-password\n            path: mariadb-root-password\n          - key: mariadb-password\n            path: mariadb-password\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "271",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-mariadb\n  namespace: default\n  labels:\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: mariadb\n    app.kubernetes.io/version: 12.0.2\n    helm.sh/chart: mariadb-22.0.2\n    app.kubernetes.io/part-of: mariadb\n    app.kubernetes.io/component: primary\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/name: mariadb\n      app.kubernetes.io/part-of: mariadb\n      app.kubernetes.io/component: primary\n  serviceName: release-name-mariadb-headless\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/configuration: 99c5698089cb2d501d6285e8a852fa828778b04554e408ae7b3b77a77a839d84\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/version: 12.0.2\n        helm.sh/chart: mariadb-22.0.2\n        app.kubernetes.io/part-of: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      automountServiceAccountToken: false\n      serviceAccountName: default\n      affinity:\n        podAffinity: null\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/instance: release-name\n                  app.kubernetes.io/name: mariadb\n                  app.kubernetes.io/component: primary\n              topologyKey: kubernetes.io/hostname\n            weight: 1\n        nodeAffinity: null\n      securityContext:\n        fsGroup: 1001\n        fsGroupChangePolicy: Always\n        supplementalGroups: []\n        sysctls: []\n      initContainers:\n      - name: preserve-logs-symlinks\n        image: registry-1.docker.io/bitnami/mariadb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        command:\n        - /bin/bash\n        args:\n        - -ec\n        - \"#!/bin/bash\\n\\n. /opt/bitnami/scripts/libfs.sh\\n# We copy the logs folder\\\n          \\ because it has symlinks to stdout and stderr\\nif ! is_dir_empty /opt/bitnami/mariadb/logs;\\\n          \\ then\\n  cp -r /opt/bitnami/mariadb/logs /emptydir/app-logs-dir\\nfi\\n\"\n        volumeMounts:\n        - name: empty-dir\n          mountPath: /emptydir\n      containers:\n      - name: mariadb\n        image: registry-1.docker.io/bitnami/mariadb:latest\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsGroup: 1001\n          runAsNonRoot: true\n          runAsUser: 1001\n          seLinuxOptions: {}\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MARIADB_ROOT_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-root-password\n        - name: MARIADB_USER\n          value: bn_wordpress\n        - name: MARIADB_PASSWORD_FILE\n          value: /opt/bitnami/mariadb/secrets/mariadb-password\n        - name: MARIADB_DATABASE\n          value: bitnami_wordpress\n        - name: MARIADB_ENABLE_SSL\n          value: 'no'\n        ports:\n        - name: mysql\n          containerPort: 3306\n        livenessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin status -uroot -p\\\"${password_aux}\\\"\\n\"\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n          exec:\n            command:\n            - /bin/bash\n            - -ec\n            - \"password_aux=\\\"${MARIADB_ROOT_PASSWORD:-}\\\"\\nif [[ -f \\\"${MARIADB_ROOT_PASSWORD_FILE:-}\\\"\\\n              \\ ]]; then\\n    password_aux=$(cat \\\"$MARIADB_ROOT_PASSWORD_FILE\\\")\\n\\\n              fi\\nmariadb-admin ping -uroot -p\\\"${password_aux}\\\"\\n\"\n        resources:\n          limits:\n            cpu: 375m\n            ephemeral-storage: 2Gi\n            memory: 384Mi\n          requests:\n            cpu: 250m\n            ephemeral-storage: 50Mi\n            memory: 256Mi\n        volumeMounts:\n        - name: data\n          mountPath: /bitnami/mariadb\n        - name: config\n          mountPath: /opt/bitnami/mariadb/conf/my.cnf\n          subPath: my.cnf\n        - name: mariadb-credentials\n          mountPath: /opt/bitnami/mariadb/secrets/\n        - name: empty-dir\n          mountPath: /tmp\n          subPath: tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/conf\n          subPath: app-conf-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/tmp\n          subPath: app-tmp-dir\n        - name: empty-dir\n          mountPath: /opt/bitnami/mariadb/logs\n          subPath: app-logs-dir\n      volumes:\n      - name: empty-dir\n        emptyDir: {}\n      - name: config\n        configMap:\n          name: release-name-mariadb\n      - name: mariadb-credentials\n        secret:\n          secretName: release-name-mariadb\n          items:\n          - key: mariadb-root-password\n            path: mariadb-root-password\n          - key: mariadb-password\n            path: mariadb-password\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n      labels:\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: mariadb\n        app.kubernetes.io/component: primary\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 8Gi\n",
    "errors": []
  },
  {
    "id": "272",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-cert-manager-cainjector\n  namespace: default\n  labels:\n    app: cainjector\n    app.kubernetes.io/name: cainjector\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: cainjector\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  type: ExternalName\n  externalName: release-name-cert-manager-cainjector.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "273",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-cert-manager\n  namespace: default\n  labels:\n    app: cert-manager\n    app.kubernetes.io/name: cert-manager\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  type: ExternalName\n  externalName: release-name-cert-manager.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "274",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: release-name-cert-manager-webhook\n  namespace: default\n  labels:\n    app: webhook\n    app.kubernetes.io/name: webhook\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: webhook\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  type: ExternalName\n  externalName: release-name-cert-manager-webhook.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "275",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager-cainjector\n  namespace: default\n  labels:\n    app: cainjector\n    app.kubernetes.io/name: cainjector\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: cainjector\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: cainjector\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: cainjector\n  template:\n    metadata:\n      labels:\n        app: cainjector\n        app.kubernetes.io/name: cainjector\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: cainjector\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: default\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-cainjector\n        image: quay.io/jetstack/cert-manager-cainjector:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --leader-election-namespace=kube-system\n        ports:\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "276",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager-cainjector\n  namespace: default\n  labels:\n    app: cainjector\n    app.kubernetes.io/name: cainjector\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: cainjector\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: cainjector\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: cainjector\n  template:\n    metadata:\n      labels:\n        app: cainjector\n        app.kubernetes.io/name: cainjector\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: cainjector\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: release-name-cert-manager-cainjector\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-cainjector\n        image: quay.io/jetstack/cert-manager-cainjector:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --leader-election-namespace=kube-system\n        ports:\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "277",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager-cainjector\n  namespace: default\n  labels:\n    app: cainjector\n    app.kubernetes.io/name: cainjector\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: cainjector\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: cainjector\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: cainjector\n  template:\n    metadata:\n      labels:\n        app: cainjector\n        app.kubernetes.io/name: cainjector\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: cainjector\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: release-name-cert-manager-cainjector\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-cainjector\n        image: quay.io/jetstack/cert-manager-cainjector:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --leader-election-namespace=kube-system\n        ports:\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "278",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager\n  namespace: default\n  labels:\n    app: cert-manager\n    app.kubernetes.io/name: cert-manager\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: cert-manager\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: controller\n  template:\n    metadata:\n      labels:\n        app: cert-manager\n        app.kubernetes.io/name: cert-manager\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: default\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-controller\n        image: quay.io/jetstack/cert-manager-controller:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --cluster-resource-namespace=$(POD_NAMESPACE)\n        - --leader-election-namespace=kube-system\n        - --acme-http01-solver-image=quay.io/jetstack/cert-manager-acmesolver:v1.19.0\n        - --max-concurrent-challenges=60\n        ports:\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        - containerPort: 9403\n          name: http-healthz\n          protocol: TCP\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        livenessProbe:\n          httpGet:\n            port: http-healthz\n            path: /livez\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 8\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "279",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager\n  namespace: default\n  labels:\n    app: cert-manager\n    app.kubernetes.io/name: cert-manager\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: cert-manager\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: controller\n  template:\n    metadata:\n      labels:\n        app: cert-manager\n        app.kubernetes.io/name: cert-manager\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: release-name-cert-manager\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-controller\n        image: quay.io/jetstack/cert-manager-controller:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --cluster-resource-namespace=$(POD_NAMESPACE)\n        - --leader-election-namespace=kube-system\n        - --acme-http01-solver-image=quay.io/jetstack/cert-manager-acmesolver:v1.19.0\n        - --max-concurrent-challenges=60\n        ports:\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        - containerPort: 9403\n          name: http-healthz\n          protocol: TCP\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        livenessProbe:\n          httpGet:\n            port: http-healthz\n            path: /livez\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 8\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "280",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager\n  namespace: default\n  labels:\n    app: cert-manager\n    app.kubernetes.io/name: cert-manager\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: cert-manager\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: controller\n  template:\n    metadata:\n      labels:\n        app: cert-manager\n        app.kubernetes.io/name: cert-manager\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: release-name-cert-manager\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-controller\n        image: quay.io/jetstack/cert-manager-controller:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --cluster-resource-namespace=$(POD_NAMESPACE)\n        - --leader-election-namespace=kube-system\n        - --acme-http01-solver-image=quay.io/jetstack/cert-manager-acmesolver:v1.19.0\n        - --max-concurrent-challenges=60\n        ports:\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        - containerPort: 9403\n          name: http-healthz\n          protocol: TCP\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        livenessProbe:\n          httpGet:\n            port: http-healthz\n            path: /livez\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 8\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "281",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager-webhook\n  namespace: default\n  labels:\n    app: webhook\n    app.kubernetes.io/name: webhook\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: webhook\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: webhook\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: webhook\n  template:\n    metadata:\n      labels:\n        app: webhook\n        app.kubernetes.io/name: webhook\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: webhook\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: default\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-webhook\n        image: quay.io/jetstack/cert-manager-webhook:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --secure-port=10250\n        - --dynamic-serving-ca-secret-namespace=$(POD_NAMESPACE)\n        - --dynamic-serving-ca-secret-name=release-name-cert-manager-webhook-ca\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook.$(POD_NAMESPACE)\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook.$(POD_NAMESPACE).svc\n        ports:\n        - name: https\n          protocol: TCP\n          containerPort: 10250\n        - name: healthcheck\n          protocol: TCP\n          containerPort: 6080\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /livez\n            port: healthcheck\n            scheme: HTTP\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: healthcheck\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "282",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager-webhook\n  namespace: default\n  labels:\n    app: webhook\n    app.kubernetes.io/name: webhook\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: webhook\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: webhook\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: webhook\n  template:\n    metadata:\n      labels:\n        app: webhook\n        app.kubernetes.io/name: webhook\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: webhook\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: release-name-cert-manager-webhook\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-webhook\n        image: quay.io/jetstack/cert-manager-webhook:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --secure-port=10250\n        - --dynamic-serving-ca-secret-namespace=$(POD_NAMESPACE)\n        - --dynamic-serving-ca-secret-name=release-name-cert-manager-webhook-ca\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook.$(POD_NAMESPACE)\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook.$(POD_NAMESPACE).svc\n        ports:\n        - name: https\n          protocol: TCP\n          containerPort: 10250\n        - name: healthcheck\n          protocol: TCP\n          containerPort: 6080\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /livez\n            port: healthcheck\n            scheme: HTTP\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: healthcheck\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "283",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-cert-manager-webhook\n  namespace: default\n  labels:\n    app: webhook\n    app.kubernetes.io/name: webhook\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: webhook\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: webhook\n      app.kubernetes.io/instance: release-name\n      app.kubernetes.io/component: webhook\n  template:\n    metadata:\n      labels:\n        app: webhook\n        app.kubernetes.io/name: webhook\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: webhook\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n      annotations:\n        prometheus.io/path: /metrics\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9402'\n    spec:\n      serviceAccountName: release-name-cert-manager-webhook\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-webhook\n        image: quay.io/jetstack/cert-manager-webhook:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=2\n        - --secure-port=10250\n        - --dynamic-serving-ca-secret-namespace=$(POD_NAMESPACE)\n        - --dynamic-serving-ca-secret-name=release-name-cert-manager-webhook-ca\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook.$(POD_NAMESPACE)\n        - --dynamic-serving-dns-names=release-name-cert-manager-webhook.$(POD_NAMESPACE).svc\n        ports:\n        - name: https\n          protocol: TCP\n          containerPort: 10250\n        - name: healthcheck\n          protocol: TCP\n          containerPort: 6080\n        - containerPort: 9402\n          name: http-metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /livez\n            port: healthcheck\n            scheme: HTTP\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: healthcheck\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "284",
    "policy_id": "job_ttl_after_finished",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-cert-manager-startupapicheck\n  namespace: default\n  labels:\n    app: startupapicheck\n    app.kubernetes.io/name: startupapicheck\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: startupapicheck\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\n  annotations:\n    helm.sh/hook: post-install\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '1'\nspec:\n  backoffLimit: 4\n  template:\n    metadata:\n      labels:\n        app: startupapicheck\n        app.kubernetes.io/name: startupapicheck\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: startupapicheck\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n    spec:\n      restartPolicy: OnFailure\n      serviceAccountName: release-name-cert-manager-startupapicheck\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-startupapicheck\n        image: quay.io/jetstack/cert-manager-startupapicheck:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - check\n        - api\n        - --wait=1m\n        - -v\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n      nodeSelector:\n        kubernetes.io/os: linux\n  ttlSecondsAfterFinished: 3600\n",
    "errors": []
  },
  {
    "id": "285",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-cert-manager-startupapicheck\n  namespace: default\n  labels:\n    app: startupapicheck\n    app.kubernetes.io/name: startupapicheck\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: startupapicheck\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\n  annotations:\n    helm.sh/hook: post-install\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '1'\nspec:\n  backoffLimit: 4\n  template:\n    metadata:\n      labels:\n        app: startupapicheck\n        app.kubernetes.io/name: startupapicheck\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: startupapicheck\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n    spec:\n      restartPolicy: OnFailure\n      serviceAccountName: default\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-startupapicheck\n        image: quay.io/jetstack/cert-manager-startupapicheck:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - check\n        - api\n        - --wait=1m\n        - -v\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "286",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-cert-manager-startupapicheck\n  namespace: default\n  labels:\n    app: startupapicheck\n    app.kubernetes.io/name: startupapicheck\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: startupapicheck\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\n  annotations:\n    helm.sh/hook: post-install\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '1'\nspec:\n  backoffLimit: 4\n  template:\n    metadata:\n      labels:\n        app: startupapicheck\n        app.kubernetes.io/name: startupapicheck\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: startupapicheck\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n    spec:\n      restartPolicy: OnFailure\n      serviceAccountName: release-name-cert-manager-startupapicheck\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-startupapicheck\n        image: quay.io/jetstack/cert-manager-startupapicheck:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - check\n        - api\n        - --wait=1m\n        - -v\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "287",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: release-name-cert-manager-startupapicheck\n  namespace: default\n  labels:\n    app: startupapicheck\n    app.kubernetes.io/name: startupapicheck\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/component: startupapicheck\n    app.kubernetes.io/version: v1.19.0\n    app.kubernetes.io/managed-by: Helm\n    helm.sh/chart: cert-manager-v1.19.0\n  annotations:\n    helm.sh/hook: post-install\n    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded\n    helm.sh/hook-weight: '1'\nspec:\n  backoffLimit: 4\n  template:\n    metadata:\n      labels:\n        app: startupapicheck\n        app.kubernetes.io/name: startupapicheck\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/component: startupapicheck\n        app.kubernetes.io/version: v1.19.0\n        app.kubernetes.io/managed-by: Helm\n        helm.sh/chart: cert-manager-v1.19.0\n    spec:\n      restartPolicy: OnFailure\n      serviceAccountName: release-name-cert-manager-startupapicheck\n      enableServiceLinks: false\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: cert-manager-startupapicheck\n        image: quay.io/jetstack/cert-manager-startupapicheck:v1.19.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - check\n        - api\n        - --wait=1m\n        - -v\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      nodeSelector:\n        kubernetes.io/os: linux\n",
    "errors": []
  },
  {
    "id": "288",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: cilium-envoy\n  namespace: default\n  annotations:\n    prometheus.io/scrape: 'true'\n    prometheus.io/port: '9964'\n  labels:\n    k8s-app: cilium-envoy\n    app.kubernetes.io/name: cilium-envoy\n    app.kubernetes.io/part-of: cilium\n    io.cilium/app: proxy\nspec:\n  type: ExternalName\n  externalName: cilium-envoy.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "289",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: hubble-peer\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: hubble-peer\nspec:\n  internalTrafficPolicy: Local\n  type: ExternalName\n  externalName: hubble-peer.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "290",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - IPC_LOCK\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "291",
    "policy_id": "no_host_network",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n  hostNetwork: false\n",
    "errors": []
  },
  {
    "id": "293",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "294",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "295",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "296",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "297",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "298",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "299",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "300",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: default\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "301",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - IPC_LOCK\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "302",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - IPC_LOCK\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "303",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - IPC_LOCK\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "304",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - IPC_LOCK\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "305",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - IPC_LOCK\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "306",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "308",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "309",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "310",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "311",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "312",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "313",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "314",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "315",
    "policy_id": "no_host_path",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "patched_yaml": null,
    "errors": [
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath"
    ]
  },
  {
    "id": "316",
    "policy_id": "no_host_path",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "patched_yaml": null,
    "errors": [
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath",
      "volume still references hostPath"
    ]
  },
  {
    "id": "318",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "319",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "320",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "321",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  },
  {
    "id": "322",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: default\n  labels:\n    k8s-app: cilium\n    app.kubernetes.io/part-of: cilium\n    app.kubernetes.io/name: cilium-agent\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n  updateStrategy:\n    rollingUpdate:\n      maxUnavailable: 2\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: cilium-agent\n      labels:\n        k8s-app: cilium\n        app.kubernetes.io/name: cilium-agent\n        app.kubernetes.io/part-of: cilium\n    spec:\n      securityContext:\n        appArmorProfile:\n          type: Unconfined\n        seccompProfile:\n          type: Unconfined\n      containers:\n      - name: cilium-agent\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-agent\n        args:\n        - --config-dir=/tmp/cilium/config-map\n        startupProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          failureThreshold: 300\n          periodSeconds: 2\n          successThreshold: 1\n          initialDelaySeconds: 5\n        livenessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n            - name: require-k8s-connectivity\n              value: 'false'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            host: 127.0.0.1\n            path: /healthz\n            port: 9879\n            scheme: HTTP\n            httpHeaders:\n            - name: brief\n              value: 'true'\n          periodSeconds: 30\n          successThreshold: 1\n          failureThreshold: 3\n          timeoutSeconds: 5\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: GOMEMLIMIT\n          valueFrom:\n            resourceFieldRef:\n              resource: limits.memory\n              divisor: '1'\n        - name: KUBE_CLIENT_BACKOFF_BASE\n          value: '1'\n        - name: KUBE_CLIENT_BACKOFF_DURATION\n          value: '120'\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - bash\n              - -c\n              - \"set -o errexit\\nset -o pipefail\\nset -o nounset\\n\\n# When running\\\n                \\ in AWS ENI mode, it's likely that 'aws-node' has\\n# had a chance\\\n                \\ to install SNAT iptables rules. These can result\\n# in dropped traffic,\\\n                \\ so we should attempt to remove them.\\n# We do it using a 'postStart'\\\n                \\ hook since this may need to run\\n# for nodes which might have already\\\n                \\ been init'ed but may still\\n# have dangling rules. This is safe\\\n                \\ because there are no\\n# dependencies on anything that is part of\\\n                \\ the startup script\\n# itself, and can be safely run multiple times\\\n                \\ per node (e.g. in\\n# case of a restart).\\nif [[ \\\"$(iptables-save\\\n                \\ | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')\\\" != \\\"0\\\" ]];\\n\\\n                then\\n    echo 'Deleting iptables rules created by the AWS CNI VPC\\\n                \\ plugin'\\n    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN'\\\n                \\ | iptables-restore\\nfi\\necho 'Done!'\\n\"\n          preStop:\n            exec:\n              command:\n              - /cni-uninstall.sh\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - CHOWN\n            - KILL\n            - NET_ADMIN\n            - NET_RAW\n            - IPC_LOCK\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            - DAC_OVERRIDE\n            - FOWNER\n            - SETGID\n            - SETUID\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: envoy-sockets\n          mountPath: /var/run/cilium/envoy/sockets\n          readOnly: false\n        - mountPath: /host/proc/sys/net\n          name: host-proc-sys-net\n        - mountPath: /host/proc/sys/kernel\n          name: host-proc-sys-kernel\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cilium-netns\n          mountPath: /var/run/cilium/netns\n          mountPropagation: HostToContainer\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: xtables-lock\n          mountPath: /run/xtables.lock\n        - name: hubble-tls\n          mountPath: /var/lib/cilium/tls/hubble\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: config\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - cilium-dbg\n        - build-config\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-cgroup\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: CGROUP_ROOT\n          value: /run/cilium/cgroupv2\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-mount /hostbin/cilium-mount;\n\n          nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-mount\"\n          $CGROUP_ROOT;\n\n          rm /hostbin/cilium-mount\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: apply-sysctl-overwrites\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIN_PATH\n          value: /opt/cni/bin\n        command:\n        - sh\n        - -ec\n        - 'cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;\n\n          nsenter --mount=/hostproc/1/ns/mnt \"${BIN_PATH}/cilium-sysctlfix\";\n\n          rm /hostbin/cilium-sysctlfix\n\n          '\n        volumeMounts:\n        - name: hostproc\n          mountPath: /hostproc\n        - name: cni-path\n          mountPath: /hostbin\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - SYS_ADMIN\n            - SYS_CHROOT\n            - SYS_PTRACE\n            drop:\n            - ALL\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: mount-bpf-fs\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        args:\n        - mount | grep \"/sys/fs/bpf type bpf\" || mount -t bpf bpf /sys/fs/bpf\n        command:\n        - /bin/bash\n        - -c\n        - --\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n          mountPropagation: Bidirectional\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: clean-cilium-state\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-state\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: clean-cilium-bpf-state\n              optional: true\n        - name: WRITE_CNI_CONF_WHEN_READY\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: write-cni-conf-when-ready\n              optional: true\n        terminationMessagePolicy: FallbackToLogsOnError\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_MODULE\n            - SYS_ADMIN\n            - SYS_RESOURCE\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-cgroup\n          mountPath: /run/cilium/cgroupv2\n          mountPropagation: HostToContainer\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: install-cni-binaries\n        image: quay.io/cilium/cilium:v1.19.0-pre.1@sha256:202e41af73c0b8b772d1847c67b4d3f7d13f075fae16fa4ad9f6edd553d4f6f4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /install-plugin.sh\n        resources:\n          requests:\n            cpu: 100m\n            memory: 10Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          seLinuxOptions:\n            level: s0\n            type: spc_t\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        terminationMessagePolicy: FallbackToLogsOnError\n        volumeMounts:\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n      restartPolicy: Always\n      priorityClassName: system-node-critical\n      serviceAccountName: cilium\n      automountServiceAccountToken: true\n      terminationGracePeriodSeconds: 1\n      hostNetwork: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: cilium\n            topologyKey: kubernetes.io/hostname\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: cilium-netns\n        hostPath:\n          path: /var/run/netns\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: hostproc\n        hostPath:\n          path: /proc\n          type: Directory\n      - name: cilium-cgroup\n        hostPath:\n          path: /run/cilium/cgroupv2\n          type: DirectoryOrCreate\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: xtables-lock\n        hostPath:\n          path: /run/xtables.lock\n          type: FileOrCreate\n      - name: envoy-sockets\n        hostPath:\n          path: /var/run/cilium/envoy/sockets\n          type: DirectoryOrCreate\n      - name: clustermesh-secrets\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: cilium-clustermesh\n              optional: true\n          - secret:\n              name: clustermesh-apiserver-remote-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: common-etcd-client.key\n              - key: tls.crt\n                path: common-etcd-client.crt\n              - key: ca.crt\n                path: common-etcd-client-ca.crt\n          - secret:\n              name: clustermesh-apiserver-local-cert\n              optional: true\n              items:\n              - key: tls.key\n                path: local-etcd-client.key\n              - key: tls.crt\n                path: local-etcd-client.crt\n              - key: ca.crt\n                path: local-etcd-client-ca.crt\n      - name: host-proc-sys-net\n        hostPath:\n          path: /proc/sys/net\n          type: Directory\n      - name: host-proc-sys-kernel\n        hostPath:\n          path: /proc/sys/kernel\n          type: Directory\n      - name: hubble-tls\n        projected:\n          defaultMode: 256\n          sources:\n          - secret:\n              name: hubble-server-certs\n              optional: true\n              items:\n              - key: tls.crt\n                path: server.crt\n              - key: tls.key\n                path: server.key\n              - key: ca.crt\n                path: client-ca.crt\n",
    "errors": []
  }
]