[
  {
    "id": "01876",
    "manifest_path": "data/manifests/the_stack_sample/sample_0664.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.118\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - make apply || make failed\n        command:\n        - /bin/sh\n        - -c\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: JX_SECRET_SIDECAR\n          value: gsm\n        - name: JX_SECRET_TMP_DIR\n          value: /workspace/source/.jx-secrets\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        image: gcr.io/jenkinsxio/jx-boot:3.1.118\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      - command:\n        - versionStream/src/wait-for-complete.sh\n        image: google/cloud-sdk:slim\n        imagePullPolicy: Always\n        name: gsm\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"job\" has cpu request 0"
  },
  {
    "id": "01877",
    "manifest_path": "data/manifests/the_stack_sample/sample_0664.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.118\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - make apply || make failed\n        command:\n        - /bin/sh\n        - -c\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: JX_SECRET_SIDECAR\n          value: gsm\n        - name: JX_SECRET_TMP_DIR\n          value: /workspace/source/.jx-secrets\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        image: gcr.io/jenkinsxio/jx-boot:3.1.118\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      - command:\n        - versionStream/src/wait-for-complete.sh\n        image: google/cloud-sdk:slim\n        imagePullPolicy: Always\n        name: gsm\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"git-clone\" has memory limit 0"
  },
  {
    "id": "01878",
    "manifest_path": "data/manifests/the_stack_sample/sample_0664.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.118\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - make apply || make failed\n        command:\n        - /bin/sh\n        - -c\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: JX_SECRET_SIDECAR\n          value: gsm\n        - name: JX_SECRET_TMP_DIR\n          value: /workspace/source/.jx-secrets\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        image: gcr.io/jenkinsxio/jx-boot:3.1.118\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      - command:\n        - versionStream/src/wait-for-complete.sh\n        image: google/cloud-sdk:slim\n        imagePullPolicy: Always\n        name: gsm\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"gsm\" has memory limit 0"
  },
  {
    "id": "01879",
    "manifest_path": "data/manifests/the_stack_sample/sample_0664.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app: jx-boot\n    jenkins-x.io/kind: jx-git-operator\nspec:\n  template:\n    metadata:\n      labels:\n        app: jx-boot\n        jenkins-x.io/kind: jx-git-operator\n    spec:\n      initContainers:\n      - args:\n        - gitops\n        - git\n        - clone\n        command:\n        - jx\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        image: gcr.io/jenkinsxio/jx-boot:3.1.118\n        name: git-clone\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace\n      containers:\n      - args:\n        - make apply || make failed\n        command:\n        - /bin/sh\n        - -c\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /workspace/xdg_config\n        - name: JX_SECRET_SIDECAR\n          value: gsm\n        - name: JX_SECRET_TMP_DIR\n          value: /workspace/source/.jx-secrets\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        image: gcr.io/jenkinsxio/jx-boot:3.1.118\n        imagePullPolicy: Always\n        name: job\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      - command:\n        - versionStream/src/wait-for-complete.sh\n        image: google/cloud-sdk:slim\n        imagePullPolicy: Always\n        name: gsm\n        volumeMounts:\n        - mountPath: /workspace\n          name: workspace-volume\n        workingDir: /workspace/source\n      serviceAccountName: jx-boot-job\n      volumes:\n      - name: workspace-volume\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"job\" has memory limit 0"
  },
  {
    "id": "01880",
    "manifest_path": "data/manifests/the_stack_sample/sample_0665.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210615-cf184f2204\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sinker\" does not have a read-only root file system"
  },
  {
    "id": "01881",
    "manifest_path": "data/manifests/the_stack_sample/sample_0665.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210615-cf184f2204\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sinker\" is not set to runAsNonRoot"
  },
  {
    "id": "01882",
    "manifest_path": "data/manifests/the_stack_sample/sample_0665.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210615-cf184f2204\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sinker\" has cpu request 0"
  },
  {
    "id": "01883",
    "manifest_path": "data/manifests/the_stack_sample/sample_0665.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210615-cf184f2204\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sinker\" has memory limit 0"
  },
  {
    "id": "01884",
    "manifest_path": "data/manifests/the_stack_sample/sample_0666.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.7.2\n    app.kubernetes.io/version: 1.7.2\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jx-pipelines-visualizer\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.7.2\n        app.kubernetes.io/version: 1.7.2\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: ghcr.io/jenkins-x/jx-pipelines-visualizer:1.7.2\n        args:\n        - -namespace\n        - jx\n        - -resync-interval\n        - 60s\n        - -archived-logs-url-template\n        - gs://logs-tf-jx-glowing-seagull-7f4cd57c6d2a/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.log\n        - -archived-pipelines-url-template\n        - gs://logs-tf-jx-glowing-seagull-7f4cd57c6d2a/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.yaml\n        - -archived-pipelineruns-url-template\n        - gs://logs-tf-jx-glowing-seagull-7f4cd57c6d2a/jenkins-x/pipelineruns/{{.Namespace}}/{{.Name}}.yaml\n        - -pipeline-trace-url-template\n        - http://grafana-jx-observability.34.72.245.235.nip.io/explore?left=%5B%22now%22,%22now%22,%22Tempo%22,%7B%22query%22:%22{{.TraceID}}%22%7D%5D\n        - -log-level\n        - INFO\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jx-pipelines-visualizer\" does not have a read-only root file system"
  },
  {
    "id": "01885",
    "manifest_path": "data/manifests/the_stack_sample/sample_0666.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.7.2\n    app.kubernetes.io/version: 1.7.2\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jx-pipelines-visualizer\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.7.2\n        app.kubernetes.io/version: 1.7.2\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: ghcr.io/jenkins-x/jx-pipelines-visualizer:1.7.2\n        args:\n        - -namespace\n        - jx\n        - -resync-interval\n        - 60s\n        - -archived-logs-url-template\n        - gs://logs-tf-jx-glowing-seagull-7f4cd57c6d2a/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.log\n        - -archived-pipelines-url-template\n        - gs://logs-tf-jx-glowing-seagull-7f4cd57c6d2a/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.yaml\n        - -archived-pipelineruns-url-template\n        - gs://logs-tf-jx-glowing-seagull-7f4cd57c6d2a/jenkins-x/pipelineruns/{{.Namespace}}/{{.Name}}.yaml\n        - -pipeline-trace-url-template\n        - http://grafana-jx-observability.34.72.245.235.nip.io/explore?left=%5B%22now%22,%22now%22,%22Tempo%22,%7B%22query%22:%22{{.TraceID}}%22%7D%5D\n        - -log-level\n        - INFO\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jx-pipelines-visualizer\" is not set to runAsNonRoot"
  },
  {
    "id": "01886",
    "manifest_path": "data/manifests/the_stack_sample/sample_0671.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: assisted-service\n  namespace: REPLACE_NAMESPACE\nspec:\n  selector:\n    matchLabels:\n      app: assisted-service\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: assisted-service\n    spec:\n      containers:\n      - name: assisted-service\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 400Mi\n        image: REPLACE_IMAGE\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8090\n        envFrom:\n        - configMapRef:\n            name: assisted-service-config\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.password\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.user\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              key: aws_secret_access_key\n              name: assisted-installer-s3\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              key: aws_access_key_id\n              name: assisted-installer-s3\n        - name: S3_REGION\n          valueFrom:\n            secretKeyRef:\n              key: aws_region\n              name: assisted-installer-s3\n        - name: S3_BUCKET\n          valueFrom:\n            secretKeyRef:\n              key: bucket\n              name: assisted-installer-s3\n        - name: S3_ENDPOINT_URL\n          valueFrom:\n            secretKeyRef:\n              key: endpoint\n              name: assisted-installer-s3\n        volumeMounts:\n        - name: route53-creds\n          mountPath: /.aws\n          readOnly: true\n      volumes:\n      - name: route53-creds\n        secret:\n          secretName: route53-creds\n          optional: true\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"assisted-service\" is using an invalid container image, \"REPLACE_IMAGE\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01887",
    "manifest_path": "data/manifests/the_stack_sample/sample_0671.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: assisted-service\n  namespace: REPLACE_NAMESPACE\nspec:\n  selector:\n    matchLabels:\n      app: assisted-service\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: assisted-service\n    spec:\n      containers:\n      - name: assisted-service\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 400Mi\n        image: REPLACE_IMAGE\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8090\n        envFrom:\n        - configMapRef:\n            name: assisted-service-config\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.password\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.user\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              key: aws_secret_access_key\n              name: assisted-installer-s3\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              key: aws_access_key_id\n              name: assisted-installer-s3\n        - name: S3_REGION\n          valueFrom:\n            secretKeyRef:\n              key: aws_region\n              name: assisted-installer-s3\n        - name: S3_BUCKET\n          valueFrom:\n            secretKeyRef:\n              key: bucket\n              name: assisted-installer-s3\n        - name: S3_ENDPOINT_URL\n          valueFrom:\n            secretKeyRef:\n              key: endpoint\n              name: assisted-installer-s3\n        volumeMounts:\n        - name: route53-creds\n          mountPath: /.aws\n          readOnly: true\n      volumes:\n      - name: route53-creds\n        secret:\n          secretName: route53-creds\n          optional: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"assisted-service\" does not have a read-only root file system"
  },
  {
    "id": "01888",
    "manifest_path": "data/manifests/the_stack_sample/sample_0671.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: assisted-service\n  namespace: REPLACE_NAMESPACE\nspec:\n  selector:\n    matchLabels:\n      app: assisted-service\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: assisted-service\n    spec:\n      containers:\n      - name: assisted-service\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 400Mi\n        image: REPLACE_IMAGE\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8090\n        envFrom:\n        - configMapRef:\n            name: assisted-service-config\n        env:\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.host\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.name\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.password\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: assisted-installer-rds\n              key: db.user\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              key: aws_secret_access_key\n              name: assisted-installer-s3\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              key: aws_access_key_id\n              name: assisted-installer-s3\n        - name: S3_REGION\n          valueFrom:\n            secretKeyRef:\n              key: aws_region\n              name: assisted-installer-s3\n        - name: S3_BUCKET\n          valueFrom:\n            secretKeyRef:\n              key: bucket\n              name: assisted-installer-s3\n        - name: S3_ENDPOINT_URL\n          valueFrom:\n            secretKeyRef:\n              key: endpoint\n              name: assisted-installer-s3\n        volumeMounts:\n        - name: route53-creds\n          mountPath: /.aws\n          readOnly: true\n      volumes:\n      - name: route53-creds\n        secret:\n          secretName: route53-creds\n          optional: true\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"assisted-service\" is not set to runAsNonRoot"
  },
  {
    "id": "01889",
    "manifest_path": "data/manifests/the_stack_sample/sample_0675.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod3\n  namespace: ns3\n  labels:\n    app: my-label-1\nspec:\n  containers:\n  - name: container1\n    image: sadedil/simpleinfoserver:1.0.0\n    ports:\n    - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"container1\" does not have a read-only root file system"
  },
  {
    "id": "01890",
    "manifest_path": "data/manifests/the_stack_sample/sample_0675.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod3\n  namespace: ns3\n  labels:\n    app: my-label-1\nspec:\n  containers:\n  - name: container1\n    image: sadedil/simpleinfoserver:1.0.0\n    ports:\n    - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"container1\" is not set to runAsNonRoot"
  },
  {
    "id": "01891",
    "manifest_path": "data/manifests/the_stack_sample/sample_0675.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod3\n  namespace: ns3\n  labels:\n    app: my-label-1\nspec:\n  containers:\n  - name: container1\n    image: sadedil/simpleinfoserver:1.0.0\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"container1\" has cpu request 0"
  },
  {
    "id": "01892",
    "manifest_path": "data/manifests/the_stack_sample/sample_0675.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod3\n  namespace: ns3\n  labels:\n    app: my-label-1\nspec:\n  containers:\n  - name: container1\n    image: sadedil/simpleinfoserver:1.0.0\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"container1\" has memory limit 0"
  },
  {
    "id": "01893",
    "manifest_path": "data/manifests/the_stack_sample/sample_0676.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pluscode-no-priority\nspec:\n  replicas: 15\n  selector:\n    matchLabels:\n      app: pluscode-no-priority\n  template:\n    metadata:\n      labels:\n        app: pluscode-no-priority\n    spec:\n      containers:\n      - name: pluscode-container\n        image: wdenniss/pluscode-demo:latest\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"pluscode-container\" is using an invalid container image, \"wdenniss/pluscode-demo:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01894",
    "manifest_path": "data/manifests/the_stack_sample/sample_0676.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pluscode-no-priority\nspec:\n  replicas: 15\n  selector:\n    matchLabels:\n      app: pluscode-no-priority\n  template:\n    metadata:\n      labels:\n        app: pluscode-no-priority\n    spec:\n      containers:\n      - name: pluscode-container\n        image: wdenniss/pluscode-demo:latest\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"pluscode-container\" does not have a read-only root file system"
  },
  {
    "id": "01895",
    "manifest_path": "data/manifests/the_stack_sample/sample_0676.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pluscode-no-priority\nspec:\n  replicas: 15\n  selector:\n    matchLabels:\n      app: pluscode-no-priority\n  template:\n    metadata:\n      labels:\n        app: pluscode-no-priority\n    spec:\n      containers:\n      - name: pluscode-container\n        image: wdenniss/pluscode-demo:latest\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"pluscode-container\" is not set to runAsNonRoot"
  },
  {
    "id": "01896",
    "manifest_path": "data/manifests/the_stack_sample/sample_0676.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pluscode-no-priority\nspec:\n  replicas: 15\n  selector:\n    matchLabels:\n      app: pluscode-no-priority\n  template:\n    metadata:\n      labels:\n        app: pluscode-no-priority\n    spec:\n      containers:\n      - name: pluscode-container\n        image: wdenniss/pluscode-demo:latest\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"pluscode-container\" has memory limit 0"
  },
  {
    "id": "01897",
    "manifest_path": "data/manifests/the_stack_sample/sample_0680.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ansible-tower\n  namespace: tower\nspec:\n  selector:\n    matchLabels:\n      app: ansible-tower\n      version: v1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ansible-tower\n        version: v1\n    spec:\n      containers:\n      - name: tower\n        image: dynatraceacm/ansibletower:3.3.1-1-2\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"tower\" does not have a read-only root file system"
  },
  {
    "id": "01898",
    "manifest_path": "data/manifests/the_stack_sample/sample_0680.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ansible-tower\n  namespace: tower\nspec:\n  selector:\n    matchLabels:\n      app: ansible-tower\n      version: v1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ansible-tower\n        version: v1\n    spec:\n      containers:\n      - name: tower\n        image: dynatraceacm/ansibletower:3.3.1-1-2\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"tower\" is not set to runAsNonRoot"
  },
  {
    "id": "01899",
    "manifest_path": "data/manifests/the_stack_sample/sample_0680.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ansible-tower\n  namespace: tower\nspec:\n  selector:\n    matchLabels:\n      app: ansible-tower\n      version: v1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ansible-tower\n        version: v1\n    spec:\n      containers:\n      - name: tower\n        image: dynatraceacm/ansibletower:3.3.1-1-2\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"tower\" has cpu request 0"
  },
  {
    "id": "01900",
    "manifest_path": "data/manifests/the_stack_sample/sample_0680.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ansible-tower\n  namespace: tower\nspec:\n  selector:\n    matchLabels:\n      app: ansible-tower\n      version: v1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ansible-tower\n        version: v1\n    spec:\n      containers:\n      - name: tower\n        image: dynatraceacm/ansibletower:3.3.1-1-2\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"tower\" has memory limit 0"
  },
  {
    "id": "01901",
    "manifest_path": "data/manifests/the_stack_sample/sample_0683.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\n  namespace: chaos-testing\n  labels:\n    app: etcd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: etcd\n  template:\n    metadata:\n      labels:\n        app: etcd\n      annotations:\n        admission-webhook.pingcap.com/request: chaosfs-etcd\n    spec:\n      containers:\n      - name: etcd\n        imagePullPolicy: IfNotPresent\n        image: k8s.gcr.io/etcd:3.4.3-0\n        args:\n        - /usr/local/bin/etcd\n        - -name=etcd\n        - -advertise-client-urls=http://0.0.0.0:2379\n        - -initial-advertise-peer-urls=http://0.0.0.0:2380\n        - -listen-client-urls=http://0.0.0.0:2379\n        - -listen-peer-urls=http://0.0.0.0:2380\n        - -initial-cluster=etcd=http://0.0.0.0:2380\n        - --data-dir=/var/run/etcd/default.etcd\n        - -initial-cluster-state=new\n        - -initial-cluster-token=etcd-cluster\n        volumeMounts:\n        - mountPath: /var/run/etcd\n          name: datadir\n      volumes:\n      - emptyDir: {}\n        name: datadir\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"etcd\" does not have a read-only root file system"
  },
  {
    "id": "01902",
    "manifest_path": "data/manifests/the_stack_sample/sample_0683.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\n  namespace: chaos-testing\n  labels:\n    app: etcd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: etcd\n  template:\n    metadata:\n      labels:\n        app: etcd\n      annotations:\n        admission-webhook.pingcap.com/request: chaosfs-etcd\n    spec:\n      containers:\n      - name: etcd\n        imagePullPolicy: IfNotPresent\n        image: k8s.gcr.io/etcd:3.4.3-0\n        args:\n        - /usr/local/bin/etcd\n        - -name=etcd\n        - -advertise-client-urls=http://0.0.0.0:2379\n        - -initial-advertise-peer-urls=http://0.0.0.0:2380\n        - -listen-client-urls=http://0.0.0.0:2379\n        - -listen-peer-urls=http://0.0.0.0:2380\n        - -initial-cluster=etcd=http://0.0.0.0:2380\n        - --data-dir=/var/run/etcd/default.etcd\n        - -initial-cluster-state=new\n        - -initial-cluster-token=etcd-cluster\n        volumeMounts:\n        - mountPath: /var/run/etcd\n          name: datadir\n      volumes:\n      - emptyDir: {}\n        name: datadir\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"etcd\" is not set to runAsNonRoot"
  },
  {
    "id": "01903",
    "manifest_path": "data/manifests/the_stack_sample/sample_0683.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\n  namespace: chaos-testing\n  labels:\n    app: etcd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: etcd\n  template:\n    metadata:\n      labels:\n        app: etcd\n      annotations:\n        admission-webhook.pingcap.com/request: chaosfs-etcd\n    spec:\n      containers:\n      - name: etcd\n        imagePullPolicy: IfNotPresent\n        image: k8s.gcr.io/etcd:3.4.3-0\n        args:\n        - /usr/local/bin/etcd\n        - -name=etcd\n        - -advertise-client-urls=http://0.0.0.0:2379\n        - -initial-advertise-peer-urls=http://0.0.0.0:2380\n        - -listen-client-urls=http://0.0.0.0:2379\n        - -listen-peer-urls=http://0.0.0.0:2380\n        - -initial-cluster=etcd=http://0.0.0.0:2380\n        - --data-dir=/var/run/etcd/default.etcd\n        - -initial-cluster-state=new\n        - -initial-cluster-token=etcd-cluster\n        volumeMounts:\n        - mountPath: /var/run/etcd\n          name: datadir\n      volumes:\n      - emptyDir: {}\n        name: datadir\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"etcd\" has cpu request 0"
  },
  {
    "id": "01904",
    "manifest_path": "data/manifests/the_stack_sample/sample_0683.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\n  namespace: chaos-testing\n  labels:\n    app: etcd\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: etcd\n  template:\n    metadata:\n      labels:\n        app: etcd\n      annotations:\n        admission-webhook.pingcap.com/request: chaosfs-etcd\n    spec:\n      containers:\n      - name: etcd\n        imagePullPolicy: IfNotPresent\n        image: k8s.gcr.io/etcd:3.4.3-0\n        args:\n        - /usr/local/bin/etcd\n        - -name=etcd\n        - -advertise-client-urls=http://0.0.0.0:2379\n        - -initial-advertise-peer-urls=http://0.0.0.0:2380\n        - -listen-client-urls=http://0.0.0.0:2379\n        - -listen-peer-urls=http://0.0.0.0:2380\n        - -initial-cluster=etcd=http://0.0.0.0:2380\n        - --data-dir=/var/run/etcd/default.etcd\n        - -initial-cluster-state=new\n        - -initial-cluster-token=etcd-cluster\n        volumeMounts:\n        - mountPath: /var/run/etcd\n          name: datadir\n      volumes:\n      - emptyDir: {}\n        name: datadir\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"etcd\" has memory limit 0"
  },
  {
    "id": "01905",
    "manifest_path": "data/manifests/the_stack_sample/sample_0684.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vdbench-sv4-svc\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: vdbench-sv4-svc\n  template:\n    metadata:\n      labels:\n        app: vdbench-sv4-svc\n    spec:\n      containers:\n      - name: vdbench\n        image: portworx/vdbench:torpedo\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 500Mi\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        command:\n        - ./bench_runner.sh\n        args:\n        - Basic\n        - '5400'\n        - $(POD_NAME)\n        - output/$(POD_NAME)\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        volumeMounts:\n        - name: vdbench-persistent-storage-enc\n          mountPath: /tmp\n        - name: vdbench-output-persistent-storage\n          mountPath: /output\n      volumes:\n      - name: vdbench-persistent-storage-enc\n        persistentVolumeClaim:\n          claimName: vdbench-pvc-enc-sv4-svc\n      - name: vdbench-output-persistent-storage\n        persistentVolumeClaim:\n          claimName: vdbench-pvc-output-sv4-svc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"vdbench\" does not have a read-only root file system"
  },
  {
    "id": "01906",
    "manifest_path": "data/manifests/the_stack_sample/sample_0684.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vdbench-sv4-svc\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: vdbench-sv4-svc\n  template:\n    metadata:\n      labels:\n        app: vdbench-sv4-svc\n    spec:\n      containers:\n      - name: vdbench\n        image: portworx/vdbench:torpedo\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 500Mi\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        command:\n        - ./bench_runner.sh\n        args:\n        - Basic\n        - '5400'\n        - $(POD_NAME)\n        - output/$(POD_NAME)\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        volumeMounts:\n        - name: vdbench-persistent-storage-enc\n          mountPath: /tmp\n        - name: vdbench-output-persistent-storage\n          mountPath: /output\n      volumes:\n      - name: vdbench-persistent-storage-enc\n        persistentVolumeClaim:\n          claimName: vdbench-pvc-enc-sv4-svc\n      - name: vdbench-output-persistent-storage\n        persistentVolumeClaim:\n          claimName: vdbench-pvc-output-sv4-svc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"vdbench\" is not set to runAsNonRoot"
  },
  {
    "id": "01907",
    "manifest_path": "data/manifests/the_stack_sample/sample_0685.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n  template:\n    metadata:\n      name: mongo-pod\n      labels:\n        app: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"mongo\" is using an invalid container image, \"mongo\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01908",
    "manifest_path": "data/manifests/the_stack_sample/sample_0685.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n  template:\n    metadata:\n      name: mongo-pod\n      labels:\n        app: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mongo\" does not have a read-only root file system"
  },
  {
    "id": "01909",
    "manifest_path": "data/manifests/the_stack_sample/sample_0685.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n  template:\n    metadata:\n      name: mongo-pod\n      labels:\n        app: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mongo\" is not set to runAsNonRoot"
  },
  {
    "id": "01910",
    "manifest_path": "data/manifests/the_stack_sample/sample_0685.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n  template:\n    metadata:\n      name: mongo-pod\n      labels:\n        app: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mongo\" has cpu request 0"
  },
  {
    "id": "01911",
    "manifest_path": "data/manifests/the_stack_sample/sample_0685.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n  template:\n    metadata:\n      name: mongo-pod\n      labels:\n        app: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mongo\" has memory limit 0"
  },
  {
    "id": "01912",
    "manifest_path": "data/manifests/the_stack_sample/sample_0686.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    foo: bar\n  name: my-nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.14.2\n        name: nginx\n        ports:\n        - containerPort: 80\n          protocol: TCP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "01913",
    "manifest_path": "data/manifests/the_stack_sample/sample_0686.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    foo: bar\n  name: my-nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.14.2\n        name: nginx\n        ports:\n        - containerPort: 80\n          protocol: TCP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "01914",
    "manifest_path": "data/manifests/the_stack_sample/sample_0686.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    foo: bar\n  name: my-nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.14.2\n        name: nginx\n        ports:\n        - containerPort: 80\n          protocol: TCP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "01915",
    "manifest_path": "data/manifests/the_stack_sample/sample_0686.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    foo: bar\n  name: my-nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:1.14.2\n        name: nginx\n        ports:\n        - containerPort: 80\n          protocol: TCP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "01916",
    "manifest_path": "data/manifests/the_stack_sample/sample_0687.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-busybox\n  namespace: mybox\nspec:\n  replicas: 2\n  selector:\n    name: nfs-busybox\n  template:\n    metadata:\n      labels:\n        name: nfs-busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do date > /mnt/index.html; hostname >> /mnt/index.html; sleep\n          $(($RANDOM % 5 + 5)); done\n        imagePullPolicy: IfNotPresent\n        name: busybox\n        volumeMounts:\n        - name: nfs\n          mountPath: /mnt\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"busybox\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01917",
    "manifest_path": "data/manifests/the_stack_sample/sample_0687.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-busybox\n  namespace: mybox\nspec:\n  replicas: 2\n  selector:\n    name: nfs-busybox\n  template:\n    metadata:\n      labels:\n        name: nfs-busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do date > /mnt/index.html; hostname >> /mnt/index.html; sleep\n          $(($RANDOM % 5 + 5)); done\n        imagePullPolicy: IfNotPresent\n        name: busybox\n        volumeMounts:\n        - name: nfs\n          mountPath: /mnt\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"busybox\" does not have a read-only root file system"
  },
  {
    "id": "01918",
    "manifest_path": "data/manifests/the_stack_sample/sample_0687.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-busybox\n  namespace: mybox\nspec:\n  replicas: 2\n  selector:\n    name: nfs-busybox\n  template:\n    metadata:\n      labels:\n        name: nfs-busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do date > /mnt/index.html; hostname >> /mnt/index.html; sleep\n          $(($RANDOM % 5 + 5)); done\n        imagePullPolicy: IfNotPresent\n        name: busybox\n        volumeMounts:\n        - name: nfs\n          mountPath: /mnt\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"busybox\" is not set to runAsNonRoot"
  },
  {
    "id": "01919",
    "manifest_path": "data/manifests/the_stack_sample/sample_0687.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-busybox\n  namespace: mybox\nspec:\n  replicas: 2\n  selector:\n    name: nfs-busybox\n  template:\n    metadata:\n      labels:\n        name: nfs-busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do date > /mnt/index.html; hostname >> /mnt/index.html; sleep\n          $(($RANDOM % 5 + 5)); done\n        imagePullPolicy: IfNotPresent\n        name: busybox\n        volumeMounts:\n        - name: nfs\n          mountPath: /mnt\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"busybox\" has cpu request 0"
  },
  {
    "id": "01920",
    "manifest_path": "data/manifests/the_stack_sample/sample_0687.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-busybox\n  namespace: mybox\nspec:\n  replicas: 2\n  selector:\n    name: nfs-busybox\n  template:\n    metadata:\n      labels:\n        name: nfs-busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do date > /mnt/index.html; hostname >> /mnt/index.html; sleep\n          $(($RANDOM % 5 + 5)); done\n        imagePullPolicy: IfNotPresent\n        name: busybox\n        volumeMounts:\n        - name: nfs\n          mountPath: /mnt\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"busybox\" has memory limit 0"
  },
  {
    "id": "01921",
    "manifest_path": "data/manifests/the_stack_sample/sample_0690.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cloudflow-patch-spark-mutatingwebhookconfig\nspec:\n  template:\n    spec:\n      serviceAccountName: cloudflow-operator\n      containers:\n      - name: main\n        image: alpine:3.12\n        command:\n        - /bin/ash\n        - -c\n        - \"apk update && apk add wget\\nwget -q -O /bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.16.12/bin/linux/amd64/kubectl\\\n          \\ && chmod 755 /bin/kubectl\\nNAME=\\\"spark-operator-sparkoperator\\\"\\nAPI_VERSION=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.apiVersion}')\\nUUID=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.metadata.uid}')\\nKIND=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.kind}')\\nHOOK_NAME=\\\"\\\n          spark-operator-sparkoperator-webhook-config\\\"\\nJSON=$(cat <<EOF\\n{\\n  \\\"\\\n          metadata\\\": {\\n    \\\"ownerReferences\\\": [\\n      {\\n        \\\"apiVersion\\\"\\\n          : \\\"$API_VERSION\\\",\\n        \\\"blockOwnerDeletion\\\": true,\\n        \\\"controller\\\"\\\n          : true,\\n        \\\"kind\\\": \\\"$KIND\\\",\\n        \\\"name\\\": \\\"$NAME\\\",\\n  \\\n          \\      \\\"uid\\\": \\\"$UUID\\\"\\n      }\\n    ]\\n  }\\n}\\nEOF\\n)\\necho $JSON\\n\\\n          kubectl patch MutatingWebhookConfiguration $HOOK_NAME -n cloudflow -p \\\"\\\n          $JSON\\\"\"\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"main\" does not have a read-only root file system"
  },
  {
    "id": "01922",
    "manifest_path": "data/manifests/the_stack_sample/sample_0690.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cloudflow-patch-spark-mutatingwebhookconfig\nspec:\n  template:\n    spec:\n      serviceAccountName: cloudflow-operator\n      containers:\n      - name: main\n        image: alpine:3.12\n        command:\n        - /bin/ash\n        - -c\n        - \"apk update && apk add wget\\nwget -q -O /bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.16.12/bin/linux/amd64/kubectl\\\n          \\ && chmod 755 /bin/kubectl\\nNAME=\\\"spark-operator-sparkoperator\\\"\\nAPI_VERSION=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.apiVersion}')\\nUUID=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.metadata.uid}')\\nKIND=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.kind}')\\nHOOK_NAME=\\\"\\\n          spark-operator-sparkoperator-webhook-config\\\"\\nJSON=$(cat <<EOF\\n{\\n  \\\"\\\n          metadata\\\": {\\n    \\\"ownerReferences\\\": [\\n      {\\n        \\\"apiVersion\\\"\\\n          : \\\"$API_VERSION\\\",\\n        \\\"blockOwnerDeletion\\\": true,\\n        \\\"controller\\\"\\\n          : true,\\n        \\\"kind\\\": \\\"$KIND\\\",\\n        \\\"name\\\": \\\"$NAME\\\",\\n  \\\n          \\      \\\"uid\\\": \\\"$UUID\\\"\\n      }\\n    ]\\n  }\\n}\\nEOF\\n)\\necho $JSON\\n\\\n          kubectl patch MutatingWebhookConfiguration $HOOK_NAME -n cloudflow -p \\\"\\\n          $JSON\\\"\"\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"main\" is not set to runAsNonRoot"
  },
  {
    "id": "01923",
    "manifest_path": "data/manifests/the_stack_sample/sample_0690.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cloudflow-patch-spark-mutatingwebhookconfig\nspec:\n  template:\n    spec:\n      serviceAccountName: cloudflow-operator\n      containers:\n      - name: main\n        image: alpine:3.12\n        command:\n        - /bin/ash\n        - -c\n        - \"apk update && apk add wget\\nwget -q -O /bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.16.12/bin/linux/amd64/kubectl\\\n          \\ && chmod 755 /bin/kubectl\\nNAME=\\\"spark-operator-sparkoperator\\\"\\nAPI_VERSION=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.apiVersion}')\\nUUID=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.metadata.uid}')\\nKIND=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.kind}')\\nHOOK_NAME=\\\"\\\n          spark-operator-sparkoperator-webhook-config\\\"\\nJSON=$(cat <<EOF\\n{\\n  \\\"\\\n          metadata\\\": {\\n    \\\"ownerReferences\\\": [\\n      {\\n        \\\"apiVersion\\\"\\\n          : \\\"$API_VERSION\\\",\\n        \\\"blockOwnerDeletion\\\": true,\\n        \\\"controller\\\"\\\n          : true,\\n        \\\"kind\\\": \\\"$KIND\\\",\\n        \\\"name\\\": \\\"$NAME\\\",\\n  \\\n          \\      \\\"uid\\\": \\\"$UUID\\\"\\n      }\\n    ]\\n  }\\n}\\nEOF\\n)\\necho $JSON\\n\\\n          kubectl patch MutatingWebhookConfiguration $HOOK_NAME -n cloudflow -p \\\"\\\n          $JSON\\\"\"\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"main\" has cpu request 0"
  },
  {
    "id": "01924",
    "manifest_path": "data/manifests/the_stack_sample/sample_0690.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cloudflow-patch-spark-mutatingwebhookconfig\nspec:\n  template:\n    spec:\n      serviceAccountName: cloudflow-operator\n      containers:\n      - name: main\n        image: alpine:3.12\n        command:\n        - /bin/ash\n        - -c\n        - \"apk update && apk add wget\\nwget -q -O /bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.16.12/bin/linux/amd64/kubectl\\\n          \\ && chmod 755 /bin/kubectl\\nNAME=\\\"spark-operator-sparkoperator\\\"\\nAPI_VERSION=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.apiVersion}')\\nUUID=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.metadata.uid}')\\nKIND=$(kubectl\\\n          \\ get deployment -n cloudflow $NAME -o jsonpath='{.kind}')\\nHOOK_NAME=\\\"\\\n          spark-operator-sparkoperator-webhook-config\\\"\\nJSON=$(cat <<EOF\\n{\\n  \\\"\\\n          metadata\\\": {\\n    \\\"ownerReferences\\\": [\\n      {\\n        \\\"apiVersion\\\"\\\n          : \\\"$API_VERSION\\\",\\n        \\\"blockOwnerDeletion\\\": true,\\n        \\\"controller\\\"\\\n          : true,\\n        \\\"kind\\\": \\\"$KIND\\\",\\n        \\\"name\\\": \\\"$NAME\\\",\\n  \\\n          \\      \\\"uid\\\": \\\"$UUID\\\"\\n      }\\n    ]\\n  }\\n}\\nEOF\\n)\\necho $JSON\\n\\\n          kubectl patch MutatingWebhookConfiguration $HOOK_NAME -n cloudflow -p \\\"\\\n          $JSON\\\"\"\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"main\" has memory limit 0"
  },
  {
    "id": "01925",
    "manifest_path": "data/manifests/the_stack_sample/sample_0693.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: utils\nspec:\n  template:\n    metadata:\n      name: utils\n    spec:\n      volumes:\n      - name: sharedvolume\n        persistentVolumeClaim:\n          claimName: shared-pvc\n      - name: dockersocket\n        hostPath:\n          path: /var/run/docker.sock\n      containers:\n      - name: cryptogen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Cryptogen Starts'; ls -l /shared/artifacts; while [ ! -d /shared/artifacts\n          ]; do echo Waiting for configFiles; sleep 1; done; cryptogen generate --config\n          /shared/artifacts/crypto-config.yaml && cp -r crypto-config /shared/ &&\n          for file in $(find /shared/ -iname *_sk); do echo $file; dir=$(dirname $file);\n          echo ${dir}; mv ${dir}/*_sk ${dir}/key.pem; done && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n      - name: configtxgen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Configtxgen Starts'; ls -l /shared; sleep 1 && while [ ! -f /shared/status_cryptogen_complete\n          ]; do echo Waiting for cryptogen; sleep 1; done; cp /shared/artifacts/configtx.yaml\n          /shared/; cd /shared/; export FABRIC_CFG_PATH=$PWD; configtxgen -profile\n          TwoOrgsOrdererGenesis -outputBlock genesis.block && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_configtxgen_complete\n          && rm /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"configtxgen\" does not have a read-only root file system"
  },
  {
    "id": "01926",
    "manifest_path": "data/manifests/the_stack_sample/sample_0693.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: utils\nspec:\n  template:\n    metadata:\n      name: utils\n    spec:\n      volumes:\n      - name: sharedvolume\n        persistentVolumeClaim:\n          claimName: shared-pvc\n      - name: dockersocket\n        hostPath:\n          path: /var/run/docker.sock\n      containers:\n      - name: cryptogen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Cryptogen Starts'; ls -l /shared/artifacts; while [ ! -d /shared/artifacts\n          ]; do echo Waiting for configFiles; sleep 1; done; cryptogen generate --config\n          /shared/artifacts/crypto-config.yaml && cp -r crypto-config /shared/ &&\n          for file in $(find /shared/ -iname *_sk); do echo $file; dir=$(dirname $file);\n          echo ${dir}; mv ${dir}/*_sk ${dir}/key.pem; done && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n      - name: configtxgen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Configtxgen Starts'; ls -l /shared; sleep 1 && while [ ! -f /shared/status_cryptogen_complete\n          ]; do echo Waiting for cryptogen; sleep 1; done; cp /shared/artifacts/configtx.yaml\n          /shared/; cd /shared/; export FABRIC_CFG_PATH=$PWD; configtxgen -profile\n          TwoOrgsOrdererGenesis -outputBlock genesis.block && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_configtxgen_complete\n          && rm /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cryptogen\" does not have a read-only root file system"
  },
  {
    "id": "01927",
    "manifest_path": "data/manifests/the_stack_sample/sample_0693.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: utils\nspec:\n  template:\n    metadata:\n      name: utils\n    spec:\n      volumes:\n      - name: sharedvolume\n        persistentVolumeClaim:\n          claimName: shared-pvc\n      - name: dockersocket\n        hostPath:\n          path: /var/run/docker.sock\n      containers:\n      - name: cryptogen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Cryptogen Starts'; ls -l /shared/artifacts; while [ ! -d /shared/artifacts\n          ]; do echo Waiting for configFiles; sleep 1; done; cryptogen generate --config\n          /shared/artifacts/crypto-config.yaml && cp -r crypto-config /shared/ &&\n          for file in $(find /shared/ -iname *_sk); do echo $file; dir=$(dirname $file);\n          echo ${dir}; mv ${dir}/*_sk ${dir}/key.pem; done && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n      - name: configtxgen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Configtxgen Starts'; ls -l /shared; sleep 1 && while [ ! -f /shared/status_cryptogen_complete\n          ]; do echo Waiting for cryptogen; sleep 1; done; cp /shared/artifacts/configtx.yaml\n          /shared/; cd /shared/; export FABRIC_CFG_PATH=$PWD; configtxgen -profile\n          TwoOrgsOrdererGenesis -outputBlock genesis.block && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_configtxgen_complete\n          && rm /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"configtxgen\" is not set to runAsNonRoot"
  },
  {
    "id": "01928",
    "manifest_path": "data/manifests/the_stack_sample/sample_0693.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: utils\nspec:\n  template:\n    metadata:\n      name: utils\n    spec:\n      volumes:\n      - name: sharedvolume\n        persistentVolumeClaim:\n          claimName: shared-pvc\n      - name: dockersocket\n        hostPath:\n          path: /var/run/docker.sock\n      containers:\n      - name: cryptogen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Cryptogen Starts'; ls -l /shared/artifacts; while [ ! -d /shared/artifacts\n          ]; do echo Waiting for configFiles; sleep 1; done; cryptogen generate --config\n          /shared/artifacts/crypto-config.yaml && cp -r crypto-config /shared/ &&\n          for file in $(find /shared/ -iname *_sk); do echo $file; dir=$(dirname $file);\n          echo ${dir}; mv ${dir}/*_sk ${dir}/key.pem; done && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n      - name: configtxgen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Configtxgen Starts'; ls -l /shared; sleep 1 && while [ ! -f /shared/status_cryptogen_complete\n          ]; do echo Waiting for cryptogen; sleep 1; done; cp /shared/artifacts/configtx.yaml\n          /shared/; cd /shared/; export FABRIC_CFG_PATH=$PWD; configtxgen -profile\n          TwoOrgsOrdererGenesis -outputBlock genesis.block && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_configtxgen_complete\n          && rm /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cryptogen\" is not set to runAsNonRoot"
  },
  {
    "id": "01929",
    "manifest_path": "data/manifests/the_stack_sample/sample_0693.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: utils\nspec:\n  template:\n    metadata:\n      name: utils\n    spec:\n      volumes:\n      - name: sharedvolume\n        persistentVolumeClaim:\n          claimName: shared-pvc\n      - name: dockersocket\n        hostPath:\n          path: /var/run/docker.sock\n      containers:\n      - name: cryptogen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Cryptogen Starts'; ls -l /shared/artifacts; while [ ! -d /shared/artifacts\n          ]; do echo Waiting for configFiles; sleep 1; done; cryptogen generate --config\n          /shared/artifacts/crypto-config.yaml && cp -r crypto-config /shared/ &&\n          for file in $(find /shared/ -iname *_sk); do echo $file; dir=$(dirname $file);\n          echo ${dir}; mv ${dir}/*_sk ${dir}/key.pem; done && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n      - name: configtxgen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Configtxgen Starts'; ls -l /shared; sleep 1 && while [ ! -f /shared/status_cryptogen_complete\n          ]; do echo Waiting for cryptogen; sleep 1; done; cp /shared/artifacts/configtx.yaml\n          /shared/; cd /shared/; export FABRIC_CFG_PATH=$PWD; configtxgen -profile\n          TwoOrgsOrdererGenesis -outputBlock genesis.block && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_configtxgen_complete\n          && rm /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"configtxgen\" has cpu request 0"
  },
  {
    "id": "01930",
    "manifest_path": "data/manifests/the_stack_sample/sample_0693.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: utils\nspec:\n  template:\n    metadata:\n      name: utils\n    spec:\n      volumes:\n      - name: sharedvolume\n        persistentVolumeClaim:\n          claimName: shared-pvc\n      - name: dockersocket\n        hostPath:\n          path: /var/run/docker.sock\n      containers:\n      - name: cryptogen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Cryptogen Starts'; ls -l /shared/artifacts; while [ ! -d /shared/artifacts\n          ]; do echo Waiting for configFiles; sleep 1; done; cryptogen generate --config\n          /shared/artifacts/crypto-config.yaml && cp -r crypto-config /shared/ &&\n          for file in $(find /shared/ -iname *_sk); do echo $file; dir=$(dirname $file);\n          echo ${dir}; mv ${dir}/*_sk ${dir}/key.pem; done && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n      - name: configtxgen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Configtxgen Starts'; ls -l /shared; sleep 1 && while [ ! -f /shared/status_cryptogen_complete\n          ]; do echo Waiting for cryptogen; sleep 1; done; cp /shared/artifacts/configtx.yaml\n          /shared/; cd /shared/; export FABRIC_CFG_PATH=$PWD; configtxgen -profile\n          TwoOrgsOrdererGenesis -outputBlock genesis.block && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_configtxgen_complete\n          && rm /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cryptogen\" has cpu request 0"
  },
  {
    "id": "01931",
    "manifest_path": "data/manifests/the_stack_sample/sample_0693.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: utils\nspec:\n  template:\n    metadata:\n      name: utils\n    spec:\n      volumes:\n      - name: sharedvolume\n        persistentVolumeClaim:\n          claimName: shared-pvc\n      - name: dockersocket\n        hostPath:\n          path: /var/run/docker.sock\n      containers:\n      - name: cryptogen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Cryptogen Starts'; ls -l /shared/artifacts; while [ ! -d /shared/artifacts\n          ]; do echo Waiting for configFiles; sleep 1; done; cryptogen generate --config\n          /shared/artifacts/crypto-config.yaml && cp -r crypto-config /shared/ &&\n          for file in $(find /shared/ -iname *_sk); do echo $file; dir=$(dirname $file);\n          echo ${dir}; mv ${dir}/*_sk ${dir}/key.pem; done && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n      - name: configtxgen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Configtxgen Starts'; ls -l /shared; sleep 1 && while [ ! -f /shared/status_cryptogen_complete\n          ]; do echo Waiting for cryptogen; sleep 1; done; cp /shared/artifacts/configtx.yaml\n          /shared/; cd /shared/; export FABRIC_CFG_PATH=$PWD; configtxgen -profile\n          TwoOrgsOrdererGenesis -outputBlock genesis.block && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_configtxgen_complete\n          && rm /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"configtxgen\" has memory limit 0"
  },
  {
    "id": "01932",
    "manifest_path": "data/manifests/the_stack_sample/sample_0693.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: utils\nspec:\n  template:\n    metadata:\n      name: utils\n    spec:\n      volumes:\n      - name: sharedvolume\n        persistentVolumeClaim:\n          claimName: shared-pvc\n      - name: dockersocket\n        hostPath:\n          path: /var/run/docker.sock\n      containers:\n      - name: cryptogen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Cryptogen Starts'; ls -l /shared/artifacts; while [ ! -d /shared/artifacts\n          ]; do echo Waiting for configFiles; sleep 1; done; cryptogen generate --config\n          /shared/artifacts/crypto-config.yaml && cp -r crypto-config /shared/ &&\n          for file in $(find /shared/ -iname *_sk); do echo $file; dir=$(dirname $file);\n          echo ${dir}; mv ${dir}/*_sk ${dir}/key.pem; done && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n      - name: configtxgen\n        image: hyperledger/fabric-tools:1.3.0\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        - echo 'Configtxgen Starts'; ls -l /shared; sleep 1 && while [ ! -f /shared/status_cryptogen_complete\n          ]; do echo Waiting for cryptogen; sleep 1; done; cp /shared/artifacts/configtx.yaml\n          /shared/; cd /shared/; export FABRIC_CFG_PATH=$PWD; configtxgen -profile\n          TwoOrgsOrdererGenesis -outputBlock genesis.block && find /shared -type d\n          | xargs chmod a+rx && find /shared -type f | xargs chmod a+r && touch /shared/status_configtxgen_complete\n          && rm /shared/status_cryptogen_complete;\n        volumeMounts:\n        - mountPath: /shared\n          name: sharedvolume\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cryptogen\" has memory limit 0"
  },
  {
    "id": "01933",
    "manifest_path": "data/manifests/the_stack_sample/sample_0697.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\n  labels:\n    app: jaeger-operator-app\n  namespace: K8s-Tracing-Namespace\n  annotations:\n    developer/name: \"Mislav Jak\\u0161i\\u0107\"\n    developer/email: jaksicmislav@gmail.com\n    developer/url: https://github.com/MislavJaksic\n    developer/role: technical lead\n    developer/timezone: Europe/Zagreb\n    developer/picUrl: https://images.app.goo.gl/PCHZgd8oattge1i96\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.16.0\n        ports:\n        - containerPort: 8383\n          name: metrics\n        args:\n        - start\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jaeger-operator\" does not have a read-only root file system"
  },
  {
    "id": "01934",
    "manifest_path": "data/manifests/the_stack_sample/sample_0697.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\n  labels:\n    app: jaeger-operator-app\n  namespace: K8s-Tracing-Namespace\n  annotations:\n    developer/name: \"Mislav Jak\\u0161i\\u0107\"\n    developer/email: jaksicmislav@gmail.com\n    developer/url: https://github.com/MislavJaksic\n    developer/role: technical lead\n    developer/timezone: Europe/Zagreb\n    developer/picUrl: https://images.app.goo.gl/PCHZgd8oattge1i96\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.16.0\n        ports:\n        - containerPort: 8383\n          name: metrics\n        args:\n        - start\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jaeger-operator\" is not set to runAsNonRoot"
  },
  {
    "id": "01935",
    "manifest_path": "data/manifests/the_stack_sample/sample_0697.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\n  labels:\n    app: jaeger-operator-app\n  namespace: K8s-Tracing-Namespace\n  annotations:\n    developer/name: \"Mislav Jak\\u0161i\\u0107\"\n    developer/email: jaksicmislav@gmail.com\n    developer/url: https://github.com/MislavJaksic\n    developer/role: technical lead\n    developer/timezone: Europe/Zagreb\n    developer/picUrl: https://images.app.goo.gl/PCHZgd8oattge1i96\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.16.0\n        ports:\n        - containerPort: 8383\n          name: metrics\n        args:\n        - start\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"jaeger-operator\" has cpu request 0"
  },
  {
    "id": "01936",
    "manifest_path": "data/manifests/the_stack_sample/sample_0697.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\n  labels:\n    app: jaeger-operator-app\n  namespace: K8s-Tracing-Namespace\n  annotations:\n    developer/name: \"Mislav Jak\\u0161i\\u0107\"\n    developer/email: jaksicmislav@gmail.com\n    developer/url: https://github.com/MislavJaksic\n    developer/role: technical lead\n    developer/timezone: Europe/Zagreb\n    developer/picUrl: https://images.app.goo.gl/PCHZgd8oattge1i96\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.16.0\n        ports:\n        - containerPort: 8383\n          name: metrics\n        args:\n        - start\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"jaeger-operator\" has memory limit 0"
  },
  {
    "id": "01937",
    "manifest_path": "data/manifests/the_stack_sample/sample_0700.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-evictor\n  namespace: bad-tenant\nspec:\n  containers:\n  - name: high-priority\n    image: nginxdemos/hello\n    resources:\n      requests:\n        cpu: 1\n        memory: 128Mi\n      limits:\n        cpu: 1\n        memory: 128Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"high-priority\" is using an invalid container image, \"nginxdemos/hello\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01938",
    "manifest_path": "data/manifests/the_stack_sample/sample_0700.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-evictor\n  namespace: bad-tenant\nspec:\n  containers:\n  - name: high-priority\n    image: nginxdemos/hello\n    resources:\n      requests:\n        cpu: 1\n        memory: 128Mi\n      limits:\n        cpu: 1\n        memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"high-priority\" does not have a read-only root file system"
  },
  {
    "id": "01939",
    "manifest_path": "data/manifests/the_stack_sample/sample_0700.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-evictor\n  namespace: bad-tenant\nspec:\n  containers:\n  - name: high-priority\n    image: nginxdemos/hello\n    resources:\n      requests:\n        cpu: 1\n        memory: 128Mi\n      limits:\n        cpu: 1\n        memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"high-priority\" is not set to runAsNonRoot"
  },
  {
    "id": "01940",
    "manifest_path": "data/manifests/the_stack_sample/sample_0703.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etherpad-lite\n  labels:\n    service: etherpad-lite\nspec:\n  selector:\n    matchLabels:\n      service: etherpad-lite\n  template:\n    metadata:\n      labels:\n        service: etherpad-lite\n    spec:\n      containers:\n      - name: etherpad-lite\n        image: etherpad/etherpad:1.8.6\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: SKIN_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: skin\n        - name: NODE_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: env\n        - name: DB_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_type\n        - name: DB_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_host\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_port\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_name\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_user\n        - name: DB_CHARSET\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_charset\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: port\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: ether-secret\n              key: db_password\n        - name: ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: ether-secret\n              key: admin_password\n        ports:\n        - containerPort: 9001\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /opt/etherpad-lite/var\n          name: data-volume\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: ether-data-vol\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"etherpad-lite\" does not have a read-only root file system"
  },
  {
    "id": "01941",
    "manifest_path": "data/manifests/the_stack_sample/sample_0703.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etherpad-lite\n  labels:\n    service: etherpad-lite\nspec:\n  selector:\n    matchLabels:\n      service: etherpad-lite\n  template:\n    metadata:\n      labels:\n        service: etherpad-lite\n    spec:\n      containers:\n      - name: etherpad-lite\n        image: etherpad/etherpad:1.8.6\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: SKIN_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: skin\n        - name: NODE_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: env\n        - name: DB_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_type\n        - name: DB_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_host\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_port\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_name\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_user\n        - name: DB_CHARSET\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_charset\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: port\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: ether-secret\n              key: db_password\n        - name: ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: ether-secret\n              key: admin_password\n        ports:\n        - containerPort: 9001\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /opt/etherpad-lite/var\n          name: data-volume\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: ether-data-vol\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"etherpad-lite\" is not set to runAsNonRoot"
  },
  {
    "id": "01942",
    "manifest_path": "data/manifests/the_stack_sample/sample_0703.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etherpad-lite\n  labels:\n    service: etherpad-lite\nspec:\n  selector:\n    matchLabels:\n      service: etherpad-lite\n  template:\n    metadata:\n      labels:\n        service: etherpad-lite\n    spec:\n      containers:\n      - name: etherpad-lite\n        image: etherpad/etherpad:1.8.6\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: SKIN_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: skin\n        - name: NODE_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: env\n        - name: DB_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_type\n        - name: DB_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_host\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_port\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_name\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_user\n        - name: DB_CHARSET\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_charset\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: port\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: ether-secret\n              key: db_password\n        - name: ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: ether-secret\n              key: admin_password\n        ports:\n        - containerPort: 9001\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /opt/etherpad-lite/var\n          name: data-volume\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: ether-data-vol\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"etherpad-lite\" has cpu request 0"
  },
  {
    "id": "01943",
    "manifest_path": "data/manifests/the_stack_sample/sample_0703.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etherpad-lite\n  labels:\n    service: etherpad-lite\nspec:\n  selector:\n    matchLabels:\n      service: etherpad-lite\n  template:\n    metadata:\n      labels:\n        service: etherpad-lite\n    spec:\n      containers:\n      - name: etherpad-lite\n        image: etherpad/etherpad:1.8.6\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: SKIN_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: skin\n        - name: NODE_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: env\n        - name: DB_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_type\n        - name: DB_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_host\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_port\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_name\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_user\n        - name: DB_CHARSET\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: db_charset\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: ether-config\n              key: port\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: ether-secret\n              key: db_password\n        - name: ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: ether-secret\n              key: admin_password\n        ports:\n        - containerPort: 9001\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /opt/etherpad-lite/var\n          name: data-volume\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: ether-data-vol\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"etherpad-lite\" has memory limit 0"
  },
  {
    "id": "01944",
    "manifest_path": "data/manifests/the_stack_sample/sample_0706.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: secret-test-pod\nspec:\n  containers:\n  - name: test-container\n    image: gcr.io/google_containers/mounttest:0.8\n    command:\n    - /mt\n    - --file_content=/etc/secret-volume/data-1\n    volumeMounts:\n    - name: secret-volume\n      mountPath: /etc/secret-volume\n  volumes:\n  - name: secret-volume\n    secret:\n      secretName: test-secret\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"test-container\" does not have a read-only root file system"
  },
  {
    "id": "01945",
    "manifest_path": "data/manifests/the_stack_sample/sample_0706.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: secret-test-pod\nspec:\n  containers:\n  - name: test-container\n    image: gcr.io/google_containers/mounttest:0.8\n    command:\n    - /mt\n    - --file_content=/etc/secret-volume/data-1\n    volumeMounts:\n    - name: secret-volume\n      mountPath: /etc/secret-volume\n  volumes:\n  - name: secret-volume\n    secret:\n      secretName: test-secret\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"test-container\" is not set to runAsNonRoot"
  },
  {
    "id": "01946",
    "manifest_path": "data/manifests/the_stack_sample/sample_0706.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: secret-test-pod\nspec:\n  containers:\n  - name: test-container\n    image: gcr.io/google_containers/mounttest:0.8\n    command:\n    - /mt\n    - --file_content=/etc/secret-volume/data-1\n    volumeMounts:\n    - name: secret-volume\n      mountPath: /etc/secret-volume\n  volumes:\n  - name: secret-volume\n    secret:\n      secretName: test-secret\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"test-container\" has cpu request 0"
  },
  {
    "id": "01947",
    "manifest_path": "data/manifests/the_stack_sample/sample_0706.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: secret-test-pod\nspec:\n  containers:\n  - name: test-container\n    image: gcr.io/google_containers/mounttest:0.8\n    command:\n    - /mt\n    - --file_content=/etc/secret-volume/data-1\n    volumeMounts:\n    - name: secret-volume\n      mountPath: /etc/secret-volume\n  volumes:\n  - name: secret-volume\n    secret:\n      secretName: test-secret\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"test-container\" has memory limit 0"
  },
  {
    "id": "01948",
    "manifest_path": "data/manifests/the_stack_sample/sample_0710.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: grafana\n  template:\n    metadata:\n      name: grafana\n      labels:\n        app: grafana\n    spec:\n      containers:\n      - name: grafana\n        image: grafana/grafana:latest\n        ports:\n        - name: grafana\n          containerPort: 3000\n        volumeMounts:\n        - mountPath: /var/lib/grafana\n          name: grafana-storage\n        - mountPath: /etc/grafana/provisioning/datasources\n          name: grafana-datasources\n          readOnly: false\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: pvc-nfs-storage\n      - name: grafana-datasources\n        configMap:\n          defaultMode: 420\n          name: grafana-datasources\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"grafana\" is using an invalid container image, \"grafana/grafana:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01949",
    "manifest_path": "data/manifests/the_stack_sample/sample_0710.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: grafana\n  template:\n    metadata:\n      name: grafana\n      labels:\n        app: grafana\n    spec:\n      containers:\n      - name: grafana\n        image: grafana/grafana:latest\n        ports:\n        - name: grafana\n          containerPort: 3000\n        volumeMounts:\n        - mountPath: /var/lib/grafana\n          name: grafana-storage\n        - mountPath: /etc/grafana/provisioning/datasources\n          name: grafana-datasources\n          readOnly: false\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: pvc-nfs-storage\n      - name: grafana-datasources\n        configMap:\n          defaultMode: 420\n          name: grafana-datasources\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"grafana\" does not have a read-only root file system"
  },
  {
    "id": "01950",
    "manifest_path": "data/manifests/the_stack_sample/sample_0710.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: grafana\n  template:\n    metadata:\n      name: grafana\n      labels:\n        app: grafana\n    spec:\n      containers:\n      - name: grafana\n        image: grafana/grafana:latest\n        ports:\n        - name: grafana\n          containerPort: 3000\n        volumeMounts:\n        - mountPath: /var/lib/grafana\n          name: grafana-storage\n        - mountPath: /etc/grafana/provisioning/datasources\n          name: grafana-datasources\n          readOnly: false\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: pvc-nfs-storage\n      - name: grafana-datasources\n        configMap:\n          defaultMode: 420\n          name: grafana-datasources\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"grafana\" is not set to runAsNonRoot"
  },
  {
    "id": "01951",
    "manifest_path": "data/manifests/the_stack_sample/sample_0710.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: grafana\n  template:\n    metadata:\n      name: grafana\n      labels:\n        app: grafana\n    spec:\n      containers:\n      - name: grafana\n        image: grafana/grafana:latest\n        ports:\n        - name: grafana\n          containerPort: 3000\n        volumeMounts:\n        - mountPath: /var/lib/grafana\n          name: grafana-storage\n        - mountPath: /etc/grafana/provisioning/datasources\n          name: grafana-datasources\n          readOnly: false\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: pvc-nfs-storage\n      - name: grafana-datasources\n        configMap:\n          defaultMode: 420\n          name: grafana-datasources\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"grafana\" has cpu request 0"
  },
  {
    "id": "01952",
    "manifest_path": "data/manifests/the_stack_sample/sample_0710.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: grafana\n  template:\n    metadata:\n      name: grafana\n      labels:\n        app: grafana\n    spec:\n      containers:\n      - name: grafana\n        image: grafana/grafana:latest\n        ports:\n        - name: grafana\n          containerPort: 3000\n        volumeMounts:\n        - mountPath: /var/lib/grafana\n          name: grafana-storage\n        - mountPath: /etc/grafana/provisioning/datasources\n          name: grafana-datasources\n          readOnly: false\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: pvc-nfs-storage\n      - name: grafana-datasources\n        configMap:\n          defaultMode: 420\n          name: grafana-datasources\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"grafana\" has memory limit 0"
  },
  {
    "id": "01953",
    "manifest_path": "data/manifests/the_stack_sample/sample_0713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1210\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01954",
    "manifest_path": "data/manifests/the_stack_sample/sample_0713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1210\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "01955",
    "manifest_path": "data/manifests/the_stack_sample/sample_0713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1210\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "01956",
    "manifest_path": "data/manifests/the_stack_sample/sample_0713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1210\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "01957",
    "manifest_path": "data/manifests/the_stack_sample/sample_0713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1210\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "01958",
    "manifest_path": "data/manifests/the_stack_sample/sample_0714.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "01959",
    "manifest_path": "data/manifests/the_stack_sample/sample_0714.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "01960",
    "manifest_path": "data/manifests/the_stack_sample/sample_0714.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "01961",
    "manifest_path": "data/manifests/the_stack_sample/sample_0714.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "01962",
    "manifest_path": "data/manifests/the_stack_sample/sample_0720.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: contoso-website\nspec:\n  selector:\n    matchLabels:\n      app: contoso-website\n  template:\n    metadata:\n      labels:\n        app: contoso-website\n    spec:\n      containers:\n      - image: acrgh12949.azurecr.io/contoso-website\n        name: contoso-website\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 250m\n            memory: 256Mi\n        ports:\n        - containerPort: 80\n          name: http\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"contoso-website\" is using an invalid container image, \"acrgh12949.azurecr.io/contoso-website\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01963",
    "manifest_path": "data/manifests/the_stack_sample/sample_0720.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: contoso-website\nspec:\n  selector:\n    matchLabels:\n      app: contoso-website\n  template:\n    metadata:\n      labels:\n        app: contoso-website\n    spec:\n      containers:\n      - image: acrgh12949.azurecr.io/contoso-website\n        name: contoso-website\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 250m\n            memory: 256Mi\n        ports:\n        - containerPort: 80\n          name: http\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"contoso-website\" does not have a read-only root file system"
  },
  {
    "id": "01964",
    "manifest_path": "data/manifests/the_stack_sample/sample_0720.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: contoso-website\nspec:\n  selector:\n    matchLabels:\n      app: contoso-website\n  template:\n    metadata:\n      labels:\n        app: contoso-website\n    spec:\n      containers:\n      - image: acrgh12949.azurecr.io/contoso-website\n        name: contoso-website\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 250m\n            memory: 256Mi\n        ports:\n        - containerPort: 80\n          name: http\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"contoso-website\" is not set to runAsNonRoot"
  },
  {
    "id": "01965",
    "manifest_path": "data/manifests/the_stack_sample/sample_0721.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210616-1938066492\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"needs-rebase\" does not have a read-only root file system"
  },
  {
    "id": "01966",
    "manifest_path": "data/manifests/the_stack_sample/sample_0721.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210616-1938066492\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"needs-rebase\" is not set to runAsNonRoot"
  },
  {
    "id": "01967",
    "manifest_path": "data/manifests/the_stack_sample/sample_0721.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210616-1938066492\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"needs-rebase\" has cpu request 0"
  },
  {
    "id": "01968",
    "manifest_path": "data/manifests/the_stack_sample/sample_0721.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210616-1938066492\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"needs-rebase\" has memory limit 0"
  },
  {
    "id": "01969",
    "manifest_path": "data/manifests/the_stack_sample/sample_0722.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: blog-web-deployment\n  namespace: microservices-namespace\n  labels:\n    app: blog-web-deployment\n    moduleid: microservice-blog-web-service\n    version: 1.70.0-master\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: blog-web-deployment\n  template:\n    metadata:\n      labels:\n        app: blog-web-deployment\n    spec:\n      containers:\n      - name: app\n        image: repoflow/microservice-blog-web-container:1.70.0-master\n        env:\n        - name: HOST\n          value: www.repoflow.com\n        - name: BLOG_BASE_ROUTE_APP\n          value: /blog\n        - name: BLOG_INTERNAL_PORT_APP\n          value: '3000'\n        - name: BLOG_EXTERNAL_URL_GRAPH\n          value: http://www.repoflow.com/blog/backend/graphql\n        - name: BLOG_INTERNAL_URL_GRAPH\n          value: http://blog-graph-service.microservices-namespace:4000/blog/backend/graphql\n        - name: RESOURCES_BASE_ROUTE\n          value: /resources\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"app\" does not have a read-only root file system"
  },
  {
    "id": "01970",
    "manifest_path": "data/manifests/the_stack_sample/sample_0722.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: blog-web-deployment\n  namespace: microservices-namespace\n  labels:\n    app: blog-web-deployment\n    moduleid: microservice-blog-web-service\n    version: 1.70.0-master\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: blog-web-deployment\n  template:\n    metadata:\n      labels:\n        app: blog-web-deployment\n    spec:\n      containers:\n      - name: app\n        image: repoflow/microservice-blog-web-container:1.70.0-master\n        env:\n        - name: HOST\n          value: www.repoflow.com\n        - name: BLOG_BASE_ROUTE_APP\n          value: /blog\n        - name: BLOG_INTERNAL_PORT_APP\n          value: '3000'\n        - name: BLOG_EXTERNAL_URL_GRAPH\n          value: http://www.repoflow.com/blog/backend/graphql\n        - name: BLOG_INTERNAL_URL_GRAPH\n          value: http://blog-graph-service.microservices-namespace:4000/blog/backend/graphql\n        - name: RESOURCES_BASE_ROUTE\n          value: /resources\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"app\" is not set to runAsNonRoot"
  },
  {
    "id": "01971",
    "manifest_path": "data/manifests/the_stack_sample/sample_0722.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: blog-web-deployment\n  namespace: microservices-namespace\n  labels:\n    app: blog-web-deployment\n    moduleid: microservice-blog-web-service\n    version: 1.70.0-master\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: blog-web-deployment\n  template:\n    metadata:\n      labels:\n        app: blog-web-deployment\n    spec:\n      containers:\n      - name: app\n        image: repoflow/microservice-blog-web-container:1.70.0-master\n        env:\n        - name: HOST\n          value: www.repoflow.com\n        - name: BLOG_BASE_ROUTE_APP\n          value: /blog\n        - name: BLOG_INTERNAL_PORT_APP\n          value: '3000'\n        - name: BLOG_EXTERNAL_URL_GRAPH\n          value: http://www.repoflow.com/blog/backend/graphql\n        - name: BLOG_INTERNAL_URL_GRAPH\n          value: http://blog-graph-service.microservices-namespace:4000/blog/backend/graphql\n        - name: RESOURCES_BASE_ROUTE\n          value: /resources\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"app\" has cpu request 0"
  },
  {
    "id": "01972",
    "manifest_path": "data/manifests/the_stack_sample/sample_0722.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: blog-web-deployment\n  namespace: microservices-namespace\n  labels:\n    app: blog-web-deployment\n    moduleid: microservice-blog-web-service\n    version: 1.70.0-master\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: blog-web-deployment\n  template:\n    metadata:\n      labels:\n        app: blog-web-deployment\n    spec:\n      containers:\n      - name: app\n        image: repoflow/microservice-blog-web-container:1.70.0-master\n        env:\n        - name: HOST\n          value: www.repoflow.com\n        - name: BLOG_BASE_ROUTE_APP\n          value: /blog\n        - name: BLOG_INTERNAL_PORT_APP\n          value: '3000'\n        - name: BLOG_EXTERNAL_URL_GRAPH\n          value: http://www.repoflow.com/blog/backend/graphql\n        - name: BLOG_INTERNAL_URL_GRAPH\n          value: http://blog-graph-service.microservices-namespace:4000/blog/backend/graphql\n        - name: RESOURCES_BASE_ROUTE\n          value: /resources\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"app\" has memory limit 0"
  },
  {
    "id": "01973",
    "manifest_path": "data/manifests/the_stack_sample/sample_0725.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: jenkins-slave\n  labels:\n    name: jenkins-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: tjkemper/jnlp-slave:0.4\n    env:\n    - name: JENKINS_URL\n      value: http://100.68.13.101:80\n    volumeMounts:\n    - name: docker-sock\n      mountPath: /var/run/docker.sock\n    - name: config\n      mountPath: /home/jenkins/.kube/\n      readOnly: true\n  volumes:\n  - name: docker-sock\n    hostPath:\n      path: /var/run/docker.sock\n  - name: config\n    secret:\n      secretName: config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jenkins-slave\" does not have a read-only root file system"
  },
  {
    "id": "01974",
    "manifest_path": "data/manifests/the_stack_sample/sample_0725.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: jenkins-slave\n  labels:\n    name: jenkins-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: tjkemper/jnlp-slave:0.4\n    env:\n    - name: JENKINS_URL\n      value: http://100.68.13.101:80\n    volumeMounts:\n    - name: docker-sock\n      mountPath: /var/run/docker.sock\n    - name: config\n      mountPath: /home/jenkins/.kube/\n      readOnly: true\n  volumes:\n  - name: docker-sock\n    hostPath:\n      path: /var/run/docker.sock\n  - name: config\n    secret:\n      secretName: config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jenkins-slave\" is not set to runAsNonRoot"
  },
  {
    "id": "01975",
    "manifest_path": "data/manifests/the_stack_sample/sample_0725.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: jenkins-slave\n  labels:\n    name: jenkins-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: tjkemper/jnlp-slave:0.4\n    env:\n    - name: JENKINS_URL\n      value: http://100.68.13.101:80\n    volumeMounts:\n    - name: docker-sock\n      mountPath: /var/run/docker.sock\n    - name: config\n      mountPath: /home/jenkins/.kube/\n      readOnly: true\n  volumes:\n  - name: docker-sock\n    hostPath:\n      path: /var/run/docker.sock\n  - name: config\n    secret:\n      secretName: config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"jenkins-slave\" has cpu request 0"
  },
  {
    "id": "01976",
    "manifest_path": "data/manifests/the_stack_sample/sample_0725.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: jenkins-slave\n  labels:\n    name: jenkins-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: tjkemper/jnlp-slave:0.4\n    env:\n    - name: JENKINS_URL\n      value: http://100.68.13.101:80\n    volumeMounts:\n    - name: docker-sock\n      mountPath: /var/run/docker.sock\n    - name: config\n      mountPath: /home/jenkins/.kube/\n      readOnly: true\n  volumes:\n  - name: docker-sock\n    hostPath:\n      path: /var/run/docker.sock\n  - name: config\n    secret:\n      secretName: config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"jenkins-slave\" has memory limit 0"
  },
  {
    "id": "01977",
    "manifest_path": "data/manifests/the_stack_sample/sample_0727.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: oxshibboleth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: oxshibboleth\n  template:\n    spec:\n      containers:\n      - name: oxshibboleth\n        imagePullPolicy: Always\n        image: gluufederation/oxshibboleth:4.0.0\n        command:\n        - /bin/sh\n        - -c\n        - '/usr/bin/python /scripts/update-lb-ip.py &\n\n          /app/scripts/entrypoint.sh\n\n          '\n        volumeMounts:\n        - name: shared-shib\n          mountPath: /opt/shared-shibboleth-idp\n        - name: cb-pass\n          mountPath: /etc/gluu/conf/couchbase_password\n          subPath: couchbase_password\n        - name: cb-crt\n          mountPath: /etc/certs/couchbase.crt\n          subPath: couchbase.crt\n        - mountPath: /scripts\n          name: update-lb-ip\n        resources:\n          requests:\n            memory: 1500Mi\n            cpu: 1000m\n          limits:\n            memory: 2000Mi\n            cpu: 1500m\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: oxshibboleth-cm\n        livenessProbe:\n          httpGet:\n            path: /idp\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /idp\n            port: 8080\n          initialDelaySeconds: 25\n          periodSeconds: 25\n      volumes:\n      - name: shared-shib\n        persistentVolumeClaim:\n          claimName: shared-shib-pvc\n      - name: cb-pass\n        secret:\n          secretName: cb-pass\n      - name: cb-crt\n        secret:\n          secretName: cb-crt\n      - name: update-lb-ip\n        configMap:\n          name: updatelbip\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"oxshibboleth\" does not have a read-only root file system"
  },
  {
    "id": "01978",
    "manifest_path": "data/manifests/the_stack_sample/sample_0727.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: oxshibboleth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: oxshibboleth\n  template:\n    spec:\n      containers:\n      - name: oxshibboleth\n        imagePullPolicy: Always\n        image: gluufederation/oxshibboleth:4.0.0\n        command:\n        - /bin/sh\n        - -c\n        - '/usr/bin/python /scripts/update-lb-ip.py &\n\n          /app/scripts/entrypoint.sh\n\n          '\n        volumeMounts:\n        - name: shared-shib\n          mountPath: /opt/shared-shibboleth-idp\n        - name: cb-pass\n          mountPath: /etc/gluu/conf/couchbase_password\n          subPath: couchbase_password\n        - name: cb-crt\n          mountPath: /etc/certs/couchbase.crt\n          subPath: couchbase.crt\n        - mountPath: /scripts\n          name: update-lb-ip\n        resources:\n          requests:\n            memory: 1500Mi\n            cpu: 1000m\n          limits:\n            memory: 2000Mi\n            cpu: 1500m\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: oxshibboleth-cm\n        livenessProbe:\n          httpGet:\n            path: /idp\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /idp\n            port: 8080\n          initialDelaySeconds: 25\n          periodSeconds: 25\n      volumes:\n      - name: shared-shib\n        persistentVolumeClaim:\n          claimName: shared-shib-pvc\n      - name: cb-pass\n        secret:\n          secretName: cb-pass\n      - name: cb-crt\n        secret:\n          secretName: cb-crt\n      - name: update-lb-ip\n        configMap:\n          name: updatelbip\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"oxshibboleth\" is not set to runAsNonRoot"
  },
  {
    "id": "01979",
    "manifest_path": "data/manifests/the_stack_sample/sample_0731.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: verify-network\nspec:\n  template:\n    spec:\n      containers:\n      - name: verify-network\n        image: busybox:1.30.1\n        command:\n        - nc\n        args:\n        - -z\n        - kubernetes\n        - '443'\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: In\n                values:\n                - verify-network\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"verify-network\" does not have a read-only root file system"
  },
  {
    "id": "01980",
    "manifest_path": "data/manifests/the_stack_sample/sample_0731.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: verify-network\nspec:\n  template:\n    spec:\n      containers:\n      - name: verify-network\n        image: busybox:1.30.1\n        command:\n        - nc\n        args:\n        - -z\n        - kubernetes\n        - '443'\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: In\n                values:\n                - verify-network\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"verify-network\" is not set to runAsNonRoot"
  },
  {
    "id": "01981",
    "manifest_path": "data/manifests/the_stack_sample/sample_0731.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: verify-network\nspec:\n  template:\n    spec:\n      containers:\n      - name: verify-network\n        image: busybox:1.30.1\n        command:\n        - nc\n        args:\n        - -z\n        - kubernetes\n        - '443'\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: In\n                values:\n                - verify-network\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"verify-network\" has cpu request 0"
  },
  {
    "id": "01982",
    "manifest_path": "data/manifests/the_stack_sample/sample_0731.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: verify-network\nspec:\n  template:\n    spec:\n      containers:\n      - name: verify-network\n        image: busybox:1.30.1\n        command:\n        - nc\n        args:\n        - -z\n        - kubernetes\n        - '443'\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: job-name\n                operator: In\n                values:\n                - verify-network\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"verify-network\" has memory limit 0"
  },
  {
    "id": "01983",
    "manifest_path": "data/manifests/the_stack_sample/sample_0732.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: demo-daemonset-prod\n  namespace: default\n  labels:\n    app: demo-daemon-prod\nspec:\n  selector:\n    matchLabels:\n      name: demo-daemon-prod\n  template:\n    metadata:\n      labels:\n        name: demo-daemon-prod\n    spec:\n      containers:\n      - name: demo-daemon-prod\n        image: busybox\n        args:\n        - /bin/sh\n        - -c\n        - date; sleep 500\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"demo-daemon-prod\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01984",
    "manifest_path": "data/manifests/the_stack_sample/sample_0732.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: demo-daemonset-prod\n  namespace: default\n  labels:\n    app: demo-daemon-prod\nspec:\n  selector:\n    matchLabels:\n      name: demo-daemon-prod\n  template:\n    metadata:\n      labels:\n        name: demo-daemon-prod\n    spec:\n      containers:\n      - name: demo-daemon-prod\n        image: busybox\n        args:\n        - /bin/sh\n        - -c\n        - date; sleep 500\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"demo-daemon-prod\" does not have a read-only root file system"
  },
  {
    "id": "01985",
    "manifest_path": "data/manifests/the_stack_sample/sample_0732.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: demo-daemonset-prod\n  namespace: default\n  labels:\n    app: demo-daemon-prod\nspec:\n  selector:\n    matchLabels:\n      name: demo-daemon-prod\n  template:\n    metadata:\n      labels:\n        name: demo-daemon-prod\n    spec:\n      containers:\n      - name: demo-daemon-prod\n        image: busybox\n        args:\n        - /bin/sh\n        - -c\n        - date; sleep 500\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"demo-daemon-prod\" is not set to runAsNonRoot"
  },
  {
    "id": "01986",
    "manifest_path": "data/manifests/the_stack_sample/sample_0734.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgress-pod\n  labels:\n    name: postress-pod\n    app: demo-voting-app\nspec:\n  containers:\n  - name: postgres\n    image: postgres:9.4\n    ports:\n    - containerPort: 5492\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"postgres\" does not have a read-only root file system"
  },
  {
    "id": "01987",
    "manifest_path": "data/manifests/the_stack_sample/sample_0734.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgress-pod\n  labels:\n    name: postress-pod\n    app: demo-voting-app\nspec:\n  containers:\n  - name: postgres\n    image: postgres:9.4\n    ports:\n    - containerPort: 5492\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"postgres\" is not set to runAsNonRoot"
  },
  {
    "id": "01988",
    "manifest_path": "data/manifests/the_stack_sample/sample_0734.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgress-pod\n  labels:\n    name: postress-pod\n    app: demo-voting-app\nspec:\n  containers:\n  - name: postgres\n    image: postgres:9.4\n    ports:\n    - containerPort: 5492\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"postgres\" has cpu request 0"
  },
  {
    "id": "01989",
    "manifest_path": "data/manifests/the_stack_sample/sample_0734.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgress-pod\n  labels:\n    name: postress-pod\n    app: demo-voting-app\nspec:\n  containers:\n  - name: postgres\n    image: postgres:9.4\n    ports:\n    - containerPort: 5492\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"postgres\" has memory limit 0"
  },
  {
    "id": "01990",
    "manifest_path": "data/manifests/the_stack_sample/sample_0735.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: artifact-tracker-server\n  labels:\n    db: pgsql\nspec:\n  selector:\n    matchLabels:\n      name: artifact-tracker-server\n  template:\n    metadata:\n      labels:\n        name: artifact-tracker-server\n    spec:\n      containers:\n      - name: artifact-tracker-server\n        image: gcr.io/pl-dev-infra/cloud/artifact_tracker_server_image\n        ports:\n        - containerPort: 50750\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-artifact-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: PL_VIZIER_VERSION\n          value: ''\n        - name: PL_CLI_VERSION\n          value: ''\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: artifact-access-sa\n          mountPath: /creds\n          readOnly: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: artifact-access-sa\n        secret:\n          secretName: artifact-access-sa\n          optional: true\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"artifact-tracker-server\" is using an invalid container image, \"gcr.io/pl-dev-infra/cloud/artifact_tracker_server_image\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01991",
    "manifest_path": "data/manifests/the_stack_sample/sample_0735.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: artifact-tracker-server\n  labels:\n    db: pgsql\nspec:\n  selector:\n    matchLabels:\n      name: artifact-tracker-server\n  template:\n    metadata:\n      labels:\n        name: artifact-tracker-server\n    spec:\n      containers:\n      - name: artifact-tracker-server\n        image: gcr.io/pl-dev-infra/cloud/artifact_tracker_server_image\n        ports:\n        - containerPort: 50750\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-artifact-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: PL_VIZIER_VERSION\n          value: ''\n        - name: PL_CLI_VERSION\n          value: ''\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: artifact-access-sa\n          mountPath: /creds\n          readOnly: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: artifact-access-sa\n        secret:\n          secretName: artifact-access-sa\n          optional: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"artifact-tracker-server\" does not have a read-only root file system"
  },
  {
    "id": "01992",
    "manifest_path": "data/manifests/the_stack_sample/sample_0735.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: artifact-tracker-server\n  labels:\n    db: pgsql\nspec:\n  selector:\n    matchLabels:\n      name: artifact-tracker-server\n  template:\n    metadata:\n      labels:\n        name: artifact-tracker-server\n    spec:\n      containers:\n      - name: artifact-tracker-server\n        image: gcr.io/pl-dev-infra/cloud/artifact_tracker_server_image\n        ports:\n        - containerPort: 50750\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-artifact-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: PL_VIZIER_VERSION\n          value: ''\n        - name: PL_CLI_VERSION\n          value: ''\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: artifact-access-sa\n          mountPath: /creds\n          readOnly: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: artifact-access-sa\n        secret:\n          secretName: artifact-access-sa\n          optional: true\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"artifact-tracker-server\" is not set to runAsNonRoot"
  },
  {
    "id": "01993",
    "manifest_path": "data/manifests/the_stack_sample/sample_0735.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: artifact-tracker-server\n  labels:\n    db: pgsql\nspec:\n  selector:\n    matchLabels:\n      name: artifact-tracker-server\n  template:\n    metadata:\n      labels:\n        name: artifact-tracker-server\n    spec:\n      containers:\n      - name: artifact-tracker-server\n        image: gcr.io/pl-dev-infra/cloud/artifact_tracker_server_image\n        ports:\n        - containerPort: 50750\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-artifact-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: PL_VIZIER_VERSION\n          value: ''\n        - name: PL_CLI_VERSION\n          value: ''\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: artifact-access-sa\n          mountPath: /creds\n          readOnly: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: artifact-access-sa\n        secret:\n          secretName: artifact-access-sa\n          optional: true\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"artifact-tracker-server\" has cpu request 0"
  },
  {
    "id": "01994",
    "manifest_path": "data/manifests/the_stack_sample/sample_0735.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: artifact-tracker-server\n  labels:\n    db: pgsql\nspec:\n  selector:\n    matchLabels:\n      name: artifact-tracker-server\n  template:\n    metadata:\n      labels:\n        name: artifact-tracker-server\n    spec:\n      containers:\n      - name: artifact-tracker-server\n        image: gcr.io/pl-dev-infra/cloud/artifact_tracker_server_image\n        ports:\n        - containerPort: 50750\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50750\n        envFrom:\n        - configMapRef:\n            name: pl-db-config\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-artifact-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_POSTGRES_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_USERNAME\n        - name: PL_POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-db-secrets\n              key: PL_POSTGRES_PASSWORD\n        - name: PL_VIZIER_VERSION\n          value: ''\n        - name: PL_CLI_VERSION\n          value: ''\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: artifact-access-sa\n          mountPath: /creds\n          readOnly: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: artifact-access-sa\n        secret:\n          secretName: artifact-access-sa\n          optional: true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"artifact-tracker-server\" has memory limit 0"
  },
  {
    "id": "01995",
    "manifest_path": "data/manifests/the_stack_sample/sample_0738.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventsource-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventsource-controller\n  template:\n    metadata:\n      labels:\n        app: eventsource-controller\n    spec:\n      serviceAccountName: argo-events-sa\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 9731\n      containers:\n      - name: eventsource-controller\n        image: quay.io/argoproj/argo-events:latest\n        imagePullPolicy: Always\n        args:\n        - eventsource-controller\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: EVENTSOURCE_IMAGE\n          value: quay.io/argoproj/argo-events:latest\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"eventsource-controller\" is using an invalid container image, \"quay.io/argoproj/argo-events:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01996",
    "manifest_path": "data/manifests/the_stack_sample/sample_0738.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventsource-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventsource-controller\n  template:\n    metadata:\n      labels:\n        app: eventsource-controller\n    spec:\n      serviceAccountName: argo-events-sa\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 9731\n      containers:\n      - name: eventsource-controller\n        image: quay.io/argoproj/argo-events:latest\n        imagePullPolicy: Always\n        args:\n        - eventsource-controller\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: EVENTSOURCE_IMAGE\n          value: quay.io/argoproj/argo-events:latest\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"eventsource-controller\" does not have a read-only root file system"
  },
  {
    "id": "01997",
    "manifest_path": "data/manifests/the_stack_sample/sample_0738.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventsource-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventsource-controller\n  template:\n    metadata:\n      labels:\n        app: eventsource-controller\n    spec:\n      serviceAccountName: argo-events-sa\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 9731\n      containers:\n      - name: eventsource-controller\n        image: quay.io/argoproj/argo-events:latest\n        imagePullPolicy: Always\n        args:\n        - eventsource-controller\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: EVENTSOURCE_IMAGE\n          value: quay.io/argoproj/argo-events:latest\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"eventsource-controller\" has cpu request 0"
  },
  {
    "id": "01998",
    "manifest_path": "data/manifests/the_stack_sample/sample_0738.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eventsource-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eventsource-controller\n  template:\n    metadata:\n      labels:\n        app: eventsource-controller\n    spec:\n      serviceAccountName: argo-events-sa\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 9731\n      containers:\n      - name: eventsource-controller\n        image: quay.io/argoproj/argo-events:latest\n        imagePullPolicy: Always\n        args:\n        - eventsource-controller\n        env:\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: EVENTSOURCE_IMAGE\n          value: quay.io/argoproj/argo-events:latest\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"eventsource-controller\" has memory limit 0"
  },
  {
    "id": "01999",
    "manifest_path": "data/manifests/the_stack_sample/sample_0739.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: sample-app\n  name: sample-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sample-app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sample-app\n    spec:\n      containers:\n      - image: quay.io/mpeters/sample-app:latest\n        imagePullPolicy: Always\n        name: sample-app\n        ports:\n        - containerPort: 8080\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"sample-app\" is using an invalid container image, \"quay.io/mpeters/sample-app:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02000",
    "manifest_path": "data/manifests/the_stack_sample/sample_0739.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: sample-app\n  name: sample-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sample-app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sample-app\n    spec:\n      containers:\n      - image: quay.io/mpeters/sample-app:latest\n        imagePullPolicy: Always\n        name: sample-app\n        ports:\n        - containerPort: 8080\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sample-app\" does not have a read-only root file system"
  },
  {
    "id": "02001",
    "manifest_path": "data/manifests/the_stack_sample/sample_0739.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: sample-app\n  name: sample-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sample-app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sample-app\n    spec:\n      containers:\n      - image: quay.io/mpeters/sample-app:latest\n        imagePullPolicy: Always\n        name: sample-app\n        ports:\n        - containerPort: 8080\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sample-app\" is not set to runAsNonRoot"
  },
  {
    "id": "02002",
    "manifest_path": "data/manifests/the_stack_sample/sample_0739.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: sample-app\n  name: sample-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sample-app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sample-app\n    spec:\n      containers:\n      - image: quay.io/mpeters/sample-app:latest\n        imagePullPolicy: Always\n        name: sample-app\n        ports:\n        - containerPort: 8080\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sample-app\" has cpu request 0"
  },
  {
    "id": "02003",
    "manifest_path": "data/manifests/the_stack_sample/sample_0739.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: sample-app\n  name: sample-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sample-app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sample-app\n    spec:\n      containers:\n      - image: quay.io/mpeters/sample-app:latest\n        imagePullPolicy: Always\n        name: sample-app\n        ports:\n        - containerPort: 8080\n        env:\n        - name: NODE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sample-app\" has memory limit 0"
  },
  {
    "id": "02004",
    "manifest_path": "data/manifests/the_stack_sample/sample_0740.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: adaptor\n  name: adaptor\n  namespace: system\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: adaptor\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: adaptor\n    spec:\n      containers:\n      - name: octopus\n        image: cnrancher/octopus-adaptor-modbus:master\n        volumeMounts:\n        - mountPath: /var/lib/octopus/adaptors/\n          name: sockets\n        - mountPath: /dev\n          name: dev\n        securityContext:\n          privileged: true\n      volumes:\n      - name: sockets\n        hostPath:\n          path: /var/lib/octopus/adaptors/\n          type: DirectoryOrCreate\n      - name: dev\n        hostPath:\n          path: /dev\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"octopus\" does not have a read-only root file system"
  },
  {
    "id": "02005",
    "manifest_path": "data/manifests/the_stack_sample/sample_0740.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: adaptor\n  name: adaptor\n  namespace: system\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: adaptor\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: adaptor\n    spec:\n      containers:\n      - name: octopus\n        image: cnrancher/octopus-adaptor-modbus:master\n        volumeMounts:\n        - mountPath: /var/lib/octopus/adaptors/\n          name: sockets\n        - mountPath: /dev\n          name: dev\n        securityContext:\n          privileged: true\n      volumes:\n      - name: sockets\n        hostPath:\n          path: /var/lib/octopus/adaptors/\n          type: DirectoryOrCreate\n      - name: dev\n        hostPath:\n          path: /dev\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"octopus\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "02006",
    "manifest_path": "data/manifests/the_stack_sample/sample_0740.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: adaptor\n  name: adaptor\n  namespace: system\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: adaptor\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: adaptor\n    spec:\n      containers:\n      - name: octopus\n        image: cnrancher/octopus-adaptor-modbus:master\n        volumeMounts:\n        - mountPath: /var/lib/octopus/adaptors/\n          name: sockets\n        - mountPath: /dev\n          name: dev\n        securityContext:\n          privileged: true\n      volumes:\n      - name: sockets\n        hostPath:\n          path: /var/lib/octopus/adaptors/\n          type: DirectoryOrCreate\n      - name: dev\n        hostPath:\n          path: /dev\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"octopus\" is privileged"
  },
  {
    "id": "02007",
    "manifest_path": "data/manifests/the_stack_sample/sample_0740.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: adaptor\n  name: adaptor\n  namespace: system\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: adaptor\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: adaptor\n    spec:\n      containers:\n      - name: octopus\n        image: cnrancher/octopus-adaptor-modbus:master\n        volumeMounts:\n        - mountPath: /var/lib/octopus/adaptors/\n          name: sockets\n        - mountPath: /dev\n          name: dev\n        securityContext:\n          privileged: true\n      volumes:\n      - name: sockets\n        hostPath:\n          path: /var/lib/octopus/adaptors/\n          type: DirectoryOrCreate\n      - name: dev\n        hostPath:\n          path: /dev\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"octopus\" is not set to runAsNonRoot"
  },
  {
    "id": "02008",
    "manifest_path": "data/manifests/the_stack_sample/sample_0740.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: adaptor\n  name: adaptor\n  namespace: system\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: adaptor\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: adaptor\n    spec:\n      containers:\n      - name: octopus\n        image: cnrancher/octopus-adaptor-modbus:master\n        volumeMounts:\n        - mountPath: /var/lib/octopus/adaptors/\n          name: sockets\n        - mountPath: /dev\n          name: dev\n        securityContext:\n          privileged: true\n      volumes:\n      - name: sockets\n        hostPath:\n          path: /var/lib/octopus/adaptors/\n          type: DirectoryOrCreate\n      - name: dev\n        hostPath:\n          path: /dev\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"octopus\" has cpu request 0"
  },
  {
    "id": "02009",
    "manifest_path": "data/manifests/the_stack_sample/sample_0740.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: adaptor\n  name: adaptor\n  namespace: system\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: adaptor\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: adaptor\n    spec:\n      containers:\n      - name: octopus\n        image: cnrancher/octopus-adaptor-modbus:master\n        volumeMounts:\n        - mountPath: /var/lib/octopus/adaptors/\n          name: sockets\n        - mountPath: /dev\n          name: dev\n        securityContext:\n          privileged: true\n      volumes:\n      - name: sockets\n        hostPath:\n          path: /var/lib/octopus/adaptors/\n          type: DirectoryOrCreate\n      - name: dev\n        hostPath:\n          path: /dev\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"octopus\" has memory limit 0"
  },
  {
    "id": "02010",
    "manifest_path": "data/manifests/the_stack_sample/sample_0742.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cron-composites-lib-unb-ca\n  namespace: dev\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-composites-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: dev\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: composites-lib-unb-ca\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cron-composites-lib-unb-ca\" is using an invalid container image, \"||DEPLOYMENTIMAGE||\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02011",
    "manifest_path": "data/manifests/the_stack_sample/sample_0742.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cron-composites-lib-unb-ca\n  namespace: dev\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-composites-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: dev\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: composites-lib-unb-ca\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cron-composites-lib-unb-ca\" does not have a read-only root file system"
  },
  {
    "id": "02012",
    "manifest_path": "data/manifests/the_stack_sample/sample_0742.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cron-composites-lib-unb-ca\n  namespace: dev\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-composites-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: dev\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: composites-lib-unb-ca\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cron-composites-lib-unb-ca\" is not set to runAsNonRoot"
  },
  {
    "id": "02013",
    "manifest_path": "data/manifests/the_stack_sample/sample_0742.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cron-composites-lib-unb-ca\n  namespace: dev\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-composites-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: dev\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: composites-lib-unb-ca\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cron-composites-lib-unb-ca\" has cpu request 0"
  },
  {
    "id": "02014",
    "manifest_path": "data/manifests/the_stack_sample/sample_0742.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cron-composites-lib-unb-ca\n  namespace: dev\n  labels:\n    app: drupal\n    tier: cron\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: cron-composites-lib-unb-ca\n          command:\n          - /scripts/drupalCronEntry.sh\n          env:\n          - name: DEPLOY_ENV\n            value: dev\n          - name: MYSQL_HOSTNAME\n            value: drupal-mysql-lib-unb-ca\n          - name: MYSQL_PORT\n            value: '3306'\n          image: '||DEPLOYMENTIMAGE||'\n          imagePullPolicy: Always\n          volumeMounts:\n          - mountPath: /app/html/sites/default\n            name: drupal-persistent-storage\n        volumes:\n        - name: drupal-persistent-storage\n          persistentVolumeClaim:\n            claimName: composites-lib-unb-ca\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cron-composites-lib-unb-ca\" has memory limit 0"
  },
  {
    "id": "02015",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"graphql-server\" is using an invalid container image, \"hongbomiao/hm-graphql-server:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02016",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"opal-client\" is using an invalid container image, \"hongbomiao/hm-opal-client:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02017",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"graphql-server\" does not have a read-only root file system"
  },
  {
    "id": "02018",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"opal-client\" does not have a read-only root file system"
  },
  {
    "id": "02019",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"graphql-server\" is not set to runAsNonRoot"
  },
  {
    "id": "02020",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"opal-client\" is not set to runAsNonRoot"
  },
  {
    "id": "02021",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"graphql-server\" has cpu request 0"
  },
  {
    "id": "02022",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"opal-client\" has cpu request 0"
  },
  {
    "id": "02023",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"graphql-server\" has memory limit 0"
  },
  {
    "id": "02024",
    "manifest_path": "data/manifests/the_stack_sample/sample_0747.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: graphql-server-deployment\n  namespace: hm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: graphql-server\n  template:\n    metadata:\n      labels:\n        component: graphql-server\n    spec:\n      containers:\n      - name: graphql-server\n        image: hongbomiao/hm-graphql-server:latest\n        env:\n        - name: APP_ENV\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: app_env\n        - name: PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: port\n        - name: GRPC_SERVER_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_host\n        - name: GRPC_SERVER_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: grpc_server_port\n        - name: OPA_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_host\n        - name: OPA_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opa_port\n        - name: DGRAPH_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_host\n        - name: DGRAPH_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: dgraph_grpc_port\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_host\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_port\n        - name: REDIS_DB\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: redis_db\n        - name: MINIO_ENDPOINT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_endpoint\n        - name: MINIO_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_access_key_id\n        - name: MINIO_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: minio_secret_access_key\n        - name: TORCH_SERVE_GRPC_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_host\n        - name: TORCH_SERVE_GRPC_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: torch_serve_grpc_port\n        - name: OPEN_CENSUS_AGENT_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_host\n        - name: OPEN_CENSUS_AGENT_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: open_census_agent_port\n        - name: JAEGER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jaeger_url\n        - name: JWT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: jwt_secret\n        - name: ELASTIC_APM_SERVICE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: elastic_apm_service_name\n        - name: ELASTIC_APM_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_url\n        - name: ELASTIC_APM_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_environment\n        - name: ELASTIC_APM_SECRET_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-elastic-apm\n              key: token\n        - name: ELASTIC_APM_VERIFY_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_verify_server_cert\n        - name: ELASTIC_APM_SERVER_CERT\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_server_cert\n        - name: ELASTIC_APM_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_level\n        - name: ELASTIC_APM_LOG_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: elastic-apm-configmap\n              key: elastic_apm_log_file\n        ports:\n        - name: graphql-server\n          protocol: TCP\n          containerPort: 31800\n        volumeMounts:\n        - mountPath: /data/elastic-apm\n          name: elastic-apm-volume\n      - name: opal-client\n        image: hongbomiao/hm-opal-client:latest\n        env:\n        - name: OPAL_CLIENT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hm-opal-client-secret\n              key: opal_client_token\n        - name: OPAL_SERVER_URL\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_server_url\n        - name: OPAL_FETCH_PROVIDER_MODULES\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_fetch_provider_modules\n        - name: OPAL_INLINE_OPA_CONFIG\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_config\n        - name: OPAL_INLINE_OPA_LOG_FORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_inline_opa_log_format\n        - name: OPAL_LOG_MODULE_EXCLUDE_LIST\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_module_exclude_list\n        - name: OPAL_LOG_COLORIZE\n          valueFrom:\n            configMapKeyRef:\n              name: graphql-server-configmap\n              key: opal_log_colorize\n        ports:\n        - name: opal-client\n          protocol: TCP\n          containerPort: 7000\n        - name: opa\n          protocol: TCP\n          containerPort: 8181\n        volumeMounts:\n        - mountPath: /data/opa\n          name: opa-volume\n      volumes:\n      - name: elastic-apm-volume\n        persistentVolumeClaim:\n          claimName: elastic-apm-pvc\n      - name: opa-volume\n        persistentVolumeClaim:\n          claimName: opa-pvc\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"opal-client\" has memory limit 0"
  },
  {
    "id": "02025",
    "manifest_path": "data/manifests/the_stack_sample/sample_0749.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: catalogue-db\n  labels:\n    name: catalogue-db\nspec:\n  containers:\n  - name: catalogue-db\n    image: weaveworksdemos/catalogue-db:0.2.0\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: fake_password\n    - name: MYSQL_DATABASE\n      value: socksdb\n    ports:\n    - name: mysql\n      containerPort: 3306\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"catalogue-db\" does not have a read-only root file system"
  },
  {
    "id": "02026",
    "manifest_path": "data/manifests/the_stack_sample/sample_0749.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: catalogue-db\n  labels:\n    name: catalogue-db\nspec:\n  containers:\n  - name: catalogue-db\n    image: weaveworksdemos/catalogue-db:0.2.0\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: fake_password\n    - name: MYSQL_DATABASE\n      value: socksdb\n    ports:\n    - name: mysql\n      containerPort: 3306\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"catalogue-db\" is not set to runAsNonRoot"
  },
  {
    "id": "02027",
    "manifest_path": "data/manifests/the_stack_sample/sample_0749.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: catalogue-db\n  labels:\n    name: catalogue-db\nspec:\n  containers:\n  - name: catalogue-db\n    image: weaveworksdemos/catalogue-db:0.2.0\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: fake_password\n    - name: MYSQL_DATABASE\n      value: socksdb\n    ports:\n    - name: mysql\n      containerPort: 3306\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"catalogue-db\" has cpu request 0"
  },
  {
    "id": "02028",
    "manifest_path": "data/manifests/the_stack_sample/sample_0749.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: catalogue-db\n  labels:\n    name: catalogue-db\nspec:\n  containers:\n  - name: catalogue-db\n    image: weaveworksdemos/catalogue-db:0.2.0\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: fake_password\n    - name: MYSQL_DATABASE\n      value: socksdb\n    ports:\n    - name: mysql\n      containerPort: 3306\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"catalogue-db\" has memory limit 0"
  },
  {
    "id": "02029",
    "manifest_path": "data/manifests/the_stack_sample/sample_0751.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: quotesweb\n  labels:\n    app: quotesweb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: quotesweb\n  template:\n    metadata:\n      labels:\n        app: quotesweb\n    spec:\n      containers:\n      - name: quotes\n        image: quay.io/donschenck/quotesweb:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"quotes\" does not have a read-only root file system"
  },
  {
    "id": "02030",
    "manifest_path": "data/manifests/the_stack_sample/sample_0751.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: quotesweb\n  labels:\n    app: quotesweb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: quotesweb\n  template:\n    metadata:\n      labels:\n        app: quotesweb\n    spec:\n      containers:\n      - name: quotes\n        image: quay.io/donschenck/quotesweb:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"quotes\" is not set to runAsNonRoot"
  },
  {
    "id": "02031",
    "manifest_path": "data/manifests/the_stack_sample/sample_0751.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: quotesweb\n  labels:\n    app: quotesweb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: quotesweb\n  template:\n    metadata:\n      labels:\n        app: quotesweb\n    spec:\n      containers:\n      - name: quotes\n        image: quay.io/donschenck/quotesweb:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"quotes\" has cpu request 0"
  },
  {
    "id": "02032",
    "manifest_path": "data/manifests/the_stack_sample/sample_0751.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: quotesweb\n  labels:\n    app: quotesweb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: quotesweb\n  template:\n    metadata:\n      labels:\n        app: quotesweb\n    spec:\n      containers:\n      - name: quotes\n        image: quay.io/donschenck/quotesweb:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"quotes\" has memory limit 0"
  },
  {
    "id": "02033",
    "manifest_path": "data/manifests/the_stack_sample/sample_0757.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-php\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      containers:\n      - name: demo-php\n        image: demo-php:latest\n        imagePullPolicy: Never\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 9000\n      - name: demo-nginx\n        image: demo-nginx:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            cpu: 150m\n          requests:\n            cpu: 50m\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"demo-nginx\" is using an invalid container image, \"demo-nginx:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02034",
    "manifest_path": "data/manifests/the_stack_sample/sample_0757.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-php\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      containers:\n      - name: demo-php\n        image: demo-php:latest\n        imagePullPolicy: Never\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 9000\n      - name: demo-nginx\n        image: demo-nginx:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            cpu: 150m\n          requests:\n            cpu: 50m\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"demo-php\" is using an invalid container image, \"demo-php:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02035",
    "manifest_path": "data/manifests/the_stack_sample/sample_0757.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-php\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      containers:\n      - name: demo-php\n        image: demo-php:latest\n        imagePullPolicy: Never\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 9000\n      - name: demo-nginx\n        image: demo-nginx:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            cpu: 150m\n          requests:\n            cpu: 50m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"demo-nginx\" does not have a read-only root file system"
  },
  {
    "id": "02036",
    "manifest_path": "data/manifests/the_stack_sample/sample_0757.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-php\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      containers:\n      - name: demo-php\n        image: demo-php:latest\n        imagePullPolicy: Never\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 9000\n      - name: demo-nginx\n        image: demo-nginx:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            cpu: 150m\n          requests:\n            cpu: 50m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"demo-php\" does not have a read-only root file system"
  },
  {
    "id": "02037",
    "manifest_path": "data/manifests/the_stack_sample/sample_0757.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-php\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      containers:\n      - name: demo-php\n        image: demo-php:latest\n        imagePullPolicy: Never\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 9000\n      - name: demo-nginx\n        image: demo-nginx:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            cpu: 150m\n          requests:\n            cpu: 50m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"demo-nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02038",
    "manifest_path": "data/manifests/the_stack_sample/sample_0757.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-php\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      containers:\n      - name: demo-php\n        image: demo-php:latest\n        imagePullPolicy: Never\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 9000\n      - name: demo-nginx\n        image: demo-nginx:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            cpu: 150m\n          requests:\n            cpu: 50m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"demo-php\" is not set to runAsNonRoot"
  },
  {
    "id": "02039",
    "manifest_path": "data/manifests/the_stack_sample/sample_0757.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-php\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      containers:\n      - name: demo-php\n        image: demo-php:latest\n        imagePullPolicy: Never\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 9000\n      - name: demo-nginx\n        image: demo-nginx:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            cpu: 150m\n          requests:\n            cpu: 50m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"demo-nginx\" has memory limit 0"
  },
  {
    "id": "02040",
    "manifest_path": "data/manifests/the_stack_sample/sample_0757.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-php\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      containers:\n      - name: demo-php\n        image: demo-php:latest\n        imagePullPolicy: Never\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 9000\n      - name: demo-nginx\n        image: demo-nginx:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 80\n        resources:\n          limits:\n            cpu: 150m\n          requests:\n            cpu: 50m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"demo-php\" has memory limit 0"
  },
  {
    "id": "02041",
    "manifest_path": "data/manifests/the_stack_sample/sample_0760.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20211216-b5865074c4\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"needs-rebase\" does not have a read-only root file system"
  },
  {
    "id": "02042",
    "manifest_path": "data/manifests/the_stack_sample/sample_0760.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20211216-b5865074c4\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"needs-rebase\" is not set to runAsNonRoot"
  },
  {
    "id": "02043",
    "manifest_path": "data/manifests/the_stack_sample/sample_0760.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20211216-b5865074c4\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"needs-rebase\" has cpu request 0"
  },
  {
    "id": "02044",
    "manifest_path": "data/manifests/the_stack_sample/sample_0760.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20211216-b5865074c4\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"needs-rebase\" has memory limit 0"
  },
  {
    "id": "02045",
    "manifest_path": "data/manifests/the_stack_sample/sample_0761.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bookstore-addbook\n  labels:\n    app: add-book\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: add-book\n  template:\n    metadata:\n      labels:\n        app: add-book\n    spec:\n      containers:\n      - name: addbook\n        image: pkarthick83/appinframodwithgke:addbook-latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        env:\n        - name: MYSQL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: username\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: password\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: dbhost\n        readinessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          failureThreshold: 3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"addbook\" does not have a read-only root file system"
  },
  {
    "id": "02046",
    "manifest_path": "data/manifests/the_stack_sample/sample_0761.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bookstore-addbook\n  labels:\n    app: add-book\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: add-book\n  template:\n    metadata:\n      labels:\n        app: add-book\n    spec:\n      containers:\n      - name: addbook\n        image: pkarthick83/appinframodwithgke:addbook-latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        env:\n        - name: MYSQL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: username\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: password\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: dbhost\n        readinessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          failureThreshold: 3\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"addbook\" is not set to runAsNonRoot"
  },
  {
    "id": "02047",
    "manifest_path": "data/manifests/the_stack_sample/sample_0761.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bookstore-addbook\n  labels:\n    app: add-book\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: add-book\n  template:\n    metadata:\n      labels:\n        app: add-book\n    spec:\n      containers:\n      - name: addbook\n        image: pkarthick83/appinframodwithgke:addbook-latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        env:\n        - name: MYSQL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: username\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: password\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: dbhost\n        readinessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          failureThreshold: 3\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"addbook\" has cpu request 0"
  },
  {
    "id": "02048",
    "manifest_path": "data/manifests/the_stack_sample/sample_0761.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bookstore-addbook\n  labels:\n    app: add-book\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: add-book\n  template:\n    metadata:\n      labels:\n        app: add-book\n    spec:\n      containers:\n      - name: addbook\n        image: pkarthick83/appinframodwithgke:addbook-latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        env:\n        - name: MYSQL_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: username\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: password\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: dbhost\n        readinessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          failureThreshold: 3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"addbook\" has memory limit 0"
  },
  {
    "id": "02049",
    "manifest_path": "data/manifests/the_stack_sample/sample_0762.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mfpod\nspec:\n  containers:\n  - name: mynginxcon\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"mynginxcon\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02050",
    "manifest_path": "data/manifests/the_stack_sample/sample_0762.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mfpod\nspec:\n  containers:\n  - name: mynginxcon\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mynginxcon\" does not have a read-only root file system"
  },
  {
    "id": "02051",
    "manifest_path": "data/manifests/the_stack_sample/sample_0762.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mfpod\nspec:\n  containers:\n  - name: mynginxcon\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mynginxcon\" is not set to runAsNonRoot"
  },
  {
    "id": "02052",
    "manifest_path": "data/manifests/the_stack_sample/sample_0762.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mfpod\nspec:\n  containers:\n  - name: mynginxcon\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mynginxcon\" has cpu request 0"
  },
  {
    "id": "02053",
    "manifest_path": "data/manifests/the_stack_sample/sample_0762.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mfpod\nspec:\n  containers:\n  - name: mynginxcon\n    image: nginx\n    ports:\n    - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mynginxcon\" has memory limit 0"
  },
  {
    "id": "02054",
    "manifest_path": "data/manifests/the_stack_sample/sample_0763.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.4\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02055",
    "manifest_path": "data/manifests/the_stack_sample/sample_0763.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.4\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02056",
    "manifest_path": "data/manifests/the_stack_sample/sample_0763.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.4\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02057",
    "manifest_path": "data/manifests/the_stack_sample/sample_0763.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.4\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02058",
    "manifest_path": "data/manifests/the_stack_sample/sample_0764.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9591\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02059",
    "manifest_path": "data/manifests/the_stack_sample/sample_0764.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9591\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02060",
    "manifest_path": "data/manifests/the_stack_sample/sample_0764.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9591\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02061",
    "manifest_path": "data/manifests/the_stack_sample/sample_0764.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9591\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02062",
    "manifest_path": "data/manifests/the_stack_sample/sample_0764.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9591\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02063",
    "manifest_path": "data/manifests/the_stack_sample/sample_0766.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flink-jobmanager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flink\n      component: jobmanager\n  template:\n    metadata:\n      labels:\n        app: flink\n        component: jobmanager\n    spec:\n      serviceAccountName: zep-flink-eks-kt-svcacct\n      containers:\n      - name: jobmanager\n        image: docker.io/kthyagar/ktflink\n        workingDir: /opt/flink\n        command:\n        - /bin/bash\n        - -c\n        - $FLINK_HOME/bin/jobmanager.sh start;while :; do if [[ -f $(find log -name\n          '*jobmanager*.log' -print -quit) ]]; then tail -f -n +1 log/*jobmanager*.log;\n          fi; done\n        env:\n        - name: blahblah\n          value: blahblah\n        - name: blahblah\n          value: blahblah\n        ports:\n        - containerPort: 6123\n          name: rpc\n        - containerPort: 6124\n          name: blob\n        - containerPort: 8081\n          hostPort: 8081\n          name: ui\n        livenessProbe:\n          tcpSocket:\n            port: 6123\n          initialDelaySeconds: 30\n          periodSeconds: 60\n        volumeMounts:\n        - name: flink-config-volume\n          mountPath: /opt/flink/conf\n        securityContext:\n          runAsUser: 0\n      volumes:\n      - name: flink-config-volume\n        configMap:\n          name: flink-config\n          items:\n          - key: flink-conf.yaml\n            path: flink-conf.yaml\n          - key: log4j.properties\n            path: log4j.properties\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"jobmanager\" is using an invalid container image, \"docker.io/kthyagar/ktflink\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02064",
    "manifest_path": "data/manifests/the_stack_sample/sample_0766.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flink-jobmanager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flink\n      component: jobmanager\n  template:\n    metadata:\n      labels:\n        app: flink\n        component: jobmanager\n    spec:\n      serviceAccountName: zep-flink-eks-kt-svcacct\n      containers:\n      - name: jobmanager\n        image: docker.io/kthyagar/ktflink\n        workingDir: /opt/flink\n        command:\n        - /bin/bash\n        - -c\n        - $FLINK_HOME/bin/jobmanager.sh start;while :; do if [[ -f $(find log -name\n          '*jobmanager*.log' -print -quit) ]]; then tail -f -n +1 log/*jobmanager*.log;\n          fi; done\n        env:\n        - name: blahblah\n          value: blahblah\n        - name: blahblah\n          value: blahblah\n        ports:\n        - containerPort: 6123\n          name: rpc\n        - containerPort: 6124\n          name: blob\n        - containerPort: 8081\n          hostPort: 8081\n          name: ui\n        livenessProbe:\n          tcpSocket:\n            port: 6123\n          initialDelaySeconds: 30\n          periodSeconds: 60\n        volumeMounts:\n        - name: flink-config-volume\n          mountPath: /opt/flink/conf\n        securityContext:\n          runAsUser: 0\n      volumes:\n      - name: flink-config-volume\n        configMap:\n          name: flink-config\n          items:\n          - key: flink-conf.yaml\n            path: flink-conf.yaml\n          - key: log4j.properties\n            path: log4j.properties\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jobmanager\" does not have a read-only root file system"
  },
  {
    "id": "02065",
    "manifest_path": "data/manifests/the_stack_sample/sample_0766.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flink-jobmanager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flink\n      component: jobmanager\n  template:\n    metadata:\n      labels:\n        app: flink\n        component: jobmanager\n    spec:\n      serviceAccountName: zep-flink-eks-kt-svcacct\n      containers:\n      - name: jobmanager\n        image: docker.io/kthyagar/ktflink\n        workingDir: /opt/flink\n        command:\n        - /bin/bash\n        - -c\n        - $FLINK_HOME/bin/jobmanager.sh start;while :; do if [[ -f $(find log -name\n          '*jobmanager*.log' -print -quit) ]]; then tail -f -n +1 log/*jobmanager*.log;\n          fi; done\n        env:\n        - name: blahblah\n          value: blahblah\n        - name: blahblah\n          value: blahblah\n        ports:\n        - containerPort: 6123\n          name: rpc\n        - containerPort: 6124\n          name: blob\n        - containerPort: 8081\n          hostPort: 8081\n          name: ui\n        livenessProbe:\n          tcpSocket:\n            port: 6123\n          initialDelaySeconds: 30\n          periodSeconds: 60\n        volumeMounts:\n        - name: flink-config-volume\n          mountPath: /opt/flink/conf\n        securityContext:\n          runAsUser: 0\n      volumes:\n      - name: flink-config-volume\n        configMap:\n          name: flink-config\n          items:\n          - key: flink-conf.yaml\n            path: flink-conf.yaml\n          - key: log4j.properties\n            path: log4j.properties\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jobmanager\" is not set to runAsNonRoot"
  },
  {
    "id": "02066",
    "manifest_path": "data/manifests/the_stack_sample/sample_0766.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flink-jobmanager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flink\n      component: jobmanager\n  template:\n    metadata:\n      labels:\n        app: flink\n        component: jobmanager\n    spec:\n      serviceAccountName: zep-flink-eks-kt-svcacct\n      containers:\n      - name: jobmanager\n        image: docker.io/kthyagar/ktflink\n        workingDir: /opt/flink\n        command:\n        - /bin/bash\n        - -c\n        - $FLINK_HOME/bin/jobmanager.sh start;while :; do if [[ -f $(find log -name\n          '*jobmanager*.log' -print -quit) ]]; then tail -f -n +1 log/*jobmanager*.log;\n          fi; done\n        env:\n        - name: blahblah\n          value: blahblah\n        - name: blahblah\n          value: blahblah\n        ports:\n        - containerPort: 6123\n          name: rpc\n        - containerPort: 6124\n          name: blob\n        - containerPort: 8081\n          hostPort: 8081\n          name: ui\n        livenessProbe:\n          tcpSocket:\n            port: 6123\n          initialDelaySeconds: 30\n          periodSeconds: 60\n        volumeMounts:\n        - name: flink-config-volume\n          mountPath: /opt/flink/conf\n        securityContext:\n          runAsUser: 0\n      volumes:\n      - name: flink-config-volume\n        configMap:\n          name: flink-config\n          items:\n          - key: flink-conf.yaml\n            path: flink-conf.yaml\n          - key: log4j.properties\n            path: log4j.properties\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"jobmanager\" has cpu request 0"
  },
  {
    "id": "02067",
    "manifest_path": "data/manifests/the_stack_sample/sample_0766.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flink-jobmanager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: flink\n      component: jobmanager\n  template:\n    metadata:\n      labels:\n        app: flink\n        component: jobmanager\n    spec:\n      serviceAccountName: zep-flink-eks-kt-svcacct\n      containers:\n      - name: jobmanager\n        image: docker.io/kthyagar/ktflink\n        workingDir: /opt/flink\n        command:\n        - /bin/bash\n        - -c\n        - $FLINK_HOME/bin/jobmanager.sh start;while :; do if [[ -f $(find log -name\n          '*jobmanager*.log' -print -quit) ]]; then tail -f -n +1 log/*jobmanager*.log;\n          fi; done\n        env:\n        - name: blahblah\n          value: blahblah\n        - name: blahblah\n          value: blahblah\n        ports:\n        - containerPort: 6123\n          name: rpc\n        - containerPort: 6124\n          name: blob\n        - containerPort: 8081\n          hostPort: 8081\n          name: ui\n        livenessProbe:\n          tcpSocket:\n            port: 6123\n          initialDelaySeconds: 30\n          periodSeconds: 60\n        volumeMounts:\n        - name: flink-config-volume\n          mountPath: /opt/flink/conf\n        securityContext:\n          runAsUser: 0\n      volumes:\n      - name: flink-config-volume\n        configMap:\n          name: flink-config\n          items:\n          - key: flink-conf.yaml\n            path: flink-conf.yaml\n          - key: log4j.properties\n            path: log4j.properties\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"jobmanager\" has memory limit 0"
  },
  {
    "id": "02068",
    "manifest_path": "data/manifests/the_stack_sample/sample_0770.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6472\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02069",
    "manifest_path": "data/manifests/the_stack_sample/sample_0770.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6472\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02070",
    "manifest_path": "data/manifests/the_stack_sample/sample_0770.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6472\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02071",
    "manifest_path": "data/manifests/the_stack_sample/sample_0770.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6472\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02072",
    "manifest_path": "data/manifests/the_stack_sample/sample_0770.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6472\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02073",
    "manifest_path": "data/manifests/the_stack_sample/sample_0772.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-privileged\nspec:\n  serviceAccountName: fake-user\n  containers:\n  - name: nginx-privileged\n    image: nginx:1.14.2\n    securityContext:\n      privileged: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx-privileged\" does not have a read-only root file system"
  },
  {
    "id": "02074",
    "manifest_path": "data/manifests/the_stack_sample/sample_0772.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-privileged\nspec:\n  serviceAccountName: fake-user\n  containers:\n  - name: nginx-privileged\n    image: nginx:1.14.2\n    securityContext:\n      privileged: true\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"nginx-privileged\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "02075",
    "manifest_path": "data/manifests/the_stack_sample/sample_0772.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-privileged\nspec:\n  serviceAccountName: fake-user\n  containers:\n  - name: nginx-privileged\n    image: nginx:1.14.2\n    securityContext:\n      privileged: true\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"nginx-privileged\" is privileged"
  },
  {
    "id": "02076",
    "manifest_path": "data/manifests/the_stack_sample/sample_0772.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-privileged\nspec:\n  serviceAccountName: fake-user\n  containers:\n  - name: nginx-privileged\n    image: nginx:1.14.2\n    securityContext:\n      privileged: true\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx-privileged\" is not set to runAsNonRoot"
  },
  {
    "id": "02077",
    "manifest_path": "data/manifests/the_stack_sample/sample_0772.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-privileged\nspec:\n  serviceAccountName: fake-user\n  containers:\n  - name: nginx-privileged\n    image: nginx:1.14.2\n    securityContext:\n      privileged: true\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx-privileged\" has cpu request 0"
  },
  {
    "id": "02078",
    "manifest_path": "data/manifests/the_stack_sample/sample_0772.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-privileged\nspec:\n  serviceAccountName: fake-user\n  containers:\n  - name: nginx-privileged\n    image: nginx:1.14.2\n    securityContext:\n      privileged: true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx-privileged\" has memory limit 0"
  },
  {
    "id": "02079",
    "manifest_path": "data/manifests/the_stack_sample/sample_0773.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selector-test-pod\n  labels:\n    name: selector-test-pod\n    unique-label: bingbang\nspec:\n  containers:\n  - name: kubernetes-pause\n    image: gcr.io/google-containers/pause:2.0\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kubernetes-pause\" does not have a read-only root file system"
  },
  {
    "id": "02080",
    "manifest_path": "data/manifests/the_stack_sample/sample_0773.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selector-test-pod\n  labels:\n    name: selector-test-pod\n    unique-label: bingbang\nspec:\n  containers:\n  - name: kubernetes-pause\n    image: gcr.io/google-containers/pause:2.0\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kubernetes-pause\" is not set to runAsNonRoot"
  },
  {
    "id": "02081",
    "manifest_path": "data/manifests/the_stack_sample/sample_0773.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selector-test-pod\n  labels:\n    name: selector-test-pod\n    unique-label: bingbang\nspec:\n  containers:\n  - name: kubernetes-pause\n    image: gcr.io/google-containers/pause:2.0\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"kubernetes-pause\" has cpu request 0"
  },
  {
    "id": "02082",
    "manifest_path": "data/manifests/the_stack_sample/sample_0773.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selector-test-pod\n  labels:\n    name: selector-test-pod\n    unique-label: bingbang\nspec:\n  containers:\n  - name: kubernetes-pause\n    image: gcr.io/google-containers/pause:2.0\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kubernetes-pause\" has memory limit 0"
  },
  {
    "id": "02083",
    "manifest_path": "data/manifests/the_stack_sample/sample_0779.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: plank\n  labels:\n    app: plank\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: plank\n  template:\n    metadata:\n      labels:\n        app: plank\n    spec:\n      containers:\n      - name: plank\n        image: gcr.io/k8s-prow/plank:v20190920-d724a578b\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --skip-report=true\n        volumeMounts:\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"plank\" does not have a read-only root file system"
  },
  {
    "id": "02084",
    "manifest_path": "data/manifests/the_stack_sample/sample_0779.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: plank\n  labels:\n    app: plank\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: plank\n  template:\n    metadata:\n      labels:\n        app: plank\n    spec:\n      containers:\n      - name: plank\n        image: gcr.io/k8s-prow/plank:v20190920-d724a578b\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --skip-report=true\n        volumeMounts:\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"plank\" is not set to runAsNonRoot"
  },
  {
    "id": "02085",
    "manifest_path": "data/manifests/the_stack_sample/sample_0779.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: plank\n  labels:\n    app: plank\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: plank\n  template:\n    metadata:\n      labels:\n        app: plank\n    spec:\n      containers:\n      - name: plank\n        image: gcr.io/k8s-prow/plank:v20190920-d724a578b\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --skip-report=true\n        volumeMounts:\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"plank\" has cpu request 0"
  },
  {
    "id": "02086",
    "manifest_path": "data/manifests/the_stack_sample/sample_0779.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: plank\n  labels:\n    app: plank\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: plank\n  template:\n    metadata:\n      labels:\n        app: plank\n    spec:\n      containers:\n      - name: plank\n        image: gcr.io/k8s-prow/plank:v20190920-d724a578b\n        args:\n        - --build-cluster=/etc/cluster/cluster\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --skip-report=true\n        volumeMounts:\n        - mountPath: /etc/cluster\n          name: cluster\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: build-cluster\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"plank\" has memory limit 0"
  },
  {
    "id": "02087",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"init-chmod-data\" is using an invalid container image, \"postgres\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02088",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"postgresql-db\" is using an invalid container image, \"postgres\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02089",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init-chmod-data\" does not have a read-only root file system"
  },
  {
    "id": "02090",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"postgresql-db\" does not have a read-only root file system"
  },
  {
    "id": "02091",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init-chmod-data\" is not set to runAsNonRoot"
  },
  {
    "id": "02092",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-chmod-data\" has cpu request 0"
  },
  {
    "id": "02093",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"postgresql-db\" has cpu request 0"
  },
  {
    "id": "02094",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-chmod-data\" has memory limit 0"
  },
  {
    "id": "02095",
    "manifest_path": "data/manifests/the_stack_sample/sample_0781.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgresql-db\nspec:\n  selector:\n    matchLabels:\n      app: postgresql-db\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: postgresql-db\n    spec:\n      securityContext:\n        fsGroup: 2000\n      initContainers:\n      - name: init-chmod-data\n        image: postgres\n        command:\n        - sh\n        - -c\n        args:\n        - chown -R 1001:2000 /data\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n      containers:\n      - name: postgresql-db\n        image: postgres\n        securityContext:\n          runAsUser: 1001\n          runAsGroup: 2000\n        volumeMounts:\n        - name: postgresql-db-disk\n          mountPath: /data\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: stock-market-secret\n              key: postgres-password\n        - name: PGDATA\n          value: /data/pgdata\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"postgresql-db\" has memory limit 0"
  },
  {
    "id": "02096",
    "manifest_path": "data/manifests/the_stack_sample/sample_0783.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: busybox\n  labels:\n    app: busybox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - name: busybox\n        image: busybox:1.28\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - busybox\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"busybox\" does not have a read-only root file system"
  },
  {
    "id": "02097",
    "manifest_path": "data/manifests/the_stack_sample/sample_0783.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: busybox\n  labels:\n    app: busybox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - name: busybox\n        image: busybox:1.28\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - busybox\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"busybox\" is not set to runAsNonRoot"
  },
  {
    "id": "02098",
    "manifest_path": "data/manifests/the_stack_sample/sample_0783.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: busybox\n  labels:\n    app: busybox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - name: busybox\n        image: busybox:1.28\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - busybox\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"busybox\" has cpu request 0"
  },
  {
    "id": "02099",
    "manifest_path": "data/manifests/the_stack_sample/sample_0783.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: busybox\n  labels:\n    app: busybox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: busybox\n  template:\n    metadata:\n      labels:\n        app: busybox\n    spec:\n      containers:\n      - name: busybox\n        image: busybox:1.28\n        command:\n        - sleep\n        - '3600'\n        imagePullPolicy: IfNotPresent\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - busybox\n            topologyKey: kubernetes.io/hostname\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"busybox\" has memory limit 0"
  },
  {
    "id": "02100",
    "manifest_path": "data/manifests/the_stack_sample/sample_0786.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hawtio-online\n  labels:\n    app: hawtio\n    deployment: hawtio-online\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hawtio\n      deployment: hawtio-online\n  template:\n    metadata:\n      labels:\n        app: hawtio\n        deployment: hawtio-online\n    spec:\n      containers:\n      - image: hawtio/online\n        imagePullPolicy: Always\n        name: hawtio-online\n        ports:\n        - name: nginx\n          containerPort: 8443\n        livenessProbe:\n          httpGet:\n            path: /online\n            port: nginx\n            scheme: HTTPS\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /online\n            port: nginx\n            scheme: HTTPS\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 1\n        env:\n        - name: HAWTIO_ONLINE_RBAC_ACL\n          value: /etc/hawtio/rbac/ACL.yaml\n        resources:\n          requests:\n            cpu: '0.2'\n            memory: 32Mi\n          limits:\n            cpu: '1.0'\n            memory: 100Mi\n        volumeMounts:\n        - name: hawtio-online\n          mountPath: /usr/share/nginx/html/online/hawtconfig.json\n          subPath: hawtconfig.json\n        - name: hawtio-integration\n          mountPath: /usr/share/nginx/html/integration/hawtconfig.json\n          subPath: hawtconfig.json\n        - name: hawtio-rbac\n          mountPath: /etc/hawtio/rbac\n        - name: hawtio-online-tls-serving\n          mountPath: /etc/tls/private/serving\n      volumes:\n      - name: hawtio-online\n        configMap:\n          name: hawtio-online\n      - name: hawtio-integration\n        configMap:\n          name: hawtio-integration\n      - name: hawtio-rbac\n        configMap:\n          name: hawtio-rbac\n      - name: hawtio-online-tls-serving\n        secret:\n          secretName: hawtio-online-tls-serving\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hawtio-online\" is using an invalid container image, \"hawtio/online\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02101",
    "manifest_path": "data/manifests/the_stack_sample/sample_0786.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hawtio-online\n  labels:\n    app: hawtio\n    deployment: hawtio-online\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hawtio\n      deployment: hawtio-online\n  template:\n    metadata:\n      labels:\n        app: hawtio\n        deployment: hawtio-online\n    spec:\n      containers:\n      - image: hawtio/online\n        imagePullPolicy: Always\n        name: hawtio-online\n        ports:\n        - name: nginx\n          containerPort: 8443\n        livenessProbe:\n          httpGet:\n            path: /online\n            port: nginx\n            scheme: HTTPS\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /online\n            port: nginx\n            scheme: HTTPS\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 1\n        env:\n        - name: HAWTIO_ONLINE_RBAC_ACL\n          value: /etc/hawtio/rbac/ACL.yaml\n        resources:\n          requests:\n            cpu: '0.2'\n            memory: 32Mi\n          limits:\n            cpu: '1.0'\n            memory: 100Mi\n        volumeMounts:\n        - name: hawtio-online\n          mountPath: /usr/share/nginx/html/online/hawtconfig.json\n          subPath: hawtconfig.json\n        - name: hawtio-integration\n          mountPath: /usr/share/nginx/html/integration/hawtconfig.json\n          subPath: hawtconfig.json\n        - name: hawtio-rbac\n          mountPath: /etc/hawtio/rbac\n        - name: hawtio-online-tls-serving\n          mountPath: /etc/tls/private/serving\n      volumes:\n      - name: hawtio-online\n        configMap:\n          name: hawtio-online\n      - name: hawtio-integration\n        configMap:\n          name: hawtio-integration\n      - name: hawtio-rbac\n        configMap:\n          name: hawtio-rbac\n      - name: hawtio-online-tls-serving\n        secret:\n          secretName: hawtio-online-tls-serving\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hawtio-online\" does not have a read-only root file system"
  },
  {
    "id": "02102",
    "manifest_path": "data/manifests/the_stack_sample/sample_0786.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hawtio-online\n  labels:\n    app: hawtio\n    deployment: hawtio-online\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hawtio\n      deployment: hawtio-online\n  template:\n    metadata:\n      labels:\n        app: hawtio\n        deployment: hawtio-online\n    spec:\n      containers:\n      - image: hawtio/online\n        imagePullPolicy: Always\n        name: hawtio-online\n        ports:\n        - name: nginx\n          containerPort: 8443\n        livenessProbe:\n          httpGet:\n            path: /online\n            port: nginx\n            scheme: HTTPS\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /online\n            port: nginx\n            scheme: HTTPS\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 1\n        env:\n        - name: HAWTIO_ONLINE_RBAC_ACL\n          value: /etc/hawtio/rbac/ACL.yaml\n        resources:\n          requests:\n            cpu: '0.2'\n            memory: 32Mi\n          limits:\n            cpu: '1.0'\n            memory: 100Mi\n        volumeMounts:\n        - name: hawtio-online\n          mountPath: /usr/share/nginx/html/online/hawtconfig.json\n          subPath: hawtconfig.json\n        - name: hawtio-integration\n          mountPath: /usr/share/nginx/html/integration/hawtconfig.json\n          subPath: hawtconfig.json\n        - name: hawtio-rbac\n          mountPath: /etc/hawtio/rbac\n        - name: hawtio-online-tls-serving\n          mountPath: /etc/tls/private/serving\n      volumes:\n      - name: hawtio-online\n        configMap:\n          name: hawtio-online\n      - name: hawtio-integration\n        configMap:\n          name: hawtio-integration\n      - name: hawtio-rbac\n        configMap:\n          name: hawtio-rbac\n      - name: hawtio-online-tls-serving\n        secret:\n          secretName: hawtio-online-tls-serving\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hawtio-online\" is not set to runAsNonRoot"
  },
  {
    "id": "02103",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"dn1\" does not have a read-only root file system"
  },
  {
    "id": "02104",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"dn2\" does not have a read-only root file system"
  },
  {
    "id": "02105",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"dn3\" does not have a read-only root file system"
  },
  {
    "id": "02106",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"dn4\" does not have a read-only root file system"
  },
  {
    "id": "02107",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"head\" does not have a read-only root file system"
  },
  {
    "id": "02108",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"rangeget\" does not have a read-only root file system"
  },
  {
    "id": "02109",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sn\" does not have a read-only root file system"
  },
  {
    "id": "02110",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"dn1\" is not set to runAsNonRoot"
  },
  {
    "id": "02111",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"dn2\" is not set to runAsNonRoot"
  },
  {
    "id": "02112",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"dn3\" is not set to runAsNonRoot"
  },
  {
    "id": "02113",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"dn4\" is not set to runAsNonRoot"
  },
  {
    "id": "02114",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"head\" is not set to runAsNonRoot"
  },
  {
    "id": "02115",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"rangeget\" is not set to runAsNonRoot"
  },
  {
    "id": "02116",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sn\" is not set to runAsNonRoot"
  },
  {
    "id": "02117",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"dn1\" has cpu request 0"
  },
  {
    "id": "02118",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"dn2\" has cpu request 0"
  },
  {
    "id": "02119",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"dn3\" has cpu request 0"
  },
  {
    "id": "02120",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"dn4\" has cpu request 0"
  },
  {
    "id": "02121",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"head\" has cpu request 0"
  },
  {
    "id": "02122",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"rangeget\" has cpu request 0"
  },
  {
    "id": "02123",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sn\" has cpu request 0"
  },
  {
    "id": "02124",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable AWS_SECRET_ACCESS_KEY in container \"alpine\" found"
  },
  {
    "id": "02125",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"alpine\" is using an invalid container image, \"alpine\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02126",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"alpine\" does not have a read-only root file system"
  },
  {
    "id": "02127",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"alpine\" is not set to runAsNonRoot"
  },
  {
    "id": "02128",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"alpine\" has cpu request 0"
  },
  {
    "id": "02129",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"alpine\" has memory limit 0"
  },
  {
    "id": "02130",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"review-app-reaper\" is using an invalid container image, \"{{ .tuberImage }}\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02131",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"review-app-reaper\" does not have a read-only root file system"
  },
  {
    "id": "02132",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"review-app-reaper\" is not set to runAsNonRoot"
  },
  {
    "id": "02133",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"review-app-reaper\" has cpu request 0"
  },
  {
    "id": "02134",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"review-app-reaper\" has memory limit 0"
  },
  {
    "id": "02135",
    "manifest_path": "data/manifests/the_stack_sample/sample_0797.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: simple-mvcboot\n  name: simple-mvcboot\n  namespace: default\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: simple-mvcboot\n    spec:\n      containers:\n      - image: sme/simple-mvc-boot:0.1\n        name: simple-mvcboot\n        ports:\n        - containerPort: 8040\n          name: http\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"simple-mvcboot\" does not have a read-only root file system"
  },
  {
    "id": "02136",
    "manifest_path": "data/manifests/the_stack_sample/sample_0797.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: simple-mvcboot\n  name: simple-mvcboot\n  namespace: default\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: simple-mvcboot\n    spec:\n      containers:\n      - image: sme/simple-mvc-boot:0.1\n        name: simple-mvcboot\n        ports:\n        - containerPort: 8040\n          name: http\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"simple-mvcboot\" is not set to runAsNonRoot"
  },
  {
    "id": "02137",
    "manifest_path": "data/manifests/the_stack_sample/sample_0797.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: simple-mvcboot\n  name: simple-mvcboot\n  namespace: default\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: simple-mvcboot\n    spec:\n      containers:\n      - image: sme/simple-mvc-boot:0.1\n        name: simple-mvcboot\n        ports:\n        - containerPort: 8040\n          name: http\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"simple-mvcboot\" has cpu request 0"
  },
  {
    "id": "02138",
    "manifest_path": "data/manifests/the_stack_sample/sample_0797.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: simple-mvcboot\n  name: simple-mvcboot\n  namespace: default\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: simple-mvcboot\n    spec:\n      containers:\n      - image: sme/simple-mvc-boot:0.1\n        name: simple-mvcboot\n        ports:\n        - containerPort: 8040\n          name: http\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"simple-mvcboot\" has memory limit 0"
  },
  {
    "id": "02139",
    "manifest_path": "data/manifests/the_stack_sample/sample_0798.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210707-32dc49e04b\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"prow-controller-manager\" does not have a read-only root file system"
  },
  {
    "id": "02140",
    "manifest_path": "data/manifests/the_stack_sample/sample_0798.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210707-32dc49e04b\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"prow-controller-manager\" is not set to runAsNonRoot"
  },
  {
    "id": "02141",
    "manifest_path": "data/manifests/the_stack_sample/sample_0798.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210707-32dc49e04b\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"prow-controller-manager\" has cpu request 0"
  },
  {
    "id": "02142",
    "manifest_path": "data/manifests/the_stack_sample/sample_0798.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210707-32dc49e04b\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"prow-controller-manager\" has memory limit 0"
  },
  {
    "id": "02143",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"init-data\" is using an invalid container image, \"gitlab-registry.nautilus.optiputer.net/prp/gsutil\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02144",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"research\" is using an invalid container image, \"gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02145",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init-data\" does not have a read-only root file system"
  },
  {
    "id": "02146",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"research\" does not have a read-only root file system"
  },
  {
    "id": "02147",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init-data\" is not set to runAsNonRoot"
  },
  {
    "id": "02148",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"research\" is not set to runAsNonRoot"
  },
  {
    "id": "02149",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-data\" has cpu request 0"
  },
  {
    "id": "02150",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-data\" has memory limit 0"
  },
  {
    "id": "02151",
    "manifest_path": "data/manifests/the_stack_sample/sample_0802.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      labels:\n        app: podinfo\n    spec:\n      containers:\n      - name: podinfo\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"podinfo\" does not have a read-only root file system"
  },
  {
    "id": "02152",
    "manifest_path": "data/manifests/the_stack_sample/sample_0802.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      labels:\n        app: podinfo\n    spec:\n      containers:\n      - name: podinfo\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"podinfo\" is not set to runAsNonRoot"
  },
  {
    "id": "02153",
    "manifest_path": "data/manifests/the_stack_sample/sample_0802.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      labels:\n        app: podinfo\n    spec:\n      containers:\n      - name: podinfo\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"podinfo\" has cpu request 0"
  },
  {
    "id": "02154",
    "manifest_path": "data/manifests/the_stack_sample/sample_0802.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      labels:\n        app: podinfo\n    spec:\n      containers:\n      - name: podinfo\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"podinfo\" has memory limit 0"
  },
  {
    "id": "02155",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"fdw-settings\" is using an invalid container image, \"catarse-deploy/catarse\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02156",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"fdw-settings\" does not have a read-only root file system"
  },
  {
    "id": "02157",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"fdw-settings\" is not set to runAsNonRoot"
  },
  {
    "id": "02158",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"fdw-settings\" has cpu request 0"
  },
  {
    "id": "02159",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"fdw-settings\" has memory limit 0"
  },
  {
    "id": "02160",
    "manifest_path": "data/manifests/the_stack_sample/sample_0805.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1708\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02161",
    "manifest_path": "data/manifests/the_stack_sample/sample_0805.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1708\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02162",
    "manifest_path": "data/manifests/the_stack_sample/sample_0805.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1708\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02163",
    "manifest_path": "data/manifests/the_stack_sample/sample_0805.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1708\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02164",
    "manifest_path": "data/manifests/the_stack_sample/sample_0805.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1708\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02165",
    "manifest_path": "data/manifests/the_stack_sample/sample_0806.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220323-9b8611d021\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"horologium\" does not have a read-only root file system"
  },
  {
    "id": "02166",
    "manifest_path": "data/manifests/the_stack_sample/sample_0806.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220323-9b8611d021\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"horologium\" is not set to runAsNonRoot"
  },
  {
    "id": "02167",
    "manifest_path": "data/manifests/the_stack_sample/sample_0806.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220323-9b8611d021\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"horologium\" has cpu request 0"
  },
  {
    "id": "02168",
    "manifest_path": "data/manifests/the_stack_sample/sample_0806.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220323-9b8611d021\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"horologium\" has memory limit 0"
  },
  {
    "id": "02169",
    "manifest_path": "data/manifests/the_stack_sample/sample_0807.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: python\nspec:\n  selector:\n    matchLabels:\n      app: python\n      tier: app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: python\n        tier: app\n    spec:\n      containers:\n      - name: python\n        image: registry.cn-hangzhou.aliyuncs.com/dal/python:v1.0\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: key\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"python\" does not have a read-only root file system"
  },
  {
    "id": "02170",
    "manifest_path": "data/manifests/the_stack_sample/sample_0807.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: python\nspec:\n  selector:\n    matchLabels:\n      app: python\n      tier: app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: python\n        tier: app\n    spec:\n      containers:\n      - name: python\n        image: registry.cn-hangzhou.aliyuncs.com/dal/python:v1.0\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: key\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"python\" is not set to runAsNonRoot"
  },
  {
    "id": "02171",
    "manifest_path": "data/manifests/the_stack_sample/sample_0807.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: python\nspec:\n  selector:\n    matchLabels:\n      app: python\n      tier: app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: python\n        tier: app\n    spec:\n      containers:\n      - name: python\n        image: registry.cn-hangzhou.aliyuncs.com/dal/python:v1.0\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: key\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"python\" has memory limit 0"
  },
  {
    "id": "02172",
    "manifest_path": "data/manifests/the_stack_sample/sample_0809.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment\nspec:\n  replicas: 0\n  selector:\n    matchLabels:\n      service: service\n  template:\n    metadata:\n      labels:\n        service: service\n    spec:\n      serviceAccountName: service-sa\n      containers:\n      - name: container\n        image: image\n        env:\n        - name: SOME_VAR1\n          value: SOME_VAL1\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 1\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /health/live\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 250m\n          limits:\n            memory: 512Mi\n            cpu: 500m\n        imagePullPolicy: Always\n      securityContext: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"container\" is using an invalid container image, \"image\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02173",
    "manifest_path": "data/manifests/the_stack_sample/sample_0809.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment\nspec:\n  replicas: 0\n  selector:\n    matchLabels:\n      service: service\n  template:\n    metadata:\n      labels:\n        service: service\n    spec:\n      serviceAccountName: service-sa\n      containers:\n      - name: container\n        image: image\n        env:\n        - name: SOME_VAR1\n          value: SOME_VAL1\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 1\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /health/live\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 250m\n          limits:\n            memory: 512Mi\n            cpu: 500m\n        imagePullPolicy: Always\n      securityContext: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"container\" does not have a read-only root file system"
  },
  {
    "id": "02174",
    "manifest_path": "data/manifests/the_stack_sample/sample_0809.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment\nspec:\n  replicas: 0\n  selector:\n    matchLabels:\n      service: service\n  template:\n    metadata:\n      labels:\n        service: service\n    spec:\n      serviceAccountName: service-sa\n      containers:\n      - name: container\n        image: image\n        env:\n        - name: SOME_VAR1\n          value: SOME_VAL1\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 1\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /health/live\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 250m\n          limits:\n            memory: 512Mi\n            cpu: 500m\n        imagePullPolicy: Always\n      securityContext: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"container\" is not set to runAsNonRoot"
  },
  {
    "id": "02175",
    "manifest_path": "data/manifests/the_stack_sample/sample_0810.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: docker.io/mreider/eatk8s-redis:latest\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"master\" is using an invalid container image, \"docker.io/mreider/eatk8s-redis:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02176",
    "manifest_path": "data/manifests/the_stack_sample/sample_0810.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: docker.io/mreider/eatk8s-redis:latest\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"master\" does not have a read-only root file system"
  },
  {
    "id": "02177",
    "manifest_path": "data/manifests/the_stack_sample/sample_0810.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: docker.io/mreider/eatk8s-redis:latest\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"master\" is not set to runAsNonRoot"
  },
  {
    "id": "02178",
    "manifest_path": "data/manifests/the_stack_sample/sample_0810.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: docker.io/mreider/eatk8s-redis:latest\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"master\" has memory limit 0"
  },
  {
    "id": "02179",
    "manifest_path": "data/manifests/the_stack_sample/sample_0815.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --server-protocol=tcp,udp\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cyclonus\" is using an invalid container image, \"mfenwick100/cyclonus:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02180",
    "manifest_path": "data/manifests/the_stack_sample/sample_0815.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --server-protocol=tcp,udp\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cyclonus\" does not have a read-only root file system"
  },
  {
    "id": "02181",
    "manifest_path": "data/manifests/the_stack_sample/sample_0815.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --server-protocol=tcp,udp\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cyclonus\" is not set to runAsNonRoot"
  },
  {
    "id": "02182",
    "manifest_path": "data/manifests/the_stack_sample/sample_0815.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --server-protocol=tcp,udp\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cyclonus\" has cpu request 0"
  },
  {
    "id": "02183",
    "manifest_path": "data/manifests/the_stack_sample/sample_0815.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cyclonus\nspec:\n  template:\n    spec:\n      containers:\n      - command:\n        - ./cyclonus\n        - generate\n        - --server-protocol=tcp,udp\n        name: cyclonus\n        imagePullPolicy: IfNotPresent\n        image: mfenwick100/cyclonus:latest\n      serviceAccount: cyclonus\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cyclonus\" has memory limit 0"
  },
  {
    "id": "02184",
    "manifest_path": "data/manifests/the_stack_sample/sample_0816.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-webhooks\n  labels:\n    chart: lighthouse-1.3.0\n    app: lighthouse-webhooks\n    git.jenkins-x.io/sha: annotate\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    checksum/config: 1cfb0afb7b5cb9aa219544875fa8c047c7257c0524a31d34dd48874589d98792\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-webhooks\n  template:\n    metadata:\n      labels:\n        app: lighthouse-webhooks\n      annotations:\n        prometheus.io/port: '2112'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: beaad4cded88f5572b6a079082f39d0b00e7b0fc527a18ceb52857330f6d746a\n    spec:\n      serviceAccountName: lighthouse-webhooks\n      containers:\n      - name: lighthouse-webhooks\n        image: ghcr.io/jenkins-x/lighthouse-webhooks:1.3.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: LH_CUSTOM_TRIGGER_COMMAND\n          value: jx\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: bussrrajeshnayak\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: stackdriver\n        - name: LOGRUS_FORMAT\n          value: stackdriver\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.3.0\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 60d2f020b3003672ecbc8c9abd2f3cf20344fee2\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 512Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-webhooks\" does not have a read-only root file system"
  },
  {
    "id": "02185",
    "manifest_path": "data/manifests/the_stack_sample/sample_0816.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-webhooks\n  labels:\n    chart: lighthouse-1.3.0\n    app: lighthouse-webhooks\n    git.jenkins-x.io/sha: annotate\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    checksum/config: 1cfb0afb7b5cb9aa219544875fa8c047c7257c0524a31d34dd48874589d98792\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-webhooks\n  template:\n    metadata:\n      labels:\n        app: lighthouse-webhooks\n      annotations:\n        prometheus.io/port: '2112'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: beaad4cded88f5572b6a079082f39d0b00e7b0fc527a18ceb52857330f6d746a\n    spec:\n      serviceAccountName: lighthouse-webhooks\n      containers:\n      - name: lighthouse-webhooks\n        image: ghcr.io/jenkins-x/lighthouse-webhooks:1.3.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: LH_CUSTOM_TRIGGER_COMMAND\n          value: jx\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: bussrrajeshnayak\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: stackdriver\n        - name: LOGRUS_FORMAT\n          value: stackdriver\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.3.0\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 60d2f020b3003672ecbc8c9abd2f3cf20344fee2\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 512Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-webhooks\" is not set to runAsNonRoot"
  },
  {
    "id": "02186",
    "manifest_path": "data/manifests/the_stack_sample/sample_0817.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: default-mem-demo-3\n  namespace: default-mem-example\nspec:\n  containers:\n  - name: default-mem-demo-3-ctr\n    image: nginx\n    resources:\n      requests:\n        memory: 128Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"default-mem-demo-3-ctr\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02187",
    "manifest_path": "data/manifests/the_stack_sample/sample_0817.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: default-mem-demo-3\n  namespace: default-mem-example\nspec:\n  containers:\n  - name: default-mem-demo-3-ctr\n    image: nginx\n    resources:\n      requests:\n        memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"default-mem-demo-3-ctr\" does not have a read-only root file system"
  },
  {
    "id": "02188",
    "manifest_path": "data/manifests/the_stack_sample/sample_0817.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: default-mem-demo-3\n  namespace: default-mem-example\nspec:\n  containers:\n  - name: default-mem-demo-3-ctr\n    image: nginx\n    resources:\n      requests:\n        memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"default-mem-demo-3-ctr\" is not set to runAsNonRoot"
  },
  {
    "id": "02189",
    "manifest_path": "data/manifests/the_stack_sample/sample_0817.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: default-mem-demo-3\n  namespace: default-mem-example\nspec:\n  containers:\n  - name: default-mem-demo-3-ctr\n    image: nginx\n    resources:\n      requests:\n        memory: 128Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"default-mem-demo-3-ctr\" has cpu request 0"
  },
  {
    "id": "02190",
    "manifest_path": "data/manifests/the_stack_sample/sample_0817.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: default-mem-demo-3\n  namespace: default-mem-example\nspec:\n  containers:\n  - name: default-mem-demo-3-ctr\n    image: nginx\n    resources:\n      requests:\n        memory: 128Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"default-mem-demo-3-ctr\" has memory limit 0"
  },
  {
    "id": "02191",
    "manifest_path": "data/manifests/the_stack_sample/sample_0827.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cronjob\n  namespace: kubernetes-starterkit\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: cronjob\n      spec:\n        containers:\n        - name: cronjob\n          image: spotify/alpine:latest\n          imagePullPolicy: Always\n          command:\n          - curl\n          args:\n          - http://bootstorage-svc:5000/api/bootstorage/deletelru\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cronjob\" is using an invalid container image, \"spotify/alpine:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02192",
    "manifest_path": "data/manifests/the_stack_sample/sample_0827.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cronjob\n  namespace: kubernetes-starterkit\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: cronjob\n      spec:\n        containers:\n        - name: cronjob\n          image: spotify/alpine:latest\n          imagePullPolicy: Always\n          command:\n          - curl\n          args:\n          - http://bootstorage-svc:5000/api/bootstorage/deletelru\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cronjob\" does not have a read-only root file system"
  },
  {
    "id": "02193",
    "manifest_path": "data/manifests/the_stack_sample/sample_0827.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cronjob\n  namespace: kubernetes-starterkit\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: cronjob\n      spec:\n        containers:\n        - name: cronjob\n          image: spotify/alpine:latest\n          imagePullPolicy: Always\n          command:\n          - curl\n          args:\n          - http://bootstorage-svc:5000/api/bootstorage/deletelru\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cronjob\" is not set to runAsNonRoot"
  },
  {
    "id": "02194",
    "manifest_path": "data/manifests/the_stack_sample/sample_0827.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cronjob\n  namespace: kubernetes-starterkit\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: cronjob\n      spec:\n        containers:\n        - name: cronjob\n          image: spotify/alpine:latest\n          imagePullPolicy: Always\n          command:\n          - curl\n          args:\n          - http://bootstorage-svc:5000/api/bootstorage/deletelru\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cronjob\" has cpu request 0"
  },
  {
    "id": "02195",
    "manifest_path": "data/manifests/the_stack_sample/sample_0827.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: cronjob\n  namespace: kubernetes-starterkit\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app: cronjob\n      spec:\n        containers:\n        - name: cronjob\n          image: spotify/alpine:latest\n          imagePullPolicy: Always\n          command:\n          - curl\n          args:\n          - http://bootstorage-svc:5000/api/bootstorage/deletelru\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cronjob\" has memory limit 0"
  },
  {
    "id": "02196",
    "manifest_path": "data/manifests/the_stack_sample/sample_0828.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jxboot-helmfile-resources-controllerrole\n  labels:\n    app: controllerrole\n    chart: controllerrole-2.0.1143\n    release: jxboot-helmfile-resources\n    heritage: Helm\nspec:\n  selector:\n    matchLabels:\n      app: controllerrole\n      release: jxboot-helmfile-resources\n  template:\n    metadata:\n      labels:\n        app: controllerrole\n        release: jxboot-helmfile-resources\n    spec:\n      serviceAccountName: jxboot-helmfile-resources-controllerrole\n      containers:\n      - name: controllerrole\n        command:\n        - jx\n        args:\n        - controller\n        - role\n        imagePullPolicy: IfNotPresent\n        image: gcr.io/jenkinsxio-labs-private/jxl:0.0.208\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        env:\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: JX_LOG_LEVEL\n          value: info\n        - name: PIPELINE_KIND\n          value: dummy\n        resources: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"controllerrole\" does not have a read-only root file system"
  },
  {
    "id": "02197",
    "manifest_path": "data/manifests/the_stack_sample/sample_0828.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jxboot-helmfile-resources-controllerrole\n  labels:\n    app: controllerrole\n    chart: controllerrole-2.0.1143\n    release: jxboot-helmfile-resources\n    heritage: Helm\nspec:\n  selector:\n    matchLabels:\n      app: controllerrole\n      release: jxboot-helmfile-resources\n  template:\n    metadata:\n      labels:\n        app: controllerrole\n        release: jxboot-helmfile-resources\n    spec:\n      serviceAccountName: jxboot-helmfile-resources-controllerrole\n      containers:\n      - name: controllerrole\n        command:\n        - jx\n        args:\n        - controller\n        - role\n        imagePullPolicy: IfNotPresent\n        image: gcr.io/jenkinsxio-labs-private/jxl:0.0.208\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        env:\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: JX_LOG_LEVEL\n          value: info\n        - name: PIPELINE_KIND\n          value: dummy\n        resources: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"controllerrole\" is not set to runAsNonRoot"
  },
  {
    "id": "02198",
    "manifest_path": "data/manifests/the_stack_sample/sample_0828.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jxboot-helmfile-resources-controllerrole\n  labels:\n    app: controllerrole\n    chart: controllerrole-2.0.1143\n    release: jxboot-helmfile-resources\n    heritage: Helm\nspec:\n  selector:\n    matchLabels:\n      app: controllerrole\n      release: jxboot-helmfile-resources\n  template:\n    metadata:\n      labels:\n        app: controllerrole\n        release: jxboot-helmfile-resources\n    spec:\n      serviceAccountName: jxboot-helmfile-resources-controllerrole\n      containers:\n      - name: controllerrole\n        command:\n        - jx\n        args:\n        - controller\n        - role\n        imagePullPolicy: IfNotPresent\n        image: gcr.io/jenkinsxio-labs-private/jxl:0.0.208\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        env:\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: JX_LOG_LEVEL\n          value: info\n        - name: PIPELINE_KIND\n          value: dummy\n        resources: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"controllerrole\" has cpu request 0"
  },
  {
    "id": "02199",
    "manifest_path": "data/manifests/the_stack_sample/sample_0828.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jxboot-helmfile-resources-controllerrole\n  labels:\n    app: controllerrole\n    chart: controllerrole-2.0.1143\n    release: jxboot-helmfile-resources\n    heritage: Helm\nspec:\n  selector:\n    matchLabels:\n      app: controllerrole\n      release: jxboot-helmfile-resources\n  template:\n    metadata:\n      labels:\n        app: controllerrole\n        release: jxboot-helmfile-resources\n    spec:\n      serviceAccountName: jxboot-helmfile-resources-controllerrole\n      containers:\n      - name: controllerrole\n        command:\n        - jx\n        args:\n        - controller\n        - role\n        imagePullPolicy: IfNotPresent\n        image: gcr.io/jenkinsxio-labs-private/jxl:0.0.208\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        env:\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: JX_LOG_LEVEL\n          value: info\n        - name: PIPELINE_KIND\n          value: dummy\n        resources: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"controllerrole\" has memory limit 0"
  },
  {
    "id": "02200",
    "manifest_path": "data/manifests/the_stack_sample/sample_0829.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cm-volume\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: config\n      mountPath: /mnt/config\n  volumes:\n  - name: config\n    configMap:\n      name: app-properties\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02201",
    "manifest_path": "data/manifests/the_stack_sample/sample_0829.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cm-volume\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: config\n      mountPath: /mnt/config\n  volumes:\n  - name: config\n    configMap:\n      name: app-properties\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02202",
    "manifest_path": "data/manifests/the_stack_sample/sample_0829.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cm-volume\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: config\n      mountPath: /mnt/config\n  volumes:\n  - name: config\n    configMap:\n      name: app-properties\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02203",
    "manifest_path": "data/manifests/the_stack_sample/sample_0829.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cm-volume\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: config\n      mountPath: /mnt/config\n  volumes:\n  - name: config\n    configMap:\n      name: app-properties\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02204",
    "manifest_path": "data/manifests/the_stack_sample/sample_0829.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cm-volume\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: config\n      mountPath: /mnt/config\n  volumes:\n  - name: config\n    configMap:\n      name: app-properties\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02205",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"crapi-community\" does not have a read-only root file system"
  },
  {
    "id": "02206",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wait-for-java\" does not have a read-only root file system"
  },
  {
    "id": "02207",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wait-for-mongo\" does not have a read-only root file system"
  },
  {
    "id": "02208",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wait-for-postgres\" does not have a read-only root file system"
  },
  {
    "id": "02209",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"crapi-community\" is not set to runAsNonRoot"
  },
  {
    "id": "02210",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wait-for-java\" is not set to runAsNonRoot"
  },
  {
    "id": "02211",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wait-for-mongo\" is not set to runAsNonRoot"
  },
  {
    "id": "02212",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wait-for-postgres\" is not set to runAsNonRoot"
  },
  {
    "id": "02213",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"wait-for-java\" has cpu request 0"
  },
  {
    "id": "02214",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"wait-for-mongo\" has cpu request 0"
  },
  {
    "id": "02215",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"wait-for-postgres\" has cpu request 0"
  },
  {
    "id": "02216",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"crapi-community\" has memory limit 0"
  },
  {
    "id": "02217",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"wait-for-java\" has memory limit 0"
  },
  {
    "id": "02218",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"wait-for-mongo\" has memory limit 0"
  },
  {
    "id": "02219",
    "manifest_path": "data/manifests/the_stack_sample/sample_0831.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crapi-community\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crapi-community\n  template:\n    metadata:\n      labels:\n        app: crapi-community\n    spec:\n      initContainers:\n      - name: wait-for-postgres\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - postgresdb\n      - name: wait-for-mongo\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - mongodb\n      - name: wait-for-java\n        image: groundnuty/k8s-wait-for:v1.3\n        imagePullPolicy: Always\n        args:\n        - service\n        - crapi-identity\n      containers:\n      - name: crapi-community\n        image: crapi/crapi-community:v1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8087\n        envFrom:\n        - configMapRef:\n            name: crapi-community-configmap\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 256m\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"wait-for-postgres\" has memory limit 0"
  },
  {
    "id": "02220",
    "manifest_path": "data/manifests/the_stack_sample/sample_0833.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: helloworld-gke\n  labels:\n    app: hello\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: helloworld-gke\n        image: gcr.io/kpt-dev/helloworld-gke:0.1.0\n        ports:\n        - name: http\n          containerPort: 80\n        env:\n        - name: PORT\n          value: '80'\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"helloworld-gke\" does not have a read-only root file system"
  },
  {
    "id": "02221",
    "manifest_path": "data/manifests/the_stack_sample/sample_0833.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: helloworld-gke\n  labels:\n    app: hello\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: helloworld-gke\n        image: gcr.io/kpt-dev/helloworld-gke:0.1.0\n        ports:\n        - name: http\n          containerPort: 80\n        env:\n        - name: PORT\n          value: '80'\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"helloworld-gke\" is not set to runAsNonRoot"
  },
  {
    "id": "02222",
    "manifest_path": "data/manifests/the_stack_sample/sample_0833.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: helloworld-gke\n  labels:\n    app: hello\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: helloworld-gke\n        image: gcr.io/kpt-dev/helloworld-gke:0.1.0\n        ports:\n        - name: http\n          containerPort: 80\n        env:\n        - name: PORT\n          value: '80'\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"helloworld-gke\" has cpu request 0"
  },
  {
    "id": "02223",
    "manifest_path": "data/manifests/the_stack_sample/sample_0833.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: helloworld-gke\n  labels:\n    app: hello\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: helloworld-gke\n        image: gcr.io/kpt-dev/helloworld-gke:0.1.0\n        ports:\n        - name: http\n          containerPort: 80\n        env:\n        - name: PORT\n          value: '80'\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"helloworld-gke\" has memory limit 0"
  },
  {
    "id": "02224",
    "manifest_path": "data/manifests/the_stack_sample/sample_0838.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\n    tier: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n        tier: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: izhur85/pay-msdemo:v0.0.2\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "02225",
    "manifest_path": "data/manifests/the_stack_sample/sample_0838.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\n    tier: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n        tier: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: izhur85/pay-msdemo:v0.0.2\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "02226",
    "manifest_path": "data/manifests/the_stack_sample/sample_0838.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\n    tier: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n        tier: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: izhur85/pay-msdemo:v0.0.2\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"server\" has cpu request 0"
  },
  {
    "id": "02227",
    "manifest_path": "data/manifests/the_stack_sample/sample_0838.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\n    tier: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n        tier: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: izhur85/pay-msdemo:v0.0.2\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"server\" has memory limit 0"
  },
  {
    "id": "02228",
    "manifest_path": "data/manifests/the_stack_sample/sample_0840.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgres\n  namespace: nestjs-app\n  labels:\n    application: postgres-pod\nspec:\n  containers:\n  - name: postgres\n    image: postgres\n    env:\n    - name: POSTGRES_PASSWORD\n      value: '123456'\n    ports:\n    - name: web\n      containerPort: 5432\n      protocol: TCP\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"postgres\" is using an invalid container image, \"postgres\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02229",
    "manifest_path": "data/manifests/the_stack_sample/sample_0840.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgres\n  namespace: nestjs-app\n  labels:\n    application: postgres-pod\nspec:\n  containers:\n  - name: postgres\n    image: postgres\n    env:\n    - name: POSTGRES_PASSWORD\n      value: '123456'\n    ports:\n    - name: web\n      containerPort: 5432\n      protocol: TCP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"postgres\" does not have a read-only root file system"
  },
  {
    "id": "02230",
    "manifest_path": "data/manifests/the_stack_sample/sample_0840.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgres\n  namespace: nestjs-app\n  labels:\n    application: postgres-pod\nspec:\n  containers:\n  - name: postgres\n    image: postgres\n    env:\n    - name: POSTGRES_PASSWORD\n      value: '123456'\n    ports:\n    - name: web\n      containerPort: 5432\n      protocol: TCP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"postgres\" is not set to runAsNonRoot"
  },
  {
    "id": "02231",
    "manifest_path": "data/manifests/the_stack_sample/sample_0840.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgres\n  namespace: nestjs-app\n  labels:\n    application: postgres-pod\nspec:\n  containers:\n  - name: postgres\n    image: postgres\n    env:\n    - name: POSTGRES_PASSWORD\n      value: '123456'\n    ports:\n    - name: web\n      containerPort: 5432\n      protocol: TCP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"postgres\" has cpu request 0"
  },
  {
    "id": "02232",
    "manifest_path": "data/manifests/the_stack_sample/sample_0840.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: postgres\n  namespace: nestjs-app\n  labels:\n    application: postgres-pod\nspec:\n  containers:\n  - name: postgres\n    image: postgres\n    env:\n    - name: POSTGRES_PASSWORD\n      value: '123456'\n    ports:\n    - name: web\n      containerPort: 5432\n      protocol: TCP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"postgres\" has memory limit 0"
  },
  {
    "id": "02233",
    "manifest_path": "data/manifests/the_stack_sample/sample_0842.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: atlasmap-operator\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      securityContext:\n        runAsNonRoot: true\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        image: controller:latest\n        name: manager\n        securityContext:\n          allowPrivilegeEscalation: false\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        resources:\n          limits:\n            cpu: 200m\n            memory: 100Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n      serviceAccountName: atlasmap-operator\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"manager\" is using an invalid container image, \"controller:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02234",
    "manifest_path": "data/manifests/the_stack_sample/sample_0842.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: atlasmap-operator\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      securityContext:\n        runAsNonRoot: true\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        image: controller:latest\n        name: manager\n        securityContext:\n          allowPrivilegeEscalation: false\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        resources:\n          limits:\n            cpu: 200m\n            memory: 100Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n      serviceAccountName: atlasmap-operator\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"manager\" does not have a read-only root file system"
  },
  {
    "id": "02235",
    "manifest_path": "data/manifests/the_stack_sample/sample_0846.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: opendesign-datapertus-test-deployment\n  namespace: opendesign-datapertus-test\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: opendesign-datapertus-test\n  template:\n    metadata:\n      labels:\n        app: opendesign-datapertus-test\n    spec:\n      containers:\n      - name: opendesign-datapertus-test\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/dataset-test:v0.0.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"opendesign-datapertus-test\" does not have a read-only root file system"
  },
  {
    "id": "02236",
    "manifest_path": "data/manifests/the_stack_sample/sample_0846.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: opendesign-datapertus-test-deployment\n  namespace: opendesign-datapertus-test\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: opendesign-datapertus-test\n  template:\n    metadata:\n      labels:\n        app: opendesign-datapertus-test\n    spec:\n      containers:\n      - name: opendesign-datapertus-test\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/dataset-test:v0.0.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"opendesign-datapertus-test\" is not set to runAsNonRoot"
  },
  {
    "id": "02237",
    "manifest_path": "data/manifests/the_stack_sample/sample_0846.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: opendesign-datapertus-test-deployment\n  namespace: opendesign-datapertus-test\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: opendesign-datapertus-test\n  template:\n    metadata:\n      labels:\n        app: opendesign-datapertus-test\n    spec:\n      containers:\n      - name: opendesign-datapertus-test\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/dataset-test:v0.0.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"opendesign-datapertus-test\" has cpu request 0"
  },
  {
    "id": "02238",
    "manifest_path": "data/manifests/the_stack_sample/sample_0846.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: opendesign-datapertus-test-deployment\n  namespace: opendesign-datapertus-test\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: opendesign-datapertus-test\n  template:\n    metadata:\n      labels:\n        app: opendesign-datapertus-test\n    spec:\n      containers:\n      - name: opendesign-datapertus-test\n        image: swr.cn-north-4.myhuaweicloud.com/opensourceway/dataset-test:v0.0.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"opendesign-datapertus-test\" has memory limit 0"
  },
  {
    "id": "02239",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"driver-registrar\" does not have a read-only root file system"
  },
  {
    "id": "02240",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hostpath\" does not have a read-only root file system"
  },
  {
    "id": "02241",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"hostpath\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "02242",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"hostpath\" is privileged"
  },
  {
    "id": "02243",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"driver-registrar\" is not set to runAsNonRoot"
  },
  {
    "id": "02244",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hostpath\" is not set to runAsNonRoot"
  },
  {
    "id": "02245",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"driver-registrar\" has cpu request 0"
  },
  {
    "id": "02246",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hostpath\" has cpu request 0"
  },
  {
    "id": "02247",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"driver-registrar\" has memory limit 0"
  },
  {
    "id": "02248",
    "manifest_path": "data/manifests/the_stack_sample/sample_0847.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-hostpathplugin\nspec:\n  selector:\n    matchLabels:\n      app: csi-hostpathplugin\n  template:\n    metadata:\n      labels:\n        app: csi-hostpathplugin\n    spec:\n      serviceAccountName: csi-driver-registrar\n      containers:\n      - name: driver-registrar\n        image: quay.io/k8scsi/driver-registrar:v0.4.1\n        args:\n        - --v=5\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-hostpath/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /registration\n          name: registration-dir\n      - name: hostpath\n        image: quay.io/k8scsi/hostpathplugin:v0.4.1\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /var/lib/kubelet/pods\n          mountPropagation: Bidirectional\n          name: mountpoint-dir\n      volumes:\n      - hostPath:\n          path: /var/lib/kubelet/plugins/csi-hostpath\n          type: DirectoryOrCreate\n        name: socket-dir\n      - hostPath:\n          path: /var/lib/kubelet/pods\n          type: DirectoryOrCreate\n        name: mountpoint-dir\n      - hostPath:\n          path: /var/lib/kubelet/plugins\n          type: Directory\n        name: registration-dir\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hostpath\" has memory limit 0"
  },
  {
    "id": "02249",
    "manifest_path": "data/manifests/the_stack_sample/sample_0855.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: skuleshov/payment_service:v0.0.2\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "02250",
    "manifest_path": "data/manifests/the_stack_sample/sample_0855.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: skuleshov/payment_service:v0.0.2\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "02251",
    "manifest_path": "data/manifests/the_stack_sample/sample_0855.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: skuleshov/payment_service:v0.0.2\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"server\" has cpu request 0"
  },
  {
    "id": "02252",
    "manifest_path": "data/manifests/the_stack_sample/sample_0855.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: skuleshov/payment_service:v0.0.2\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"server\" has memory limit 0"
  },
  {
    "id": "02253",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"container1\" is using an invalid container image, \"redis:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02254",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"container1\" does not have a read-only root file system"
  },
  {
    "id": "02255",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"container2\" does not have a read-only root file system"
  },
  {
    "id": "02256",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"container3\" does not have a read-only root file system"
  },
  {
    "id": "02257",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"container1\" is not set to runAsNonRoot"
  },
  {
    "id": "02258",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"container2\" is not set to runAsNonRoot"
  },
  {
    "id": "02259",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"container3\" is not set to runAsNonRoot"
  },
  {
    "id": "02260",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"container1\" has cpu request 0"
  },
  {
    "id": "02261",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"container2\" has cpu request 0"
  },
  {
    "id": "02262",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"container3\" has cpu request 0"
  },
  {
    "id": "02263",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"container1\" has memory limit 0"
  },
  {
    "id": "02264",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"container2\" has memory limit 0"
  },
  {
    "id": "02265",
    "manifest_path": "data/manifests/the_stack_sample/sample_0858.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test21\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: redis:latest\n        name: container1\n      - image: docker.io/dgeiger/alpine:3\n        name: container2\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"container3\" has memory limit 0"
  },
  {
    "id": "02266",
    "manifest_path": "data/manifests/the_stack_sample/sample_0859.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      containers:\n      - name: minio\n        image: minio/minio:RELEASE.2020-05-16T01-33-21Z\n        args:\n        - gateway\n        - gcs\n        - gcp_project_id\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/application_default_credentials.json\n        ports:\n        - containerPort: 9000\n        volumeMounts:\n        - name: gcs-credentials\n          mountPath: /etc/credentials\n          readOnly: true\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable MINIO_SECRET_KEY in container \"minio\" found"
  },
  {
    "id": "02267",
    "manifest_path": "data/manifests/the_stack_sample/sample_0859.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      containers:\n      - name: minio\n        image: minio/minio:RELEASE.2020-05-16T01-33-21Z\n        args:\n        - gateway\n        - gcs\n        - gcp_project_id\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/application_default_credentials.json\n        ports:\n        - containerPort: 9000\n        volumeMounts:\n        - name: gcs-credentials\n          mountPath: /etc/credentials\n          readOnly: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"minio\" does not have a read-only root file system"
  },
  {
    "id": "02268",
    "manifest_path": "data/manifests/the_stack_sample/sample_0859.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      containers:\n      - name: minio\n        image: minio/minio:RELEASE.2020-05-16T01-33-21Z\n        args:\n        - gateway\n        - gcs\n        - gcp_project_id\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/application_default_credentials.json\n        ports:\n        - containerPort: 9000\n        volumeMounts:\n        - name: gcs-credentials\n          mountPath: /etc/credentials\n          readOnly: true\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"minio\" is not set to runAsNonRoot"
  },
  {
    "id": "02269",
    "manifest_path": "data/manifests/the_stack_sample/sample_0859.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      containers:\n      - name: minio\n        image: minio/minio:RELEASE.2020-05-16T01-33-21Z\n        args:\n        - gateway\n        - gcs\n        - gcp_project_id\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/application_default_credentials.json\n        ports:\n        - containerPort: 9000\n        volumeMounts:\n        - name: gcs-credentials\n          mountPath: /etc/credentials\n          readOnly: true\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"minio\" has cpu request 0"
  },
  {
    "id": "02270",
    "manifest_path": "data/manifests/the_stack_sample/sample_0859.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      containers:\n      - name: minio\n        image: minio/minio:RELEASE.2020-05-16T01-33-21Z\n        args:\n        - gateway\n        - gcs\n        - gcp_project_id\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/application_default_credentials.json\n        ports:\n        - containerPort: 9000\n        volumeMounts:\n        - name: gcs-credentials\n          mountPath: /etc/credentials\n          readOnly: true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"minio\" has memory limit 0"
  },
  {
    "id": "02271",
    "manifest_path": "data/manifests/the_stack_sample/sample_0864.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    io.sourceloop.service: postgres-orchestrator\n  name: postgres-orchestrator\n  namespace: sourceloop-sandbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.sourceloop.service: postgres-orchestrator\n  template:\n    metadata:\n      labels:\n        io.sourceloop.service: postgres-orchestrator\n    spec:\n      containers:\n      - args:\n        - bash\n        - -c\n        - 'export PGPASSWORD=${POSTGRES_PASSWORD:-changeme}; sleep 30;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          authentication_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          notification_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          workflow_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          audit_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          scheduler_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          in_mail_db'' 2>&1;\n\n          exit 0'\n        env:\n        - name: PGDATA\n          value: /data/postgres\n        - name: PGPASSWORD\n          value: changeme\n        - name: POSTGRES_PASSWORD\n          value: changeme\n        - name: POSTGRES_USER\n          value: postgres\n        image: postgres\n        name: postgres-orchestrator\n        ports:\n        - containerPort: 5433\n        resources: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"postgres-orchestrator\" is using an invalid container image, \"postgres\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02272",
    "manifest_path": "data/manifests/the_stack_sample/sample_0864.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    io.sourceloop.service: postgres-orchestrator\n  name: postgres-orchestrator\n  namespace: sourceloop-sandbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.sourceloop.service: postgres-orchestrator\n  template:\n    metadata:\n      labels:\n        io.sourceloop.service: postgres-orchestrator\n    spec:\n      containers:\n      - args:\n        - bash\n        - -c\n        - 'export PGPASSWORD=${POSTGRES_PASSWORD:-changeme}; sleep 30;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          authentication_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          notification_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          workflow_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          audit_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          scheduler_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          in_mail_db'' 2>&1;\n\n          exit 0'\n        env:\n        - name: PGDATA\n          value: /data/postgres\n        - name: PGPASSWORD\n          value: changeme\n        - name: POSTGRES_PASSWORD\n          value: changeme\n        - name: POSTGRES_USER\n          value: postgres\n        image: postgres\n        name: postgres-orchestrator\n        ports:\n        - containerPort: 5433\n        resources: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"postgres-orchestrator\" does not have a read-only root file system"
  },
  {
    "id": "02273",
    "manifest_path": "data/manifests/the_stack_sample/sample_0864.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    io.sourceloop.service: postgres-orchestrator\n  name: postgres-orchestrator\n  namespace: sourceloop-sandbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.sourceloop.service: postgres-orchestrator\n  template:\n    metadata:\n      labels:\n        io.sourceloop.service: postgres-orchestrator\n    spec:\n      containers:\n      - args:\n        - bash\n        - -c\n        - 'export PGPASSWORD=${POSTGRES_PASSWORD:-changeme}; sleep 30;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          authentication_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          notification_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          workflow_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          audit_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          scheduler_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          in_mail_db'' 2>&1;\n\n          exit 0'\n        env:\n        - name: PGDATA\n          value: /data/postgres\n        - name: PGPASSWORD\n          value: changeme\n        - name: POSTGRES_PASSWORD\n          value: changeme\n        - name: POSTGRES_USER\n          value: postgres\n        image: postgres\n        name: postgres-orchestrator\n        ports:\n        - containerPort: 5433\n        resources: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"postgres-orchestrator\" is not set to runAsNonRoot"
  },
  {
    "id": "02274",
    "manifest_path": "data/manifests/the_stack_sample/sample_0864.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    io.sourceloop.service: postgres-orchestrator\n  name: postgres-orchestrator\n  namespace: sourceloop-sandbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.sourceloop.service: postgres-orchestrator\n  template:\n    metadata:\n      labels:\n        io.sourceloop.service: postgres-orchestrator\n    spec:\n      containers:\n      - args:\n        - bash\n        - -c\n        - 'export PGPASSWORD=${POSTGRES_PASSWORD:-changeme}; sleep 30;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          authentication_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          notification_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          workflow_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          audit_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          scheduler_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          in_mail_db'' 2>&1;\n\n          exit 0'\n        env:\n        - name: PGDATA\n          value: /data/postgres\n        - name: PGPASSWORD\n          value: changeme\n        - name: POSTGRES_PASSWORD\n          value: changeme\n        - name: POSTGRES_USER\n          value: postgres\n        image: postgres\n        name: postgres-orchestrator\n        ports:\n        - containerPort: 5433\n        resources: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"postgres-orchestrator\" has cpu request 0"
  },
  {
    "id": "02275",
    "manifest_path": "data/manifests/the_stack_sample/sample_0864.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    io.sourceloop.service: postgres-orchestrator\n  name: postgres-orchestrator\n  namespace: sourceloop-sandbox\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.sourceloop.service: postgres-orchestrator\n  template:\n    metadata:\n      labels:\n        io.sourceloop.service: postgres-orchestrator\n    spec:\n      containers:\n      - args:\n        - bash\n        - -c\n        - 'export PGPASSWORD=${POSTGRES_PASSWORD:-changeme}; sleep 30;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          authentication_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          notification_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          workflow_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          audit_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          scheduler_db'' 2>&1;\n\n          psql -U ${POSTGRES_USER:-postgres} -d postgres -h postgres -c ''create database\n          in_mail_db'' 2>&1;\n\n          exit 0'\n        env:\n        - name: PGDATA\n          value: /data/postgres\n        - name: PGPASSWORD\n          value: changeme\n        - name: POSTGRES_PASSWORD\n          value: changeme\n        - name: POSTGRES_USER\n          value: postgres\n        image: postgres\n        name: postgres-orchestrator\n        ports:\n        - containerPort: 5433\n        resources: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"postgres-orchestrator\" has memory limit 0"
  },
  {
    "id": "02276",
    "manifest_path": "data/manifests/the_stack_sample/sample_0865.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: check-acr-sync\n  namespace: monitoring\n  labels:\n    app: check-acr-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: check-acr-sync\n          image: hmctspublic.azurecr.io/check-acr-sync:dbbbwb\n          imagePullPolicy: IfNotPresent\n          resources:\n            requests:\n              memory: 64Mi\n              cpu: 250m\n            limits:\n              memory: 256Mi\n              cpu: 500m\n          env:\n          - name: SLACK_WEBHOOK\n            valueFrom:\n              secretKeyRef:\n                name: monitoring-values\n                key: slack-webhook\n          - name: SLACK_ICON\n            value: flux\n          - name: ACR_MAX_RESULTS\n            value: '3000'\n          - name: ACR_SYNC_DEBUG\n            value: 'true'\n          envFrom:\n          - secretRef:\n              name: acr-sync\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"check-acr-sync\" does not have a read-only root file system"
  },
  {
    "id": "02277",
    "manifest_path": "data/manifests/the_stack_sample/sample_0865.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: check-acr-sync\n  namespace: monitoring\n  labels:\n    app: check-acr-sync\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: check-acr-sync\n          image: hmctspublic.azurecr.io/check-acr-sync:dbbbwb\n          imagePullPolicy: IfNotPresent\n          resources:\n            requests:\n              memory: 64Mi\n              cpu: 250m\n            limits:\n              memory: 256Mi\n              cpu: 500m\n          env:\n          - name: SLACK_WEBHOOK\n            valueFrom:\n              secretKeyRef:\n                name: monitoring-values\n                key: slack-webhook\n          - name: SLACK_ICON\n            value: flux\n          - name: ACR_MAX_RESULTS\n            value: '3000'\n          - name: ACR_SYNC_DEBUG\n            value: 'true'\n          envFrom:\n          - secretRef:\n              name: acr-sync\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"check-acr-sync\" is not set to runAsNonRoot"
  },
  {
    "id": "02278",
    "manifest_path": "data/manifests/the_stack_sample/sample_0866.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fortunes\n  labels:\n    app: fortunes\nspec:\n  containers:\n  - name: fortunes\n    image: localhost:5000/fortunes\n    imagePullPolicy: Always\n    ports:\n    - name: app\n      containerPort: 3000\n    env:\n    - name: REDIS_HOST\n      value: redis-master\n    - name: REDIS_PORT\n      value: '6379'\n    - name: REDIS_PWD\n      value: none\n    - name: FORTUNES_TARGET_TOPIC\n      value: fc_fortunes_out\n    - name: FORTUNES_SOURCE_TOPIC\n      value: fc_fortunes_in\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"fortunes\" is using an invalid container image, \"localhost:5000/fortunes\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02279",
    "manifest_path": "data/manifests/the_stack_sample/sample_0866.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fortunes\n  labels:\n    app: fortunes\nspec:\n  containers:\n  - name: fortunes\n    image: localhost:5000/fortunes\n    imagePullPolicy: Always\n    ports:\n    - name: app\n      containerPort: 3000\n    env:\n    - name: REDIS_HOST\n      value: redis-master\n    - name: REDIS_PORT\n      value: '6379'\n    - name: REDIS_PWD\n      value: none\n    - name: FORTUNES_TARGET_TOPIC\n      value: fc_fortunes_out\n    - name: FORTUNES_SOURCE_TOPIC\n      value: fc_fortunes_in\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"fortunes\" does not have a read-only root file system"
  },
  {
    "id": "02280",
    "manifest_path": "data/manifests/the_stack_sample/sample_0866.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fortunes\n  labels:\n    app: fortunes\nspec:\n  containers:\n  - name: fortunes\n    image: localhost:5000/fortunes\n    imagePullPolicy: Always\n    ports:\n    - name: app\n      containerPort: 3000\n    env:\n    - name: REDIS_HOST\n      value: redis-master\n    - name: REDIS_PORT\n      value: '6379'\n    - name: REDIS_PWD\n      value: none\n    - name: FORTUNES_TARGET_TOPIC\n      value: fc_fortunes_out\n    - name: FORTUNES_SOURCE_TOPIC\n      value: fc_fortunes_in\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"fortunes\" is not set to runAsNonRoot"
  },
  {
    "id": "02281",
    "manifest_path": "data/manifests/the_stack_sample/sample_0866.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fortunes\n  labels:\n    app: fortunes\nspec:\n  containers:\n  - name: fortunes\n    image: localhost:5000/fortunes\n    imagePullPolicy: Always\n    ports:\n    - name: app\n      containerPort: 3000\n    env:\n    - name: REDIS_HOST\n      value: redis-master\n    - name: REDIS_PORT\n      value: '6379'\n    - name: REDIS_PWD\n      value: none\n    - name: FORTUNES_TARGET_TOPIC\n      value: fc_fortunes_out\n    - name: FORTUNES_SOURCE_TOPIC\n      value: fc_fortunes_in\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"fortunes\" has cpu request 0"
  },
  {
    "id": "02282",
    "manifest_path": "data/manifests/the_stack_sample/sample_0866.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fortunes\n  labels:\n    app: fortunes\nspec:\n  containers:\n  - name: fortunes\n    image: localhost:5000/fortunes\n    imagePullPolicy: Always\n    ports:\n    - name: app\n      containerPort: 3000\n    env:\n    - name: REDIS_HOST\n      value: redis-master\n    - name: REDIS_PORT\n      value: '6379'\n    - name: REDIS_PWD\n      value: none\n    - name: FORTUNES_TARGET_TOPIC\n      value: fc_fortunes_out\n    - name: FORTUNES_SOURCE_TOPIC\n      value: fc_fortunes_in\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"fortunes\" has memory limit 0"
  },
  {
    "id": "02283",
    "manifest_path": "data/manifests/the_stack_sample/sample_0867.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-client\n  namespace: es-cluster\n  labels:\n    component: elasticsearch\n    role: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: client\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-client\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: madcore_es\n        - name: NODE_MASTER\n          value: 'false'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"es-client\" does not have a read-only root file system"
  },
  {
    "id": "02284",
    "manifest_path": "data/manifests/the_stack_sample/sample_0867.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-client\n  namespace: es-cluster\n  labels:\n    component: elasticsearch\n    role: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: client\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-client\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: madcore_es\n        - name: NODE_MASTER\n          value: 'false'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"es-client\" is not set to runAsNonRoot"
  },
  {
    "id": "02285",
    "manifest_path": "data/manifests/the_stack_sample/sample_0867.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-client\n  namespace: es-cluster\n  labels:\n    component: elasticsearch\n    role: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: client\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-client\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: madcore_es\n        - name: NODE_MASTER\n          value: 'false'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"es-client\" has cpu request 0"
  },
  {
    "id": "02286",
    "manifest_path": "data/manifests/the_stack_sample/sample_0867.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-client\n  namespace: es-cluster\n  labels:\n    component: elasticsearch\n    role: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: client\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-client\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: madcore_es\n        - name: NODE_MASTER\n          value: 'false'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"es-client\" has memory limit 0"
  },
  {
    "id": "02287",
    "manifest_path": "data/manifests/the_stack_sample/sample_0870.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\nspec:\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      name: mysql\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - name: mysql\n        image: mysql:5.7\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: mysql-config\n              key: MYSQL_ROOT_PASSWORD\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mysql\" does not have a read-only root file system"
  },
  {
    "id": "02288",
    "manifest_path": "data/manifests/the_stack_sample/sample_0870.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\nspec:\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      name: mysql\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - name: mysql\n        image: mysql:5.7\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: mysql-config\n              key: MYSQL_ROOT_PASSWORD\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mysql\" is not set to runAsNonRoot"
  },
  {
    "id": "02289",
    "manifest_path": "data/manifests/the_stack_sample/sample_0870.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\nspec:\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      name: mysql\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - name: mysql\n        image: mysql:5.7\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: mysql-config\n              key: MYSQL_ROOT_PASSWORD\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mysql\" has cpu request 0"
  },
  {
    "id": "02290",
    "manifest_path": "data/manifests/the_stack_sample/sample_0870.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\nspec:\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      name: mysql\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - name: mysql\n        image: mysql:5.7\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: mysql-config\n              key: MYSQL_ROOT_PASSWORD\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mysql\" has memory limit 0"
  },
  {
    "id": "02291",
    "manifest_path": "data/manifests/the_stack_sample/sample_0872.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bandicoot-prod\n  labels:\n    app: bandicoot\n    version: 1.0.0\n    env: prod\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: bandicoot\n  template:\n    metadata:\n      labels:\n        app: bandicoot\n    spec:\n      containers:\n      - image: gcr.io/k8s-vr-2021/kuard-amd64:blue\n        name: bandicoot-prod\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          periodSeconds: 2\n          initialDelaySeconds: 0\n          failureThreshold: 3\n          successThreshold: 1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"bandicoot-prod\" does not have a read-only root file system"
  },
  {
    "id": "02292",
    "manifest_path": "data/manifests/the_stack_sample/sample_0872.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bandicoot-prod\n  labels:\n    app: bandicoot\n    version: 1.0.0\n    env: prod\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: bandicoot\n  template:\n    metadata:\n      labels:\n        app: bandicoot\n    spec:\n      containers:\n      - image: gcr.io/k8s-vr-2021/kuard-amd64:blue\n        name: bandicoot-prod\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          periodSeconds: 2\n          initialDelaySeconds: 0\n          failureThreshold: 3\n          successThreshold: 1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"bandicoot-prod\" is not set to runAsNonRoot"
  },
  {
    "id": "02293",
    "manifest_path": "data/manifests/the_stack_sample/sample_0872.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bandicoot-prod\n  labels:\n    app: bandicoot\n    version: 1.0.0\n    env: prod\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: bandicoot\n  template:\n    metadata:\n      labels:\n        app: bandicoot\n    spec:\n      containers:\n      - image: gcr.io/k8s-vr-2021/kuard-amd64:blue\n        name: bandicoot-prod\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          periodSeconds: 2\n          initialDelaySeconds: 0\n          failureThreshold: 3\n          successThreshold: 1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"bandicoot-prod\" has cpu request 0"
  },
  {
    "id": "02294",
    "manifest_path": "data/manifests/the_stack_sample/sample_0872.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bandicoot-prod\n  labels:\n    app: bandicoot\n    version: 1.0.0\n    env: prod\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: bandicoot\n  template:\n    metadata:\n      labels:\n        app: bandicoot\n    spec:\n      containers:\n      - image: gcr.io/k8s-vr-2021/kuard-amd64:blue\n        name: bandicoot-prod\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          periodSeconds: 2\n          initialDelaySeconds: 0\n          failureThreshold: 3\n          successThreshold: 1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"bandicoot-prod\" has memory limit 0"
  },
  {
    "id": "02295",
    "manifest_path": "data/manifests/the_stack_sample/sample_0873.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-service\nspec:\n  containers:\n  - name: hello-service\n    image: skaffold-hello\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hello-service\" is using an invalid container image, \"skaffold-hello\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02296",
    "manifest_path": "data/manifests/the_stack_sample/sample_0873.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-service\nspec:\n  containers:\n  - name: hello-service\n    image: skaffold-hello\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hello-service\" does not have a read-only root file system"
  },
  {
    "id": "02297",
    "manifest_path": "data/manifests/the_stack_sample/sample_0873.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-service\nspec:\n  containers:\n  - name: hello-service\n    image: skaffold-hello\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hello-service\" is not set to runAsNonRoot"
  },
  {
    "id": "02298",
    "manifest_path": "data/manifests/the_stack_sample/sample_0873.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-service\nspec:\n  containers:\n  - name: hello-service\n    image: skaffold-hello\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hello-service\" has cpu request 0"
  },
  {
    "id": "02299",
    "manifest_path": "data/manifests/the_stack_sample/sample_0873.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-service\nspec:\n  containers:\n  - name: hello-service\n    image: skaffold-hello\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hello-service\" has memory limit 0"
  },
  {
    "id": "02300",
    "manifest_path": "data/manifests/the_stack_sample/sample_0875.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: some-other-pod\nspec:\n  containers:\n  - name: some-container\n    image: busybox\n    command:\n    - /bin/sh\n    - -c\n    - watch \"cat /etc/config/comics\"\n    volumeMounts:\n    - name: config-volume\n      mountPath: /etc/config\n  volumes:\n  - name: config-volume\n    configMap:\n      name: file-config\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"some-container\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02301",
    "manifest_path": "data/manifests/the_stack_sample/sample_0875.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: some-other-pod\nspec:\n  containers:\n  - name: some-container\n    image: busybox\n    command:\n    - /bin/sh\n    - -c\n    - watch \"cat /etc/config/comics\"\n    volumeMounts:\n    - name: config-volume\n      mountPath: /etc/config\n  volumes:\n  - name: config-volume\n    configMap:\n      name: file-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"some-container\" does not have a read-only root file system"
  },
  {
    "id": "02302",
    "manifest_path": "data/manifests/the_stack_sample/sample_0875.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: some-other-pod\nspec:\n  containers:\n  - name: some-container\n    image: busybox\n    command:\n    - /bin/sh\n    - -c\n    - watch \"cat /etc/config/comics\"\n    volumeMounts:\n    - name: config-volume\n      mountPath: /etc/config\n  volumes:\n  - name: config-volume\n    configMap:\n      name: file-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"some-container\" is not set to runAsNonRoot"
  },
  {
    "id": "02303",
    "manifest_path": "data/manifests/the_stack_sample/sample_0875.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: some-other-pod\nspec:\n  containers:\n  - name: some-container\n    image: busybox\n    command:\n    - /bin/sh\n    - -c\n    - watch \"cat /etc/config/comics\"\n    volumeMounts:\n    - name: config-volume\n      mountPath: /etc/config\n  volumes:\n  - name: config-volume\n    configMap:\n      name: file-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"some-container\" has cpu request 0"
  },
  {
    "id": "02304",
    "manifest_path": "data/manifests/the_stack_sample/sample_0875.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: some-other-pod\nspec:\n  containers:\n  - name: some-container\n    image: busybox\n    command:\n    - /bin/sh\n    - -c\n    - watch \"cat /etc/config/comics\"\n    volumeMounts:\n    - name: config-volume\n      mountPath: /etc/config\n  volumes:\n  - name: config-volume\n    configMap:\n      name: file-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"some-container\" has memory limit 0"
  },
  {
    "id": "02305",
    "manifest_path": "data/manifests/the_stack_sample/sample_0878.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.5.7\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 15344ed303d5710e2cd3a4efcdd4a3cd191aa324d9f6b90bca190762be07d2a7\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.5.7\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: osstap1989\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.5.7\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 52b4dd6da9e7d2edaa3548ce1bd2f9e86032cccb\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-foghorn\" does not have a read-only root file system"
  },
  {
    "id": "02306",
    "manifest_path": "data/manifests/the_stack_sample/sample_0878.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.5.7\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 15344ed303d5710e2cd3a4efcdd4a3cd191aa324d9f6b90bca190762be07d2a7\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.5.7\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: osstap1989\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.5.7\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 52b4dd6da9e7d2edaa3548ce1bd2f9e86032cccb\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-foghorn\" is not set to runAsNonRoot"
  },
  {
    "id": "02307",
    "manifest_path": "data/manifests/the_stack_sample/sample_0889.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: login-deployment\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      component: login\n  template:\n    metadata:\n      labels:\n        component: login\n    spec:\n      containers:\n      - name: login\n        image: sbalasubramanian14/login-api\n        ports:\n        - containerPort: 5001\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          value: admin@123\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"login\" is using an invalid container image, \"sbalasubramanian14/login-api\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02308",
    "manifest_path": "data/manifests/the_stack_sample/sample_0889.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: login-deployment\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      component: login\n  template:\n    metadata:\n      labels:\n        component: login\n    spec:\n      containers:\n      - name: login\n        image: sbalasubramanian14/login-api\n        ports:\n        - containerPort: 5001\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          value: admin@123\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"login\" does not have a read-only root file system"
  },
  {
    "id": "02309",
    "manifest_path": "data/manifests/the_stack_sample/sample_0889.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: login-deployment\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      component: login\n  template:\n    metadata:\n      labels:\n        component: login\n    spec:\n      containers:\n      - name: login\n        image: sbalasubramanian14/login-api\n        ports:\n        - containerPort: 5001\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          value: admin@123\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"login\" is not set to runAsNonRoot"
  },
  {
    "id": "02310",
    "manifest_path": "data/manifests/the_stack_sample/sample_0889.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: login-deployment\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      component: login\n  template:\n    metadata:\n      labels:\n        component: login\n    spec:\n      containers:\n      - name: login\n        image: sbalasubramanian14/login-api\n        ports:\n        - containerPort: 5001\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          value: admin@123\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"login\" has cpu request 0"
  },
  {
    "id": "02311",
    "manifest_path": "data/manifests/the_stack_sample/sample_0889.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: login-deployment\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      component: login\n  template:\n    metadata:\n      labels:\n        component: login\n    spec:\n      containers:\n      - name: login\n        image: sbalasubramanian14/login-api\n        ports:\n        - containerPort: 5001\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          value: admin@123\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"login\" has memory limit 0"
  },
  {
    "id": "02312",
    "manifest_path": "data/manifests/the_stack_sample/sample_0892.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: direct-mapper\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: directmapper\n  template:\n    metadata:\n      labels:\n        app: directmapper\n    spec:\n      containers:\n      - name: direct-mapper-container\n        image: directmapper:v1.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/kubeedge/\n        - mountPath: /dev/ttyS0\n          name: direct-dev0\n        - mountPath: /dev/ttyS1\n          name: direct-dev1\n      volumes:\n      - name: config-volume\n        configMap:\n          name: device-profile-config-test\n      - name: direct-dev0\n        hostPath:\n          path: /dev/ttyS0\n      - name: direct-dev1\n        hostPath:\n          path: /dev/ttyS1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"direct-mapper-container\" does not have a read-only root file system"
  },
  {
    "id": "02313",
    "manifest_path": "data/manifests/the_stack_sample/sample_0892.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: direct-mapper\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: directmapper\n  template:\n    metadata:\n      labels:\n        app: directmapper\n    spec:\n      containers:\n      - name: direct-mapper-container\n        image: directmapper:v1.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/kubeedge/\n        - mountPath: /dev/ttyS0\n          name: direct-dev0\n        - mountPath: /dev/ttyS1\n          name: direct-dev1\n      volumes:\n      - name: config-volume\n        configMap:\n          name: device-profile-config-test\n      - name: direct-dev0\n        hostPath:\n          path: /dev/ttyS0\n      - name: direct-dev1\n        hostPath:\n          path: /dev/ttyS1\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"direct-mapper-container\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "02314",
    "manifest_path": "data/manifests/the_stack_sample/sample_0892.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: direct-mapper\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: directmapper\n  template:\n    metadata:\n      labels:\n        app: directmapper\n    spec:\n      containers:\n      - name: direct-mapper-container\n        image: directmapper:v1.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/kubeedge/\n        - mountPath: /dev/ttyS0\n          name: direct-dev0\n        - mountPath: /dev/ttyS1\n          name: direct-dev1\n      volumes:\n      - name: config-volume\n        configMap:\n          name: device-profile-config-test\n      - name: direct-dev0\n        hostPath:\n          path: /dev/ttyS0\n      - name: direct-dev1\n        hostPath:\n          path: /dev/ttyS1\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"direct-mapper-container\" is privileged"
  },
  {
    "id": "02315",
    "manifest_path": "data/manifests/the_stack_sample/sample_0892.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: direct-mapper\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: directmapper\n  template:\n    metadata:\n      labels:\n        app: directmapper\n    spec:\n      containers:\n      - name: direct-mapper-container\n        image: directmapper:v1.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/kubeedge/\n        - mountPath: /dev/ttyS0\n          name: direct-dev0\n        - mountPath: /dev/ttyS1\n          name: direct-dev1\n      volumes:\n      - name: config-volume\n        configMap:\n          name: device-profile-config-test\n      - name: direct-dev0\n        hostPath:\n          path: /dev/ttyS0\n      - name: direct-dev1\n        hostPath:\n          path: /dev/ttyS1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"direct-mapper-container\" is not set to runAsNonRoot"
  },
  {
    "id": "02316",
    "manifest_path": "data/manifests/the_stack_sample/sample_0892.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: direct-mapper\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: directmapper\n  template:\n    metadata:\n      labels:\n        app: directmapper\n    spec:\n      containers:\n      - name: direct-mapper-container\n        image: directmapper:v1.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/kubeedge/\n        - mountPath: /dev/ttyS0\n          name: direct-dev0\n        - mountPath: /dev/ttyS1\n          name: direct-dev1\n      volumes:\n      - name: config-volume\n        configMap:\n          name: device-profile-config-test\n      - name: direct-dev0\n        hostPath:\n          path: /dev/ttyS0\n      - name: direct-dev1\n        hostPath:\n          path: /dev/ttyS1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"direct-mapper-container\" has cpu request 0"
  },
  {
    "id": "02317",
    "manifest_path": "data/manifests/the_stack_sample/sample_0892.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: direct-mapper\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: directmapper\n  template:\n    metadata:\n      labels:\n        app: directmapper\n    spec:\n      containers:\n      - name: direct-mapper-container\n        image: directmapper:v1.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: config-volume\n          mountPath: /opt/kubeedge/\n        - mountPath: /dev/ttyS0\n          name: direct-dev0\n        - mountPath: /dev/ttyS1\n          name: direct-dev1\n      volumes:\n      - name: config-volume\n        configMap:\n          name: device-profile-config-test\n      - name: direct-dev0\n        hostPath:\n          path: /dev/ttyS0\n      - name: direct-dev1\n        hostPath:\n          path: /dev/ttyS1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"direct-mapper-container\" has memory limit 0"
  },
  {
    "id": "02318",
    "manifest_path": "data/manifests/the_stack_sample/sample_0894.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: axonserver\n  labels:\n    app: axonserver\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: axonserver\n  template:\n    metadata:\n      labels:\n        app: axonserver\n    spec:\n      containers:\n      - name: axonserver\n        image: axoniq/axonserver\n        imagePullPolicy: Always\n        ports:\n        - name: grpc\n          containerPort: 8124\n          protocol: TCP\n        - name: http\n          containerPort: 8024\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            port: http\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n        livenessProbe:\n          httpGet:\n            port: gui\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"axonserver\" is using an invalid container image, \"axoniq/axonserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02319",
    "manifest_path": "data/manifests/the_stack_sample/sample_0894.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: axonserver\n  labels:\n    app: axonserver\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: axonserver\n  template:\n    metadata:\n      labels:\n        app: axonserver\n    spec:\n      containers:\n      - name: axonserver\n        image: axoniq/axonserver\n        imagePullPolicy: Always\n        ports:\n        - name: grpc\n          containerPort: 8124\n          protocol: TCP\n        - name: http\n          containerPort: 8024\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            port: http\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n        livenessProbe:\n          httpGet:\n            port: gui\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"axonserver\" does not have a read-only root file system"
  },
  {
    "id": "02320",
    "manifest_path": "data/manifests/the_stack_sample/sample_0894.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: axonserver\n  labels:\n    app: axonserver\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: axonserver\n  template:\n    metadata:\n      labels:\n        app: axonserver\n    spec:\n      containers:\n      - name: axonserver\n        image: axoniq/axonserver\n        imagePullPolicy: Always\n        ports:\n        - name: grpc\n          containerPort: 8124\n          protocol: TCP\n        - name: http\n          containerPort: 8024\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            port: http\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n        livenessProbe:\n          httpGet:\n            port: gui\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"axonserver\" is not set to runAsNonRoot"
  },
  {
    "id": "02321",
    "manifest_path": "data/manifests/the_stack_sample/sample_0894.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: axonserver\n  labels:\n    app: axonserver\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: axonserver\n  template:\n    metadata:\n      labels:\n        app: axonserver\n    spec:\n      containers:\n      - name: axonserver\n        image: axoniq/axonserver\n        imagePullPolicy: Always\n        ports:\n        - name: grpc\n          containerPort: 8124\n          protocol: TCP\n        - name: http\n          containerPort: 8024\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            port: http\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n        livenessProbe:\n          httpGet:\n            port: gui\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"axonserver\" has cpu request 0"
  },
  {
    "id": "02322",
    "manifest_path": "data/manifests/the_stack_sample/sample_0894.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: axonserver\n  labels:\n    app: axonserver\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: axonserver\n  template:\n    metadata:\n      labels:\n        app: axonserver\n    spec:\n      containers:\n      - name: axonserver\n        image: axoniq/axonserver\n        imagePullPolicy: Always\n        ports:\n        - name: grpc\n          containerPort: 8124\n          protocol: TCP\n        - name: http\n          containerPort: 8024\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            port: http\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n        livenessProbe:\n          httpGet:\n            port: gui\n            path: /actuator/info\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          timeoutSeconds: 1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"axonserver\" has memory limit 0"
  },
  {
    "id": "02323",
    "manifest_path": "data/manifests/the_stack_sample/sample_0895.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-httpd\n  annotations:\n    annotation1: hello\n  labels:\n    app: httpd\nspec:\n  containers:\n  - name: cntr-httpd\n    image: httpd:latest\n    ports:\n    - containerPort: 80\n    env:\n    - name: pod_name\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: pod_namespace\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    - name: pod_nodeName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n    - name: pod_serviceAccountName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.serviceAccountName\n    - name: pod_hostIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.hostIP\n    - name: pod_podIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cntr-httpd\" is using an invalid container image, \"httpd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02324",
    "manifest_path": "data/manifests/the_stack_sample/sample_0895.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-httpd\n  annotations:\n    annotation1: hello\n  labels:\n    app: httpd\nspec:\n  containers:\n  - name: cntr-httpd\n    image: httpd:latest\n    ports:\n    - containerPort: 80\n    env:\n    - name: pod_name\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: pod_namespace\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    - name: pod_nodeName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n    - name: pod_serviceAccountName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.serviceAccountName\n    - name: pod_hostIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.hostIP\n    - name: pod_podIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cntr-httpd\" does not have a read-only root file system"
  },
  {
    "id": "02325",
    "manifest_path": "data/manifests/the_stack_sample/sample_0895.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-httpd\n  annotations:\n    annotation1: hello\n  labels:\n    app: httpd\nspec:\n  containers:\n  - name: cntr-httpd\n    image: httpd:latest\n    ports:\n    - containerPort: 80\n    env:\n    - name: pod_name\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: pod_namespace\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    - name: pod_nodeName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n    - name: pod_serviceAccountName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.serviceAccountName\n    - name: pod_hostIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.hostIP\n    - name: pod_podIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cntr-httpd\" is not set to runAsNonRoot"
  },
  {
    "id": "02326",
    "manifest_path": "data/manifests/the_stack_sample/sample_0895.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-httpd\n  annotations:\n    annotation1: hello\n  labels:\n    app: httpd\nspec:\n  containers:\n  - name: cntr-httpd\n    image: httpd:latest\n    ports:\n    - containerPort: 80\n    env:\n    - name: pod_name\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: pod_namespace\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    - name: pod_nodeName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n    - name: pod_serviceAccountName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.serviceAccountName\n    - name: pod_hostIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.hostIP\n    - name: pod_podIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"cntr-httpd\" has cpu request 0"
  },
  {
    "id": "02327",
    "manifest_path": "data/manifests/the_stack_sample/sample_0895.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-httpd\n  annotations:\n    annotation1: hello\n  labels:\n    app: httpd\nspec:\n  containers:\n  - name: cntr-httpd\n    image: httpd:latest\n    ports:\n    - containerPort: 80\n    env:\n    - name: pod_name\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n    - name: pod_namespace\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    - name: pod_nodeName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n    - name: pod_serviceAccountName\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.serviceAccountName\n    - name: pod_hostIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.hostIP\n    - name: pod_podIP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"cntr-httpd\" has memory limit 0"
  },
  {
    "id": "02328",
    "manifest_path": "data/manifests/the_stack_sample/sample_0907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: id\nspec:\n  selector:\n    matchLabels:\n      app: id\n  template:\n    metadata:\n      labels:\n        app: id\n    spec:\n      containers:\n      - name: sitecore-xm1-id\n        env:\n        - name: Sitecore_Sitecore__IdentityServer__Clients__DefaultClient__AllowedCorsOrigins__AllowedCorsOriginsGroup2\n          value: https://hrz.globalhost\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"sitecore-xm1-id\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02329",
    "manifest_path": "data/manifests/the_stack_sample/sample_0907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: id\nspec:\n  selector:\n    matchLabels:\n      app: id\n  template:\n    metadata:\n      labels:\n        app: id\n    spec:\n      containers:\n      - name: sitecore-xm1-id\n        env:\n        - name: Sitecore_Sitecore__IdentityServer__Clients__DefaultClient__AllowedCorsOrigins__AllowedCorsOriginsGroup2\n          value: https://hrz.globalhost\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sitecore-xm1-id\" does not have a read-only root file system"
  },
  {
    "id": "02330",
    "manifest_path": "data/manifests/the_stack_sample/sample_0907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: id\nspec:\n  selector:\n    matchLabels:\n      app: id\n  template:\n    metadata:\n      labels:\n        app: id\n    spec:\n      containers:\n      - name: sitecore-xm1-id\n        env:\n        - name: Sitecore_Sitecore__IdentityServer__Clients__DefaultClient__AllowedCorsOrigins__AllowedCorsOriginsGroup2\n          value: https://hrz.globalhost\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"sitecore-xm1-id\" is not set to runAsNonRoot"
  },
  {
    "id": "02331",
    "manifest_path": "data/manifests/the_stack_sample/sample_0907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: id\nspec:\n  selector:\n    matchLabels:\n      app: id\n  template:\n    metadata:\n      labels:\n        app: id\n    spec:\n      containers:\n      - name: sitecore-xm1-id\n        env:\n        - name: Sitecore_Sitecore__IdentityServer__Clients__DefaultClient__AllowedCorsOrigins__AllowedCorsOriginsGroup2\n          value: https://hrz.globalhost\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sitecore-xm1-id\" has cpu request 0"
  },
  {
    "id": "02332",
    "manifest_path": "data/manifests/the_stack_sample/sample_0907.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: id\nspec:\n  selector:\n    matchLabels:\n      app: id\n  template:\n    metadata:\n      labels:\n        app: id\n    spec:\n      containers:\n      - name: sitecore-xm1-id\n        env:\n        - name: Sitecore_Sitecore__IdentityServer__Clients__DefaultClient__AllowedCorsOrigins__AllowedCorsOriginsGroup2\n          value: https://hrz.globalhost\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sitecore-xm1-id\" has memory limit 0"
  },
  {
    "id": "02333",
    "manifest_path": "data/manifests/the_stack_sample/sample_0911.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7699\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02334",
    "manifest_path": "data/manifests/the_stack_sample/sample_0911.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7699\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02335",
    "manifest_path": "data/manifests/the_stack_sample/sample_0911.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7699\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02336",
    "manifest_path": "data/manifests/the_stack_sample/sample_0911.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7699\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02337",
    "manifest_path": "data/manifests/the_stack_sample/sample_0911.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7699\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02338",
    "manifest_path": "data/manifests/the_stack_sample/sample_0914.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: litmus\nspec:\n  template:\n    metadata:\n      name: litmus\n      labels:\n        app: k8s-snapshot-litmus\n    spec:\n      serviceAccountName: litmus\n      containers:\n      - name: ansibletest\n        image: openebs/ansible-runner:ci\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: APP_LABEL\n          value: name=percona\n        - name: APP_PVC\n          value: percona-mysql-claim\n        - name: APP_NAMESPACE\n          value: app-percona-ns\n        - name: PROVIDER_STORAGE_CLASS\n          value: openebs-snapshot-promoter\n        - name: DB_USER_NAME\n          value: root\n        - name: DB_PASSWORD\n          value: k8sDem0\n        - name: CLONE_VOL_CLAIM\n          value: snap-mysql-claim\n        - name: CLONE_APP_NAME\n          value: percona-new\n        - name: SNAPSHOT_NAME\n          value: snapshot-percona\n        - name: CAPACITY\n          value: 5Gi\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./apps/percona/functional/k8s_snapshot/test.yml -i /etc/ansible/hosts\n          -vv; exit 0\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ansibletest\" does not have a read-only root file system"
  },
  {
    "id": "02339",
    "manifest_path": "data/manifests/the_stack_sample/sample_0914.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: litmus\nspec:\n  template:\n    metadata:\n      name: litmus\n      labels:\n        app: k8s-snapshot-litmus\n    spec:\n      serviceAccountName: litmus\n      containers:\n      - name: ansibletest\n        image: openebs/ansible-runner:ci\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: APP_LABEL\n          value: name=percona\n        - name: APP_PVC\n          value: percona-mysql-claim\n        - name: APP_NAMESPACE\n          value: app-percona-ns\n        - name: PROVIDER_STORAGE_CLASS\n          value: openebs-snapshot-promoter\n        - name: DB_USER_NAME\n          value: root\n        - name: DB_PASSWORD\n          value: k8sDem0\n        - name: CLONE_VOL_CLAIM\n          value: snap-mysql-claim\n        - name: CLONE_APP_NAME\n          value: percona-new\n        - name: SNAPSHOT_NAME\n          value: snapshot-percona\n        - name: CAPACITY\n          value: 5Gi\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./apps/percona/functional/k8s_snapshot/test.yml -i /etc/ansible/hosts\n          -vv; exit 0\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ansibletest\" is not set to runAsNonRoot"
  },
  {
    "id": "02340",
    "manifest_path": "data/manifests/the_stack_sample/sample_0914.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: litmus\nspec:\n  template:\n    metadata:\n      name: litmus\n      labels:\n        app: k8s-snapshot-litmus\n    spec:\n      serviceAccountName: litmus\n      containers:\n      - name: ansibletest\n        image: openebs/ansible-runner:ci\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: APP_LABEL\n          value: name=percona\n        - name: APP_PVC\n          value: percona-mysql-claim\n        - name: APP_NAMESPACE\n          value: app-percona-ns\n        - name: PROVIDER_STORAGE_CLASS\n          value: openebs-snapshot-promoter\n        - name: DB_USER_NAME\n          value: root\n        - name: DB_PASSWORD\n          value: k8sDem0\n        - name: CLONE_VOL_CLAIM\n          value: snap-mysql-claim\n        - name: CLONE_APP_NAME\n          value: percona-new\n        - name: SNAPSHOT_NAME\n          value: snapshot-percona\n        - name: CAPACITY\n          value: 5Gi\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./apps/percona/functional/k8s_snapshot/test.yml -i /etc/ansible/hosts\n          -vv; exit 0\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ansibletest\" has cpu request 0"
  },
  {
    "id": "02341",
    "manifest_path": "data/manifests/the_stack_sample/sample_0914.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: litmus\nspec:\n  template:\n    metadata:\n      name: litmus\n      labels:\n        app: k8s-snapshot-litmus\n    spec:\n      serviceAccountName: litmus\n      containers:\n      - name: ansibletest\n        image: openebs/ansible-runner:ci\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: APP_LABEL\n          value: name=percona\n        - name: APP_PVC\n          value: percona-mysql-claim\n        - name: APP_NAMESPACE\n          value: app-percona-ns\n        - name: PROVIDER_STORAGE_CLASS\n          value: openebs-snapshot-promoter\n        - name: DB_USER_NAME\n          value: root\n        - name: DB_PASSWORD\n          value: k8sDem0\n        - name: CLONE_VOL_CLAIM\n          value: snap-mysql-claim\n        - name: CLONE_APP_NAME\n          value: percona-new\n        - name: SNAPSHOT_NAME\n          value: snapshot-percona\n        - name: CAPACITY\n          value: 5Gi\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./apps/percona/functional/k8s_snapshot/test.yml -i /etc/ansible/hosts\n          -vv; exit 0\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ansibletest\" has memory limit 0"
  },
  {
    "id": "02342",
    "manifest_path": "data/manifests/the_stack_sample/sample_0917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20220513-69ff551a87\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"prow-controller-manager\" does not have a read-only root file system"
  },
  {
    "id": "02343",
    "manifest_path": "data/manifests/the_stack_sample/sample_0917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20220513-69ff551a87\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"prow-controller-manager\" is not set to runAsNonRoot"
  },
  {
    "id": "02344",
    "manifest_path": "data/manifests/the_stack_sample/sample_0917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20220513-69ff551a87\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"prow-controller-manager\" has cpu request 0"
  },
  {
    "id": "02345",
    "manifest_path": "data/manifests/the_stack_sample/sample_0917.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20220513-69ff551a87\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"prow-controller-manager\" has memory limit 0"
  },
  {
    "id": "02346",
    "manifest_path": "data/manifests/the_stack_sample/sample_0919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  namespace: mayastor\n  name: mayastor-csi\n  labels:\n    openebs/engine: mayastor\nspec:\n  selector:\n    matchLabels:\n      app: mayastor-csi\n  template:\n    metadata:\n      labels:\n        app: mayastor-csi\n    spec:\n      containers:\n      - name: mayastor-csi\n        image: mayadata/mayastor-csi:latest\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        env:\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: RUST_BACKTRACE\n          value: '1'\n        args:\n        - --csi-socket=/csi/csi.sock\n        - --node-name=$(MY_NODE_NAME)\n        - --grpc-endpoint=$(MY_POD_IP):10199\n        - -v\n        volumeMounts:\n        - name: device\n          mountPath: /dev\n        - name: sys\n          mountPath: /sys\n        - name: run-udev\n          mountPath: /run/udev\n        - name: host-root\n          mountPath: /host\n        - name: plugin-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n      - name: csi-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.3.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/mayastor.openebs.io/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 10199\n          protocol: TCP\n          name: mayastor-node\n      volumes:\n      - name: device\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: run-udev\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: host-root\n        hostPath:\n          path: /\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/mayastor.openebs.io/\n          type: DirectoryOrCreate\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"mayastor-csi\" is using an invalid container image, \"mayadata/mayastor-csi:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02347",
    "manifest_path": "data/manifests/the_stack_sample/sample_0919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  namespace: mayastor\n  name: mayastor-csi\n  labels:\n    openebs/engine: mayastor\nspec:\n  selector:\n    matchLabels:\n      app: mayastor-csi\n  template:\n    metadata:\n      labels:\n        app: mayastor-csi\n    spec:\n      containers:\n      - name: mayastor-csi\n        image: mayadata/mayastor-csi:latest\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        env:\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: RUST_BACKTRACE\n          value: '1'\n        args:\n        - --csi-socket=/csi/csi.sock\n        - --node-name=$(MY_NODE_NAME)\n        - --grpc-endpoint=$(MY_POD_IP):10199\n        - -v\n        volumeMounts:\n        - name: device\n          mountPath: /dev\n        - name: sys\n          mountPath: /sys\n        - name: run-udev\n          mountPath: /run/udev\n        - name: host-root\n          mountPath: /host\n        - name: plugin-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n      - name: csi-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.3.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/mayastor.openebs.io/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 10199\n          protocol: TCP\n          name: mayastor-node\n      volumes:\n      - name: device\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: run-udev\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: host-root\n        hostPath:\n          path: /\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/mayastor.openebs.io/\n          type: DirectoryOrCreate\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"csi-driver-registrar\" does not have a read-only root file system"
  },
  {
    "id": "02348",
    "manifest_path": "data/manifests/the_stack_sample/sample_0919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  namespace: mayastor\n  name: mayastor-csi\n  labels:\n    openebs/engine: mayastor\nspec:\n  selector:\n    matchLabels:\n      app: mayastor-csi\n  template:\n    metadata:\n      labels:\n        app: mayastor-csi\n    spec:\n      containers:\n      - name: mayastor-csi\n        image: mayadata/mayastor-csi:latest\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        env:\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: RUST_BACKTRACE\n          value: '1'\n        args:\n        - --csi-socket=/csi/csi.sock\n        - --node-name=$(MY_NODE_NAME)\n        - --grpc-endpoint=$(MY_POD_IP):10199\n        - -v\n        volumeMounts:\n        - name: device\n          mountPath: /dev\n        - name: sys\n          mountPath: /sys\n        - name: run-udev\n          mountPath: /run/udev\n        - name: host-root\n          mountPath: /host\n        - name: plugin-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n      - name: csi-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.3.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/mayastor.openebs.io/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 10199\n          protocol: TCP\n          name: mayastor-node\n      volumes:\n      - name: device\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: run-udev\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: host-root\n        hostPath:\n          path: /\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/mayastor.openebs.io/\n          type: DirectoryOrCreate\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mayastor-csi\" does not have a read-only root file system"
  },
  {
    "id": "02349",
    "manifest_path": "data/manifests/the_stack_sample/sample_0919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  namespace: mayastor\n  name: mayastor-csi\n  labels:\n    openebs/engine: mayastor\nspec:\n  selector:\n    matchLabels:\n      app: mayastor-csi\n  template:\n    metadata:\n      labels:\n        app: mayastor-csi\n    spec:\n      containers:\n      - name: mayastor-csi\n        image: mayadata/mayastor-csi:latest\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        env:\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: RUST_BACKTRACE\n          value: '1'\n        args:\n        - --csi-socket=/csi/csi.sock\n        - --node-name=$(MY_NODE_NAME)\n        - --grpc-endpoint=$(MY_POD_IP):10199\n        - -v\n        volumeMounts:\n        - name: device\n          mountPath: /dev\n        - name: sys\n          mountPath: /sys\n        - name: run-udev\n          mountPath: /run/udev\n        - name: host-root\n          mountPath: /host\n        - name: plugin-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n      - name: csi-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.3.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/mayastor.openebs.io/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 10199\n          protocol: TCP\n          name: mayastor-node\n      volumes:\n      - name: device\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: run-udev\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: host-root\n        hostPath:\n          path: /\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/mayastor.openebs.io/\n          type: DirectoryOrCreate\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"mayastor-csi\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "02350",
    "manifest_path": "data/manifests/the_stack_sample/sample_0919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  namespace: mayastor\n  name: mayastor-csi\n  labels:\n    openebs/engine: mayastor\nspec:\n  selector:\n    matchLabels:\n      app: mayastor-csi\n  template:\n    metadata:\n      labels:\n        app: mayastor-csi\n    spec:\n      containers:\n      - name: mayastor-csi\n        image: mayadata/mayastor-csi:latest\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        env:\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: RUST_BACKTRACE\n          value: '1'\n        args:\n        - --csi-socket=/csi/csi.sock\n        - --node-name=$(MY_NODE_NAME)\n        - --grpc-endpoint=$(MY_POD_IP):10199\n        - -v\n        volumeMounts:\n        - name: device\n          mountPath: /dev\n        - name: sys\n          mountPath: /sys\n        - name: run-udev\n          mountPath: /run/udev\n        - name: host-root\n          mountPath: /host\n        - name: plugin-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n      - name: csi-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.3.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/mayastor.openebs.io/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 10199\n          protocol: TCP\n          name: mayastor-node\n      volumes:\n      - name: device\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: run-udev\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: host-root\n        hostPath:\n          path: /\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/mayastor.openebs.io/\n          type: DirectoryOrCreate\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"mayastor-csi\" is privileged"
  },
  {
    "id": "02351",
    "manifest_path": "data/manifests/the_stack_sample/sample_0919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  namespace: mayastor\n  name: mayastor-csi\n  labels:\n    openebs/engine: mayastor\nspec:\n  selector:\n    matchLabels:\n      app: mayastor-csi\n  template:\n    metadata:\n      labels:\n        app: mayastor-csi\n    spec:\n      containers:\n      - name: mayastor-csi\n        image: mayadata/mayastor-csi:latest\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        env:\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: RUST_BACKTRACE\n          value: '1'\n        args:\n        - --csi-socket=/csi/csi.sock\n        - --node-name=$(MY_NODE_NAME)\n        - --grpc-endpoint=$(MY_POD_IP):10199\n        - -v\n        volumeMounts:\n        - name: device\n          mountPath: /dev\n        - name: sys\n          mountPath: /sys\n        - name: run-udev\n          mountPath: /run/udev\n        - name: host-root\n          mountPath: /host\n        - name: plugin-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n      - name: csi-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.3.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/mayastor.openebs.io/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 10199\n          protocol: TCP\n          name: mayastor-node\n      volumes:\n      - name: device\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: run-udev\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: host-root\n        hostPath:\n          path: /\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/mayastor.openebs.io/\n          type: DirectoryOrCreate\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"csi-driver-registrar\" is not set to runAsNonRoot"
  },
  {
    "id": "02352",
    "manifest_path": "data/manifests/the_stack_sample/sample_0919.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  namespace: mayastor\n  name: mayastor-csi\n  labels:\n    openebs/engine: mayastor\nspec:\n  selector:\n    matchLabels:\n      app: mayastor-csi\n  template:\n    metadata:\n      labels:\n        app: mayastor-csi\n    spec:\n      containers:\n      - name: mayastor-csi\n        image: mayadata/mayastor-csi:latest\n        imagePullPolicy: Always\n        securityContext:\n          privileged: true\n        env:\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: RUST_BACKTRACE\n          value: '1'\n        args:\n        - --csi-socket=/csi/csi.sock\n        - --node-name=$(MY_NODE_NAME)\n        - --grpc-endpoint=$(MY_POD_IP):10199\n        - -v\n        volumeMounts:\n        - name: device\n          mountPath: /dev\n        - name: sys\n          mountPath: /sys\n        - name: run-udev\n          mountPath: /run/udev\n        - name: host-root\n          mountPath: /host\n        - name: plugin-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n      - name: csi-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.3.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --kubelet-registration-path=/var/lib/kubelet/plugins/mayastor.openebs.io/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 10199\n          protocol: TCP\n          name: mayastor-node\n      volumes:\n      - name: device\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: run-udev\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: host-root\n        hostPath:\n          path: /\n          type: Directory\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/mayastor.openebs.io/\n          type: DirectoryOrCreate\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mayastor-csi\" is not set to runAsNonRoot"
  },
  {
    "id": "02353",
    "manifest_path": "data/manifests/the_stack_sample/sample_0920.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-plus-ingress-rc\n  labels:\n    app: nginx-plus-ingress\nspec:\n  replicas: 1\n  selector:\n    app: nginx-plus-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-plus-ingress\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: nginx-plus-ingress:1.0.0\n        name: nginx-plus-ingress\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 8080\n          hostPort: 8080\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        args:\n        - -nginx-plus\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx-plus-ingress\" does not have a read-only root file system"
  },
  {
    "id": "02354",
    "manifest_path": "data/manifests/the_stack_sample/sample_0920.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-plus-ingress-rc\n  labels:\n    app: nginx-plus-ingress\nspec:\n  replicas: 1\n  selector:\n    app: nginx-plus-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-plus-ingress\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: nginx-plus-ingress:1.0.0\n        name: nginx-plus-ingress\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 8080\n          hostPort: 8080\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        args:\n        - -nginx-plus\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx-plus-ingress\" is not set to runAsNonRoot"
  },
  {
    "id": "02355",
    "manifest_path": "data/manifests/the_stack_sample/sample_0920.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-plus-ingress-rc\n  labels:\n    app: nginx-plus-ingress\nspec:\n  replicas: 1\n  selector:\n    app: nginx-plus-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-plus-ingress\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: nginx-plus-ingress:1.0.0\n        name: nginx-plus-ingress\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 8080\n          hostPort: 8080\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        args:\n        - -nginx-plus\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx-plus-ingress\" has cpu request 0"
  },
  {
    "id": "02356",
    "manifest_path": "data/manifests/the_stack_sample/sample_0920.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-plus-ingress-rc\n  labels:\n    app: nginx-plus-ingress\nspec:\n  replicas: 1\n  selector:\n    app: nginx-plus-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-plus-ingress\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: nginx-plus-ingress:1.0.0\n        name: nginx-plus-ingress\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 8080\n          hostPort: 8080\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        args:\n        - -nginx-plus\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx-plus-ingress\" has memory limit 0"
  },
  {
    "id": "02357",
    "manifest_path": "data/manifests/the_stack_sample/sample_0923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-874\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02358",
    "manifest_path": "data/manifests/the_stack_sample/sample_0923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-874\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02359",
    "manifest_path": "data/manifests/the_stack_sample/sample_0923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-874\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02360",
    "manifest_path": "data/manifests/the_stack_sample/sample_0923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-874\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02361",
    "manifest_path": "data/manifests/the_stack_sample/sample_0923.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-874\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02362",
    "manifest_path": "data/manifests/the_stack_sample/sample_0925.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - image: mongo:3.4.10\n        name: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        persistentVolumeClaim:\n          claimName: mongodata\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mongo\" does not have a read-only root file system"
  },
  {
    "id": "02363",
    "manifest_path": "data/manifests/the_stack_sample/sample_0925.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - image: mongo:3.4.10\n        name: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        persistentVolumeClaim:\n          claimName: mongodata\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mongo\" is not set to runAsNonRoot"
  },
  {
    "id": "02364",
    "manifest_path": "data/manifests/the_stack_sample/sample_0925.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - image: mongo:3.4.10\n        name: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        persistentVolumeClaim:\n          claimName: mongodata\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mongo\" has cpu request 0"
  },
  {
    "id": "02365",
    "manifest_path": "data/manifests/the_stack_sample/sample_0925.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - image: mongo:3.4.10\n        name: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n      volumes:\n      - name: mongo-persistent-storage\n        persistentVolumeClaim:\n          claimName: mongodata\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mongo\" has memory limit 0"
  },
  {
    "id": "02366",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"monitor\" does not have a read-only root file system"
  },
  {
    "id": "02367",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"publisher\" does not have a read-only root file system"
  },
  {
    "id": "02368",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"train\" does not have a read-only root file system"
  },
  {
    "id": "02369",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"monitor\" is not set to runAsNonRoot"
  },
  {
    "id": "02370",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"publisher\" is not set to runAsNonRoot"
  },
  {
    "id": "02371",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"train\" is not set to runAsNonRoot"
  },
  {
    "id": "02372",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"monitor\" has cpu request 0"
  },
  {
    "id": "02373",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"publisher\" has cpu request 0"
  },
  {
    "id": "02374",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"train\" has cpu request 0"
  },
  {
    "id": "02375",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"monitor\" has memory limit 0"
  },
  {
    "id": "02376",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"publisher\" has memory limit 0"
  },
  {
    "id": "02377",
    "manifest_path": "data/manifests/the_stack_sample/sample_0928.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: tf-r1.15.4-efficientnet-conv-v3-32\n  namespace: automated\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          tf-version.cloud-tpus.google.com: 1.15.4\n      spec:\n        containers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          image: gcr.io/xl-ml-test/health-monitor:stable\n          imagePullPolicy: Always\n          name: monitor\n        - args:\n          - python3\n          - /tpu/models/official/efficientnet/main.py\n          - --tpu=$(KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS)\n          - --iterations_per_loop=1000\n          - --mode=train\n          - --use_cache=False\n          - --data_dir=$(IMAGENET_DIR)\n          - --model_dir=$(MODEL_DIR)\n          - --train_batch_size=4096\n          - --train_steps=109474\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/tensorflow-tpu-1x:r1.15.4\n          imagePullPolicy: Always\n          name: train\n          resources:\n            limits:\n              cloud-tpus.google.com/v3: 32\n        initContainers:\n        - env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.name\n          - name: POD_UID\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.uid\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.namespace\n          - name: JOB_NAME\n            valueFrom:\n              fieldRef:\n                fieldPath: metadata.labels['job-name']\n          - name: MODEL_DIR\n            value: $(OUTPUT_BUCKET)/tf-r1.15.4/efficientnet/conv/v3-32/$(JOB_NAME)\n          - name: METRIC_CONFIG\n            value: \"{\\n \\\"metric_collection_config\\\": {\\n  \\\"default_aggregation_strategies\\\"\\\n              : [\\n   \\\"final\\\"\\n  ],\\n  \\\"write_to_bigquery\\\": true\\n },\\n \\\"regression_test_config\\\"\\\n              : {\\n  \\\"metric_success_conditions\\\": {\\n   \\\"total_wall_time\\\": {\\n\\\n              \\    \\\"comparison\\\": \\\"less\\\",\\n    \\\"success_threshold\\\": {\\n     \\\"\\\n              stddevs_from_mean\\\": 5\\n    },\\n    \\\"wait_for_n_points_of_history\\\"\\\n              : 10\\n   }\\n  }\\n },\\n \\\"test_name\\\": \\\"tf-r1.15.4-efficientnet-conv-v3-32\\\"\\\n              \\n}\\n\"\n          envFrom:\n          - configMapRef:\n              name: gcs-buckets\n          image: gcr.io/xl-ml-test/publisher:stable\n          imagePullPolicy: Always\n          name: publisher\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"train\" has memory limit 0"
  },
  {
    "id": "02378",
    "manifest_path": "data/manifests/the_stack_sample/sample_0929.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7687\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02379",
    "manifest_path": "data/manifests/the_stack_sample/sample_0929.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7687\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02380",
    "manifest_path": "data/manifests/the_stack_sample/sample_0929.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7687\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02381",
    "manifest_path": "data/manifests/the_stack_sample/sample_0929.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7687\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02382",
    "manifest_path": "data/manifests/the_stack_sample/sample_0929.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7687\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02383",
    "manifest_path": "data/manifests/the_stack_sample/sample_0930.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9543\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02384",
    "manifest_path": "data/manifests/the_stack_sample/sample_0930.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9543\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02385",
    "manifest_path": "data/manifests/the_stack_sample/sample_0930.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9543\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "02386",
    "manifest_path": "data/manifests/the_stack_sample/sample_0930.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9543\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "02387",
    "manifest_path": "data/manifests/the_stack_sample/sample_0930.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9543\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "02388",
    "manifest_path": "data/manifests/the_stack_sample/sample_0932.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: inline-pod\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx-inline\n    volumeMounts:\n    - name: my-csi-volume\n      mountPath: /var/lib/www/html\n  volumes:\n  - name: my-csi-volume\n    csi:\n      driver: cinder.csi.openstack.org\n      volumeAttributes:\n        capacity: 1Gi\n      readOnly: false\n      fsType: ext4\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx-inline\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02389",
    "manifest_path": "data/manifests/the_stack_sample/sample_0932.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: inline-pod\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx-inline\n    volumeMounts:\n    - name: my-csi-volume\n      mountPath: /var/lib/www/html\n  volumes:\n  - name: my-csi-volume\n    csi:\n      driver: cinder.csi.openstack.org\n      volumeAttributes:\n        capacity: 1Gi\n      readOnly: false\n      fsType: ext4\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx-inline\" does not have a read-only root file system"
  },
  {
    "id": "02390",
    "manifest_path": "data/manifests/the_stack_sample/sample_0932.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: inline-pod\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx-inline\n    volumeMounts:\n    - name: my-csi-volume\n      mountPath: /var/lib/www/html\n  volumes:\n  - name: my-csi-volume\n    csi:\n      driver: cinder.csi.openstack.org\n      volumeAttributes:\n        capacity: 1Gi\n      readOnly: false\n      fsType: ext4\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx-inline\" is not set to runAsNonRoot"
  },
  {
    "id": "02391",
    "manifest_path": "data/manifests/the_stack_sample/sample_0932.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: inline-pod\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx-inline\n    volumeMounts:\n    - name: my-csi-volume\n      mountPath: /var/lib/www/html\n  volumes:\n  - name: my-csi-volume\n    csi:\n      driver: cinder.csi.openstack.org\n      volumeAttributes:\n        capacity: 1Gi\n      readOnly: false\n      fsType: ext4\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx-inline\" has cpu request 0"
  },
  {
    "id": "02392",
    "manifest_path": "data/manifests/the_stack_sample/sample_0932.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: inline-pod\nspec:\n  containers:\n  - image: nginx\n    imagePullPolicy: IfNotPresent\n    name: nginx-inline\n    volumeMounts:\n    - name: my-csi-volume\n      mountPath: /var/lib/www/html\n  volumes:\n  - name: my-csi-volume\n    csi:\n      driver: cinder.csi.openstack.org\n      volumeAttributes:\n        capacity: 1Gi\n      readOnly: false\n      fsType: ext4\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx-inline\" has memory limit 0"
  },
  {
    "id": "02393",
    "manifest_path": "data/manifests/the_stack_sample/sample_0933.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ecsdemo-nodejs\n  labels:\n    app: ecsdemo-nodejs\n  namespace: default\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ecsdemo-nodejs\n  template:\n    metadata:\n      labels:\n        app: ecsdemo-nodejs\n    spec:\n      containers:\n      - image: brentley/ecsdemo-nodejs:latest\n        imagePullPolicy: Always\n        name: ecsdemo-nodejs\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"ecsdemo-nodejs\" is using an invalid container image, \"brentley/ecsdemo-nodejs:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02394",
    "manifest_path": "data/manifests/the_stack_sample/sample_0933.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ecsdemo-nodejs\n  labels:\n    app: ecsdemo-nodejs\n  namespace: default\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ecsdemo-nodejs\n  template:\n    metadata:\n      labels:\n        app: ecsdemo-nodejs\n    spec:\n      containers:\n      - image: brentley/ecsdemo-nodejs:latest\n        imagePullPolicy: Always\n        name: ecsdemo-nodejs\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ecsdemo-nodejs\" does not have a read-only root file system"
  },
  {
    "id": "02395",
    "manifest_path": "data/manifests/the_stack_sample/sample_0933.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ecsdemo-nodejs\n  labels:\n    app: ecsdemo-nodejs\n  namespace: default\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ecsdemo-nodejs\n  template:\n    metadata:\n      labels:\n        app: ecsdemo-nodejs\n    spec:\n      containers:\n      - image: brentley/ecsdemo-nodejs:latest\n        imagePullPolicy: Always\n        name: ecsdemo-nodejs\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ecsdemo-nodejs\" is not set to runAsNonRoot"
  },
  {
    "id": "02396",
    "manifest_path": "data/manifests/the_stack_sample/sample_0933.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ecsdemo-nodejs\n  labels:\n    app: ecsdemo-nodejs\n  namespace: default\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ecsdemo-nodejs\n  template:\n    metadata:\n      labels:\n        app: ecsdemo-nodejs\n    spec:\n      containers:\n      - image: brentley/ecsdemo-nodejs:latest\n        imagePullPolicy: Always\n        name: ecsdemo-nodejs\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ecsdemo-nodejs\" has cpu request 0"
  },
  {
    "id": "02397",
    "manifest_path": "data/manifests/the_stack_sample/sample_0933.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ecsdemo-nodejs\n  labels:\n    app: ecsdemo-nodejs\n  namespace: default\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ecsdemo-nodejs\n  template:\n    metadata:\n      labels:\n        app: ecsdemo-nodejs\n    spec:\n      containers:\n      - image: brentley/ecsdemo-nodejs:latest\n        imagePullPolicy: Always\n        name: ecsdemo-nodejs\n        ports:\n        - containerPort: 3000\n          protocol: TCP\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ecsdemo-nodejs\" has memory limit 0"
  },
  {
    "id": "02398",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"kube-rbac-proxy-main\" is using an invalid container image, \"quay.io/openshift/origin-kube-rbac-proxy:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02399",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"kube-rbac-proxy-self\" is using an invalid container image, \"quay.io/openshift/origin-kube-rbac-proxy:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02400",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"openshift-state-metrics\" is using an invalid container image, \"quay.io/openshift/origin-openshift-state-metrics:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02401",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-rbac-proxy-main\" does not have a read-only root file system"
  },
  {
    "id": "02402",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-rbac-proxy-self\" does not have a read-only root file system"
  },
  {
    "id": "02403",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"openshift-state-metrics\" does not have a read-only root file system"
  },
  {
    "id": "02404",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kube-rbac-proxy-main\" is not set to runAsNonRoot"
  },
  {
    "id": "02405",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kube-rbac-proxy-self\" is not set to runAsNonRoot"
  },
  {
    "id": "02406",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"openshift-state-metrics\" is not set to runAsNonRoot"
  },
  {
    "id": "02407",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kube-rbac-proxy-main\" has memory limit 0"
  },
  {
    "id": "02408",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kube-rbac-proxy-self\" has memory limit 0"
  },
  {
    "id": "02409",
    "manifest_path": "data/manifests/the_stack_sample/sample_0934.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: openshift-state-metrics\n  name: openshift-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: openshift-state-metrics\n  template:\n    metadata:\n      labels:\n        k8s-app: openshift-state-metrics\n    spec:\n      containers:\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/openshift/origin-kube-rbac-proxy:latest\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 20Mi\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: openshift-state-metrics-tls\n          readOnly: false\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        image: quay.io/openshift/origin-openshift-state-metrics:latest\n        name: openshift-state-metrics\n        resources:\n          requests:\n            cpu: 1m\n            memory: 150Mi\n      serviceAccountName: openshift-state-metrics\n      volumes:\n      - name: openshift-state-metrics-tls\n        secret:\n          secretName: openshift-state-metrics-tls\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"openshift-state-metrics\" has memory limit 0"
  },
  {
    "id": "02410",
    "manifest_path": "data/manifests/the_stack_sample/sample_0942.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    description: Simple-Vault\n  labels:\n    app: simple-vault\n    environment: Development\n    tier: Service\n  name: simple-vault\n  namespace: sirius\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: simple-vault\n  template:\n    metadata:\n      labels:\n        app: simple-vault\n      name: simple-vault\n    spec:\n      containers:\n      - name: simple-vault\n        image: docker.io/swisschains/sirius-simple-vault:dev\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        - containerPort: 5001\n        readinessProbe:\n          httpGet:\n            path: /api/isalive\n            port: 5000\n          initialDelaySeconds: 40\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /api/isalive\n            port: 5000\n          initialDelaySeconds: 40\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 40m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: RemoteSettingsUrls__0\n          value: http://settings.common.svc.cluster.local/common\n        - name: RemoteSettingsUrls__1\n          value: http://settings.common.svc.cluster.local/sirius/common\n        - name: RemoteSettingsUrls__2\n          value: http://settings.common.svc.cluster.local/sirius/simple-vault\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"simple-vault\" does not have a read-only root file system"
  },
  {
    "id": "02411",
    "manifest_path": "data/manifests/the_stack_sample/sample_0942.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    description: Simple-Vault\n  labels:\n    app: simple-vault\n    environment: Development\n    tier: Service\n  name: simple-vault\n  namespace: sirius\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: simple-vault\n  template:\n    metadata:\n      labels:\n        app: simple-vault\n      name: simple-vault\n    spec:\n      containers:\n      - name: simple-vault\n        image: docker.io/swisschains/sirius-simple-vault:dev\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        - containerPort: 5001\n        readinessProbe:\n          httpGet:\n            path: /api/isalive\n            port: 5000\n          initialDelaySeconds: 40\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /api/isalive\n            port: 5000\n          initialDelaySeconds: 40\n          periodSeconds: 20\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 40m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: RemoteSettingsUrls__0\n          value: http://settings.common.svc.cluster.local/common\n        - name: RemoteSettingsUrls__1\n          value: http://settings.common.svc.cluster.local/sirius/common\n        - name: RemoteSettingsUrls__2\n          value: http://settings.common.svc.cluster.local/sirius/simple-vault\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"simple-vault\" is not set to runAsNonRoot"
  },
  {
    "id": "02412",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"frontendservice\" is using an invalid container image, \"karthequian/helloworld\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02413",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"frontendservice\" does not have a read-only root file system"
  },
  {
    "id": "02414",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mysql\" does not have a read-only root file system"
  },
  {
    "id": "02415",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"frontendservice\" is not set to runAsNonRoot"
  },
  {
    "id": "02416",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mysql\" is not set to runAsNonRoot"
  },
  {
    "id": "02417",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"frontendservice\" has cpu request 0"
  },
  {
    "id": "02418",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mysql\" has cpu request 0"
  },
  {
    "id": "02419",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"frontendservice\" has memory limit 0"
  },
  {
    "id": "02420",
    "manifest_path": "data/manifests/the_stack_sample/sample_0952.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: deployment\n  template:\n    metadata:\n      labels:\n        app: deployment\n    spec:\n      containers:\n      - image: mysql:5.6\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n      - name: frontendservice\n        image: karthequian/helloworld\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - echo 'start await' && cp /opt/scripts/*.sh /tmp && sh /tmp/await-tcp.sh\n          30 localhost:3306 -- nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: await-volume\n          mountPath: /opt/scripts\n      volumes:\n      - name: await-volume\n        configMap:\n          name: await-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mysql\" has memory limit 0"
  },
  {
    "id": "02421",
    "manifest_path": "data/manifests/the_stack_sample/sample_0961.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: command-demo\n  labels:\n    purpose: demonstrate-command\nspec:\n  containers:\n  - name: command-demo-container\n    image: gcr.io/google_containers/kube-apiserver-amd64:v1.6.0\n    command:\n    - kube-apiserver\n    args:\n    - --kubelet-https=true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"command-demo-container\" does not have a read-only root file system"
  },
  {
    "id": "02422",
    "manifest_path": "data/manifests/the_stack_sample/sample_0961.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: command-demo\n  labels:\n    purpose: demonstrate-command\nspec:\n  containers:\n  - name: command-demo-container\n    image: gcr.io/google_containers/kube-apiserver-amd64:v1.6.0\n    command:\n    - kube-apiserver\n    args:\n    - --kubelet-https=true\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"command-demo-container\" is not set to runAsNonRoot"
  },
  {
    "id": "02423",
    "manifest_path": "data/manifests/the_stack_sample/sample_0961.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: command-demo\n  labels:\n    purpose: demonstrate-command\nspec:\n  containers:\n  - name: command-demo-container\n    image: gcr.io/google_containers/kube-apiserver-amd64:v1.6.0\n    command:\n    - kube-apiserver\n    args:\n    - --kubelet-https=true\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"command-demo-container\" has cpu request 0"
  },
  {
    "id": "02424",
    "manifest_path": "data/manifests/the_stack_sample/sample_0961.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: command-demo\n  labels:\n    purpose: demonstrate-command\nspec:\n  containers:\n  - name: command-demo-container\n    image: gcr.io/google_containers/kube-apiserver-amd64:v1.6.0\n    command:\n    - kube-apiserver\n    args:\n    - --kubelet-https=true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"command-demo-container\" has memory limit 0"
  },
  {
    "id": "02425",
    "manifest_path": "data/manifests/the_stack_sample/sample_0962.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-secret\nspec:\n  containers:\n  - image: mysql:5.5\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: mysql\n          key: password\n    imagePullPolicy: IfNotPresent\n    name: mysql\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mysql\" does not have a read-only root file system"
  },
  {
    "id": "02426",
    "manifest_path": "data/manifests/the_stack_sample/sample_0962.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-secret\nspec:\n  containers:\n  - image: mysql:5.5\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: mysql\n          key: password\n    imagePullPolicy: IfNotPresent\n    name: mysql\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mysql\" is not set to runAsNonRoot"
  },
  {
    "id": "02427",
    "manifest_path": "data/manifests/the_stack_sample/sample_0962.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-secret\nspec:\n  containers:\n  - image: mysql:5.5\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: mysql\n          key: password\n    imagePullPolicy: IfNotPresent\n    name: mysql\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mysql\" has cpu request 0"
  },
  {
    "id": "02428",
    "manifest_path": "data/manifests/the_stack_sample/sample_0962.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-secret\nspec:\n  containers:\n  - image: mysql:5.5\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: mysql\n          key: password\n    imagePullPolicy: IfNotPresent\n    name: mysql\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mysql\" has memory limit 0"
  },
  {
    "id": "02429",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ksql\" does not have a read-only root file system"
  },
  {
    "id": "02430",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ksql-datagen-pageviews\" does not have a read-only root file system"
  },
  {
    "id": "02431",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ksql-datagen-users\" does not have a read-only root file system"
  },
  {
    "id": "02432",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ksql\" is not set to runAsNonRoot"
  },
  {
    "id": "02433",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ksql-datagen-pageviews\" is not set to runAsNonRoot"
  },
  {
    "id": "02434",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ksql-datagen-users\" is not set to runAsNonRoot"
  },
  {
    "id": "02435",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ksql\" has cpu request 0"
  },
  {
    "id": "02436",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ksql-datagen-pageviews\" has cpu request 0"
  },
  {
    "id": "02437",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ksql-datagen-users\" has cpu request 0"
  },
  {
    "id": "02438",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ksql\" has memory limit 0"
  },
  {
    "id": "02439",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ksql-datagen-pageviews\" has memory limit 0"
  },
  {
    "id": "02440",
    "manifest_path": "data/manifests/the_stack_sample/sample_0963.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.0.1\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n  - name: ksql\n    image: confluentinc/ksql-cli:5.0.1\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ksql-datagen-users\" has memory limit 0"
  },
  {
    "id": "02441",
    "manifest_path": "data/manifests/the_stack_sample/sample_0964.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: alexeyyakovlev1982/hipster_shop_paymentservice_v0.0.2\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"server\" is using an invalid container image, \"alexeyyakovlev1982/hipster_shop_paymentservice_v0.0.2\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02442",
    "manifest_path": "data/manifests/the_stack_sample/sample_0964.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: alexeyyakovlev1982/hipster_shop_paymentservice_v0.0.2\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"server\" does not have a read-only root file system"
  },
  {
    "id": "02443",
    "manifest_path": "data/manifests/the_stack_sample/sample_0964.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: alexeyyakovlev1982/hipster_shop_paymentservice_v0.0.2\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"server\" is not set to runAsNonRoot"
  },
  {
    "id": "02444",
    "manifest_path": "data/manifests/the_stack_sample/sample_0964.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: alexeyyakovlev1982/hipster_shop_paymentservice_v0.0.2\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"server\" has cpu request 0"
  },
  {
    "id": "02445",
    "manifest_path": "data/manifests/the_stack_sample/sample_0964.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: alexeyyakovlev1982/hipster_shop_paymentservice_v0.0.2\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"server\" has memory limit 0"
  },
  {
    "id": "02446",
    "manifest_path": "data/manifests/the_stack_sample/sample_0966.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: demo-k8s-pod\n  labels:\n    app: demo-k8s\nspec:\n  containers:\n  - name: demok8s\n    image: karatejb/demo-k8s:latest\n    ports:\n    - containerPort: 5000\n    - containerPort: 5001\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"demok8s\" is using an invalid container image, \"karatejb/demo-k8s:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02447",
    "manifest_path": "data/manifests/the_stack_sample/sample_0966.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: demo-k8s-pod\n  labels:\n    app: demo-k8s\nspec:\n  containers:\n  - name: demok8s\n    image: karatejb/demo-k8s:latest\n    ports:\n    - containerPort: 5000\n    - containerPort: 5001\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"demok8s\" does not have a read-only root file system"
  },
  {
    "id": "02448",
    "manifest_path": "data/manifests/the_stack_sample/sample_0966.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: demo-k8s-pod\n  labels:\n    app: demo-k8s\nspec:\n  containers:\n  - name: demok8s\n    image: karatejb/demo-k8s:latest\n    ports:\n    - containerPort: 5000\n    - containerPort: 5001\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"demok8s\" is not set to runAsNonRoot"
  },
  {
    "id": "02449",
    "manifest_path": "data/manifests/the_stack_sample/sample_0966.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: demo-k8s-pod\n  labels:\n    app: demo-k8s\nspec:\n  containers:\n  - name: demok8s\n    image: karatejb/demo-k8s:latest\n    ports:\n    - containerPort: 5000\n    - containerPort: 5001\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"demok8s\" has cpu request 0"
  },
  {
    "id": "02450",
    "manifest_path": "data/manifests/the_stack_sample/sample_0966.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: demo-k8s-pod\n  labels:\n    app: demo-k8s\nspec:\n  containers:\n  - name: demok8s\n    image: karatejb/demo-k8s:latest\n    ports:\n    - containerPort: 5000\n    - containerPort: 5001\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"demok8s\" has memory limit 0"
  },
  {
    "id": "02451",
    "manifest_path": "data/manifests/the_stack_sample/sample_0970.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: scum-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      kind: scum\n  template:\n    metadata:\n      labels:\n        kind: scum\n    spec:\n      containers:\n      - name: scum-pod\n        image: ihippik/k8s-scum:main\n        args:\n        - server\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"scum-pod\" does not have a read-only root file system"
  },
  {
    "id": "02452",
    "manifest_path": "data/manifests/the_stack_sample/sample_0970.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: scum-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      kind: scum\n  template:\n    metadata:\n      labels:\n        kind: scum\n    spec:\n      containers:\n      - name: scum-pod\n        image: ihippik/k8s-scum:main\n        args:\n        - server\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"scum-pod\" is not set to runAsNonRoot"
  },
  {
    "id": "02453",
    "manifest_path": "data/manifests/the_stack_sample/sample_0970.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: scum-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      kind: scum\n  template:\n    metadata:\n      labels:\n        kind: scum\n    spec:\n      containers:\n      - name: scum-pod\n        image: ihippik/k8s-scum:main\n        args:\n        - server\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"scum-pod\" has cpu request 0"
  },
  {
    "id": "02454",
    "manifest_path": "data/manifests/the_stack_sample/sample_0970.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: scum-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      kind: scum\n  template:\n    metadata:\n      labels:\n        kind: scum\n    spec:\n      containers:\n      - name: scum-pod\n        image: ihippik/k8s-scum:main\n        args:\n        - server\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"scum-pod\" has memory limit 0"
  },
  {
    "id": "02455",
    "manifest_path": "data/manifests/the_stack_sample/sample_0971.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-exporter\n  labels:\n    app: prow-exporter\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-exporter\n  template:\n    metadata:\n      labels:\n        app: prow-exporter\n    spec:\n      serviceAccountName: prow-exporter\n      containers:\n      - name: prow-exporter\n        image: gcr.io/k8s-prow/exporter:v20211028-7017c540b0\n        imagePullPolicy: Always\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: healthz\n          containerPort: 8081\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n          timeoutSeconds: 15\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n          timeoutSeconds: 15\n        resources:\n          requests:\n            cpu: 100m\n            memory: 500Mi\n          limits:\n            cpu: 100m\n            memory: 500Mi\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"prow-exporter\" does not have a read-only root file system"
  },
  {
    "id": "02456",
    "manifest_path": "data/manifests/the_stack_sample/sample_0971.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-exporter\n  labels:\n    app: prow-exporter\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-exporter\n  template:\n    metadata:\n      labels:\n        app: prow-exporter\n    spec:\n      serviceAccountName: prow-exporter\n      containers:\n      - name: prow-exporter\n        image: gcr.io/k8s-prow/exporter:v20211028-7017c540b0\n        imagePullPolicy: Always\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: healthz\n          containerPort: 8081\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n          timeoutSeconds: 15\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n          timeoutSeconds: 15\n        resources:\n          requests:\n            cpu: 100m\n            memory: 500Mi\n          limits:\n            cpu: 100m\n            memory: 500Mi\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"prow-exporter\" is not set to runAsNonRoot"
  },
  {
    "id": "02457",
    "manifest_path": "data/manifests/the_stack_sample/sample_0973.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: privileged\n  labels:\n    app: privileged\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: privileged\n      labels:\n        app: privileged\n    spec:\n      containers:\n      - name: test\n        image: e2eteam/busybox:1.29-windows-amd64-1809\n        command:\n        - cmd\n        - /c\n        - ping -t localhost\n        resources:\n          limits:\n            cpu: 1\n            memory: 800m\n          requests:\n            cpu: '0.1'\n            memory: 300m\n  selector:\n    matchLabels:\n      app: privileged\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"test\" does not have a read-only root file system"
  },
  {
    "id": "02458",
    "manifest_path": "data/manifests/the_stack_sample/sample_0973.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: privileged\n  labels:\n    app: privileged\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: privileged\n      labels:\n        app: privileged\n    spec:\n      containers:\n      - name: test\n        image: e2eteam/busybox:1.29-windows-amd64-1809\n        command:\n        - cmd\n        - /c\n        - ping -t localhost\n        resources:\n          limits:\n            cpu: 1\n            memory: 800m\n          requests:\n            cpu: '0.1'\n            memory: 300m\n  selector:\n    matchLabels:\n      app: privileged\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"test\" is not set to runAsNonRoot"
  },
  {
    "id": "02459",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"web\" is using an invalid container image, \"alsam/alex:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02460",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init-web\" does not have a read-only root file system"
  },
  {
    "id": "02461",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"web\" does not have a read-only root file system"
  },
  {
    "id": "02462",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init-web\" is not set to runAsNonRoot"
  },
  {
    "id": "02463",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"web\" is not set to runAsNonRoot"
  },
  {
    "id": "02464",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-web\" has cpu request 0"
  },
  {
    "id": "02465",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"web\" has cpu request 0"
  },
  {
    "id": "02466",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-web\" has memory limit 0"
  },
  {
    "id": "02467",
    "manifest_path": "data/manifests/the_stack_sample/sample_0975.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: web\n    image: alsam/alex:latest\n    volumeMounts:\n    - name: app\n      mountPath: /app\n  initContainers:\n  - name: init-web\n    image: busybox:1.31.0\n    volumeMounts:\n    - name: app\n      mountPath: /app\n    command:\n    - sh\n    - -c\n    - wget -O- --no-check-certificate https://raw.githubusercontent.com/express42/otus-platform-snippets/master/Module-02/Introduction-to-Kubernetes/wget.sh\n      | sh\n  volumes:\n  - name: app\n    emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"web\" has memory limit 0"
  },
  {
    "id": "02468",
    "manifest_path": "data/manifests/the_stack_sample/sample_0978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n        blinkt: show\n        blinktColor: 3307A2\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"php-redis\" does not have a read-only root file system"
  },
  {
    "id": "02469",
    "manifest_path": "data/manifests/the_stack_sample/sample_0978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n        blinkt: show\n        blinktColor: 3307A2\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"php-redis\" is not set to runAsNonRoot"
  },
  {
    "id": "02470",
    "manifest_path": "data/manifests/the_stack_sample/sample_0978.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n        blinkt: show\n        blinktColor: 3307A2\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"php-redis\" has memory limit 0"
  },
  {
    "id": "02471",
    "manifest_path": "data/manifests/the_stack_sample/sample_0982.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: foo@sha256:your-image-digest\n        imagePullPolicy: Always\n        name: foo\n        resources:\n          limits:\n            memory: 768Mi\n        env:\n        - name: HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        livenessProbe:\n          httpGet:\n            path: /actuator/health/liveness\n            port: 8080\n          initialDelaySeconds: 2\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /actuator/health/readiness\n            port: 8080\n          initialDelaySeconds: 2\n          timeoutSeconds: 11\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"foo\" does not have a read-only root file system"
  },
  {
    "id": "02472",
    "manifest_path": "data/manifests/the_stack_sample/sample_0982.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: foo@sha256:your-image-digest\n        imagePullPolicy: Always\n        name: foo\n        resources:\n          limits:\n            memory: 768Mi\n        env:\n        - name: HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        livenessProbe:\n          httpGet:\n            path: /actuator/health/liveness\n            port: 8080\n          initialDelaySeconds: 2\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /actuator/health/readiness\n            port: 8080\n          initialDelaySeconds: 2\n          timeoutSeconds: 11\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"foo\" is not set to runAsNonRoot"
  },
  {
    "id": "02473",
    "manifest_path": "data/manifests/the_stack_sample/sample_0982.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: foo@sha256:your-image-digest\n        imagePullPolicy: Always\n        name: foo\n        resources:\n          limits:\n            memory: 768Mi\n        env:\n        - name: HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_SERVICE_ACCOUNT\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.serviceAccountName\n        livenessProbe:\n          httpGet:\n            path: /actuator/health/liveness\n            port: 8080\n          initialDelaySeconds: 2\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /actuator/health/readiness\n            port: 8080\n          initialDelaySeconds: 2\n          timeoutSeconds: 11\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"foo\" has cpu request 0"
  },
  {
    "id": "02474",
    "manifest_path": "data/manifests/the_stack_sample/sample_0983.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: weave-scope-app\n  labels:\n    name: weave-scope-app\n    app: weave-scope\n    weave-cloud-component: scope\n    weave-scope-component: app\n  namespace: weave\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: weave-scope\n  template:\n    metadata:\n      labels:\n        name: weave-scope-app\n        app: weave-scope\n        weave-cloud-component: scope\n        weave-scope-component: app\n    spec:\n      containers:\n      - name: app\n        args:\n        - --no-probe\n        env: []\n        image: weaveworks/scope:1.13.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 4040\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 200m\n            memory: 200Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"app\" does not have a read-only root file system"
  },
  {
    "id": "02475",
    "manifest_path": "data/manifests/the_stack_sample/sample_0983.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: weave-scope-app\n  labels:\n    name: weave-scope-app\n    app: weave-scope\n    weave-cloud-component: scope\n    weave-scope-component: app\n  namespace: weave\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: weave-scope\n  template:\n    metadata:\n      labels:\n        name: weave-scope-app\n        app: weave-scope\n        weave-cloud-component: scope\n        weave-scope-component: app\n    spec:\n      containers:\n      - name: app\n        args:\n        - --no-probe\n        env: []\n        image: weaveworks/scope:1.13.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 4040\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 200m\n            memory: 200Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"app\" is not set to runAsNonRoot"
  },
  {
    "id": "02476",
    "manifest_path": "data/manifests/the_stack_sample/sample_0983.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: weave-scope-app\n  labels:\n    name: weave-scope-app\n    app: weave-scope\n    weave-cloud-component: scope\n    weave-scope-component: app\n  namespace: weave\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: weave-scope\n  template:\n    metadata:\n      labels:\n        name: weave-scope-app\n        app: weave-scope\n        weave-cloud-component: scope\n        weave-scope-component: app\n    spec:\n      containers:\n      - name: app\n        args:\n        - --no-probe\n        env: []\n        image: weaveworks/scope:1.13.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 4040\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 200m\n            memory: 200Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"app\" has memory limit 0"
  },
  {
    "id": "02477",
    "manifest_path": "data/manifests/the_stack_sample/sample_0987.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.885\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\n    jenkins-x.io/hash: e815f2ccc606190328779dadb61e45181c1c8c828dbf6f63e28438c1fba1f776\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        draft: draft-app\n        app: lighthouse-foghorn\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: gcr.io/jenkinsxio/lighthouse-foghorn:0.0.885\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: hlechuga\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: gcr.io/jenkinsxio/builder-maven:2.1.142-761\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"lighthouse-foghorn\" does not have a read-only root file system"
  },
  {
    "id": "02478",
    "manifest_path": "data/manifests/the_stack_sample/sample_0987.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.885\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\n    jenkins-x.io/hash: e815f2ccc606190328779dadb61e45181c1c8c828dbf6f63e28438c1fba1f776\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        draft: draft-app\n        app: lighthouse-foghorn\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: gcr.io/jenkinsxio/lighthouse-foghorn:0.0.885\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: hlechuga\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: gcr.io/jenkinsxio/builder-maven:2.1.142-761\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"lighthouse-foghorn\" is not set to runAsNonRoot"
  },
  {
    "id": "02479",
    "manifest_path": "data/manifests/the_stack_sample/sample_0987.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.885\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\n    jenkins-x.io/hash: e815f2ccc606190328779dadb61e45181c1c8c828dbf6f63e28438c1fba1f776\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        draft: draft-app\n        app: lighthouse-foghorn\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: gcr.io/jenkinsxio/lighthouse-foghorn:0.0.885\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: hlechuga\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: gcr.io/jenkinsxio/builder-maven:2.1.142-761\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"lighthouse-foghorn\" has cpu request 0"
  },
  {
    "id": "02480",
    "manifest_path": "data/manifests/the_stack_sample/sample_0997.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: mysql-operator\n  template:\n    metadata:\n      labels:\n        name: mysql-operator\n    spec:\n      serviceAccountName: mysql-operator\n      containers:\n      - name: operator\n        image: atalabirchuk/otus:mysql-operator_v1\n        imagePullPolicy: Always\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"operator\" does not have a read-only root file system"
  },
  {
    "id": "02481",
    "manifest_path": "data/manifests/the_stack_sample/sample_0997.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: mysql-operator\n  template:\n    metadata:\n      labels:\n        name: mysql-operator\n    spec:\n      serviceAccountName: mysql-operator\n      containers:\n      - name: operator\n        image: atalabirchuk/otus:mysql-operator_v1\n        imagePullPolicy: Always\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"operator\" is not set to runAsNonRoot"
  },
  {
    "id": "02482",
    "manifest_path": "data/manifests/the_stack_sample/sample_0997.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: mysql-operator\n  template:\n    metadata:\n      labels:\n        name: mysql-operator\n    spec:\n      serviceAccountName: mysql-operator\n      containers:\n      - name: operator\n        image: atalabirchuk/otus:mysql-operator_v1\n        imagePullPolicy: Always\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"operator\" has cpu request 0"
  },
  {
    "id": "02483",
    "manifest_path": "data/manifests/the_stack_sample/sample_0997.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: mysql-operator\n  template:\n    metadata:\n      labels:\n        name: mysql-operator\n    spec:\n      serviceAccountName: mysql-operator\n      containers:\n      - name: operator\n        image: atalabirchuk/otus:mysql-operator_v1\n        imagePullPolicy: Always\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"operator\" has memory limit 0"
  },
  {
    "id": "02484",
    "manifest_path": "data/manifests/the_stack_sample/sample_1000.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.8.0\n    app.kubernetes.io/version: 1.8.0\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jx-pipelines-visualizer\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.8.0\n        app.kubernetes.io/version: 1.8.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: ghcr.io/jenkins-x/jx-pipelines-visualizer:1.8.0\n        args:\n        - -resync-interval\n        - 60s\n        - -pipeline-trace-url-template\n        - http://grafana-jx-observability.192.168.59.101.nip.io/explore?left=%5B%22now%22,%22now%22,%22Tempo%22,%7B%22query%22:%22{{.TraceID}}%22%7D%5D\n        - -log-level\n        - INFO\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jx-pipelines-visualizer\" does not have a read-only root file system"
  },
  {
    "id": "02485",
    "manifest_path": "data/manifests/the_stack_sample/sample_1000.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.8.0\n    app.kubernetes.io/version: 1.8.0\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: jx-pipelines-visualizer\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.8.0\n        app.kubernetes.io/version: 1.8.0\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: ghcr.io/jenkins-x/jx-pipelines-visualizer:1.8.0\n        args:\n        - -resync-interval\n        - 60s\n        - -pipeline-trace-url-template\n        - http://grafana-jx-observability.192.168.59.101.nip.io/explore?left=%5B%22now%22,%22now%22,%22Tempo%22,%7B%22query%22:%22{{.TraceID}}%22%7D%5D\n        - -log-level\n        - INFO\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jx-pipelines-visualizer\" is not set to runAsNonRoot"
  },
  {
    "id": "02486",
    "manifest_path": "data/manifests/the_stack_sample/sample_1002.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-allowed\n  labels:\n    app: nginx-allowed\nspec:\n  securityContext:\n    supplementalGroups:\n    - 101\n    fsGroup: 101\n  containers:\n  - name: nginx\n    image: nginxinc/nginx-unprivileged:1.19\n    resources:\n      limits:\n        cpu: 1\n        memory: 1Gi\n      requests:\n        cpu: 1\n        memory: 1Gi\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    securityContext:\n      runAsUser: 101\n      runAsGroup: 101\n      capabilities:\n        drop:\n        - ALL\n      allowPrivilegeEscalation: false\n    readinessProbe:\n      httpGet:\n        scheme: HTTP\n        path: /index.html\n        port: 8080\n    livenessProbe:\n      httpGet:\n        scheme: HTTP\n        path: /index.html\n        port: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "02487",
    "manifest_path": "data/manifests/the_stack_sample/sample_1005.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200116-52fe941d7\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"horologium\" does not have a read-only root file system"
  },
  {
    "id": "02488",
    "manifest_path": "data/manifests/the_stack_sample/sample_1005.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200116-52fe941d7\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"horologium\" is not set to runAsNonRoot"
  },
  {
    "id": "02489",
    "manifest_path": "data/manifests/the_stack_sample/sample_1005.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200116-52fe941d7\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"horologium\" has cpu request 0"
  },
  {
    "id": "02490",
    "manifest_path": "data/manifests/the_stack_sample/sample_1005.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200116-52fe941d7\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"horologium\" has memory limit 0"
  },
  {
    "id": "02491",
    "manifest_path": "data/manifests/the_stack_sample/sample_1006.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntuapp\n  labels:\n    app: ubuntuapp\n  annotations:\n    opencontrail.org/network: '{\"domain\":\"default-domain\", \"project\": \"admin\", \"name\":\"VN-01\"}'\nspec:\n  containers:\n  - name: ubuntuapp\n    image: ubuntu-upstart\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"ubuntuapp\" is using an invalid container image, \"ubuntu-upstart\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02492",
    "manifest_path": "data/manifests/the_stack_sample/sample_1006.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntuapp\n  labels:\n    app: ubuntuapp\n  annotations:\n    opencontrail.org/network: '{\"domain\":\"default-domain\", \"project\": \"admin\", \"name\":\"VN-01\"}'\nspec:\n  containers:\n  - name: ubuntuapp\n    image: ubuntu-upstart\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ubuntuapp\" does not have a read-only root file system"
  },
  {
    "id": "02493",
    "manifest_path": "data/manifests/the_stack_sample/sample_1006.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntuapp\n  labels:\n    app: ubuntuapp\n  annotations:\n    opencontrail.org/network: '{\"domain\":\"default-domain\", \"project\": \"admin\", \"name\":\"VN-01\"}'\nspec:\n  containers:\n  - name: ubuntuapp\n    image: ubuntu-upstart\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ubuntuapp\" is not set to runAsNonRoot"
  },
  {
    "id": "02494",
    "manifest_path": "data/manifests/the_stack_sample/sample_1006.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntuapp\n  labels:\n    app: ubuntuapp\n  annotations:\n    opencontrail.org/network: '{\"domain\":\"default-domain\", \"project\": \"admin\", \"name\":\"VN-01\"}'\nspec:\n  containers:\n  - name: ubuntuapp\n    image: ubuntu-upstart\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ubuntuapp\" has cpu request 0"
  },
  {
    "id": "02495",
    "manifest_path": "data/manifests/the_stack_sample/sample_1006.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntuapp\n  labels:\n    app: ubuntuapp\n  annotations:\n    opencontrail.org/network: '{\"domain\":\"default-domain\", \"project\": \"admin\", \"name\":\"VN-01\"}'\nspec:\n  containers:\n  - name: ubuntuapp\n    image: ubuntu-upstart\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ubuntuapp\" has memory limit 0"
  },
  {
    "id": "02496",
    "manifest_path": "data/manifests/the_stack_sample/sample_1010.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210902-02bdcbd6bf\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"deck\" does not have a read-only root file system"
  },
  {
    "id": "02497",
    "manifest_path": "data/manifests/the_stack_sample/sample_1010.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210902-02bdcbd6bf\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"deck\" is not set to runAsNonRoot"
  },
  {
    "id": "02498",
    "manifest_path": "data/manifests/the_stack_sample/sample_1010.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210902-02bdcbd6bf\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"deck\" has cpu request 0"
  },
  {
    "id": "02499",
    "manifest_path": "data/manifests/the_stack_sample/sample_1010.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210902-02bdcbd6bf\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"deck\" has memory limit 0"
  },
  {
    "id": "02500",
    "manifest_path": "data/manifests/the_stack_sample/sample_1011.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: goapp-deployment\nspec:\n  selector:\n    matchLabels:\n      app: goapp\n  template:\n    metadata:\n      labels:\n        app: goapp\n    spec:\n      containers:\n      - name: goapp\n        image: docker.pkg.github.com/ynishi18/cicd-handson-2021-code/go-image:base\n        ports:\n        - containerPort: 9090\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"goapp\" does not have a read-only root file system"
  }
]