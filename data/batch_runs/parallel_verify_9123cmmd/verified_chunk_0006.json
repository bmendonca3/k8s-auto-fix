[
  {
    "id": "03751",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cuda-vector-add\nspec:\n  containers:\n  - name: cuda-vector-add\n    image: k8s.gcr.io/cuda-vector-add:v0.1\n    resources:\n      limits:\n        nvidia.com/gpu: 1\n        cpu: 500m\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03752",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: plank\n  labels:\n    app: plank\nspec:\n  selector:\n    matchLabels:\n      app: plank\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: plank\n    spec:\n      serviceAccountName: plank\n      containers:\n      - name: plank\n        image: gcr.io/k8s-prow/plank:v20200319-1aea24112\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/workload-clusters/config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        volumeMounts:\n        - name: kubeconfig\n          mountPath: /etc/workload-clusters\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: cluster\n          mountPath: /etc/cluster\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubeconfig\n        secret:\n          secretName: workload-clusters-kubeconfig\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: workload-cluster\n",
    "errors": []
  },
  {
    "id": "03753",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: plank\n  labels:\n    app: plank\nspec:\n  selector:\n    matchLabels:\n      app: plank\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: plank\n    spec:\n      serviceAccountName: plank\n      containers:\n      - name: plank\n        image: gcr.io/k8s-prow/plank:v20200319-1aea24112\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/workload-clusters/config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        volumeMounts:\n        - name: kubeconfig\n          mountPath: /etc/workload-clusters\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: cluster\n          mountPath: /etc/cluster\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubeconfig\n        secret:\n          secretName: workload-clusters-kubeconfig\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: workload-cluster\n",
    "errors": []
  },
  {
    "id": "03754",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: plank\n  labels:\n    app: plank\nspec:\n  selector:\n    matchLabels:\n      app: plank\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: plank\n    spec:\n      serviceAccountName: plank\n      containers:\n      - name: plank\n        image: gcr.io/k8s-prow/plank:v20200319-1aea24112\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/workload-clusters/config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        volumeMounts:\n        - name: kubeconfig\n          mountPath: /etc/workload-clusters\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: cluster\n          mountPath: /etc/cluster\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubeconfig\n        secret:\n          secretName: workload-clusters-kubeconfig\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: workload-cluster\n",
    "errors": []
  },
  {
    "id": "03755",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: plank\n  labels:\n    app: plank\nspec:\n  selector:\n    matchLabels:\n      app: plank\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: plank\n    spec:\n      serviceAccountName: plank\n      containers:\n      - name: plank\n        image: gcr.io/k8s-prow/plank:v20200319-1aea24112\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/workload-clusters/config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        volumeMounts:\n        - name: kubeconfig\n          mountPath: /etc/workload-clusters\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: cluster\n          mountPath: /etc/cluster\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubeconfig\n        secret:\n          secretName: workload-clusters-kubeconfig\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: cluster\n        secret:\n          defaultMode: 420\n          secretName: workload-cluster\n",
    "errors": []
  },
  {
    "id": "03756",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zabbix-web\n  labels:\n    app: zabbix\n    tier: zabbix-web\n  namespace: zabbix\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: zabbix-web\n        app: zabbix\n    spec:\n      containers:\n      - name: zabbix-web\n        image: zabbix/zabbix-web-nginx-mysql:alpine-5.0-latest\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: web-http\n        - containerPort: 8443\n          name: web-https\n        env:\n        - name: ZBX_SERVER_NAME\n          value: Zabbix kubernetes\n        - name: PHP_TZ\n          value: Europe/Riga\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-zbx-user\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-zbx-pass\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-root-pass\n        - name: MYSQL_DATABASE\n          value: zabbix\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03757",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zabbix-web\n  labels:\n    app: zabbix\n    tier: zabbix-web\n  namespace: zabbix\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: zabbix-web\n        app: zabbix\n    spec:\n      containers:\n      - name: zabbix-web\n        image: zabbix/zabbix-web-nginx-mysql:alpine-5.0-latest\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: web-http\n        - containerPort: 8443\n          name: web-https\n        env:\n        - name: ZBX_SERVER_NAME\n          value: Zabbix kubernetes\n        - name: PHP_TZ\n          value: Europe/Riga\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-zbx-user\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-zbx-pass\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-root-pass\n        - name: MYSQL_DATABASE\n          value: zabbix\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03758",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zabbix-web\n  labels:\n    app: zabbix\n    tier: zabbix-web\n  namespace: zabbix\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: zabbix-web\n        app: zabbix\n    spec:\n      containers:\n      - name: zabbix-web\n        image: zabbix/zabbix-web-nginx-mysql:alpine-5.0-latest\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: web-http\n        - containerPort: 8443\n          name: web-https\n        env:\n        - name: ZBX_SERVER_NAME\n          value: Zabbix kubernetes\n        - name: PHP_TZ\n          value: Europe/Riga\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-zbx-user\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-zbx-pass\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-root-pass\n        - name: MYSQL_DATABASE\n          value: zabbix\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03759",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zabbix-web\n  labels:\n    app: zabbix\n    tier: zabbix-web\n  namespace: zabbix\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: zabbix-web\n        app: zabbix\n    spec:\n      containers:\n      - name: zabbix-web\n        image: zabbix/zabbix-web-nginx-mysql:alpine-5.0-latest\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: web-http\n        - containerPort: 8443\n          name: web-https\n        env:\n        - name: ZBX_SERVER_NAME\n          value: Zabbix kubernetes\n        - name: PHP_TZ\n          value: Europe/Riga\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-zbx-user\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-zbx-pass\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: db-root-pass\n        - name: MYSQL_DATABASE\n          value: zabbix\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03760",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1357\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03761",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1357\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03762",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1357\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03763",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1357\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03764",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1357\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03765",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210514-64850e516d\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-tidb-logs/tide-status\n        - --history-uri=gs://prow-tidb-logs/tide-history.json\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03766",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210514-64850e516d\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-tidb-logs/tide-status\n        - --history-uri=gs://prow-tidb-logs/tide-history.json\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03767",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210514-64850e516d\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-tidb-logs/tide-status\n        - --history-uri=gs://prow-tidb-logs/tide-history.json\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03768",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210514-64850e516d\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-tidb-logs/tide-status\n        - --history-uri=gs://prow-tidb-logs/tide-history.json\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03769",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03770",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03771",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03772",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03773",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03774",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210624-69a9f34cd9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://fakeghserver\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03775",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210624-69a9f34cd9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://fakeghserver\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03776",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210624-69a9f34cd9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://fakeghserver\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03777",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210624-69a9f34cd9\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://fakeghserver\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03778",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-jx-controller\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.683\n    app: lighthouse-jx-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\n    jenkins-x.io/hash: 02b017d8f4c2c6a9dff81ac769baa5da7d60fcc9fee59859671642d393c6f4e2\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-jx-controller\n  template:\n    metadata:\n      labels:\n        draft: draft-app\n        app: lighthouse-jx-controller\n    spec:\n      serviceAccountName: lighthouse-jx-controller\n      containers:\n      - name: lighthouse-jx-controller\n        image: gcr.io/jenkinsxio/lighthouse-jx-controller:0.0.683\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: hnaung\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: JX_DEFAULT_IMAGE\n          value: gcr.io/jenkinsxio/builder-maven:2.1.142-761\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03779",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-jx-controller\n  labels:\n    draft: draft-app\n    chart: lighthouse-0.0.683\n    app: lighthouse-jx-controller\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\n    jenkins-x.io/hash: 02b017d8f4c2c6a9dff81ac769baa5da7d60fcc9fee59859671642d393c6f4e2\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      draft: draft-app\n      app: lighthouse-jx-controller\n  template:\n    metadata:\n      labels:\n        draft: draft-app\n        app: lighthouse-jx-controller\n    spec:\n      serviceAccountName: lighthouse-jx-controller\n      containers:\n      - name: lighthouse-jx-controller\n        image: gcr.io/jenkinsxio/lighthouse-jx-controller:0.0.683\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: hnaung\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: JX_DEFAULT_IMAGE\n          value: gcr.io/jenkinsxio/builder-maven:2.1.142-761\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03780",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    visualize: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n        visualize: 'true'\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03781",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    visualize: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n        visualize: 'true'\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03782",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    visualize: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n        visualize: 'true'\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03783",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    visualize: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n        visualize: 'true'\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03784",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    visualize: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n        visualize: 'true'\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03785",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-noobaa-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: example-noobaa-data\n        image: yiannisgkoufas/awscli-alpine:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 10 && export AWS_ACCESS_KEY_ID={KEY_ID} && export AWS_SECRET_ACCESS_KEY={ACCESS_KEY}\n          && echo ''hello'' > file1.txt && echo ''world'' > file2.txt && aws --no-verify-ssl\n          --endpoint https://s3.default.svc:443 s3 cp file1.txt s3://{BUCKET} && aws\n          --no-verify-ssl --endpoint https://s3.default.svc:443 s3 cp file2.txt s3://{BUCKET} '\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03786",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-noobaa-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: example-noobaa-data\n        image: yiannisgkoufas/awscli-alpine:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 10 && export AWS_ACCESS_KEY_ID={KEY_ID} && export AWS_SECRET_ACCESS_KEY={ACCESS_KEY}\n          && echo ''hello'' > file1.txt && echo ''world'' > file2.txt && aws --no-verify-ssl\n          --endpoint https://s3.default.svc:443 s3 cp file1.txt s3://{BUCKET} && aws\n          --no-verify-ssl --endpoint https://s3.default.svc:443 s3 cp file2.txt s3://{BUCKET} '\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03787",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-noobaa-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: example-noobaa-data\n        image: yiannisgkoufas/awscli-alpine:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 10 && export AWS_ACCESS_KEY_ID={KEY_ID} && export AWS_SECRET_ACCESS_KEY={ACCESS_KEY}\n          && echo ''hello'' > file1.txt && echo ''world'' > file2.txt && aws --no-verify-ssl\n          --endpoint https://s3.default.svc:443 s3 cp file1.txt s3://{BUCKET} && aws\n          --no-verify-ssl --endpoint https://s3.default.svc:443 s3 cp file2.txt s3://{BUCKET} '\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03788",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-noobaa-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: example-noobaa-data\n        image: yiannisgkoufas/awscli-alpine:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 10 && export AWS_ACCESS_KEY_ID={KEY_ID} && export AWS_SECRET_ACCESS_KEY={ACCESS_KEY}\n          && echo ''hello'' > file1.txt && echo ''world'' > file2.txt && aws --no-verify-ssl\n          --endpoint https://s3.default.svc:443 s3 cp file1.txt s3://{BUCKET} && aws\n          --no-verify-ssl --endpoint https://s3.default.svc:443 s3 cp file2.txt s3://{BUCKET} '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03789",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-noobaa-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: example-noobaa-data\n        image: yiannisgkoufas/awscli-alpine:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 10 && export AWS_ACCESS_KEY_ID={KEY_ID} && export AWS_SECRET_ACCESS_KEY={ACCESS_KEY}\n          && echo ''hello'' > file1.txt && echo ''world'' > file2.txt && aws --no-verify-ssl\n          --endpoint https://s3.default.svc:443 s3 cp file1.txt s3://{BUCKET} && aws\n          --no-verify-ssl --endpoint https://s3.default.svc:443 s3 cp file2.txt s3://{BUCKET} '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03790",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: ticommunityinfra/tide:v20220130-v1.0.4\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-tidb-logs/tide-status\n        - --history-uri=gs://prow-tidb-logs/tide-history.json\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03791",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: ticommunityinfra/tide:v20220130-v1.0.4\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-tidb-logs/tide-status\n        - --history-uri=gs://prow-tidb-logs/tide-history.json\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03792",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: ticommunityinfra/tide:v20220130-v1.0.4\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-tidb-logs/tide-status\n        - --history-uri=gs://prow-tidb-logs/tide-history.json\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03793",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: ticommunityinfra/tide:v20220130-v1.0.4\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-tidb-logs/tide-status\n        - --history-uri=gs://prow-tidb-logs/tide-history.json\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03794",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: env\nspec:\n  containers:\n  - name: env\n    image: nicholasdille/sleeper:stable\n    env:\n    - name: ENV_SECRET\n      valueFrom:\n        configMapKeyRef:\n          name: config\n          key: foo\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03795",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: env\nspec:\n  containers:\n  - name: env\n    image: nicholasdille/sleeper:stable\n    env:\n    - name: ENV_SECRET\n      valueFrom:\n        configMapKeyRef:\n          name: config\n          key: foo\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03796",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: env\nspec:\n  containers:\n  - name: env\n    image: nicholasdille/sleeper:stable\n    env:\n    - name: ENV_SECRET\n      valueFrom:\n        configMapKeyRef:\n          name: config\n          key: foo\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03797",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: env\nspec:\n  containers:\n  - name: env\n    image: nicholasdille/sleeper:stable\n    env:\n    - name: ENV_SECRET\n      valueFrom:\n        configMapKeyRef:\n          name: config\n          key: foo\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03798",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: env\nspec:\n  containers:\n  - name: env\n    image: nicholasdille/sleeper:stable\n    env:\n    - name: ENV_SECRET\n      valueFrom:\n        configMapKeyRef:\n          name: config\n          key: foo\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03799",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    injection.smarttuning.ibm.com: 'true'\n  labels:\n    app: mock\n  name: mock\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mock\n  template:\n    metadata:\n      labels:\n        app: mock\n    spec:\n      containers:\n      - image: open-liberty:full-java11-openj9\n        imagePullPolicy: IfNotPresent\n        name: openliberty\n        ports:\n        - containerPort: 9080\n        envFrom:\n        - configMapRef:\n            name: mock-envvar\n        volumeMounts:\n        - mountPath: /config/jvm.options\n          subPath: jvm.options\n          name: mock-jvm\n        securityContext:\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        resources:\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        readinessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            port: 9080\n      volumes:\n      - name: mock-jvm\n        configMap:\n          name: mock-jvm\n",
    "errors": []
  },
  {
    "id": "03800",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    injection.smarttuning.ibm.com: 'true'\n  labels:\n    app: mock\n  name: mock\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mock\n  template:\n    metadata:\n      labels:\n        app: mock\n    spec:\n      containers:\n      - image: open-liberty:full-java11-openj9\n        imagePullPolicy: IfNotPresent\n        name: openliberty\n        ports:\n        - containerPort: 9080\n        envFrom:\n        - configMapRef:\n            name: mock-envvar\n        volumeMounts:\n        - mountPath: /config/jvm.options\n          subPath: jvm.options\n          name: mock-jvm\n        securityContext:\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        resources:\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        readinessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            port: 9080\n      volumes:\n      - name: mock-jvm\n        configMap:\n          name: mock-jvm\n",
    "errors": []
  },
  {
    "id": "03801",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    injection.smarttuning.ibm.com: 'true'\n  labels:\n    app: mock\n  name: mock\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mock\n  template:\n    metadata:\n      labels:\n        app: mock\n    spec:\n      containers:\n      - image: open-liberty:full-java11-openj9\n        imagePullPolicy: IfNotPresent\n        name: openliberty\n        ports:\n        - containerPort: 9080\n        envFrom:\n        - configMapRef:\n            name: mock-envvar\n        volumeMounts:\n        - mountPath: /config/jvm.options\n          subPath: jvm.options\n          name: mock-jvm\n        securityContext:\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        resources:\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        readinessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            port: 9080\n      volumes:\n      - name: mock-jvm\n        configMap:\n          name: mock-jvm\n",
    "errors": []
  },
  {
    "id": "03802",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    injection.smarttuning.ibm.com: 'true'\n  labels:\n    app: mock\n  name: mock\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mock\n  template:\n    metadata:\n      labels:\n        app: mock\n    spec:\n      containers:\n      - image: open-liberty:full-java11-openj9\n        imagePullPolicy: IfNotPresent\n        name: openliberty\n        ports:\n        - containerPort: 9080\n        envFrom:\n        - configMapRef:\n            name: mock-envvar\n        volumeMounts:\n        - mountPath: /config/jvm.options\n          subPath: jvm.options\n          name: mock-jvm\n        securityContext:\n          runAsUser: 0\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        resources:\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        readinessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            port: 9080\n      volumes:\n      - name: mock-jvm\n        configMap:\n          name: mock-jvm\n",
    "errors": []
  },
  {
    "id": "03803",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    injection.smarttuning.ibm.com: 'true'\n  labels:\n    app: mock\n  name: mock\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mock\n  template:\n    metadata:\n      labels:\n        app: mock\n    spec:\n      containers:\n      - image: open-liberty:full-java11-openj9\n        imagePullPolicy: IfNotPresent\n        name: openliberty\n        ports:\n        - containerPort: 9080\n        envFrom:\n        - configMapRef:\n            name: mock-envvar\n        volumeMounts:\n        - mountPath: /config/jvm.options\n          subPath: jvm.options\n          name: mock-jvm\n        securityContext:\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        resources:\n          limits:\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        readinessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            port: 9080\n      volumes:\n      - name: mock-jvm\n        configMap:\n          name: mock-jvm\n",
    "errors": []
  },
  {
    "id": "03804",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: descheduler\n  namespace: kube-system\n  labels:\n    app: descheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: descheduler\n  template:\n    metadata:\n      labels:\n        app: descheduler\n    spec:\n      serviceAccountName: descheduler-sa\n      containers:\n      - name: descheduler\n        image: cr.d.xiaomi.net/cloud-ml/descheduler:v20211207-v0.22.0-16-g50f9513cb\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/descheduler\n        args:\n        - --policy-config-file\n        - /policy-dir/policy.yaml\n        - --nodeSelector\n        - type=virtual-kubelet\n        - --descheduling-interval\n        - 30m\n        - --v\n        - '3'\n        ports:\n        - containerPort: 10258\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 500m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /policy-dir\n          name: policy-volume\n      volumes:\n      - name: policy-volume\n        configMap:\n          name: descheduler-policy-configmap\n",
    "errors": []
  },
  {
    "id": "03805",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-eureka\n  labels:\n    deploy: apm-eureka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-eureka\n  template:\n    metadata:\n      name: apm-eureka\n      labels:\n        app: apm-eureka\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: apm-eureka\n        image: evanxuhe/apm-eureka:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-eureka\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo\n        ports:\n        - name: http\n          containerPort: 8761\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03806",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-eureka\n  labels:\n    deploy: apm-eureka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-eureka\n  template:\n    metadata:\n      name: apm-eureka\n      labels:\n        app: apm-eureka\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: apm-eureka\n        image: evanxuhe/apm-eureka:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-eureka\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo\n        ports:\n        - name: http\n          containerPort: 8761\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03807",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-eureka\n  labels:\n    deploy: apm-eureka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-eureka\n  template:\n    metadata:\n      name: apm-eureka\n      labels:\n        app: apm-eureka\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: apm-eureka\n        image: evanxuhe/apm-eureka:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-eureka\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo\n        ports:\n        - name: http\n          containerPort: 8761\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03808",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-eureka\n  labels:\n    deploy: apm-eureka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-eureka\n  template:\n    metadata:\n      name: apm-eureka\n      labels:\n        app: apm-eureka\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: apm-eureka\n        image: evanxuhe/apm-eureka:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-eureka\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo\n        ports:\n        - name: http\n          containerPort: 8761\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03809",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-eureka\n  labels:\n    deploy: apm-eureka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-eureka\n  template:\n    metadata:\n      name: apm-eureka\n      labels:\n        app: apm-eureka\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: apm-eureka\n        image: evanxuhe/apm-eureka:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-eureka\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo\n        ports:\n        - name: http\n          containerPort: 8761\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03810",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-eureka\n  labels:\n    deploy: apm-eureka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-eureka\n  template:\n    metadata:\n      name: apm-eureka\n      labels:\n        app: apm-eureka\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: apm-eureka\n        image: evanxuhe/apm-eureka:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-eureka\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo\n        ports:\n        - name: http\n          containerPort: 8761\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03811",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-eureka\n  labels:\n    deploy: apm-eureka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-eureka\n  template:\n    metadata:\n      name: apm-eureka\n      labels:\n        app: apm-eureka\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: apm-eureka\n        image: evanxuhe/apm-eureka:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-eureka\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo\n        ports:\n        - name: http\n          containerPort: 8761\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03812",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apm-eureka\n  labels:\n    deploy: apm-eureka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apm-eureka\n  template:\n    metadata:\n      name: apm-eureka\n      labels:\n        app: apm-eureka\n    spec:\n      initContainers:\n      - name: sidecar\n        image: apache/skywalking-base:6.5.0\n        imagePullPolicy: IfNotPresent\n        command:\n        - cp\n        - -r\n        - /skywalking/agent\n        - /sidecar\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: apm-eureka\n        image: evanxuhe/apm-eureka:6.1.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: JAVA_OPTS\n          value: -javaagent:/sidecar/agent/skywalking-agent.jar\n        - name: SW_AGENT_NAME\n          value: apm-eureka\n        - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES\n          value: skywalk-1h6lqf-skywalking-skywalking-oap.demo\n        ports:\n        - name: http\n          containerPort: 8761\n        volumeMounts:\n        - name: sidecar\n          mountPath: /sidecar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: sidecar\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03813",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.51\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: e0f23ac6addb6dce6a649e73f5c7584203878aee72cf33274a296a208bedc454\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.51\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: zpzjzj\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.51\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 78ee09edfc1815a0057f1df4a3749b0dba55c117\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03814",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.51\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: e0f23ac6addb6dce6a649e73f5c7584203878aee72cf33274a296a208bedc454\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.51\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: zpzjzj\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.51\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 78ee09edfc1815a0057f1df4a3749b0dba55c117\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03815",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  volumes:\n  - name: persistentsharedspace\n    persistentVolumeClaim:\n      claimName: my-pv-claim\n  containers:\n  - name: nginx\n    image: nginx:1.7.9\n    volumeMounts:\n    - mountPath: /containerMount\n      name: persistentsharedspace\n    ports:\n    - containerPort: 80\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03816",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  volumes:\n  - name: persistentsharedspace\n    persistentVolumeClaim:\n      claimName: my-pv-claim\n  containers:\n  - name: nginx\n    image: nginx:1.7.9\n    volumeMounts:\n    - mountPath: /containerMount\n      name: persistentsharedspace\n    ports:\n    - containerPort: 80\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03817",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  volumes:\n  - name: persistentsharedspace\n    persistentVolumeClaim:\n      claimName: my-pv-claim\n  containers:\n  - name: nginx\n    image: nginx:1.7.9\n    volumeMounts:\n    - mountPath: /containerMount\n      name: persistentsharedspace\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03818",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  volumes:\n  - name: persistentsharedspace\n    persistentVolumeClaim:\n      claimName: my-pv-claim\n  containers:\n  - name: nginx\n    image: nginx:1.7.9\n    volumeMounts:\n    - mountPath: /containerMount\n      name: persistentsharedspace\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03819",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: cntr-apache\n    image: httpd:stable\n    ports:\n    - containerPort: 80\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03820",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: cntr-apache\n    image: httpd:stable\n    ports:\n    - containerPort: 80\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03821",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: cntr-apache\n    image: httpd:stable\n    ports:\n    - containerPort: 80\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03822",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: cntr-apache\n    image: httpd:stable\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03823",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: cntr-apache\n    image: httpd:stable\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03824",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: github-actions-runner-controller-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: github-actions-runner-controller-registry\n  template:\n    metadata:\n      labels:\n        app: github-actions-runner-controller-registry\n    spec:\n      containers:\n      - name: registry\n        image: registry:2\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/registry\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03825",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: github-actions-runner-controller-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: github-actions-runner-controller-registry\n  template:\n    metadata:\n      labels:\n        app: github-actions-runner-controller-registry\n    spec:\n      containers:\n      - name: registry\n        image: registry:2\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/registry\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03826",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: github-actions-runner-controller-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: github-actions-runner-controller-registry\n  template:\n    metadata:\n      labels:\n        app: github-actions-runner-controller-registry\n    spec:\n      containers:\n      - name: registry\n        image: registry:2\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/registry\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03827",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: github-actions-runner-controller-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: github-actions-runner-controller-registry\n  template:\n    metadata:\n      labels:\n        app: github-actions-runner-controller-registry\n    spec:\n      containers:\n      - name: registry\n        image: registry:2\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/registry\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03828",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: nginx-ingress-operator\n  template:\n    metadata:\n      labels:\n        name: nginx-ingress-operator\n    spec:\n      serviceAccountName: nginx-ingress-operator\n      containers:\n      - name: nginx-ingress-operator\n        image: nginx/nginx-ingress-operator:stable\n        command:\n        - nginx-ingress-operator\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: nginx-ingress-operator\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03829",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: nginx-ingress-operator\n  template:\n    metadata:\n      labels:\n        name: nginx-ingress-operator\n    spec:\n      serviceAccountName: nginx-ingress-operator\n      containers:\n      - name: nginx-ingress-operator\n        image: nginx/nginx-ingress-operator:stable\n        command:\n        - nginx-ingress-operator\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: nginx-ingress-operator\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03830",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: nginx-ingress-operator\n  template:\n    metadata:\n      labels:\n        name: nginx-ingress-operator\n    spec:\n      serviceAccountName: nginx-ingress-operator\n      containers:\n      - name: nginx-ingress-operator\n        image: nginx/nginx-ingress-operator:stable\n        command:\n        - nginx-ingress-operator\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: nginx-ingress-operator\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03831",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: nginx-ingress-operator\n  template:\n    metadata:\n      labels:\n        name: nginx-ingress-operator\n    spec:\n      serviceAccountName: nginx-ingress-operator\n      containers:\n      - name: nginx-ingress-operator\n        image: nginx/nginx-ingress-operator:stable\n        command:\n        - nginx-ingress-operator\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: nginx-ingress-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03832",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: nginx-ingress-operator\n  template:\n    metadata:\n      labels:\n        name: nginx-ingress-operator\n    spec:\n      serviceAccountName: nginx-ingress-operator\n      containers:\n      - name: nginx-ingress-operator\n        image: nginx/nginx-ingress-operator:stable\n        command:\n        - nginx-ingress-operator\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: nginx-ingress-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03833",
    "policy_id": "env_var_secret",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret-access-key-secret\n              key: aws_secret_access_key\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03834",
    "policy_id": "env_var_secret",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret-access-key-secret\n              key: aws_secret_access_key\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03835",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03836",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03837",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03838",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03839",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03840",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03841",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03842",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03843",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03844",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: app\n        image: alpine:stable\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03845",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness:stable\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03846",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness:stable\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03847",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness:stable\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03848",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness:stable\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03849",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness:stable\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03850",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03851",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03852",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03853",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03854",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03855",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-nginx-dp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-dp\n  template:\n    metadata:\n      labels:\n        app: nginx-dp\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03856",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-nginx-dp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-dp\n  template:\n    metadata:\n      labels:\n        app: nginx-dp\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03857",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-nginx-dp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-dp\n  template:\n    metadata:\n      labels:\n        app: nginx-dp\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03858",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-nginx-dp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-dp\n  template:\n    metadata:\n      labels:\n        app: nginx-dp\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03859",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220330-40eb179576\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03860",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220330-40eb179576\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03861",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220330-40eb179576\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03862",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220330-40eb179576\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03863",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:stable\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03864",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:stable\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03865",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:stable\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03866",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:stable\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03867",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:stable\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03868",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\nspec:\n  containers:\n  - command:\n    - /bin/sh\n    - -c\n    - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns\n      --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce  --service-account-private-key-file=/srv/kubernetes/server.key\n      --v=2 1>>/var/log/kube-controller-manager.log --leader-elect 2>&1\n    image: k8s.gcr.io/kube-controller-manager:fda24638d51a48baa13c35337fcd4793\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    name: kube-controller-manager\n    volumeMounts:\n    - mountPath: /srv/kubernetes\n      name: srvkube\n      readOnly: true\n    - mountPath: /var/log/kube-controller-manager.log\n      name: logfile\n    - mountPath: /etc/ssl\n      name: etcssl\n      readOnly: true\n    - mountPath: /usr/share/ssl\n      name: usrsharessl\n      readOnly: true\n    - mountPath: /var/ssl\n      name: varssl\n      readOnly: true\n    - mountPath: /usr/ssl\n      name: usrssl\n      readOnly: true\n    - mountPath: /usr/lib/ssl\n      name: usrlibssl\n      readOnly: true\n    - mountPath: /usr/local/openssl\n      name: usrlocalopenssl\n      readOnly: true\n    - mountPath: /etc/openssl\n      name: etcopenssl\n      readOnly: true\n    - mountPath: /etc/pki/tls\n      name: etcpkitls\n      readOnly: true\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  volumes:\n  - hostPath:\n      path: /srv/kubernetes\n    name: srvkube\n  - hostPath:\n      path: /var/log/kube-controller-manager.log\n      type: FileOrCreate\n    name: logfile\n  - hostPath:\n      path: /etc/ssl\n    name: etcssl\n  - hostPath:\n      path: /usr/share/ssl\n    name: usrsharessl\n  - hostPath:\n      path: /var/ssl\n    name: varssl\n  - hostPath:\n      path: /usr/ssl\n    name: usrssl\n  - hostPath:\n      path: /usr/lib/ssl\n    name: usrlibssl\n  - hostPath:\n      path: /usr/local/openssl\n    name: usrlocalopenssl\n  - hostPath:\n      path: /etc/openssl\n    name: etcopenssl\n  - hostPath:\n      path: /etc/pki/tls\n    name: etcpkitls\n",
    "errors": []
  },
  {
    "id": "03869",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\nspec:\n  containers:\n  - command:\n    - /bin/sh\n    - -c\n    - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns\n      --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce  --service-account-private-key-file=/srv/kubernetes/server.key\n      --v=2 1>>/var/log/kube-controller-manager.log --leader-elect 2>&1\n    image: k8s.gcr.io/kube-controller-manager:fda24638d51a48baa13c35337fcd4793\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    name: kube-controller-manager\n    volumeMounts:\n    - mountPath: /srv/kubernetes\n      name: srvkube\n      readOnly: true\n    - mountPath: /var/log/kube-controller-manager.log\n      name: logfile\n    - mountPath: /etc/ssl\n      name: etcssl\n      readOnly: true\n    - mountPath: /usr/share/ssl\n      name: usrsharessl\n      readOnly: true\n    - mountPath: /var/ssl\n      name: varssl\n      readOnly: true\n    - mountPath: /usr/ssl\n      name: usrssl\n      readOnly: true\n    - mountPath: /usr/lib/ssl\n      name: usrlibssl\n      readOnly: true\n    - mountPath: /usr/local/openssl\n      name: usrlocalopenssl\n      readOnly: true\n    - mountPath: /etc/openssl\n      name: etcopenssl\n      readOnly: true\n    - mountPath: /etc/pki/tls\n      name: etcpkitls\n      readOnly: true\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  volumes:\n  - hostPath:\n      path: /srv/kubernetes\n    name: srvkube\n  - hostPath:\n      path: /var/log/kube-controller-manager.log\n      type: FileOrCreate\n    name: logfile\n  - hostPath:\n      path: /etc/ssl\n    name: etcssl\n  - hostPath:\n      path: /usr/share/ssl\n    name: usrsharessl\n  - hostPath:\n      path: /var/ssl\n    name: varssl\n  - hostPath:\n      path: /usr/ssl\n    name: usrssl\n  - hostPath:\n      path: /usr/lib/ssl\n    name: usrlibssl\n  - hostPath:\n      path: /usr/local/openssl\n    name: usrlocalopenssl\n  - hostPath:\n      path: /etc/openssl\n    name: etcopenssl\n  - hostPath:\n      path: /etc/pki/tls\n    name: etcpkitls\n",
    "errors": []
  },
  {
    "id": "03870",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\nspec:\n  containers:\n  - command:\n    - /bin/sh\n    - -c\n    - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns\n      --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce  --service-account-private-key-file=/srv/kubernetes/server.key\n      --v=2 1>>/var/log/kube-controller-manager.log --leader-elect 2>&1\n    image: k8s.gcr.io/kube-controller-manager:fda24638d51a48baa13c35337fcd4793\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    name: kube-controller-manager\n    volumeMounts:\n    - mountPath: /srv/kubernetes\n      name: srvkube\n      readOnly: true\n    - mountPath: /var/log/kube-controller-manager.log\n      name: logfile\n    - mountPath: /etc/ssl\n      name: etcssl\n      readOnly: true\n    - mountPath: /usr/share/ssl\n      name: usrsharessl\n      readOnly: true\n    - mountPath: /var/ssl\n      name: varssl\n      readOnly: true\n    - mountPath: /usr/ssl\n      name: usrssl\n      readOnly: true\n    - mountPath: /usr/lib/ssl\n      name: usrlibssl\n      readOnly: true\n    - mountPath: /usr/local/openssl\n      name: usrlocalopenssl\n      readOnly: true\n    - mountPath: /etc/openssl\n      name: etcopenssl\n      readOnly: true\n    - mountPath: /etc/pki/tls\n      name: etcpkitls\n      readOnly: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  volumes:\n  - hostPath:\n      path: /srv/kubernetes\n    name: srvkube\n  - hostPath:\n      path: /var/log/kube-controller-manager.log\n      type: FileOrCreate\n    name: logfile\n  - hostPath:\n      path: /etc/ssl\n    name: etcssl\n  - hostPath:\n      path: /usr/share/ssl\n    name: usrsharessl\n  - hostPath:\n      path: /var/ssl\n    name: varssl\n  - hostPath:\n      path: /usr/ssl\n    name: usrssl\n  - hostPath:\n      path: /usr/lib/ssl\n    name: usrlibssl\n  - hostPath:\n      path: /usr/local/openssl\n    name: usrlocalopenssl\n  - hostPath:\n      path: /etc/openssl\n    name: etcopenssl\n  - hostPath:\n      path: /etc/pki/tls\n    name: etcpkitls\n",
    "errors": []
  },
  {
    "id": "03871",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\nspec:\n  containers:\n  - command:\n    - /bin/sh\n    - -c\n    - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns\n      --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce  --service-account-private-key-file=/srv/kubernetes/server.key\n      --v=2 1>>/var/log/kube-controller-manager.log --leader-elect 2>&1\n    image: k8s.gcr.io/kube-controller-manager:fda24638d51a48baa13c35337fcd4793\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    name: kube-controller-manager\n    volumeMounts:\n    - mountPath: /srv/kubernetes\n      name: srvkube\n      readOnly: true\n    - mountPath: /var/log/kube-controller-manager.log\n      name: logfile\n    - mountPath: /etc/ssl\n      name: etcssl\n      readOnly: true\n    - mountPath: /usr/share/ssl\n      name: usrsharessl\n      readOnly: true\n    - mountPath: /var/ssl\n      name: varssl\n      readOnly: true\n    - mountPath: /usr/ssl\n      name: usrssl\n      readOnly: true\n    - mountPath: /usr/lib/ssl\n      name: usrlibssl\n      readOnly: true\n    - mountPath: /usr/local/openssl\n      name: usrlocalopenssl\n      readOnly: true\n    - mountPath: /etc/openssl\n      name: etcopenssl\n      readOnly: true\n    - mountPath: /etc/pki/tls\n      name: etcpkitls\n      readOnly: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  volumes:\n  - hostPath:\n      path: /srv/kubernetes\n    name: srvkube\n  - hostPath:\n      path: /var/log/kube-controller-manager.log\n      type: FileOrCreate\n    name: logfile\n  - hostPath:\n      path: /etc/ssl\n    name: etcssl\n  - hostPath:\n      path: /usr/share/ssl\n    name: usrsharessl\n  - hostPath:\n      path: /var/ssl\n    name: varssl\n  - hostPath:\n      path: /usr/ssl\n    name: usrssl\n  - hostPath:\n      path: /usr/lib/ssl\n    name: usrlibssl\n  - hostPath:\n      path: /usr/local/openssl\n    name: usrlocalopenssl\n  - hostPath:\n      path: /etc/openssl\n    name: etcopenssl\n  - hostPath:\n      path: /etc/pki/tls\n    name: etcpkitls\n",
    "errors": []
  },
  {
    "id": "03872",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nats\n  labels:\n    component: nats\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: nats\n  template:\n    metadata:\n      labels:\n        component: nats\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: component\n                operator: In\n                values:\n                - nats\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: nats\n        image: nats:1.1.0\n        args:\n        - --config\n        - /etc/nats/config/nats.conf\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/nats/config\n        ports:\n        - containerPort: 4222\n          name: client\n        - containerPort: 6222\n          name: cluster\n        - containerPort: 8222\n          name: monitor\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8222\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config-volume\n        configMap:\n          name: nats-config\n",
    "errors": []
  },
  {
    "id": "03873",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nats\n  labels:\n    component: nats\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: nats\n  template:\n    metadata:\n      labels:\n        component: nats\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: component\n                operator: In\n                values:\n                - nats\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: nats\n        image: nats:1.1.0\n        args:\n        - --config\n        - /etc/nats/config/nats.conf\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/nats/config\n        ports:\n        - containerPort: 4222\n          name: client\n        - containerPort: 6222\n          name: cluster\n        - containerPort: 8222\n          name: monitor\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8222\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config-volume\n        configMap:\n          name: nats-config\n",
    "errors": []
  },
  {
    "id": "03874",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nats\n  labels:\n    component: nats\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: nats\n  template:\n    metadata:\n      labels:\n        component: nats\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: component\n                operator: In\n                values:\n                - nats\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: nats\n        image: nats:1.1.0\n        args:\n        - --config\n        - /etc/nats/config/nats.conf\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/nats/config\n        ports:\n        - containerPort: 4222\n          name: client\n        - containerPort: 6222\n          name: cluster\n        - containerPort: 8222\n          name: monitor\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8222\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config-volume\n        configMap:\n          name: nats-config\n",
    "errors": []
  },
  {
    "id": "03875",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nats\n  labels:\n    component: nats\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: nats\n  template:\n    metadata:\n      labels:\n        component: nats\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: component\n                operator: In\n                values:\n                - nats\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: nats\n        image: nats:1.1.0\n        args:\n        - --config\n        - /etc/nats/config/nats.conf\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/nats/config\n        ports:\n        - containerPort: 4222\n          name: client\n        - containerPort: 6222\n          name: cluster\n        - containerPort: 8222\n          name: monitor\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8222\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config-volume\n        configMap:\n          name: nats-config\n",
    "errors": []
  },
  {
    "id": "03876",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '14271'\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:1.18.1\n        args:\n        - --config-file=/conf/agent.yaml\n        volumeMounts:\n        - name: jaeger-configuration-volume\n          mountPath: /conf\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 14271\n          name: admin-http\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: jaeger-configuration\n          items:\n          - key: agent\n            path: agent.yaml\n        name: jaeger-configuration-volume\n",
    "errors": []
  },
  {
    "id": "03877",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '14271'\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:1.18.1\n        args:\n        - --config-file=/conf/agent.yaml\n        volumeMounts:\n        - name: jaeger-configuration-volume\n          mountPath: /conf\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 14271\n          name: admin-http\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: jaeger-configuration\n          items:\n          - key: agent\n            path: agent.yaml\n        name: jaeger-configuration-volume\n",
    "errors": []
  },
  {
    "id": "03878",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '14271'\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:1.18.1\n        args:\n        - --config-file=/conf/agent.yaml\n        volumeMounts:\n        - name: jaeger-configuration-volume\n          mountPath: /conf\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 14271\n          name: admin-http\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: jaeger-configuration\n          items:\n          - key: agent\n            path: agent.yaml\n        name: jaeger-configuration-volume\n",
    "errors": []
  },
  {
    "id": "03879",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '14271'\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:1.18.1\n        args:\n        - --config-file=/conf/agent.yaml\n        volumeMounts:\n        - name: jaeger-configuration-volume\n          mountPath: /conf\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 14271\n          name: admin-http\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: jaeger-configuration\n          items:\n          - key: agent\n            path: agent.yaml\n        name: jaeger-configuration-volume\n",
    "errors": []
  },
  {
    "id": "03880",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-aws-iam-controller\n  namespace: kube-system\n  labels:\n    application: kube-aws-iam-controller\n    version: latest\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      application: kube-aws-iam-controller\n  template:\n    metadata:\n      labels:\n        application: kube-aws-iam-controller\n        version: latest\n    spec:\n      serviceAccountName: kube-aws-iam-controller\n      containers:\n      - name: kube-aws-iam-controller\n        image: registry.opensource.zalan.do/teapot/kube-aws-iam-controller:stable\n        resources:\n          limits:\n            cpu: 25m\n            memory: 100Mi\n          requests:\n            cpu: 25m\n            memory: 100Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03881",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-aws-iam-controller\n  namespace: kube-system\n  labels:\n    application: kube-aws-iam-controller\n    version: latest\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      application: kube-aws-iam-controller\n  template:\n    metadata:\n      labels:\n        application: kube-aws-iam-controller\n        version: latest\n    spec:\n      serviceAccountName: kube-aws-iam-controller\n      containers:\n      - name: kube-aws-iam-controller\n        image: registry.opensource.zalan.do/teapot/kube-aws-iam-controller:stable\n        resources:\n          limits:\n            cpu: 25m\n            memory: 100Mi\n          requests:\n            cpu: 25m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03882",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-aws-iam-controller\n  namespace: kube-system\n  labels:\n    application: kube-aws-iam-controller\n    version: latest\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      application: kube-aws-iam-controller\n  template:\n    metadata:\n      labels:\n        application: kube-aws-iam-controller\n        version: latest\n    spec:\n      serviceAccountName: kube-aws-iam-controller\n      containers:\n      - name: kube-aws-iam-controller\n        image: registry.opensource.zalan.do/teapot/kube-aws-iam-controller:stable\n        resources:\n          limits:\n            cpu: 25m\n            memory: 100Mi\n          requests:\n            cpu: 25m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03883",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9766\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03884",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9766\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03885",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9766\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03886",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9766\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03887",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9766\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03888",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nsc-memif\n  labels:\n    app: nsc-memif\nspec:\n  selector:\n    matchLabels:\n      app: nsc-memif\n  template:\n    metadata:\n      labels:\n        app: nsc-memif\n    spec:\n      containers:\n      - name: nsc\n        image: networkservicemeshci/cmd-nsc-vpp:da4acb28\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NSM_REQUEST_TIMEOUT\n          value: 1m\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm-socket\n          mountPath: /var/lib/networkservicemesh\n          readOnly: true\n        resources:\n          limits:\n            memory: 400Mi\n            cpu: 500m\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm-socket\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "03889",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nsc-memif\n  labels:\n    app: nsc-memif\nspec:\n  selector:\n    matchLabels:\n      app: nsc-memif\n  template:\n    metadata:\n      labels:\n        app: nsc-memif\n    spec:\n      containers:\n      - name: nsc\n        image: networkservicemeshci/cmd-nsc-vpp:da4acb28\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NSM_REQUEST_TIMEOUT\n          value: 1m\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm-socket\n          mountPath: /var/lib/networkservicemesh\n          readOnly: true\n        resources:\n          limits:\n            memory: 400Mi\n            cpu: 500m\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm-socket\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "03890",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nsc-memif\n  labels:\n    app: nsc-memif\nspec:\n  selector:\n    matchLabels:\n      app: nsc-memif\n  template:\n    metadata:\n      labels:\n        app: nsc-memif\n    spec:\n      containers:\n      - name: nsc\n        image: networkservicemeshci/cmd-nsc-vpp:da4acb28\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NSM_REQUEST_TIMEOUT\n          value: 1m\n        - name: SPIFFE_ENDPOINT_SOCKET\n          value: unix:///run/spire/sockets/agent.sock\n        - name: NSM_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        volumeMounts:\n        - name: spire-agent-socket\n          mountPath: /run/spire/sockets\n          readOnly: true\n        - name: nsm-socket\n          mountPath: /var/lib/networkservicemesh\n          readOnly: true\n        resources:\n          limits:\n            memory: 400Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: spire-agent-socket\n        hostPath:\n          path: /run/spire/sockets\n          type: Directory\n      - name: nsm-socket\n        hostPath:\n          path: /var/lib/networkservicemesh\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "03891",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cadvisor\nspec:\n  replicas: 50\n  selector:\n    app: cadvisor\n  template:\n    metadata:\n      labels:\n        app: cadvisor\n    spec:\n      containers:\n      - name: cadvisor\n        image: google/cadvisor:v0.22.0\n        volumeMounts:\n        - name: rootfs\n          mountPath: /rootfs\n          readOnly: true\n        - name: var-run\n          mountPath: /var/run\n          readOnly: false\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        - name: docker\n          mountPath: /var/lib/docker\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        args:\n        - --profiling\n        - --housekeeping_interval=1s\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: rootfs\n        hostPath:\n          path: /\n      - name: var-run\n        hostPath:\n          path: /var/run\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: docker\n        hostPath:\n          path: /var/lib/docker\n",
    "errors": []
  },
  {
    "id": "03892",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cadvisor\nspec:\n  replicas: 50\n  selector:\n    app: cadvisor\n  template:\n    metadata:\n      labels:\n        app: cadvisor\n    spec:\n      containers:\n      - name: cadvisor\n        image: google/cadvisor:v0.22.0\n        volumeMounts:\n        - name: rootfs\n          mountPath: /rootfs\n          readOnly: true\n        - name: var-run\n          mountPath: /var/run\n          readOnly: false\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        - name: docker\n          mountPath: /var/lib/docker\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        args:\n        - --profiling\n        - --housekeeping_interval=1s\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: rootfs\n        hostPath:\n          path: /\n      - name: var-run\n        hostPath:\n          path: /var/run\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: docker\n        hostPath:\n          path: /var/lib/docker\n",
    "errors": []
  },
  {
    "id": "03893",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cadvisor\nspec:\n  replicas: 50\n  selector:\n    app: cadvisor\n  template:\n    metadata:\n      labels:\n        app: cadvisor\n    spec:\n      containers:\n      - name: cadvisor\n        image: google/cadvisor:v0.22.0\n        volumeMounts:\n        - name: rootfs\n          mountPath: /rootfs\n          readOnly: true\n        - name: var-run\n          mountPath: /var/run\n          readOnly: false\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        - name: docker\n          mountPath: /var/lib/docker\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        args:\n        - --profiling\n        - --housekeeping_interval=1s\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: rootfs\n        hostPath:\n          path: /\n      - name: var-run\n        hostPath:\n          path: /var/run\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: docker\n        hostPath:\n          path: /var/lib/docker\n",
    "errors": []
  },
  {
    "id": "03894",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cadvisor\nspec:\n  replicas: 50\n  selector:\n    app: cadvisor\n  template:\n    metadata:\n      labels:\n        app: cadvisor\n    spec:\n      containers:\n      - name: cadvisor\n        image: google/cadvisor:v0.22.0\n        volumeMounts:\n        - name: rootfs\n          mountPath: /rootfs\n          readOnly: true\n        - name: var-run\n          mountPath: /var/run\n          readOnly: false\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        - name: docker\n          mountPath: /var/lib/docker\n          readOnly: true\n        ports:\n        - name: http\n          containerPort: 8080\n          protocol: TCP\n        args:\n        - --profiling\n        - --housekeeping_interval=1s\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: rootfs\n        hostPath:\n          path: /\n      - name: var-run\n        hostPath:\n          path: /var/run\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: docker\n        hostPath:\n          path: /var/lib/docker\n",
    "errors": []
  },
  {
    "id": "03895",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: prometheus-operator\n    app.kubernetes.io/part-of: kube-prometheus\n    app.kubernetes.io/version: 0.51.1\n  name: prometheus-operator\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/name: prometheus-operator\n      app.kubernetes.io/part-of: kube-prometheus\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: prometheus-operator\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/name: prometheus-operator\n        app.kubernetes.io/part-of: kube-prometheus\n        app.kubernetes.io/version: 0.51.1\n    spec:\n      containers:\n      - args:\n        - --kubelet-service=kube-system/kubelet\n        - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.51.1\n        image: quay.io/prometheus-operator/prometheus-operator:v0.51.1\n        name: prometheus-operator\n        ports:\n        - containerPort: 8080\n          name: http\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8080/\n        image: quay.io/brancz/kube-rbac-proxy:v0.11.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        resources:\n          limits:\n            cpu: 20m\n            memory: 40Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsGroup: 65532\n          runAsNonRoot: true\n          runAsUser: 65532\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 65534\n      serviceAccountName: prometheus-operator\n",
    "errors": []
  },
  {
    "id": "03896",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: prometheus-operator\n    app.kubernetes.io/part-of: kube-prometheus\n    app.kubernetes.io/version: 0.51.1\n  name: prometheus-operator\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/name: prometheus-operator\n      app.kubernetes.io/part-of: kube-prometheus\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: prometheus-operator\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/name: prometheus-operator\n        app.kubernetes.io/part-of: kube-prometheus\n        app.kubernetes.io/version: 0.51.1\n    spec:\n      containers:\n      - args:\n        - --kubelet-service=kube-system/kubelet\n        - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.51.1\n        image: quay.io/prometheus-operator/prometheus-operator:v0.51.1\n        name: prometheus-operator\n        ports:\n        - containerPort: 8080\n          name: http\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - --upstream=http://127.0.0.1:8080/\n        image: quay.io/brancz/kube-rbac-proxy:v0.11.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        resources:\n          limits:\n            cpu: 20m\n            memory: 40Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsGroup: 65532\n          runAsNonRoot: true\n          runAsUser: 65532\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 65534\n      serviceAccountName: prometheus-operator\n",
    "errors": []
  },
  {
    "id": "03897",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "03898",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "03899",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "03900",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "03901",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "03902",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalog-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: catalog-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: catalog-operator\n  template:\n    metadata:\n      labels:\n        app: catalog-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: catalog-operator\n        command:\n        - /bin/catalog\n        args:\n        - -namespace\n        - openshift-marketplace\n        - -configmapServerImage=quay.io/operator-framework/configmap-operator-registry:latest\n        - -writeStatusName\n        - operator-lifecycle-manager-catalog\n        - -tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - -tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:93751ae9d398d571c2cb3d11b0ac4ae052117fd1726025364a6f2f3a5caef68e\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: catalog-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "03903",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalog-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: catalog-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: catalog-operator\n  template:\n    metadata:\n      labels:\n        app: catalog-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: catalog-operator\n        command:\n        - /bin/catalog\n        args:\n        - -namespace\n        - openshift-marketplace\n        - -configmapServerImage=quay.io/operator-framework/configmap-operator-registry:latest\n        - -writeStatusName\n        - operator-lifecycle-manager-catalog\n        - -tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - -tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:93751ae9d398d571c2cb3d11b0ac4ae052117fd1726025364a6f2f3a5caef68e\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: catalog-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "03904",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalog-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: catalog-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: catalog-operator\n  template:\n    metadata:\n      labels:\n        app: catalog-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: catalog-operator\n        command:\n        - /bin/catalog\n        args:\n        - -namespace\n        - openshift-marketplace\n        - -configmapServerImage=quay.io/operator-framework/configmap-operator-registry:latest\n        - -writeStatusName\n        - operator-lifecycle-manager-catalog\n        - -tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - -tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:93751ae9d398d571c2cb3d11b0ac4ae052117fd1726025364a6f2f3a5caef68e\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: catalog-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "03905",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalog-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: catalog-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: catalog-operator\n  template:\n    metadata:\n      labels:\n        app: catalog-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: catalog-operator\n        command:\n        - /bin/catalog\n        args:\n        - -namespace\n        - openshift-marketplace\n        - -configmapServerImage=quay.io/operator-framework/configmap-operator-registry:latest\n        - -writeStatusName\n        - operator-lifecycle-manager-catalog\n        - -tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - -tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:93751ae9d398d571c2cb3d11b0ac4ae052117fd1726025364a6f2f3a5caef68e\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: catalog-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "03906",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-users-allowed\n  labels:\n    app: nginx-users\nspec:\n  securityContext:\n    supplementalGroups:\n    - 199\n    fsGroup: 199\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsUser: 199\n      runAsGroup: 199\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03907",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-users-allowed\n  labels:\n    app: nginx-users\nspec:\n  securityContext:\n    supplementalGroups:\n    - 199\n    fsGroup: 199\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsUser: 199\n      runAsGroup: 199\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03908",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-users-allowed\n  labels:\n    app: nginx-users\nspec:\n  securityContext:\n    supplementalGroups:\n    - 199\n    fsGroup: 199\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsUser: 199\n      runAsGroup: 199\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03909",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-users-allowed\n  labels:\n    app: nginx-users\nspec:\n  securityContext:\n    supplementalGroups:\n    - 199\n    fsGroup: 199\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsUser: 199\n      runAsGroup: 199\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03910",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: general\n  name: ddns-updater-anagno-dev\nspec:\n  selector:\n    matchLabels:\n      app: ddns\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ddns\n    spec:\n      containers:\n      - name: ddns\n        image: anagno/gandi-ddns:0.3\n        env:\n        - name: DOMAIN\n          value: anagno.dev\n        - name: SUBDOMAIN\n          value: zh\n        - name: APIKEY\n          valueFrom:\n            secretKeyRef:\n              name: gandi\n              key: API_KEY\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03911",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: general\n  name: ddns-updater-anagno-dev\nspec:\n  selector:\n    matchLabels:\n      app: ddns\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ddns\n    spec:\n      containers:\n      - name: ddns\n        image: anagno/gandi-ddns:0.3\n        env:\n        - name: DOMAIN\n          value: anagno.dev\n        - name: SUBDOMAIN\n          value: zh\n        - name: APIKEY\n          valueFrom:\n            secretKeyRef:\n              name: gandi\n              key: API_KEY\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03912",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: general\n  name: ddns-updater-anagno-dev\nspec:\n  selector:\n    matchLabels:\n      app: ddns\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ddns\n    spec:\n      containers:\n      - name: ddns\n        image: anagno/gandi-ddns:0.3\n        env:\n        - name: DOMAIN\n          value: anagno.dev\n        - name: SUBDOMAIN\n          value: zh\n        - name: APIKEY\n          valueFrom:\n            secretKeyRef:\n              name: gandi\n              key: API_KEY\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03913",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: general\n  name: ddns-updater-anagno-dev\nspec:\n  selector:\n    matchLabels:\n      app: ddns\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ddns\n    spec:\n      containers:\n      - name: ddns\n        image: anagno/gandi-ddns:0.3\n        env:\n        - name: DOMAIN\n          value: anagno.dev\n        - name: SUBDOMAIN\n          value: zh\n        - name: APIKEY\n          valueFrom:\n            secretKeyRef:\n              name: gandi\n              key: API_KEY\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03914",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable SECRETS_secret_key must use secretKeyRef"
    ]
  },
  {
    "id": "03915",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable SECRETS_secret_key must use secretKeyRef"
    ]
  },
  {
    "id": "03916",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03917",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03918",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03919",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03920",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03921",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03922",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03923",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03924",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03925",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03926",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03927",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03928",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03929",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03930",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03931",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03932",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03933",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03934",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: zulip-1\n  labels:\n    version: 1.8.0-2\n    app: zulip\nspec:\n  replicas: 1\n  selector:\n    version: 1.8.0-2\n    app: zulip\n  template:\n    metadata:\n      labels:\n        version: 1.8.0-2\n        app: zulip\n    spec:\n      containers:\n      - name: redis\n        image: quay.io/sameersbn/redis:stable\n        resources:\n          limits:\n            cpu: 50m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - name: redis-persistent-storage\n          mountPath: /var/lib/redis\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: memcached\n        image: quay.io/sameersbn/memcached:stable\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: rabbitmq\n        image: rabbitmq:3.5.5\n        resources:\n          limits:\n            cpu: 75m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: RABBITMQ_DEFAULT_USER\n          value: zulip\n        - name: RABBITMQ_DEFAULT_PASS\n          value: zulip\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: postgresql\n        image: quay.io/galexrt/zulip-postgresql-tsearchextras:stable\n        resources:\n          limits:\n            cpu: 80m\n            memory: 768Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_NAME\n          value: zulip\n        - name: DB_USER\n          value: zulip\n        - name: DB_PASS\n          value: zulip\n        volumeMounts:\n        - name: postgresql-persistent-storage\n          mountPath: /var/lib/postgresql\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: zulip\n        image: quay.io/galexrt/zulip:1.8.0-2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 3584Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        env:\n        - name: DB_HOST\n          value: database\n        - name: MEMCACHED_HOST\n          value: memcached\n        - name: REDIS_HOST\n          value: redis\n        - name: RABBITMQ_HOST\n          value: rabbitmq\n        - name: ZULIP_AUTH_BACKENDS\n          value: EmailAuthBackend\n        - name: SECRETS_email_password\n          value: '123456789'\n        - name: SETTING_EXTERNAL_HOST\n          value: localhost\n        - name: SETTING_ZULIP_ADMINISTRATOR\n          value: admin@example.com\n        - name: SETTING_ADMIN_DOMAIN\n          value: zerbytes.net\n        - name: SETTING_NOREPLY_EMAIL_ADDRESS\n          value: noreply@example.com\n        - name: SETTING_DEFAULT_FROM_EMAIL\n          value: Zulip <noreply@example.com>\n        - name: SETTING_EMAIL_HOST\n          value: smtp.example.com\n        - name: SETTING_EMAIL_HOST_USER\n          value: noreply@example.com\n        - name: ZULIP_USER_EMAIL\n          value: example@example.com\n        - name: ZULIP_USER_DOMAIN\n          value: example.com\n        - name: ZULIP_USER_PASS\n          value: '123456789'\n        - name: SECRETS_secret_key\n          value: REPLCAE_WITH_SECURE_SECRET_KEY\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        volumeMounts:\n        - name: zulip-persistent-storage\n          mountPath: /data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: redis-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/redis\n      - name: postgresql-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/postgresql\n      - name: zulip-persistent-storage\n        hostPath:\n          path: /opt/docker/zulip/zulip\n",
    "errors": []
  },
  {
    "id": "03935",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: mysql-operator\n  template:\n    metadata:\n      labels:\n        name: mysql-operator\n    spec:\n      serviceAccountName: mysql-operator\n      containers:\n      - name: operator\n        image: olegim89/mysql-operator:v0.1\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03936",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: mysql-operator\n  template:\n    metadata:\n      labels:\n        name: mysql-operator\n    spec:\n      serviceAccountName: mysql-operator\n      containers:\n      - name: operator\n        image: olegim89/mysql-operator:v0.1\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03937",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: mysql-operator\n  template:\n    metadata:\n      labels:\n        name: mysql-operator\n    spec:\n      serviceAccountName: mysql-operator\n      containers:\n      - name: operator\n        image: olegim89/mysql-operator:v0.1\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03938",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: mysql-operator\n  template:\n    metadata:\n      labels:\n        name: mysql-operator\n    spec:\n      serviceAccountName: mysql-operator\n      containers:\n      - name: operator\n        image: olegim89/mysql-operator:v0.1\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03939",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: product-composite\nspec:\n  selector:\n    matchLabels:\n      app: product-composite\n  template:\n    metadata:\n      labels:\n        app: product-composite\n        version: v2\n    spec:\n      containers:\n      - name: comp\n        image: hands-on/product-composite-service:v2\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: docker,prod\n        resources:\n          requests:\n            memory: 200Mi\n          limits:\n            memory: 400Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03940",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: product-composite\nspec:\n  selector:\n    matchLabels:\n      app: product-composite\n  template:\n    metadata:\n      labels:\n        app: product-composite\n        version: v2\n    spec:\n      containers:\n      - name: comp\n        image: hands-on/product-composite-service:v2\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: docker,prod\n        resources:\n          requests:\n            memory: 200Mi\n          limits:\n            memory: 400Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03941",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: product-composite\nspec:\n  selector:\n    matchLabels:\n      app: product-composite\n  template:\n    metadata:\n      labels:\n        app: product-composite\n        version: v2\n    spec:\n      containers:\n      - name: comp\n        image: hands-on/product-composite-service:v2\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: docker,prod\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 100m\n          limits:\n            memory: 400Mi\n            cpu: 500m\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03942",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: akschallenge97396acr.azurecr.io/captureorder:cf1\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03943",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: akschallenge97396acr.azurecr.io/captureorder:cf1\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03944",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: querier\n    app.kubernetes.io/instance: observatorium-xyz\n    app.kubernetes.io/name: loki\n    app.kubernetes.io/part-of: observatorium\n    app.kubernetes.io/version: 2.2.0\n  name: observatorium-xyz-loki-querier\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: querier\n      app.kubernetes.io/instance: observatorium-xyz\n      app.kubernetes.io/name: loki\n      app.kubernetes.io/part-of: observatorium\n      loki.grafana.com/gossip: 'true'\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: querier\n        app.kubernetes.io/instance: observatorium-xyz\n        app.kubernetes.io/name: loki\n        app.kubernetes.io/part-of: observatorium\n        loki.grafana.com/gossip: 'true'\n    spec:\n      containers:\n      - args:\n        - -target=querier\n        - -config.file=/etc/loki/config/config.yaml\n        - -limits.per-user-override-config=/etc/loki/config/overrides.yaml\n        - -log.level=error\n        - -s3.url=$(S3_URL)\n        - -s3.force-path-style=true\n        - -distributor.replication-factor=1\n        env:\n        - name: S3_URL\n          valueFrom:\n            secretKeyRef:\n              key: endpoint\n              name: loki-objectstorage\n        image: docker.io/grafana/loki:2.2.0\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /metrics\n            port: 3100\n            scheme: HTTP\n          periodSeconds: 30\n        name: observatorium-xyz-loki-querier\n        ports:\n        - containerPort: 3100\n          name: metrics\n        - containerPort: 9095\n          name: grpc\n        - containerPort: 7946\n          name: gossip-ring\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 3100\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - mountPath: /etc/loki/config/\n          name: config\n          readOnly: false\n        - mountPath: /data\n          name: storage\n          readOnly: false\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: observatorium-xyz-loki\n        name: config\n",
    "errors": []
  },
  {
    "id": "03945",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: querier\n    app.kubernetes.io/instance: observatorium-xyz\n    app.kubernetes.io/name: loki\n    app.kubernetes.io/part-of: observatorium\n    app.kubernetes.io/version: 2.2.0\n  name: observatorium-xyz-loki-querier\n  namespace: observatorium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: querier\n      app.kubernetes.io/instance: observatorium-xyz\n      app.kubernetes.io/name: loki\n      app.kubernetes.io/part-of: observatorium\n      loki.grafana.com/gossip: 'true'\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: querier\n        app.kubernetes.io/instance: observatorium-xyz\n        app.kubernetes.io/name: loki\n        app.kubernetes.io/part-of: observatorium\n        loki.grafana.com/gossip: 'true'\n    spec:\n      containers:\n      - args:\n        - -target=querier\n        - -config.file=/etc/loki/config/config.yaml\n        - -limits.per-user-override-config=/etc/loki/config/overrides.yaml\n        - -log.level=error\n        - -s3.url=$(S3_URL)\n        - -s3.force-path-style=true\n        - -distributor.replication-factor=1\n        env:\n        - name: S3_URL\n          valueFrom:\n            secretKeyRef:\n              key: endpoint\n              name: loki-objectstorage\n        image: docker.io/grafana/loki:2.2.0\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /metrics\n            port: 3100\n            scheme: HTTP\n          periodSeconds: 30\n        name: observatorium-xyz-loki-querier\n        ports:\n        - containerPort: 3100\n          name: metrics\n        - containerPort: 9095\n          name: grpc\n        - containerPort: 7946\n          name: gossip-ring\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 3100\n            scheme: HTTP\n          initialDelaySeconds: 15\n          timeoutSeconds: 1\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - mountPath: /etc/loki/config/\n          name: config\n          readOnly: false\n        - mountPath: /data\n          name: storage\n          readOnly: false\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: observatorium-xyz-loki\n        name: config\n",
    "errors": []
  },
  {
    "id": "03946",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: failed-pod\nspec:\n  containers:\n  - name: motor\n    image: busybox:stable\n    resources:\n      limits:\n        cpu: 100m\n        memory: 16Mi\n      requests:\n        cpu: 100m\n        memory: 16Mi\n    command:\n    - sh\n    - -c\n    args:\n    - echo \"This is failed phase\"; exit 1\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03947",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: failed-pod\nspec:\n  containers:\n  - name: motor\n    image: busybox:stable\n    resources:\n      limits:\n        cpu: 100m\n        memory: 16Mi\n      requests:\n        cpu: 100m\n        memory: 16Mi\n    command:\n    - sh\n    - -c\n    args:\n    - echo \"This is failed phase\"; exit 1\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03948",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: failed-pod\nspec:\n  containers:\n  - name: motor\n    image: busybox:stable\n    resources:\n      limits:\n        cpu: 100m\n        memory: 16Mi\n      requests:\n        cpu: 100m\n        memory: 16Mi\n    command:\n    - sh\n    - -c\n    args:\n    - echo \"This is failed phase\"; exit 1\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03949",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: salesforce-connector\n  name: salesforce-connector\n  namespace: gfw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: salesforce-connector\n  template:\n    metadata:\n      labels:\n        name: salesforce-connector\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: type\n                operator: In\n                values:\n                - gfw\n      containers:\n      - args:\n        - start\n        env:\n        - name: PORT\n          value: '9500'\n        - name: LOGGER_TYPE\n          value: console\n        - name: LOGGER_LEVEL\n          value: debug\n        - name: NODE_ENV\n          value: staging\n        - name: NODE_PATH\n          value: app/src\n        - name: MICROSERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: MICROSERVICE_TOKEN\n              name: mssecrets\n        - name: GATEWAY_URL\n          valueFrom:\n            secretKeyRef:\n              key: GATEWAY_URL\n              name: mssecrets\n        - name: FASTLY_ENABLED\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_ENABLED\n              name: mssecrets\n        - name: FASTLY_APIKEY\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_APIKEY\n              name: mssecrets\n              optional: true\n        - name: FASTLY_SERVICEID\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_SERVICEID\n              name: mssecrets\n              optional: true\n        - name: SALESFORCE_URL\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_URL\n              name: mssecrets\n        - name: SALESFORCE_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_USERNAME\n              name: mssecrets\n        - name: SALESFORCE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_PASSWORD\n              name: mssecrets\n        image: gfwdockerhub/salesforce-connector:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthcheck\n            port: 9500\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: salesforce-connector\n        ports:\n        - containerPort: 9500\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthcheck\n            port: 9500\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: 350m\n            memory: 256M\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "03950",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: salesforce-connector\n  name: salesforce-connector\n  namespace: gfw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: salesforce-connector\n  template:\n    metadata:\n      labels:\n        name: salesforce-connector\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: type\n                operator: In\n                values:\n                - gfw\n      containers:\n      - args:\n        - start\n        env:\n        - name: PORT\n          value: '9500'\n        - name: LOGGER_TYPE\n          value: console\n        - name: LOGGER_LEVEL\n          value: debug\n        - name: NODE_ENV\n          value: staging\n        - name: NODE_PATH\n          value: app/src\n        - name: MICROSERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: MICROSERVICE_TOKEN\n              name: mssecrets\n        - name: GATEWAY_URL\n          valueFrom:\n            secretKeyRef:\n              key: GATEWAY_URL\n              name: mssecrets\n        - name: FASTLY_ENABLED\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_ENABLED\n              name: mssecrets\n        - name: FASTLY_APIKEY\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_APIKEY\n              name: mssecrets\n              optional: true\n        - name: FASTLY_SERVICEID\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_SERVICEID\n              name: mssecrets\n              optional: true\n        - name: SALESFORCE_URL\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_URL\n              name: mssecrets\n        - name: SALESFORCE_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_USERNAME\n              name: mssecrets\n        - name: SALESFORCE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_PASSWORD\n              name: mssecrets\n        image: gfwdockerhub/salesforce-connector:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthcheck\n            port: 9500\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: salesforce-connector\n        ports:\n        - containerPort: 9500\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthcheck\n            port: 9500\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: 350m\n            memory: 256M\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "03951",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: salesforce-connector\n  name: salesforce-connector\n  namespace: gfw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: salesforce-connector\n  template:\n    metadata:\n      labels:\n        name: salesforce-connector\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: type\n                operator: In\n                values:\n                - gfw\n      containers:\n      - args:\n        - start\n        env:\n        - name: PORT\n          value: '9500'\n        - name: LOGGER_TYPE\n          value: console\n        - name: LOGGER_LEVEL\n          value: debug\n        - name: NODE_ENV\n          value: staging\n        - name: NODE_PATH\n          value: app/src\n        - name: MICROSERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: MICROSERVICE_TOKEN\n              name: mssecrets\n        - name: GATEWAY_URL\n          valueFrom:\n            secretKeyRef:\n              key: GATEWAY_URL\n              name: mssecrets\n        - name: FASTLY_ENABLED\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_ENABLED\n              name: mssecrets\n        - name: FASTLY_APIKEY\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_APIKEY\n              name: mssecrets\n              optional: true\n        - name: FASTLY_SERVICEID\n          valueFrom:\n            secretKeyRef:\n              key: FASTLY_SERVICEID\n              name: mssecrets\n              optional: true\n        - name: SALESFORCE_URL\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_URL\n              name: mssecrets\n        - name: SALESFORCE_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_USERNAME\n              name: mssecrets\n        - name: SALESFORCE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: SALESFORCE_PASSWORD\n              name: mssecrets\n        image: gfwdockerhub/salesforce-connector:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthcheck\n            port: 9500\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: salesforce-connector\n        ports:\n        - containerPort: 9500\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthcheck\n            port: 9500\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: 350m\n            memory: 256M\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "03952",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: systemize-user-api\nspec:\n  selector:\n    matchLabels:\n      app: systemize-user-api\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: systemize-user-api\n    spec:\n      containers:\n      - name: systemize-user-api\n        image: systemize-user-api:stable\n        ports:\n        - containerPort: 3000\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          httpGet:\n            path: /health\n            port: 3000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03953",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: systemize-user-api\nspec:\n  selector:\n    matchLabels:\n      app: systemize-user-api\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: systemize-user-api\n    spec:\n      containers:\n      - name: systemize-user-api\n        image: systemize-user-api:stable\n        ports:\n        - containerPort: 3000\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          httpGet:\n            path: /health\n            port: 3000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03954",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: systemize-user-api\nspec:\n  selector:\n    matchLabels:\n      app: systemize-user-api\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: systemize-user-api\n    spec:\n      containers:\n      - name: systemize-user-api\n        image: systemize-user-api:stable\n        ports:\n        - containerPort: 3000\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          httpGet:\n            path: /health\n            port: 3000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03955",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: systemize-user-api\nspec:\n  selector:\n    matchLabels:\n      app: systemize-user-api\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: systemize-user-api\n    spec:\n      containers:\n      - name: systemize-user-api\n        image: systemize-user-api:stable\n        ports:\n        - containerPort: 3000\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          httpGet:\n            path: /health\n            port: 3000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03956",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: systemize-user-api\nspec:\n  selector:\n    matchLabels:\n      app: systemize-user-api\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: systemize-user-api\n    spec:\n      containers:\n      - name: systemize-user-api\n        image: systemize-user-api:stable\n        ports:\n        - containerPort: 3000\n        livenessProbe:\n          initialDelaySeconds: 20\n          periodSeconds: 5\n          httpGet:\n            path: /health\n            port: 3000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03957",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2476\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03958",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2476\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03959",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2476\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03960",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2476\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03961",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2476\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03962",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sensordeploy\n  labels:\n    app: sensorapp\nspec:\n  selector:\n    matchLabels:\n      app: sensorapp\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: sensorapp\n    spec:\n      containers:\n      - name: sensorapp\n        image: 03021994/sensor:stable\n        command:\n        - python\n        - ./app/sensor-test.py\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        - containerPort: 8083\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 50m\n          limits:\n            memory: 256Mi\n            cpu: 500m\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03963",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sensordeploy\n  labels:\n    app: sensorapp\nspec:\n  selector:\n    matchLabels:\n      app: sensorapp\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: sensorapp\n    spec:\n      containers:\n      - name: sensorapp\n        image: 03021994/sensor:stable\n        command:\n        - python\n        - ./app/sensor-test.py\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        - containerPort: 8083\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 50m\n          limits:\n            memory: 256Mi\n            cpu: 500m\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03964",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sensordeploy\n  labels:\n    app: sensorapp\nspec:\n  selector:\n    matchLabels:\n      app: sensorapp\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: sensorapp\n    spec:\n      containers:\n      - name: sensorapp\n        image: 03021994/sensor:stable\n        command:\n        - python\n        - ./app/sensor-test.py\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 5000\n        - containerPort: 8083\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 50m\n          limits:\n            memory: 256Mi\n            cpu: 500m\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03965",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: percona-xtradb-cluster-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: operator\n      app.kubernetes.io/instance: percona-xtradb-cluster-operator\n      app.kubernetes.io/name: percona-xtradb-cluster-operator\n      app.kubernetes.io/part-of: percona-xtradb-cluster-operator\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: operator\n        app.kubernetes.io/instance: percona-xtradb-cluster-operator\n        app.kubernetes.io/name: percona-xtradb-cluster-operator\n        app.kubernetes.io/part-of: percona-xtradb-cluster-operator\n    spec:\n      containers:\n      - command:\n        - percona-xtradb-cluster-operator\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: percona-xtradb-cluster-operator\n        image: perconalab/percona-xtradb-cluster-operator:main\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /metrics\n            port: metrics\n            scheme: HTTP\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        name: percona-xtradb-cluster-operator\n        ports:\n        - containerPort: 8080\n          name: metrics\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccountName: percona-xtradb-cluster-operator\n",
    "errors": []
  },
  {
    "id": "03966",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: percona-xtradb-cluster-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: operator\n      app.kubernetes.io/instance: percona-xtradb-cluster-operator\n      app.kubernetes.io/name: percona-xtradb-cluster-operator\n      app.kubernetes.io/part-of: percona-xtradb-cluster-operator\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: operator\n        app.kubernetes.io/instance: percona-xtradb-cluster-operator\n        app.kubernetes.io/name: percona-xtradb-cluster-operator\n        app.kubernetes.io/part-of: percona-xtradb-cluster-operator\n    spec:\n      containers:\n      - command:\n        - percona-xtradb-cluster-operator\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: percona-xtradb-cluster-operator\n        image: perconalab/percona-xtradb-cluster-operator:main\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /metrics\n            port: metrics\n            scheme: HTTP\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        name: percona-xtradb-cluster-operator\n        ports:\n        - containerPort: 8080\n          name: metrics\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccountName: percona-xtradb-cluster-operator\n",
    "errors": []
  },
  {
    "id": "03967",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20201015-deb1bd1036\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03968",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20201015-deb1bd1036\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03969",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20201015-deb1bd1036\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03970",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20201015-deb1bd1036\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03971",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03972",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03973",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03974",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03975",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03976",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibms-deployment\n  labels:\n    app: ibms-uat\nspec:\n  selector:\n    matchLabels:\n      app: ibms-uat\n  template:\n    metadata:\n      labels:\n        app: ibms-uat\n    spec:\n      containers:\n      - name: ibms\n        image: ghcr.io/dbca-wa/ibms:stable\n        imagePullPolicy: Always\n        env:\n        - name: IBMS_URL\n          value: https://ibms-uat.dbca.wa.gov.au\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: DATABASE_URL\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: SECRET_KEY\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03977",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibms-deployment\n  labels:\n    app: ibms-uat\nspec:\n  selector:\n    matchLabels:\n      app: ibms-uat\n  template:\n    metadata:\n      labels:\n        app: ibms-uat\n    spec:\n      containers:\n      - name: ibms\n        image: ghcr.io/dbca-wa/ibms:stable\n        imagePullPolicy: Always\n        env:\n        - name: IBMS_URL\n          value: https://ibms-uat.dbca.wa.gov.au\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: DATABASE_URL\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: SECRET_KEY\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03978",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibms-deployment\n  labels:\n    app: ibms-uat\nspec:\n  selector:\n    matchLabels:\n      app: ibms-uat\n  template:\n    metadata:\n      labels:\n        app: ibms-uat\n    spec:\n      containers:\n      - name: ibms\n        image: ghcr.io/dbca-wa/ibms:stable\n        imagePullPolicy: Always\n        env:\n        - name: IBMS_URL\n          value: https://ibms-uat.dbca.wa.gov.au\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: DATABASE_URL\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: SECRET_KEY\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03979",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibms-deployment\n  labels:\n    app: ibms-uat\nspec:\n  selector:\n    matchLabels:\n      app: ibms-uat\n  template:\n    metadata:\n      labels:\n        app: ibms-uat\n    spec:\n      containers:\n      - name: ibms\n        image: ghcr.io/dbca-wa/ibms:stable\n        imagePullPolicy: Always\n        env:\n        - name: IBMS_URL\n          value: https://ibms-uat.dbca.wa.gov.au\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: DATABASE_URL\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: SECRET_KEY\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03980",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibms-deployment\n  labels:\n    app: ibms-uat\nspec:\n  selector:\n    matchLabels:\n      app: ibms-uat\n  template:\n    metadata:\n      labels:\n        app: ibms-uat\n    spec:\n      containers:\n      - name: ibms\n        image: ghcr.io/dbca-wa/ibms:stable\n        imagePullPolicy: Always\n        env:\n        - name: IBMS_URL\n          value: https://ibms-uat.dbca.wa.gov.au\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: DATABASE_URL\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: ibms-env-uat\n              key: SECRET_KEY\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03981",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3123\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03982",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3123\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03983",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3123\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03984",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3123\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03985",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3123\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "03986",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03987",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03988",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03989",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03990",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03991",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03992",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03993",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03994",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03995",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03996",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03997",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03998",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --container-runtime=crio\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/crio/crio.sock\n          name: crio-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /var/run/crio/crio.sock\n          type: Socket\n        name: crio-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "03999",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: a337134d0e64ec21fde04859d87d697b47666d6c4d404b7e8f1eb39a41ffc05d\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: ranggaperwiratama\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 46bcf702811226edac90b77c43cdbfec99bc6fe6\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04000",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: a337134d0e64ec21fde04859d87d697b47666d6c4d404b7e8f1eb39a41ffc05d\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: ranggaperwiratama\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 46bcf702811226edac90b77c43cdbfec99bc6fe6\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04001",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9889\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04002",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9889\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04003",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9889\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04004",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9889\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04005",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9889\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04006",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rollem-prod-20-deployment\nspec:\n  selector:\n    matchLabels:\n      app: rollem-prod\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: rollem-prod\n    spec:\n      containers:\n      - name: rollem-shard-20\n        image: lemtzas/rollem-discord:2.6.4\n        resources:\n          requests:\n            cpu: 50m\n            memory: 250M\n        env:\n        - name: reboot\n          value: '2021-04-20'\n        - name: DISCORD_BOT_SHARD_ID\n          value: '20'\n        - name: DISCORD_BOT_SHARD_COUNT\n          value: '50'\n        - name: DISCORD_BOT_USER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DISCORD_BOT_USER_TOKEN\n        - name: APPINSIGHTS_CONNECTIONSTRING\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: APPINSIGHTS_CONNECTIONSTRING\n        - name: DEFER_TO_CLIENT_IDS\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DEFER_TO_CLIENT_IDS\n        - name: DB_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DB_CONNECTION_STRING\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04007",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rollem-prod-20-deployment\nspec:\n  selector:\n    matchLabels:\n      app: rollem-prod\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: rollem-prod\n    spec:\n      containers:\n      - name: rollem-shard-20\n        image: lemtzas/rollem-discord:2.6.4\n        resources:\n          requests:\n            cpu: 50m\n            memory: 250M\n        env:\n        - name: reboot\n          value: '2021-04-20'\n        - name: DISCORD_BOT_SHARD_ID\n          value: '20'\n        - name: DISCORD_BOT_SHARD_COUNT\n          value: '50'\n        - name: DISCORD_BOT_USER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DISCORD_BOT_USER_TOKEN\n        - name: APPINSIGHTS_CONNECTIONSTRING\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: APPINSIGHTS_CONNECTIONSTRING\n        - name: DEFER_TO_CLIENT_IDS\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DEFER_TO_CLIENT_IDS\n        - name: DB_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DB_CONNECTION_STRING\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04008",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rollem-prod-20-deployment\nspec:\n  selector:\n    matchLabels:\n      app: rollem-prod\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: rollem-prod\n    spec:\n      containers:\n      - name: rollem-shard-20\n        image: lemtzas/rollem-discord:2.6.4\n        resources:\n          requests:\n            cpu: 50m\n            memory: 250M\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: reboot\n          value: '2021-04-20'\n        - name: DISCORD_BOT_SHARD_ID\n          value: '20'\n        - name: DISCORD_BOT_SHARD_COUNT\n          value: '50'\n        - name: DISCORD_BOT_USER_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DISCORD_BOT_USER_TOKEN\n        - name: APPINSIGHTS_CONNECTIONSTRING\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: APPINSIGHTS_CONNECTIONSTRING\n        - name: DEFER_TO_CLIENT_IDS\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DEFER_TO_CLIENT_IDS\n        - name: DB_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: rollem-prod-2\n              key: DB_CONNECTION_STRING\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04009",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: digilocker-support-api\n  name: digilocker-support-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: digilocker-support-api\n  template:\n    metadata:\n      labels:\n        k8s-app: digilocker-support-api\n    spec:\n      containers:\n      - image: REGISTRY/digilocker_support_api:stable\n        imagePullPolicy: Always\n        name: digilocker-support-api\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04010",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: digilocker-support-api\n  name: digilocker-support-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: digilocker-support-api\n  template:\n    metadata:\n      labels:\n        k8s-app: digilocker-support-api\n    spec:\n      containers:\n      - image: REGISTRY/digilocker_support_api:stable\n        imagePullPolicy: Always\n        name: digilocker-support-api\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04011",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: digilocker-support-api\n  name: digilocker-support-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: digilocker-support-api\n  template:\n    metadata:\n      labels:\n        k8s-app: digilocker-support-api\n    spec:\n      containers:\n      - image: REGISTRY/digilocker_support_api:stable\n        imagePullPolicy: Always\n        name: digilocker-support-api\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04012",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: digilocker-support-api\n  name: digilocker-support-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: digilocker-support-api\n  template:\n    metadata:\n      labels:\n        k8s-app: digilocker-support-api\n    spec:\n      containers:\n      - image: REGISTRY/digilocker_support_api:stable\n        imagePullPolicy: Always\n        name: digilocker-support-api\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04013",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    k8s-app: digilocker-support-api\n  name: digilocker-support-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: digilocker-support-api\n  template:\n    metadata:\n      labels:\n        k8s-app: digilocker-support-api\n    spec:\n      containers:\n      - image: REGISTRY/digilocker_support_api:stable\n        imagePullPolicy: Always\n        name: digilocker-support-api\n        envFrom:\n        - configMapRef:\n            name: divoc-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04014",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04015",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04016",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04017",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04018",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: smtp\n  name: smtp\n  namespace: utils\nspec:\n  selector:\n    matchLabels:\n      app: smtp\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: smtp\n    spec:\n      containers:\n      - image: devture/exim-relay:4.94.2-r0-3\n        imagePullPolicy: Always\n        name: smtp\n        env:\n        - name: TZ\n          value: Europe/Zurich\n        - name: smtp.int.eighty-three.me\n        - name: SMARTHOST\n          value: smtp.sendgrid.net::587\n        - name: SMTP_USERNAME\n          value: apikey\n        - name: SMTP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: smtp-password\n              key: password\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n          limits:\n            cpu: 400m\n            memory: 100Mi\n        ports:\n        - containerPort: 8025\n        livenessProbe:\n          exec:\n            command:\n            - exim\n            - -bt\n            - test@tuxpeople.org\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04019",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: smtp\n  name: smtp\n  namespace: utils\nspec:\n  selector:\n    matchLabels:\n      app: smtp\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: smtp\n    spec:\n      containers:\n      - image: devture/exim-relay:4.94.2-r0-3\n        imagePullPolicy: Always\n        name: smtp\n        env:\n        - name: TZ\n          value: Europe/Zurich\n        - name: smtp.int.eighty-three.me\n        - name: SMARTHOST\n          value: smtp.sendgrid.net::587\n        - name: SMTP_USERNAME\n          value: apikey\n        - name: SMTP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: smtp-password\n              key: password\n        resources:\n          requests:\n            cpu: 10m\n            memory: 10Mi\n          limits:\n            cpu: 400m\n            memory: 100Mi\n        ports:\n        - containerPort: 8025\n        livenessProbe:\n          exec:\n            command:\n            - exim\n            - -bt\n            - test@tuxpeople.org\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04020",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: motive-back-end-deployment\nspec:\n  template:\n    metadata:\n      name: motive-back-end-pod\n      labels:\n        app: motive-back-end\n    spec:\n      containers:\n      - name: motive-back-end-container\n        image: $FULL_IMAGE:stable\n        imagePullPolicy: Always\n        env:\n        - name: DATABASE_URL\n          value: $DATABASE_JDBC_URL\n        - name: DATABASE_USERNAME\n          valueFrom:\n            configMapKeyRef:\n              name: motive-config\n              key: postgres-username\n              optional: false\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: $APP_DATABASE_NAME-postgresql\n              key: postgres-password\n              optional: false\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        livenessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n  replicas: 2\n  selector:\n    matchLabels:\n      app: motive-back-end\n",
    "errors": []
  },
  {
    "id": "04021",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: motive-back-end-deployment\nspec:\n  template:\n    metadata:\n      name: motive-back-end-pod\n      labels:\n        app: motive-back-end\n    spec:\n      containers:\n      - name: motive-back-end-container\n        image: $FULL_IMAGE:stable\n        imagePullPolicy: Always\n        env:\n        - name: DATABASE_URL\n          value: $DATABASE_JDBC_URL\n        - name: DATABASE_USERNAME\n          valueFrom:\n            configMapKeyRef:\n              name: motive-config\n              key: postgres-username\n              optional: false\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: $APP_DATABASE_NAME-postgresql\n              key: postgres-password\n              optional: false\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        livenessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n  replicas: 2\n  selector:\n    matchLabels:\n      app: motive-back-end\n",
    "errors": []
  },
  {
    "id": "04022",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: motive-back-end-deployment\nspec:\n  template:\n    metadata:\n      name: motive-back-end-pod\n      labels:\n        app: motive-back-end\n    spec:\n      containers:\n      - name: motive-back-end-container\n        image: $FULL_IMAGE:stable\n        imagePullPolicy: Always\n        env:\n        - name: DATABASE_URL\n          value: $DATABASE_JDBC_URL\n        - name: DATABASE_USERNAME\n          valueFrom:\n            configMapKeyRef:\n              name: motive-config\n              key: postgres-username\n              optional: false\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: $APP_DATABASE_NAME-postgresql\n              key: postgres-password\n              optional: false\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        livenessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n  replicas: 2\n  selector:\n    matchLabels:\n      app: motive-back-end\n",
    "errors": []
  },
  {
    "id": "04023",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: motive-back-end-deployment\nspec:\n  template:\n    metadata:\n      name: motive-back-end-pod\n      labels:\n        app: motive-back-end\n    spec:\n      containers:\n      - name: motive-back-end-container\n        image: $FULL_IMAGE:stable\n        imagePullPolicy: Always\n        env:\n        - name: DATABASE_URL\n          value: $DATABASE_JDBC_URL\n        - name: DATABASE_USERNAME\n          valueFrom:\n            configMapKeyRef:\n              name: motive-config\n              key: postgres-username\n              optional: false\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: $APP_DATABASE_NAME-postgresql\n              key: postgres-password\n              optional: false\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        livenessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n  replicas: 2\n  selector:\n    matchLabels:\n      app: motive-back-end\n",
    "errors": []
  },
  {
    "id": "04024",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: motive-back-end-deployment\nspec:\n  template:\n    metadata:\n      name: motive-back-end-pod\n      labels:\n        app: motive-back-end\n    spec:\n      containers:\n      - name: motive-back-end-container\n        image: $FULL_IMAGE:stable\n        imagePullPolicy: Always\n        env:\n        - name: DATABASE_URL\n          value: $DATABASE_JDBC_URL\n        - name: DATABASE_USERNAME\n          valueFrom:\n            configMapKeyRef:\n              name: motive-config\n              key: postgres-username\n              optional: false\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: $APP_DATABASE_NAME-postgresql\n              key: postgres-password\n              optional: false\n        ports:\n        - containerPort: 8080\n        readinessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        livenessProbe:\n          initialDelaySeconds: 120\n          httpGet:\n            port: 8080\n            path: /actuator/health\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n  replicas: 2\n  selector:\n    matchLabels:\n      app: motive-back-end\n",
    "errors": []
  },
  {
    "id": "04025",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-sriov-device-plugin-amd64\n  namespace: kube-system\n  labels:\n    tier: node\n    app: sriovdp\nspec:\n  selector:\n    matchLabels:\n      name: sriov-device-plugin\n  template:\n    metadata:\n      labels:\n        name: sriov-device-plugin\n        tier: node\n        app: sriovdp\n    spec:\n      serviceAccountName: sriov-device-plugin\n      containers:\n      - name: kube-sriovdp\n        image: docker.io/nfvpe/sriov-device-plugin:v3.1\n        imagePullPolicy: Never\n        args:\n        - --log-dir=sriovdp\n        - --log-level=10\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: devicesock\n          mountPath: /var/lib/kubelet/\n          readOnly: false\n        - name: log\n          mountPath: /var/log\n        - name: config-volume\n          mountPath: /etc/pcidp\n      volumes:\n      - name: devicesock\n        hostPath:\n          path: /var/lib/kubelet/\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: config-volume\n        configMap:\n          name: sriovdp-config\n          items:\n          - key: config.json\n            path: config.json\n",
    "errors": []
  },
  {
    "id": "04026",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-sriov-device-plugin-amd64\n  namespace: kube-system\n  labels:\n    tier: node\n    app: sriovdp\nspec:\n  selector:\n    matchLabels:\n      name: sriov-device-plugin\n  template:\n    metadata:\n      labels:\n        name: sriov-device-plugin\n        tier: node\n        app: sriovdp\n    spec:\n      serviceAccountName: sriov-device-plugin\n      containers:\n      - name: kube-sriovdp\n        image: docker.io/nfvpe/sriov-device-plugin:v3.1\n        imagePullPolicy: Never\n        args:\n        - --log-dir=sriovdp\n        - --log-level=10\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: devicesock\n          mountPath: /var/lib/kubelet/\n          readOnly: false\n        - name: log\n          mountPath: /var/log\n        - name: config-volume\n          mountPath: /etc/pcidp\n      volumes:\n      - name: devicesock\n        hostPath:\n          path: /var/lib/kubelet/\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: config-volume\n        configMap:\n          name: sriovdp-config\n          items:\n          - key: config.json\n            path: config.json\n",
    "errors": []
  },
  {
    "id": "04027",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-sriov-device-plugin-amd64\n  namespace: kube-system\n  labels:\n    tier: node\n    app: sriovdp\nspec:\n  selector:\n    matchLabels:\n      name: sriov-device-plugin\n  template:\n    metadata:\n      labels:\n        name: sriov-device-plugin\n        tier: node\n        app: sriovdp\n    spec:\n      serviceAccountName: sriov-device-plugin\n      containers:\n      - name: kube-sriovdp\n        image: docker.io/nfvpe/sriov-device-plugin:v3.1\n        imagePullPolicy: Never\n        args:\n        - --log-dir=sriovdp\n        - --log-level=10\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: devicesock\n          mountPath: /var/lib/kubelet/\n          readOnly: false\n        - name: log\n          mountPath: /var/log\n        - name: config-volume\n          mountPath: /etc/pcidp\n      volumes:\n      - name: devicesock\n        hostPath:\n          path: /var/lib/kubelet/\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: config-volume\n        configMap:\n          name: sriovdp-config\n          items:\n          - key: config.json\n            path: config.json\n",
    "errors": []
  },
  {
    "id": "04028",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-sriov-device-plugin-amd64\n  namespace: kube-system\n  labels:\n    tier: node\n    app: sriovdp\nspec:\n  selector:\n    matchLabels:\n      name: sriov-device-plugin\n  template:\n    metadata:\n      labels:\n        name: sriov-device-plugin\n        tier: node\n        app: sriovdp\n    spec:\n      serviceAccountName: sriov-device-plugin\n      containers:\n      - name: kube-sriovdp\n        image: docker.io/nfvpe/sriov-device-plugin:v3.1\n        imagePullPolicy: Never\n        args:\n        - --log-dir=sriovdp\n        - --log-level=10\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: devicesock\n          mountPath: /var/lib/kubelet/\n          readOnly: false\n        - name: log\n          mountPath: /var/log\n        - name: config-volume\n          mountPath: /etc/pcidp\n      volumes:\n      - name: devicesock\n        hostPath:\n          path: /var/lib/kubelet/\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: config-volume\n        configMap:\n          name: sriovdp-config\n          items:\n          - key: config.json\n            path: config.json\n",
    "errors": []
  },
  {
    "id": "04029",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-sriov-device-plugin-amd64\n  namespace: kube-system\n  labels:\n    tier: node\n    app: sriovdp\nspec:\n  selector:\n    matchLabels:\n      name: sriov-device-plugin\n  template:\n    metadata:\n      labels:\n        name: sriov-device-plugin\n        tier: node\n        app: sriovdp\n    spec:\n      serviceAccountName: sriov-device-plugin\n      containers:\n      - name: kube-sriovdp\n        image: docker.io/nfvpe/sriov-device-plugin:v3.1\n        imagePullPolicy: Never\n        args:\n        - --log-dir=sriovdp\n        - --log-level=10\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: devicesock\n          mountPath: /var/lib/kubelet/\n          readOnly: false\n        - name: log\n          mountPath: /var/log\n        - name: config-volume\n          mountPath: /etc/pcidp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: devicesock\n        hostPath:\n          path: /var/lib/kubelet/\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: config-volume\n        configMap:\n          name: sriovdp-config\n          items:\n          - key: config.json\n            path: config.json\n",
    "errors": []
  },
  {
    "id": "04030",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-sriov-device-plugin-amd64\n  namespace: kube-system\n  labels:\n    tier: node\n    app: sriovdp\nspec:\n  selector:\n    matchLabels:\n      name: sriov-device-plugin\n  template:\n    metadata:\n      labels:\n        name: sriov-device-plugin\n        tier: node\n        app: sriovdp\n    spec:\n      serviceAccountName: sriov-device-plugin\n      containers:\n      - name: kube-sriovdp\n        image: docker.io/nfvpe/sriov-device-plugin:v3.1\n        imagePullPolicy: Never\n        args:\n        - --log-dir=sriovdp\n        - --log-level=10\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - name: devicesock\n          mountPath: /var/lib/kubelet/\n          readOnly: false\n        - name: log\n          mountPath: /var/log\n        - name: config-volume\n          mountPath: /etc/pcidp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: devicesock\n        hostPath:\n          path: /var/lib/kubelet/\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: config-volume\n        configMap:\n          name: sriovdp-config\n          items:\n          - key: config.json\n            path: config.json\n",
    "errors": []
  },
  {
    "id": "04031",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04032",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04033",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04034",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04035",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04036",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04037",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04038",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04039",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04040",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04041",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n            cpu: 500m\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n            cpu: 500m\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04042",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: testground-daemon\n  labels:\n    app: testground-daemon\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: testground-daemon\n  template:\n    metadata:\n      labels:\n        app: testground-daemon\n    spec:\n      serviceAccountName: testground-daemon\n      initContainers:\n      - name: iproute-add\n        image: busybox:1.31.1\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        command:\n        - sh\n        - -ac\n        - 'while [ \"$GW\" = \"\" ]; do export GW=$(ip route | grep cni0 | awk ''{print\n          $7}''); echo \"Got GW: $GW\"; sleep 5; done; echo $GW && ip route && ip route\n          add 100.64.0.0/16 via $GW && ip route || true;\n\n          '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: goproxy\n        image: iptestground/goproxy:2.0.2\n        ports:\n        - containerPort: 8081\n          hostPort: 8081\n        volumeMounts:\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        - name: efs-pvc\n          mountPath: /go\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 500m\n          limits:\n            memory: 512Mi\n            cpu: 500m\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: testground-daemon\n        image: iptestground/testground:edge\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOST\n          value: testground-infra-redis-headless\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        ports:\n        - containerPort: 8042\n          hostPort: 8042\n        volumeMounts:\n        - name: daemon-datadir\n          mountPath: /root/testground/\n        - name: efs-pvc\n          mountPath: /efs\n        - name: dockersock\n          mountPath: /var/run/docker.sock\n        - name: envtoml\n          mountPath: /root/testground/.env.toml\n          subPath: .env.toml\n        resources:\n          requests:\n            memory: 2048Mi\n            cpu: 2000m\n          limits:\n            memory: 2048Mi\n            cpu: 500m\n      volumes:\n      - name: efs-pvc\n        persistentVolumeClaim:\n          claimName: efs\n      - name: daemon-datadir\n        persistentVolumeClaim:\n          claimName: testground-daemon-datadir-pvc\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n      - name: envtoml\n        configMap:\n          name: env-toml-cfg\n",
    "errors": []
  },
  {
    "id": "04043",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: shippingservice\nspec:\n  selector:\n    matchLabels:\n      app: shippingservice\n  template:\n    metadata:\n      labels:\n        app: shippingservice\n    spec:\n      containers:\n      - name: server\n        image: shippingservice:stable\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        readinessProbe:\n          periodSeconds: 5\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:50051\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:50051\n        resources:\n          requests:\n            cpu: 100m\n            memory: 64Mi\n          limits:\n            cpu: 200m\n            memory: 128Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04044",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: shippingservice\nspec:\n  selector:\n    matchLabels:\n      app: shippingservice\n  template:\n    metadata:\n      labels:\n        app: shippingservice\n    spec:\n      containers:\n      - name: server\n        image: shippingservice:stable\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        readinessProbe:\n          periodSeconds: 5\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:50051\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:50051\n        resources:\n          requests:\n            cpu: 100m\n            memory: 64Mi\n          limits:\n            cpu: 200m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04045",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: shippingservice\nspec:\n  selector:\n    matchLabels:\n      app: shippingservice\n  template:\n    metadata:\n      labels:\n        app: shippingservice\n    spec:\n      containers:\n      - name: server\n        image: shippingservice:stable\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        readinessProbe:\n          periodSeconds: 5\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:50051\n        livenessProbe:\n          exec:\n            command:\n            - /bin/grpc_health_probe\n            - -addr=:50051\n        resources:\n          requests:\n            cpu: 100m\n            memory: 64Mi\n          limits:\n            cpu: 200m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04046",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: strimzi-user-operator\n  labels:\n    app: strimzi\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: strimzi-user-operator\n  template:\n    metadata:\n      labels:\n        name: strimzi-user-operator\n    spec:\n      serviceAccountName: strimzi-user-operator\n      containers:\n      - name: strimzi-user-operator\n        image: quay.io/strimzi/operator:0.25.0\n        args:\n        - /opt/strimzi/bin/user_operator_run.sh\n        env:\n        - name: STRIMZI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_LABELS\n          value: strimzi.io/cluster=my-cluster\n        - name: STRIMZI_CA_CERT_NAME\n          value: my-cluster-clients-ca-cert\n        - name: STRIMZI_CA_KEY_NAME\n          value: my-cluster-clients-ca\n        - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS\n          value: '120000'\n        - name: STRIMZI_LOG_LEVEL\n          value: INFO\n        - name: STRIMZI_GC_LOG_ENABLED\n          value: 'true'\n        - name: STRIMZI_CA_VALIDITY\n          value: '365'\n        - name: STRIMZI_CA_RENEWAL\n          value: '30'\n        livenessProbe:\n          httpGet:\n            path: /healthy\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        resources:\n          limits:\n            memory: 256Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04047",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: strimzi-user-operator\n  labels:\n    app: strimzi\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: strimzi-user-operator\n  template:\n    metadata:\n      labels:\n        name: strimzi-user-operator\n    spec:\n      serviceAccountName: strimzi-user-operator\n      containers:\n      - name: strimzi-user-operator\n        image: quay.io/strimzi/operator:0.25.0\n        args:\n        - /opt/strimzi/bin/user_operator_run.sh\n        env:\n        - name: STRIMZI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_LABELS\n          value: strimzi.io/cluster=my-cluster\n        - name: STRIMZI_CA_CERT_NAME\n          value: my-cluster-clients-ca-cert\n        - name: STRIMZI_CA_KEY_NAME\n          value: my-cluster-clients-ca\n        - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS\n          value: '120000'\n        - name: STRIMZI_LOG_LEVEL\n          value: INFO\n        - name: STRIMZI_GC_LOG_ENABLED\n          value: 'true'\n        - name: STRIMZI_CA_VALIDITY\n          value: '365'\n        - name: STRIMZI_CA_RENEWAL\n          value: '30'\n        livenessProbe:\n          httpGet:\n            path: /healthy\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        resources:\n          limits:\n            memory: 256Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04048",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sistema-noticias-statefulset\nspec:\n  selector:\n    matchLabels:\n      app: sistema-noticias\n  template:\n    metadata:\n      name: sistema-noticias\n      labels:\n        app: sistema-noticias\n    spec:\n      containers:\n      - name: sistema-noticias\n        image: aluracursos/sistema-noticias:1\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: sistema-noticias-config-map\n        volumeMounts:\n        - mountPath: /var/www/html/uploads\n          name: imagens-pvc\n        - mountPath: /tmp\n          name: sessao-pvc\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: imagens-pvc\n        persistentVolumeClaim:\n          claimName: imagens-pvc\n      - name: sessao-pvc\n        persistentVolumeClaim:\n          claimName: sessao-pvc\n",
    "errors": []
  },
  {
    "id": "04049",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sistema-noticias-statefulset\nspec:\n  selector:\n    matchLabels:\n      app: sistema-noticias\n  template:\n    metadata:\n      name: sistema-noticias\n      labels:\n        app: sistema-noticias\n    spec:\n      containers:\n      - name: sistema-noticias\n        image: aluracursos/sistema-noticias:1\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: sistema-noticias-config-map\n        volumeMounts:\n        - mountPath: /var/www/html/uploads\n          name: imagens-pvc\n        - mountPath: /tmp\n          name: sessao-pvc\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: imagens-pvc\n        persistentVolumeClaim:\n          claimName: imagens-pvc\n      - name: sessao-pvc\n        persistentVolumeClaim:\n          claimName: sessao-pvc\n",
    "errors": []
  },
  {
    "id": "04050",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sistema-noticias-statefulset\nspec:\n  selector:\n    matchLabels:\n      app: sistema-noticias\n  template:\n    metadata:\n      name: sistema-noticias\n      labels:\n        app: sistema-noticias\n    spec:\n      containers:\n      - name: sistema-noticias\n        image: aluracursos/sistema-noticias:1\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: sistema-noticias-config-map\n        volumeMounts:\n        - mountPath: /var/www/html/uploads\n          name: imagens-pvc\n        - mountPath: /tmp\n          name: sessao-pvc\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: imagens-pvc\n        persistentVolumeClaim:\n          claimName: imagens-pvc\n      - name: sessao-pvc\n        persistentVolumeClaim:\n          claimName: sessao-pvc\n",
    "errors": []
  },
  {
    "id": "04051",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: sistema-noticias-statefulset\nspec:\n  selector:\n    matchLabels:\n      app: sistema-noticias\n  template:\n    metadata:\n      name: sistema-noticias\n      labels:\n        app: sistema-noticias\n    spec:\n      containers:\n      - name: sistema-noticias\n        image: aluracursos/sistema-noticias:1\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: sistema-noticias-config-map\n        volumeMounts:\n        - mountPath: /var/www/html/uploads\n          name: imagens-pvc\n        - mountPath: /tmp\n          name: sessao-pvc\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: imagens-pvc\n        persistentVolumeClaim:\n          claimName: imagens-pvc\n      - name: sessao-pvc\n        persistentVolumeClaim:\n          claimName: sessao-pvc\n",
    "errors": []
  },
  {
    "id": "04052",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-api\n  labels:\n    micro: runtime\n    name: micro-api\n  annotations:\n    name: go.micro.api\n    version: latest\n    source: github.com/xinhari/hari\n    owner: micro\n    group: micro\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: micro-api\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-api\n        micro: runtime\n    spec:\n      containers:\n      - name: api\n        env:\n        - name: MICRO_AUTH\n          value: service\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_API_NAMESPACE\n          value: domain\n        - name: MICRO_ENABLE_STATS\n          value: 'true'\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_REGISTER_TTL\n          value: '60'\n        - name: MICRO_REGISTER_INTERVAL\n          value: '30'\n        - name: MICRO_ENABLE_ACME\n          value: 'true'\n        - name: MICRO_ACME_PROVIDER\n          value: certmagic\n        - name: MICRO_ACME_HOSTS\n          value: '*.micro.mu,*.cloud.micro.mu,micro.mu'\n        - name: MICRO_STORE\n          value: service\n        - name: MICRO_STORE_DATABASE\n          value: micro\n        - name: MICRO_STORE_TABLE\n          value: micro\n        - name: CF_API_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: CF_API_TOKEN\n              name: cloudflare-credentials\n        args:\n        - api\n        image: agus7fauzi/hari:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 443\n          name: api-port\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04053",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-api\n  labels:\n    micro: runtime\n    name: micro-api\n  annotations:\n    name: go.micro.api\n    version: latest\n    source: github.com/xinhari/hari\n    owner: micro\n    group: micro\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: micro-api\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-api\n        micro: runtime\n    spec:\n      containers:\n      - name: api\n        env:\n        - name: MICRO_AUTH\n          value: service\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_API_NAMESPACE\n          value: domain\n        - name: MICRO_ENABLE_STATS\n          value: 'true'\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_REGISTER_TTL\n          value: '60'\n        - name: MICRO_REGISTER_INTERVAL\n          value: '30'\n        - name: MICRO_ENABLE_ACME\n          value: 'true'\n        - name: MICRO_ACME_PROVIDER\n          value: certmagic\n        - name: MICRO_ACME_HOSTS\n          value: '*.micro.mu,*.cloud.micro.mu,micro.mu'\n        - name: MICRO_STORE\n          value: service\n        - name: MICRO_STORE_DATABASE\n          value: micro\n        - name: MICRO_STORE_TABLE\n          value: micro\n        - name: CF_API_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: CF_API_TOKEN\n              name: cloudflare-credentials\n        args:\n        - api\n        image: agus7fauzi/hari:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 443\n          name: api-port\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04054",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-api\n  labels:\n    micro: runtime\n    name: micro-api\n  annotations:\n    name: go.micro.api\n    version: latest\n    source: github.com/xinhari/hari\n    owner: micro\n    group: micro\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: micro-api\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-api\n        micro: runtime\n    spec:\n      containers:\n      - name: api\n        env:\n        - name: MICRO_AUTH\n          value: service\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_API_NAMESPACE\n          value: domain\n        - name: MICRO_ENABLE_STATS\n          value: 'true'\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_REGISTER_TTL\n          value: '60'\n        - name: MICRO_REGISTER_INTERVAL\n          value: '30'\n        - name: MICRO_ENABLE_ACME\n          value: 'true'\n        - name: MICRO_ACME_PROVIDER\n          value: certmagic\n        - name: MICRO_ACME_HOSTS\n          value: '*.micro.mu,*.cloud.micro.mu,micro.mu'\n        - name: MICRO_STORE\n          value: service\n        - name: MICRO_STORE_DATABASE\n          value: micro\n        - name: MICRO_STORE_TABLE\n          value: micro\n        - name: CF_API_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: CF_API_TOKEN\n              name: cloudflare-credentials\n        args:\n        - api\n        image: agus7fauzi/hari:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 443\n          name: api-port\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04055",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-api\n  labels:\n    micro: runtime\n    name: micro-api\n  annotations:\n    name: go.micro.api\n    version: latest\n    source: github.com/xinhari/hari\n    owner: micro\n    group: micro\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: micro-api\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-api\n        micro: runtime\n    spec:\n      containers:\n      - name: api\n        env:\n        - name: MICRO_AUTH\n          value: service\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_API_NAMESPACE\n          value: domain\n        - name: MICRO_ENABLE_STATS\n          value: 'true'\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_REGISTER_TTL\n          value: '60'\n        - name: MICRO_REGISTER_INTERVAL\n          value: '30'\n        - name: MICRO_ENABLE_ACME\n          value: 'true'\n        - name: MICRO_ACME_PROVIDER\n          value: certmagic\n        - name: MICRO_ACME_HOSTS\n          value: '*.micro.mu,*.cloud.micro.mu,micro.mu'\n        - name: MICRO_STORE\n          value: service\n        - name: MICRO_STORE_DATABASE\n          value: micro\n        - name: MICRO_STORE_TABLE\n          value: micro\n        - name: CF_API_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: CF_API_TOKEN\n              name: cloudflare-credentials\n        args:\n        - api\n        image: agus7fauzi/hari:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 443\n          name: api-port\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04056",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-api\n  labels:\n    micro: runtime\n    name: micro-api\n  annotations:\n    name: go.micro.api\n    version: latest\n    source: github.com/xinhari/hari\n    owner: micro\n    group: micro\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      name: micro-api\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-api\n        micro: runtime\n    spec:\n      containers:\n      - name: api\n        env:\n        - name: MICRO_AUTH\n          value: service\n        - name: MICRO_AUTH_PUBLIC_KEY\n          valueFrom:\n            secretKeyRef:\n              name: micro-keypair\n              key: public\n        - name: MICRO_API_NAMESPACE\n          value: domain\n        - name: MICRO_ENABLE_STATS\n          value: 'true'\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_REGISTER_TTL\n          value: '60'\n        - name: MICRO_REGISTER_INTERVAL\n          value: '30'\n        - name: MICRO_ENABLE_ACME\n          value: 'true'\n        - name: MICRO_ACME_PROVIDER\n          value: certmagic\n        - name: MICRO_ACME_HOSTS\n          value: '*.micro.mu,*.cloud.micro.mu,micro.mu'\n        - name: MICRO_STORE\n          value: service\n        - name: MICRO_STORE_DATABASE\n          value: micro\n        - name: MICRO_STORE_TABLE\n          value: micro\n        - name: CF_API_TOKEN\n          valueFrom:\n            secretKeyRef:\n              key: CF_API_TOKEN\n              name: cloudflare-credentials\n        args:\n        - api\n        image: agus7fauzi/hari:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 443\n          name: api-port\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04057",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-a1\n  namespace: test-kahoy\n  labels:\n    app: app-a1\n  annotations:\n    app: app-a1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app-a1\n  template:\n    metadata:\n      labels:\n        app: app-a1\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04058",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-a1\n  namespace: test-kahoy\n  labels:\n    app: app-a1\n  annotations:\n    app: app-a1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app-a1\n  template:\n    metadata:\n      labels:\n        app: app-a1\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04059",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-a1\n  namespace: test-kahoy\n  labels:\n    app: app-a1\n  annotations:\n    app: app-a1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app-a1\n  template:\n    metadata:\n      labels:\n        app: app-a1\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04060",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-a1\n  namespace: test-kahoy\n  labels:\n    app: app-a1\n  annotations:\n    app: app-a1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app-a1\n  template:\n    metadata:\n      labels:\n        app: app-a1\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04061",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-a1\n  namespace: test-kahoy\n  labels:\n    app: app-a1\n  annotations:\n    app: app-a1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app-a1\n  template:\n    metadata:\n      labels:\n        app: app-a1\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04062",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04063",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04064",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04065",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04066",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04067",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04068",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04069",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04070",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04071",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04072",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04073",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04074",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04075",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04076",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04077",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04078",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04079",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04080",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04081",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: image-downloader\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      name: image-downloader\n  template:\n    metadata:\n      labels:\n        name: image-downloader\n    spec:\n      containers:\n      - name: python-predictor-cpu\n        image: $CORTEX_IMAGE_PYTHON_PREDICTOR_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-serving-cpu\n        image: $CORTEX_IMAGE_TENSORFLOW_SERVING_CPU:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: tensorflow-predictor\n        image: $CORTEX_IMAGE_TENSORFLOW_PREDICTOR:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: downloader\n        image: $CORTEX_IMAGE_DOWNLOADER:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - sleep 1000000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04082",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: yeah-it-works\nspec:\n  template:\n    spec:\n      containers:\n      - name: yeah-it-works\n        image: python:3.6-alpine\n        command:\n        - python\n        - -c\n        - print('Yeah, it works in a Job!!!')\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04083",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: yeah-it-works\nspec:\n  template:\n    spec:\n      containers:\n      - name: yeah-it-works\n        image: python:3.6-alpine\n        command:\n        - python\n        - -c\n        - print('Yeah, it works in a Job!!!')\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04084",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: yeah-it-works\nspec:\n  template:\n    spec:\n      containers:\n      - name: yeah-it-works\n        image: python:3.6-alpine\n        command:\n        - python\n        - -c\n        - print('Yeah, it works in a Job!!!')\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04085",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: yeah-it-works\nspec:\n  template:\n    spec:\n      containers:\n      - name: yeah-it-works\n        image: python:3.6-alpine\n        command:\n        - python\n        - -c\n        - print('Yeah, it works in a Job!!!')\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04086",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: modeldb\n  name: modeldb-artifact-store\nspec:\n  selector:\n    matchLabels:\n      app: modeldb\n      tier: artifact-store\n  template:\n    metadata:\n      labels:\n        app: modeldb\n        tier: artifact-store\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - env:\n        - name: VERTA_ARTIFACT_CONFIG\n          value: /config/config.yaml\n        image: vertaaiofficial/modeldb-artifact-store:kubeflow\n        imagePullPolicy: Always\n        name: modeldb-artifact-store\n        ports:\n        - containerPort: 8086\n        volumeMounts:\n        - mountPath: /config\n          name: modeldb-artifact-store-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: modeldb-artifact-store-config\n        name: modeldb-artifact-store-config\n",
    "errors": []
  },
  {
    "id": "04087",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: modeldb\n  name: modeldb-artifact-store\nspec:\n  selector:\n    matchLabels:\n      app: modeldb\n      tier: artifact-store\n  template:\n    metadata:\n      labels:\n        app: modeldb\n        tier: artifact-store\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - env:\n        - name: VERTA_ARTIFACT_CONFIG\n          value: /config/config.yaml\n        image: vertaaiofficial/modeldb-artifact-store:kubeflow\n        imagePullPolicy: Always\n        name: modeldb-artifact-store\n        ports:\n        - containerPort: 8086\n        volumeMounts:\n        - mountPath: /config\n          name: modeldb-artifact-store-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: modeldb-artifact-store-config\n        name: modeldb-artifact-store-config\n",
    "errors": []
  },
  {
    "id": "04088",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: modeldb\n  name: modeldb-artifact-store\nspec:\n  selector:\n    matchLabels:\n      app: modeldb\n      tier: artifact-store\n  template:\n    metadata:\n      labels:\n        app: modeldb\n        tier: artifact-store\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - env:\n        - name: VERTA_ARTIFACT_CONFIG\n          value: /config/config.yaml\n        image: vertaaiofficial/modeldb-artifact-store:kubeflow\n        imagePullPolicy: Always\n        name: modeldb-artifact-store\n        ports:\n        - containerPort: 8086\n        volumeMounts:\n        - mountPath: /config\n          name: modeldb-artifact-store-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: modeldb-artifact-store-config\n        name: modeldb-artifact-store-config\n",
    "errors": []
  },
  {
    "id": "04089",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: modeldb\n  name: modeldb-artifact-store\nspec:\n  selector:\n    matchLabels:\n      app: modeldb\n      tier: artifact-store\n  template:\n    metadata:\n      labels:\n        app: modeldb\n        tier: artifact-store\n      annotations:\n        sidecar.istio.io/inject: 'true'\n    spec:\n      containers:\n      - env:\n        - name: VERTA_ARTIFACT_CONFIG\n          value: /config/config.yaml\n        image: vertaaiofficial/modeldb-artifact-store:kubeflow\n        imagePullPolicy: Always\n        name: modeldb-artifact-store\n        ports:\n        - containerPort: 8086\n        volumeMounts:\n        - mountPath: /config\n          name: modeldb-artifact-store-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - configMap:\n          name: modeldb-artifact-store-config\n        name: modeldb-artifact-store-config\n",
    "errors": []
  },
  {
    "id": "04090",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: compliance-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: compliance-operator\n  template:\n    metadata:\n      labels:\n        name: compliance-operator\n      annotations:\n        workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n    spec:\n      serviceAccountName: compliance-operator\n      containers:\n      - name: compliance-operator\n        image: quay.io/compliance-operator/compliance-operator:stable\n        command:\n        - compliance-operator\n        - operator\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 10m\n          limits:\n            memory: 200Mi\n            cpu: 100m\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: compliance-operator\n        - name: RELATED_IMAGE_OPENSCAP\n          value: quay.io/compliance-operator/openscap-ocp:1.3.5\n        - name: RELATED_IMAGE_OPERATOR\n          value: quay.io/compliance-operator/compliance-operator:latest\n        - name: RELATED_IMAGE_PROFILE\n          value: quay.io/complianceascode/ocp4:latest\n        volumeMounts:\n        - name: serving-cert\n          mountPath: /var/run/secrets/serving-cert\n          readOnly: true\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: compliance-operator-serving-cert\n          optional: true\n",
    "errors": []
  },
  {
    "id": "04091",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: compliance-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: compliance-operator\n  template:\n    metadata:\n      labels:\n        name: compliance-operator\n      annotations:\n        workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n    spec:\n      serviceAccountName: compliance-operator\n      containers:\n      - name: compliance-operator\n        image: quay.io/compliance-operator/compliance-operator:stable\n        command:\n        - compliance-operator\n        - operator\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 10m\n          limits:\n            memory: 200Mi\n            cpu: 100m\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: compliance-operator\n        - name: RELATED_IMAGE_OPENSCAP\n          value: quay.io/compliance-operator/openscap-ocp:1.3.5\n        - name: RELATED_IMAGE_OPERATOR\n          value: quay.io/compliance-operator/compliance-operator:latest\n        - name: RELATED_IMAGE_PROFILE\n          value: quay.io/complianceascode/ocp4:latest\n        volumeMounts:\n        - name: serving-cert\n          mountPath: /var/run/secrets/serving-cert\n          readOnly: true\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: compliance-operator-serving-cert\n          optional: true\n",
    "errors": []
  },
  {
    "id": "04092",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04093",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04094",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04095",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04096",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04097",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04098",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04099",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04100",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04101",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04102",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-cinder-nodeplugin\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-cinder-nodeplugin\n  template:\n    metadata:\n      labels:\n        app: csi-cinder-nodeplugin\n    spec:\n      serviceAccount: csi-cinder-node-sa\n      containers:\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/cinder.csi.openstack.org/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: cinder-csi-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: docker.io/k8scloudprovider/cinder-csi-plugin:stable\n        args:\n        - /bin/cinder-csi-plugin\n        - --nodeid=$(NODE_ID)\n        - --endpoint=$(CSI_ENDPOINT)\n        - --cloud-config=$(CLOUD_CONFIG)\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/config/cloud.conf\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: pods-cloud-data\n          mountPath: /var/lib/cloud/data\n          readOnly: true\n        - name: pods-probe-dir\n          mountPath: /dev\n          mountPropagation: HostToContainer\n        - name: secret-cinderplugin\n          mountPath: /etc/config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/cinder.csi.openstack.org\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: pods-cloud-data\n        hostPath:\n          path: /var/lib/cloud/data\n          type: Directory\n      - name: pods-probe-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: secret-cinderplugin\n        secret:\n          secretName: cloud-config\n",
    "errors": []
  },
  {
    "id": "04103",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: podinfo-ds\n  labels:\n    app.kubernetes.io/name: podinfo-ds\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: podinfo-ds\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app.kubernetes.io/name: podinfo-ds\n    spec:\n      containers:\n      - name: podinfod\n        image: ghcr.io/stefanprodan/podinfo:6.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        livenessProbe:\n          httpGet:\n            port: 9898\n            path: /healthz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            port: 9898\n            path: /readyz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 1m\n            memory: 16Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04104",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: podinfo-ds\n  labels:\n    app.kubernetes.io/name: podinfo-ds\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: podinfo-ds\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app.kubernetes.io/name: podinfo-ds\n    spec:\n      containers:\n      - name: podinfod\n        image: ghcr.io/stefanprodan/podinfo:6.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        livenessProbe:\n          httpGet:\n            port: 9898\n            path: /healthz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            port: 9898\n            path: /readyz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 1m\n            memory: 16Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04105",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7290\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04106",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7290\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04107",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7290\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04108",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7290\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04109",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7290\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04110",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-minio-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: minio-client\n        image: minio/mc:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 100 && mc config host add minio-service http://minio-service:9000\n          minio minio123 && mc mb minio-service/my-bucket && echo ''hello'' > file1.txt\n          && echo ''world'' > file2.txt && mc cp *.txt minio-service/my-bucket '\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04111",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-minio-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: minio-client\n        image: minio/mc:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 100 && mc config host add minio-service http://minio-service:9000\n          minio minio123 && mc mb minio-service/my-bucket && echo ''hello'' > file1.txt\n          && echo ''world'' > file2.txt && mc cp *.txt minio-service/my-bucket '\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04112",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-minio-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: minio-client\n        image: minio/mc:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 100 && mc config host add minio-service http://minio-service:9000\n          minio minio123 && mc mb minio-service/my-bucket && echo ''hello'' > file1.txt\n          && echo ''world'' > file2.txt && mc cp *.txt minio-service/my-bucket '\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04113",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-minio-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: minio-client\n        image: minio/mc:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 100 && mc config host add minio-service http://minio-service:9000\n          minio minio123 && mc mb minio-service/my-bucket && echo ''hello'' > file1.txt\n          && echo ''world'' > file2.txt && mc cp *.txt minio-service/my-bucket '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04114",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: example-minio-data\nspec:\n  template:\n    spec:\n      containers:\n      - name: minio-client\n        image: minio/mc:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sleep 100 && mc config host add minio-service http://minio-service:9000\n          minio minio123 && mc mb minio-service/my-bucket && echo ''hello'' > file1.txt\n          && echo ''world'' > file2.txt && mc cp *.txt minio-service/my-bucket '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04115",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dummy-name\nspec:\n  containers:\n  - env:\n    - name: AIRFLOW__CORE__EXECUTOR\n      value: LocalExecutor\n    - name: AIRFLOW__CORE__FERNET_KEY\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-fernet-key\n          key: fernet-key\n    - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-airflow-metadata\n          key: connection\n    - name: AIRFLOW_CONN_AIRFLOW_DB\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-airflow-metadata\n          key: connection\n    image: dummy_image:stable\n    imagePullPolicy: IfNotPresent\n    name: base\n    volumeMounts:\n    - mountPath: /opt/airflow/logs\n      name: airflow-logs\n    - mountPath: /opt/airflow/airflow.cfg\n      name: airflow-config\n      readOnly: true\n      subPath: airflow.cfg\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsUser: 50000\n    fsGroup: 50000\n  serviceAccountName: RELEASE-NAME-worker-serviceaccount\n  volumes:\n  - emptyDir: {}\n    name: airflow-logs\n  - configMap:\n      name: RELEASE-NAME-airflow-config\n    name: airflow-config\n",
    "errors": []
  },
  {
    "id": "04116",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dummy-name\nspec:\n  containers:\n  - env:\n    - name: AIRFLOW__CORE__EXECUTOR\n      value: LocalExecutor\n    - name: AIRFLOW__CORE__FERNET_KEY\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-fernet-key\n          key: fernet-key\n    - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-airflow-metadata\n          key: connection\n    - name: AIRFLOW_CONN_AIRFLOW_DB\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-airflow-metadata\n          key: connection\n    image: dummy_image:stable\n    imagePullPolicy: IfNotPresent\n    name: base\n    volumeMounts:\n    - mountPath: /opt/airflow/logs\n      name: airflow-logs\n    - mountPath: /opt/airflow/airflow.cfg\n      name: airflow-config\n      readOnly: true\n      subPath: airflow.cfg\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsUser: 50000\n    fsGroup: 50000\n  serviceAccountName: RELEASE-NAME-worker-serviceaccount\n  volumes:\n  - emptyDir: {}\n    name: airflow-logs\n  - configMap:\n      name: RELEASE-NAME-airflow-config\n    name: airflow-config\n",
    "errors": []
  },
  {
    "id": "04117",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dummy-name\nspec:\n  containers:\n  - env:\n    - name: AIRFLOW__CORE__EXECUTOR\n      value: LocalExecutor\n    - name: AIRFLOW__CORE__FERNET_KEY\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-fernet-key\n          key: fernet-key\n    - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-airflow-metadata\n          key: connection\n    - name: AIRFLOW_CONN_AIRFLOW_DB\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-airflow-metadata\n          key: connection\n    image: dummy_image:stable\n    imagePullPolicy: IfNotPresent\n    name: base\n    volumeMounts:\n    - mountPath: /opt/airflow/logs\n      name: airflow-logs\n    - mountPath: /opt/airflow/airflow.cfg\n      name: airflow-config\n      readOnly: true\n      subPath: airflow.cfg\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsUser: 50000\n    fsGroup: 50000\n  serviceAccountName: RELEASE-NAME-worker-serviceaccount\n  volumes:\n  - emptyDir: {}\n    name: airflow-logs\n  - configMap:\n      name: RELEASE-NAME-airflow-config\n    name: airflow-config\n",
    "errors": []
  },
  {
    "id": "04118",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dummy-name\nspec:\n  containers:\n  - env:\n    - name: AIRFLOW__CORE__EXECUTOR\n      value: LocalExecutor\n    - name: AIRFLOW__CORE__FERNET_KEY\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-fernet-key\n          key: fernet-key\n    - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-airflow-metadata\n          key: connection\n    - name: AIRFLOW_CONN_AIRFLOW_DB\n      valueFrom:\n        secretKeyRef:\n          name: RELEASE-NAME-airflow-metadata\n          key: connection\n    image: dummy_image:stable\n    imagePullPolicy: IfNotPresent\n    name: base\n    volumeMounts:\n    - mountPath: /opt/airflow/logs\n      name: airflow-logs\n    - mountPath: /opt/airflow/airflow.cfg\n      name: airflow-config\n      readOnly: true\n      subPath: airflow.cfg\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsUser: 50000\n    fsGroup: 50000\n  serviceAccountName: RELEASE-NAME-worker-serviceaccount\n  volumes:\n  - emptyDir: {}\n    name: airflow-logs\n  - configMap:\n      name: RELEASE-NAME-airflow-config\n    name: airflow-config\n",
    "errors": []
  },
  {
    "id": "04119",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vote\n  labels:\n    app: vote\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: vote\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: vote\n        env: dev\n    spec:\n      containers:\n      - name: vote\n        image: dockersamples/examplevotingapp_vote:before\n        ports:\n        - containerPort: 80\n          name: vote\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04120",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vote\n  labels:\n    app: vote\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: vote\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: vote\n        env: dev\n    spec:\n      containers:\n      - name: vote\n        image: dockersamples/examplevotingapp_vote:before\n        ports:\n        - containerPort: 80\n          name: vote\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04121",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vote\n  labels:\n    app: vote\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: vote\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: vote\n        env: dev\n    spec:\n      containers:\n      - name: vote\n        image: dockersamples/examplevotingapp_vote:before\n        ports:\n        - containerPort: 80\n          name: vote\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04122",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vote\n  labels:\n    app: vote\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: vote\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: vote\n        env: dev\n    spec:\n      containers:\n      - name: vote\n        image: dockersamples/examplevotingapp_vote:before\n        ports:\n        - containerPort: 80\n          name: vote\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04123",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6441\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04124",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6441\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04125",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6441\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04126",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6441\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04127",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6441\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04128",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: org2-install-k8s-builder\nspec:\n  template:\n    metadata:\n      name: org2-install-k8s-builder\n    spec:\n      containers:\n      - name: main\n        image: ghcr.io/hyperledgendary/k8s-fabric-peer:${K8S_CHAINCODE_BUILDER_VERSION}\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/fabric-org2/fabric/external_builders && cp -rv /opt/hyperledger/k8s_builder\n          /mnt/fabric-org2/fabric/external_builders/\n        volumeMounts:\n        - name: fabric-org2-volume\n          mountPath: /mnt/fabric-org2\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: fabric-org2-volume\n        persistentVolumeClaim:\n          claimName: fabric-org2\n",
    "errors": []
  },
  {
    "id": "04129",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: org2-install-k8s-builder\nspec:\n  template:\n    metadata:\n      name: org2-install-k8s-builder\n    spec:\n      containers:\n      - name: main\n        image: ghcr.io/hyperledgendary/k8s-fabric-peer:${K8S_CHAINCODE_BUILDER_VERSION}\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/fabric-org2/fabric/external_builders && cp -rv /opt/hyperledger/k8s_builder\n          /mnt/fabric-org2/fabric/external_builders/\n        volumeMounts:\n        - name: fabric-org2-volume\n          mountPath: /mnt/fabric-org2\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: fabric-org2-volume\n        persistentVolumeClaim:\n          claimName: fabric-org2\n",
    "errors": []
  },
  {
    "id": "04130",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: org2-install-k8s-builder\nspec:\n  template:\n    metadata:\n      name: org2-install-k8s-builder\n    spec:\n      containers:\n      - name: main\n        image: ghcr.io/hyperledgendary/k8s-fabric-peer:${K8S_CHAINCODE_BUILDER_VERSION}\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/fabric-org2/fabric/external_builders && cp -rv /opt/hyperledger/k8s_builder\n          /mnt/fabric-org2/fabric/external_builders/\n        volumeMounts:\n        - name: fabric-org2-volume\n          mountPath: /mnt/fabric-org2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: fabric-org2-volume\n        persistentVolumeClaim:\n          claimName: fabric-org2\n",
    "errors": []
  },
  {
    "id": "04131",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: org2-install-k8s-builder\nspec:\n  template:\n    metadata:\n      name: org2-install-k8s-builder\n    spec:\n      containers:\n      - name: main\n        image: ghcr.io/hyperledgendary/k8s-fabric-peer:${K8S_CHAINCODE_BUILDER_VERSION}\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/fabric-org2/fabric/external_builders && cp -rv /opt/hyperledger/k8s_builder\n          /mnt/fabric-org2/fabric/external_builders/\n        volumeMounts:\n        - name: fabric-org2-volume\n          mountPath: /mnt/fabric-org2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: fabric-org2-volume\n        persistentVolumeClaim:\n          claimName: fabric-org2\n",
    "errors": []
  },
  {
    "id": "04132",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k3s-cluster-doc\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k3s-cluster-docs\n  template:\n    metadata:\n      labels:\n        app: k3s-cluster-docs\n    spec:\n      containers:\n      - name: server\n        image: k3s-cluster-docs:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04133",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k3s-cluster-doc\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k3s-cluster-docs\n  template:\n    metadata:\n      labels:\n        app: k3s-cluster-docs\n    spec:\n      containers:\n      - name: server\n        image: k3s-cluster-docs:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04134",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k3s-cluster-doc\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k3s-cluster-docs\n  template:\n    metadata:\n      labels:\n        app: k3s-cluster-docs\n    spec:\n      containers:\n      - name: server\n        image: k3s-cluster-docs:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04135",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k3s-cluster-doc\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k3s-cluster-docs\n  template:\n    metadata:\n      labels:\n        app: k3s-cluster-docs\n    spec:\n      containers:\n      - name: server\n        image: k3s-cluster-docs:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04136",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k3s-cluster-doc\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: k3s-cluster-docs\n  template:\n    metadata:\n      labels:\n        app: k3s-cluster-docs\n    spec:\n      containers:\n      - name: server\n        image: k3s-cluster-docs:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04137",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6664\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04138",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6664\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04139",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6664\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04140",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6664\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04141",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6664\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04142",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04143",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04144",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04145",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04146",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04147",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04148",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04149",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04150",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04151",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04152",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04153",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04154",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04155",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04156",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04157",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-sfs-turbo-controller\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-sfs-turbo-controller\n  template:\n    metadata:\n      labels:\n        app: csi-sfs-turbo-controller\n    spec:\n      serviceAccountName: csi-sfs-turbo-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.4.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v3.1.0\n        args:\n        - -v=5\n        - --csi-address=$(ADDRESS)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: sfs-turbo-csi-plugin\n        image: registry.eu-west-0.prod-cloud-ocb.orange-business.com/official/sfsturbo-csi-plugin:v1.8\n        args:\n        - --v=2\n        - --logtostderr\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(NODE_ID)\n        - --cloud-config=$(CLOUD_CONFIG)\n        ports:\n        - containerPort: 28888\n          name: healthz\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: NODE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CSI_ENDPOINT\n          value: unix://csi/csi.sock\n        - name: CLOUD_CONFIG\n          value: /etc/sfs-turbo/cloud-config\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/sfs-turbo/\n          name: sfs-turbo-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        imagePullPolicy: Always\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --connection-timeout=3s\n        - --health-port=28888\n        - --v=5\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: sfs-turbo-config\n        hostPath:\n          path: /etc/sfs-turbo/\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04158",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-soak-tests\nspec:\n  template:\n    spec:\n      containers:\n      - name: soak\n        image: docker-registry-default.centralpark2.lightbend.com/akka-long-running/cluster-soak-tests:stable\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04159",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-soak-tests\nspec:\n  template:\n    spec:\n      containers:\n      - name: soak\n        image: docker-registry-default.centralpark2.lightbend.com/akka-long-running/cluster-soak-tests:stable\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04160",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-soak-tests\nspec:\n  template:\n    spec:\n      containers:\n      - name: soak\n        image: docker-registry-default.centralpark2.lightbend.com/akka-long-running/cluster-soak-tests:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04161",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-soak-tests\nspec:\n  template:\n    spec:\n      containers:\n      - name: soak\n        image: docker-registry-default.centralpark2.lightbend.com/akka-long-running/cluster-soak-tests:stable\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04162",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-soak-tests\nspec:\n  template:\n    spec:\n      containers:\n      - name: soak\n        image: docker-registry-default.centralpark2.lightbend.com/akka-long-running/cluster-soak-tests:stable\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04163",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: msg-path-demo\nspec:\n  containers:\n  - name: msg-path-demo-container\n    image: debian:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04164",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: msg-path-demo\nspec:\n  containers:\n  - name: msg-path-demo-container\n    image: debian:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04165",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: msg-path-demo\nspec:\n  containers:\n  - name: msg-path-demo-container\n    image: debian:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04166",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: msg-path-demo\nspec:\n  containers:\n  - name: msg-path-demo-container\n    image: debian:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04167",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: msg-path-demo\nspec:\n  containers:\n  - name: msg-path-demo-container\n    image: debian:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04168",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cirros-vm\n  annotations:\n    kubernetes.io/target-runtime: virtlet.cloud\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: extraRuntime\n            operator: In\n            values:\n            - virtlet\n  containers:\n  - name: cirros-vm\n    imagePullPolicy: IfNotPresent\n    image: virtlet.cloud/cirros:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n  volumes:\n  - name: raw\n    flexVolume:\n      driver: virtlet/flexvolume_driver\n      options:\n        type: raw\n        path: /dev/loop0\n",
    "errors": []
  },
  {
    "id": "04169",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cirros-vm\n  annotations:\n    kubernetes.io/target-runtime: virtlet.cloud\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: extraRuntime\n            operator: In\n            values:\n            - virtlet\n  containers:\n  - name: cirros-vm\n    imagePullPolicy: IfNotPresent\n    image: virtlet.cloud/cirros:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  volumes:\n  - name: raw\n    flexVolume:\n      driver: virtlet/flexvolume_driver\n      options:\n        type: raw\n        path: /dev/loop0\n",
    "errors": []
  },
  {
    "id": "04170",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cirros-vm\n  annotations:\n    kubernetes.io/target-runtime: virtlet.cloud\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: extraRuntime\n            operator: In\n            values:\n            - virtlet\n  containers:\n  - name: cirros-vm\n    imagePullPolicy: IfNotPresent\n    image: virtlet.cloud/cirros:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  volumes:\n  - name: raw\n    flexVolume:\n      driver: virtlet/flexvolume_driver\n      options:\n        type: raw\n        path: /dev/loop0\n",
    "errors": []
  },
  {
    "id": "04171",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cirros-vm\n  annotations:\n    kubernetes.io/target-runtime: virtlet.cloud\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: extraRuntime\n            operator: In\n            values:\n            - virtlet\n  containers:\n  - name: cirros-vm\n    imagePullPolicy: IfNotPresent\n    image: virtlet.cloud/cirros:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  volumes:\n  - name: raw\n    flexVolume:\n      driver: virtlet/flexvolume_driver\n      options:\n        type: raw\n        path: /dev/loop0\n",
    "errors": []
  },
  {
    "id": "04172",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cirros-vm\n  annotations:\n    kubernetes.io/target-runtime: virtlet.cloud\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: extraRuntime\n            operator: In\n            values:\n            - virtlet\n  containers:\n  - name: cirros-vm\n    imagePullPolicy: IfNotPresent\n    image: virtlet.cloud/cirros:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n  volumes:\n  - name: raw\n    flexVolume:\n      driver: virtlet/flexvolume_driver\n      options:\n        type: raw\n        path: /dev/loop0\n",
    "errors": []
  },
  {
    "id": "04173",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04174",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04175",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04176",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04177",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04178",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04179",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04180",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04181",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04182",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04183",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeker-qualifiers-nrfin00009-pov1\n  labels:\n    type: cyborg-seeker\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeker-qualifiers-nrfin00009-pov1\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeker.py qualifiers NRFIN_00009\n      pov_1 3600\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 1\n        memory: 10Gi\n      requests:\n        cpu: 1\n        memory: 10Gi\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04184",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeker-qualifiers-nrfin00009-pov1\n  labels:\n    type: cyborg-seeker\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeker-qualifiers-nrfin00009-pov1\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeker.py qualifiers NRFIN_00009\n      pov_1 3600\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 1\n        memory: 10Gi\n      requests:\n        cpu: 1\n        memory: 10Gi\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04185",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: rmt.example.com:5000/nginx:1.12.0\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04186",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: rmt.example.com:5000/nginx:1.12.0\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04187",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: rmt.example.com:5000/nginx:1.12.0\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04188",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: rmt.example.com:5000/nginx:1.12.0\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04189",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04190",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04191",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04192",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04193",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04194",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220217-362d6ac4a0\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/service-account.json\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --pubsub-workers=5\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        - --gcs-credentials-file=/etc/credentials/service-account.json\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        - name: gcs-service-account\n          mountPath: /etc/credentials\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: gcs-service-account\n        secret:\n          secretName: sa-crier\n",
    "errors": []
  },
  {
    "id": "04195",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220217-362d6ac4a0\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/service-account.json\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --pubsub-workers=5\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        - --gcs-credentials-file=/etc/credentials/service-account.json\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        - name: gcs-service-account\n          mountPath: /etc/credentials\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: gcs-service-account\n        secret:\n          secretName: sa-crier\n",
    "errors": []
  },
  {
    "id": "04196",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220217-362d6ac4a0\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/service-account.json\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --pubsub-workers=5\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        - --gcs-credentials-file=/etc/credentials/service-account.json\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        - name: gcs-service-account\n          mountPath: /etc/credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: gcs-service-account\n        secret:\n          secretName: sa-crier\n",
    "errors": []
  },
  {
    "id": "04197",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220217-362d6ac4a0\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/service-account.json\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --pubsub-workers=5\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        - --gcs-credentials-file=/etc/credentials/service-account.json\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        - name: gcs-service-account\n          mountPath: /etc/credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: gcs-service-account\n        secret:\n          secretName: sa-crier\n",
    "errors": []
  },
  {
    "id": "04198",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04199",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04200",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04201",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04202",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04203",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04204",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04205",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04206",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04207",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04208",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04209",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04210",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: false\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04211",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04212",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04213",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ibm-vpc-block-csi-node\nspec:\n  selector:\n    matchLabels:\n      app: ibm-vpc-block-csi-driver\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9080'\n        prometheus.io/path: /metrics\n      labels:\n        app: ibm-vpc-block-csi-driver\n    spec:\n      serviceAccountName: ibm-vpc-block-node-sa\n      containers:\n      - name: csi-driver-registrar\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --v=5\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REGISTRATION_SOCK)\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REGISTRATION_SOCK\n          value: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n      - name: iks-vpc-block-node-driver\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        imagePullPolicy: Always\n        args:\n        - --v=5\n        - --endpoint=unix:/csi/csi.sock\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        envFrom:\n        - configMapRef:\n            name: ibm-vpc-block-csi-configmap\n        resources:\n          limits:\n            cpu: 200m\n            memory: 250Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        volumeMounts:\n        - name: kubelet-data-dir\n          mountPath: /var/data/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        - name: etcudevpath\n          mountPath: /etc/udev\n        - name: runudevpath\n          mountPath: /run/udev\n        - name: libudevpath\n          mountPath: /lib/udev\n        - name: syspath\n          mountPath: /sys\n        - name: customer-auth\n          readOnly: true\n          mountPath: /etc/storage_ibmc\n        - name: cluster-info\n          readOnly: true\n          mountPath: /etc/storage_ibmc/cluster_info\n      - name: liveness-probe\n        image: MUSTPATCHWITHKUSTOMIZE:stable\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - --csi-address=/csi/csi.sock\n        resources:\n          limits:\n            cpu: 50m\n            memory: 50Mi\n          requests:\n            cpu: 5m\n            memory: 10Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n      volumes:\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: kubelet-data-dir\n        hostPath:\n          path: /var/data/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/csi-plugins/vpc.block.csi.ibm.io/\n          type: DirectoryOrCreate\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n      - name: etcudevpath\n        hostPath:\n          path: /etc/udev\n          type: Directory\n      - name: runudevpath\n        hostPath:\n          path: /run/udev\n          type: Directory\n      - name: libudevpath\n        hostPath:\n          path: /lib/udev\n          type: Directory\n      - name: syspath\n        hostPath:\n          path: /sys\n          type: Directory\n      - name: customer-auth\n        secret:\n          secretName: storage-secret-store\n      - name: cluster-info\n        configMap:\n          name: cluster-info\n",
    "errors": []
  },
  {
    "id": "04214",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04215",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04216",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04217",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04218",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04219",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04220",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04221",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04222",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04223",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable STANDARD_AUTHSERVICE_CERT_SECRET_NAME must use secretKeyRef",
      "environment variable WILDCARD_ENDPOINT_CERT_SECRET must use secretKeyRef"
    ]
  },
  {
    "id": "04224",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable STANDARD_AUTHSERVICE_CERT_SECRET_NAME must use secretKeyRef",
      "environment variable WILDCARD_ENDPOINT_CERT_SECRET must use secretKeyRef"
    ]
  },
  {
    "id": "04225",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: enmasse\n    name: address-space-controller\n  name: address-space-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: address-space-controller\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: address-space-controller\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      containers:\n      - env:\n        - name: JAVA_OPTS\n          value: -verbose:gc\n        - name: ENABLE_EVENT_LOGGER\n          value: 'true'\n        - name: EXPOSE_ENDPOINTS_BY_DEFAULT\n          valueFrom:\n            configMapKeyRef:\n              key: exposeEndpointsByDefault\n              name: address-space-controller-config\n              optional: true\n        - name: ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              key: environment\n              name: address-space-controller-config\n              optional: true\n        - name: TEMPLATE_DIR\n          value: /opt/templates\n        - name: RESOURCES_DIR\n          value: /opt\n        - name: STANDARD_AUTHSERVICE_CONFIG_NAME\n          value: keycloak-config\n        - name: STANDARD_AUTHSERVICE_CREDENTIALS_SECRET_NAME\n          value: keycloak-credentials\n        - name: STANDARD_AUTHSERVICE_CERT_SECRET_NAME\n          value: standard-authservice-cert\n        - name: WILDCARD_ENDPOINT_CERT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              key: wildcardEndpointCertSecret\n              name: address-space-controller-config\n              optional: true\n        - name: RESYNC_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: resyncInterval\n              name: address-space-controller-config\n              optional: true\n        - name: RECHECK_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: recheckInterval\n              name: address-space-controller-config\n              optional: true\n        - name: IMAGE_PULL_POLICY\n          value: Always\n        - name: ROUTER_IMAGE\n          value: registry.redhat.io/amq7/amq-interconnect:1.4\n        - name: STANDARD_CONTROLLER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-standard-controller:dev\n        - name: AGENT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-agent:dev\n        - name: BROKER_IMAGE\n          value: registry.redhat.io/amq-broker-7/amq-broker-73-openshift:latest\n        - name: BROKER_PLUGIN_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-broker-plugin:dev\n        - name: TOPIC_FORWARDER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-topic-forwarder:dev\n        - name: MQTT_GATEWAY_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-gateway:dev\n        - name: MQTT_LWT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-lwt:dev\n        image: registry.redhat.io/amq7/amq-online-1-address-space-controller:dev\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        name: address-space-controller\n        ports:\n        - containerPort: 8080\n          name: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        resources:\n          limits:\n            memory: 512Mi\n          requests:\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccountName: address-space-controller\n",
    "errors": []
  },
  {
    "id": "04226",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: enmasse\n    name: address-space-controller\n  name: address-space-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: address-space-controller\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: address-space-controller\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      containers:\n      - env:\n        - name: JAVA_OPTS\n          value: -verbose:gc\n        - name: ENABLE_EVENT_LOGGER\n          value: 'true'\n        - name: EXPOSE_ENDPOINTS_BY_DEFAULT\n          valueFrom:\n            configMapKeyRef:\n              key: exposeEndpointsByDefault\n              name: address-space-controller-config\n              optional: true\n        - name: ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              key: environment\n              name: address-space-controller-config\n              optional: true\n        - name: TEMPLATE_DIR\n          value: /opt/templates\n        - name: RESOURCES_DIR\n          value: /opt\n        - name: STANDARD_AUTHSERVICE_CONFIG_NAME\n          value: keycloak-config\n        - name: STANDARD_AUTHSERVICE_CREDENTIALS_SECRET_NAME\n          value: keycloak-credentials\n        - name: STANDARD_AUTHSERVICE_CERT_SECRET_NAME\n          value: standard-authservice-cert\n        - name: WILDCARD_ENDPOINT_CERT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              key: wildcardEndpointCertSecret\n              name: address-space-controller-config\n              optional: true\n        - name: RESYNC_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: resyncInterval\n              name: address-space-controller-config\n              optional: true\n        - name: RECHECK_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: recheckInterval\n              name: address-space-controller-config\n              optional: true\n        - name: IMAGE_PULL_POLICY\n          value: Always\n        - name: ROUTER_IMAGE\n          value: registry.redhat.io/amq7/amq-interconnect:1.4\n        - name: STANDARD_CONTROLLER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-standard-controller:dev\n        - name: AGENT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-agent:dev\n        - name: BROKER_IMAGE\n          value: registry.redhat.io/amq-broker-7/amq-broker-73-openshift:latest\n        - name: BROKER_PLUGIN_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-broker-plugin:dev\n        - name: TOPIC_FORWARDER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-topic-forwarder:dev\n        - name: MQTT_GATEWAY_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-gateway:dev\n        - name: MQTT_LWT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-lwt:dev\n        image: registry.redhat.io/amq7/amq-online-1-address-space-controller:dev\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        name: address-space-controller\n        ports:\n        - containerPort: 8080\n          name: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        resources:\n          limits:\n            memory: 512Mi\n          requests:\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccountName: address-space-controller\n",
    "errors": []
  },
  {
    "id": "04227",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: enmasse\n    name: address-space-controller\n  name: address-space-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: address-space-controller\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: address-space-controller\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      containers:\n      - env:\n        - name: JAVA_OPTS\n          value: -verbose:gc\n        - name: ENABLE_EVENT_LOGGER\n          value: 'true'\n        - name: EXPOSE_ENDPOINTS_BY_DEFAULT\n          valueFrom:\n            configMapKeyRef:\n              key: exposeEndpointsByDefault\n              name: address-space-controller-config\n              optional: true\n        - name: ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              key: environment\n              name: address-space-controller-config\n              optional: true\n        - name: TEMPLATE_DIR\n          value: /opt/templates\n        - name: RESOURCES_DIR\n          value: /opt\n        - name: STANDARD_AUTHSERVICE_CONFIG_NAME\n          value: keycloak-config\n        - name: STANDARD_AUTHSERVICE_CREDENTIALS_SECRET_NAME\n          value: keycloak-credentials\n        - name: STANDARD_AUTHSERVICE_CERT_SECRET_NAME\n          value: standard-authservice-cert\n        - name: WILDCARD_ENDPOINT_CERT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              key: wildcardEndpointCertSecret\n              name: address-space-controller-config\n              optional: true\n        - name: RESYNC_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: resyncInterval\n              name: address-space-controller-config\n              optional: true\n        - name: RECHECK_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: recheckInterval\n              name: address-space-controller-config\n              optional: true\n        - name: IMAGE_PULL_POLICY\n          value: Always\n        - name: ROUTER_IMAGE\n          value: registry.redhat.io/amq7/amq-interconnect:1.4\n        - name: STANDARD_CONTROLLER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-standard-controller:dev\n        - name: AGENT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-agent:dev\n        - name: BROKER_IMAGE\n          value: registry.redhat.io/amq-broker-7/amq-broker-73-openshift:latest\n        - name: BROKER_PLUGIN_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-broker-plugin:dev\n        - name: TOPIC_FORWARDER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-topic-forwarder:dev\n        - name: MQTT_GATEWAY_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-gateway:dev\n        - name: MQTT_LWT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-lwt:dev\n        image: registry.redhat.io/amq7/amq-online-1-address-space-controller:dev\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        name: address-space-controller\n        ports:\n        - containerPort: 8080\n          name: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        resources:\n          limits:\n            memory: 512Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccountName: address-space-controller\n",
    "errors": []
  },
  {
    "id": "04228",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dc-api\n  labels:\n    app: dc-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dc-api\n  template:\n    metadata:\n      labels:\n        app: dc-api\n    spec:\n      containers:\n      - name: dc-api\n        image: gcr.io/neural-pattern-278618/dc-api:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: dc-api\n        - secretRef:\n            name: dc-api\n        - secretRef:\n            name: postgres\n        resources:\n          limits:\n            cpu: '0.3'\n          requests:\n            cpu: '0.3'\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          periodSeconds: 5\n          initialDelaySeconds: 200\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04229",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dc-api\n  labels:\n    app: dc-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dc-api\n  template:\n    metadata:\n      labels:\n        app: dc-api\n    spec:\n      containers:\n      - name: dc-api\n        image: gcr.io/neural-pattern-278618/dc-api:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: dc-api\n        - secretRef:\n            name: dc-api\n        - secretRef:\n            name: postgres\n        resources:\n          limits:\n            cpu: '0.3'\n          requests:\n            cpu: '0.3'\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          periodSeconds: 5\n          initialDelaySeconds: 200\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04230",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dc-api\n  labels:\n    app: dc-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dc-api\n  template:\n    metadata:\n      labels:\n        app: dc-api\n    spec:\n      containers:\n      - name: dc-api\n        image: gcr.io/neural-pattern-278618/dc-api:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: dc-api\n        - secretRef:\n            name: dc-api\n        - secretRef:\n            name: postgres\n        resources:\n          limits:\n            cpu: '0.3'\n          requests:\n            cpu: '0.3'\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          periodSeconds: 5\n          initialDelaySeconds: 200\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04231",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dc-api\n  labels:\n    app: dc-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dc-api\n  template:\n    metadata:\n      labels:\n        app: dc-api\n    spec:\n      containers:\n      - name: dc-api\n        image: gcr.io/neural-pattern-278618/dc-api:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: dc-api\n        - secretRef:\n            name: dc-api\n        - secretRef:\n            name: postgres\n        resources:\n          limits:\n            cpu: '0.3'\n            memory: 256Mi\n          requests:\n            cpu: '0.3'\n            memory: 128Mi\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          periodSeconds: 5\n          initialDelaySeconds: 200\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04232",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources: {}\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04233",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources: {}\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04234",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources: {}\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04235",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04236",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04237",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04238",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04239",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04240",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04241",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04242",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04243",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04244",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04245",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04246",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04247",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04248",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04249",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04250",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04251",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210305-350f3b2f2e\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04252",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210305-350f3b2f2e\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04253",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210305-350f3b2f2e\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04254",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210305-350f3b2f2e\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04255",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04256",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04257",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04258",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04259",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04260",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04261",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04262",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04263",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04264",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04265",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04266",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04267",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04268",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04269",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04270",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04271",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04272",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04273",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04274",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04275",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04276",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04277",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04278",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04279",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04280",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04281",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04282",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04283",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04284",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04285",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04286",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: signalfx-agent\n  labels:\n    app: signalfx-agent\n    version: 5.1.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: signalfx-agent\n  template:\n    metadata:\n      labels:\n        app: signalfx-agent\n        version: 5.1.4\n      annotations: {}\n    spec:\n      serviceAccountName: signalfx-agent\n      containers:\n      - name: signalfx-agent\n        image: quay.io/signalfx/signalfx-agent:5.1.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/signalfx-agent\n        volumeMounts:\n        - mountPath: /etc/signalfx\n          name: config\n        resources: {}\n        env:\n        - name: SFX_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: signalfx-agent\n              key: access-token\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: signalfx-agent-v5\n",
    "errors": []
  },
  {
    "id": "04287",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: signalfx-agent\n  labels:\n    app: signalfx-agent\n    version: 5.1.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: signalfx-agent\n  template:\n    metadata:\n      labels:\n        app: signalfx-agent\n        version: 5.1.4\n      annotations: {}\n    spec:\n      serviceAccountName: signalfx-agent\n      containers:\n      - name: signalfx-agent\n        image: quay.io/signalfx/signalfx-agent:5.1.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/signalfx-agent\n        volumeMounts:\n        - mountPath: /etc/signalfx\n          name: config\n        resources: {}\n        env:\n        - name: SFX_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: signalfx-agent\n              key: access-token\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: signalfx-agent-v5\n",
    "errors": []
  },
  {
    "id": "04288",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: signalfx-agent\n  labels:\n    app: signalfx-agent\n    version: 5.1.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: signalfx-agent\n  template:\n    metadata:\n      labels:\n        app: signalfx-agent\n        version: 5.1.4\n      annotations: {}\n    spec:\n      serviceAccountName: signalfx-agent\n      containers:\n      - name: signalfx-agent\n        image: quay.io/signalfx/signalfx-agent:5.1.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/signalfx-agent\n        volumeMounts:\n        - mountPath: /etc/signalfx\n          name: config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: SFX_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: signalfx-agent\n              key: access-token\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: signalfx-agent-v5\n",
    "errors": []
  },
  {
    "id": "04289",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: signalfx-agent\n  labels:\n    app: signalfx-agent\n    version: 5.1.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: signalfx-agent\n  template:\n    metadata:\n      labels:\n        app: signalfx-agent\n        version: 5.1.4\n      annotations: {}\n    spec:\n      serviceAccountName: signalfx-agent\n      containers:\n      - name: signalfx-agent\n        image: quay.io/signalfx/signalfx-agent:5.1.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/signalfx-agent\n        volumeMounts:\n        - mountPath: /etc/signalfx\n          name: config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: SFX_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: signalfx-agent\n              key: access-token\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: config\n        configMap:\n          name: signalfx-agent-v5\n",
    "errors": []
  },
  {
    "id": "04290",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04291",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04292",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04293",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04294",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04295",
    "policy_id": "env_var_secret",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy-kotsadm\n  labels:\n    app: kurl-proxy-kotsadm\n    kots.io/kotsadm: \\\"true\\\"\n    velero.io/exclude-from-backup: \\\"true\\\"\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy-kotsadm\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy-kotsadm\n        kots.io/kotsadm: \\\"true\\\"\n        velero.io/exclude-from-backup: \\\"true\\\"\n    spec:\n      containers:\n      - name: proxy\n        image: kotsadm/kurl-proxy:alpha\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NODE_PORT\n          value: \\\"8800\\\"\n        - name: UPSTREAM_ORIGIN\n          value: http://kotsadm:3000\n        - name: TLS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: tls-secret-name-secret\n              key: tls_secret_name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "04296",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy-kotsadm\n  labels:\n    app: kurl-proxy-kotsadm\n    kots.io/kotsadm: \\\"true\\\"\n    velero.io/exclude-from-backup: \\\"true\\\"\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy-kotsadm\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy-kotsadm\n        kots.io/kotsadm: \\\"true\\\"\n        velero.io/exclude-from-backup: \\\"true\\\"\n    spec:\n      containers:\n      - name: proxy\n        image: kotsadm/kurl-proxy:alpha\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NODE_PORT\n          value: \\\"8800\\\"\n        - name: UPSTREAM_ORIGIN\n          value: http://kotsadm:3000\n        - name: TLS_SECRET_NAME\n          value: kotsadm-tls\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "04297",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy-kotsadm\n  labels:\n    app: kurl-proxy-kotsadm\n    kots.io/kotsadm: \\\"true\\\"\n    velero.io/exclude-from-backup: \\\"true\\\"\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy-kotsadm\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy-kotsadm\n        kots.io/kotsadm: \\\"true\\\"\n        velero.io/exclude-from-backup: \\\"true\\\"\n    spec:\n      containers:\n      - name: proxy\n        image: kotsadm/kurl-proxy:alpha\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NODE_PORT\n          value: \\\"8800\\\"\n        - name: UPSTREAM_ORIGIN\n          value: http://kotsadm:3000\n        - name: TLS_SECRET_NAME\n          value: kotsadm-tls\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "04298",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy-kotsadm\n  labels:\n    app: kurl-proxy-kotsadm\n    kots.io/kotsadm: \\\"true\\\"\n    velero.io/exclude-from-backup: \\\"true\\\"\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy-kotsadm\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy-kotsadm\n        kots.io/kotsadm: \\\"true\\\"\n        velero.io/exclude-from-backup: \\\"true\\\"\n    spec:\n      containers:\n      - name: proxy\n        image: kotsadm/kurl-proxy:alpha\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NODE_PORT\n          value: \\\"8800\\\"\n        - name: UPSTREAM_ORIGIN\n          value: http://kotsadm:3000\n        - name: TLS_SECRET_NAME\n          value: kotsadm-tls\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "04299",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy-kotsadm\n  labels:\n    app: kurl-proxy-kotsadm\n    kots.io/kotsadm: \\\"true\\\"\n    velero.io/exclude-from-backup: \\\"true\\\"\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy-kotsadm\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy-kotsadm\n        kots.io/kotsadm: \\\"true\\\"\n        velero.io/exclude-from-backup: \\\"true\\\"\n    spec:\n      containers:\n      - name: proxy\n        image: kotsadm/kurl-proxy:alpha\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NODE_PORT\n          value: \\\"8800\\\"\n        - name: UPSTREAM_ORIGIN\n          value: http://kotsadm:3000\n        - name: TLS_SECRET_NAME\n          value: kotsadm-tls\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "04300",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04301",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04302",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04303",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04304",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04305",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04306",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04307",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04308",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04309",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04310",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04311",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04312",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04313",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200910-8c70361b39\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04314",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200910-8c70361b39\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04315",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200910-8c70361b39\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04316",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200910-8c70361b39\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04317",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: litmus\nspec:\n  template:\n    metadata:\n      name: litmus\n      labels:\n        app: wordpress-litmus\n    spec:\n      serviceAccountName: litmus\n      containers:\n      - name: ansibletest\n        image: openebs/ansible-runner:ci\n        imagePullPolicy: Always\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: PROVIDER_STORAGE_CLASS\n          value: openebs-cstor-disk\n        - name: STORAGE_CLASS\n          value: openebs-nfs\n        - name: MYSQL_APP_PVC\n          value: openebs-mysql\n        - name: MYSQL_PASS\n          value: w0rdpres5\n        - name: WORDPRESS_APP_PVC\n          value: openebs-wordpress\n        - name: APP_LABEL\n          value: app=wordpress\n        - name: AFFINITY_LABEL\n          value: openebs.io/target-affinity\n        - name: APP_NAMESPACE\n          value: app-wordpress-ns\n        - name: APP_REPLICA\n          value: replicas=1\n        - name: ACTION\n          value: provision\n        - name: MYSQL_PV_CAPACITY\n          value: 5G\n        - name: WORDPRESS_PV_CAPACITY\n          value: 5G\n        - name: PVC_ACCESS_MODE\n          value: ReadWriteMany\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./apps/wordpress/deployers/test.yml -i /etc/ansible/hosts\n          -v; exit 0\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04318",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: litmus\nspec:\n  template:\n    metadata:\n      name: litmus\n      labels:\n        app: wordpress-litmus\n    spec:\n      serviceAccountName: litmus\n      containers:\n      - name: ansibletest\n        image: openebs/ansible-runner:ci\n        imagePullPolicy: Always\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: PROVIDER_STORAGE_CLASS\n          value: openebs-cstor-disk\n        - name: STORAGE_CLASS\n          value: openebs-nfs\n        - name: MYSQL_APP_PVC\n          value: openebs-mysql\n        - name: MYSQL_PASS\n          value: w0rdpres5\n        - name: WORDPRESS_APP_PVC\n          value: openebs-wordpress\n        - name: APP_LABEL\n          value: app=wordpress\n        - name: AFFINITY_LABEL\n          value: openebs.io/target-affinity\n        - name: APP_NAMESPACE\n          value: app-wordpress-ns\n        - name: APP_REPLICA\n          value: replicas=1\n        - name: ACTION\n          value: provision\n        - name: MYSQL_PV_CAPACITY\n          value: 5G\n        - name: WORDPRESS_PV_CAPACITY\n          value: 5G\n        - name: PVC_ACCESS_MODE\n          value: ReadWriteMany\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./apps/wordpress/deployers/test.yml -i /etc/ansible/hosts\n          -v; exit 0\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04319",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: litmus\nspec:\n  template:\n    metadata:\n      name: litmus\n      labels:\n        app: wordpress-litmus\n    spec:\n      serviceAccountName: litmus\n      containers:\n      - name: ansibletest\n        image: openebs/ansible-runner:ci\n        imagePullPolicy: Always\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: PROVIDER_STORAGE_CLASS\n          value: openebs-cstor-disk\n        - name: STORAGE_CLASS\n          value: openebs-nfs\n        - name: MYSQL_APP_PVC\n          value: openebs-mysql\n        - name: MYSQL_PASS\n          value: w0rdpres5\n        - name: WORDPRESS_APP_PVC\n          value: openebs-wordpress\n        - name: APP_LABEL\n          value: app=wordpress\n        - name: AFFINITY_LABEL\n          value: openebs.io/target-affinity\n        - name: APP_NAMESPACE\n          value: app-wordpress-ns\n        - name: APP_REPLICA\n          value: replicas=1\n        - name: ACTION\n          value: provision\n        - name: MYSQL_PV_CAPACITY\n          value: 5G\n        - name: WORDPRESS_PV_CAPACITY\n          value: 5G\n        - name: PVC_ACCESS_MODE\n          value: ReadWriteMany\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./apps/wordpress/deployers/test.yml -i /etc/ansible/hosts\n          -v; exit 0\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04320",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: litmus\nspec:\n  template:\n    metadata:\n      name: litmus\n      labels:\n        app: wordpress-litmus\n    spec:\n      serviceAccountName: litmus\n      containers:\n      - name: ansibletest\n        image: openebs/ansible-runner:ci\n        imagePullPolicy: Always\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: PROVIDER_STORAGE_CLASS\n          value: openebs-cstor-disk\n        - name: STORAGE_CLASS\n          value: openebs-nfs\n        - name: MYSQL_APP_PVC\n          value: openebs-mysql\n        - name: MYSQL_PASS\n          value: w0rdpres5\n        - name: WORDPRESS_APP_PVC\n          value: openebs-wordpress\n        - name: APP_LABEL\n          value: app=wordpress\n        - name: AFFINITY_LABEL\n          value: openebs.io/target-affinity\n        - name: APP_NAMESPACE\n          value: app-wordpress-ns\n        - name: APP_REPLICA\n          value: replicas=1\n        - name: ACTION\n          value: provision\n        - name: MYSQL_PV_CAPACITY\n          value: 5G\n        - name: WORDPRESS_PV_CAPACITY\n          value: 5G\n        - name: PVC_ACCESS_MODE\n          value: ReadWriteMany\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./apps/wordpress/deployers/test.yml -i /etc/ansible/hosts\n          -v; exit 0\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04321",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary\n  labels:\n    app: canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: canary\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: gcr.io/pipecd/helloworld:v0.6.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04322",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary\n  labels:\n    app: canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: canary\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: gcr.io/pipecd/helloworld:v0.6.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04323",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary\n  labels:\n    app: canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: canary\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: gcr.io/pipecd/helloworld:v0.6.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04324",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary\n  labels:\n    app: canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: canary\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: gcr.io/pipecd/helloworld:v0.6.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04325",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: s01-deployment\n  namespace: scenario01\n  labels:\n    app: s01-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: s01-app\n  template:\n    metadata:\n      labels:\n        app: s01-app\n    spec:\n      containers:\n      - name: container\n        image: wordpress:latast\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04326",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: s01-deployment\n  namespace: scenario01\n  labels:\n    app: s01-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: s01-app\n  template:\n    metadata:\n      labels:\n        app: s01-app\n    spec:\n      containers:\n      - name: container\n        image: wordpress:latast\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04327",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: s01-deployment\n  namespace: scenario01\n  labels:\n    app: s01-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: s01-app\n  template:\n    metadata:\n      labels:\n        app: s01-app\n    spec:\n      containers:\n      - name: container\n        image: wordpress:latast\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04328",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: s01-deployment\n  namespace: scenario01\n  labels:\n    app: s01-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: s01-app\n  template:\n    metadata:\n      labels:\n        app: s01-app\n    spec:\n      containers:\n      - name: container\n        image: wordpress:latast\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04329",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04330",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04331",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04332",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04333",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04334",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04335",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04336",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04337",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04338",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04339",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": false,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "no containers found in manifest"
    ]
  },
  {
    "id": "04340",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: load\n  labels:\n    service: load\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      service: load\n  template:\n    metadata:\n      labels:\n        service: load\n    spec:\n      containers:\n      - name: load\n        env:\n        - name: HOST\n          value: http://payment.robotshop:8080/health\n        - name: NUM_CLIENTS\n          value: '15'\n        - name: SILENT\n          value: '1'\n        - name: ERROR\n          value: '1'\n        image: robotshop/rs-load:stable\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04341",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: load\n  labels:\n    service: load\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      service: load\n  template:\n    metadata:\n      labels:\n        service: load\n    spec:\n      containers:\n      - name: load\n        env:\n        - name: HOST\n          value: http://payment.robotshop:8080/health\n        - name: NUM_CLIENTS\n          value: '15'\n        - name: SILENT\n          value: '1'\n        - name: ERROR\n          value: '1'\n        image: robotshop/rs-load:stable\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04342",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: load\n  labels:\n    service: load\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      service: load\n  template:\n    metadata:\n      labels:\n        service: load\n    spec:\n      containers:\n      - name: load\n        env:\n        - name: HOST\n          value: http://payment.robotshop:8080/health\n        - name: NUM_CLIENTS\n          value: '15'\n        - name: SILENT\n          value: '1'\n        - name: ERROR\n          value: '1'\n        image: robotshop/rs-load:stable\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04343",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: tf-ssdmobilenet-default-1024-26\nspec:\n  template:\n    metadata:\n      name: tf-ssdmobilenet-default-1024-26-pod\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - cp /root/configs/1024/mlperf.conf /root/inference/v0.5/ && cd /root/inference/v0.5/classification_and_detection\n          && MODEL_DIR=/root/models/tf-ssdmobilenet-default DATA_DIR=/root/datasets/coco-300\n          ./run_local.sh tf ssd-mobilenet gpu --scenario SingleStream\n        image: aferikoglou/mlperf-inference:stable\n        name: mlperf-inference-container\n        resources:\n          limits:\n            aliyun.com/gpu-mem: 24\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04344",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: tf-ssdmobilenet-default-1024-26\nspec:\n  template:\n    metadata:\n      name: tf-ssdmobilenet-default-1024-26-pod\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - cp /root/configs/1024/mlperf.conf /root/inference/v0.5/ && cd /root/inference/v0.5/classification_and_detection\n          && MODEL_DIR=/root/models/tf-ssdmobilenet-default DATA_DIR=/root/datasets/coco-300\n          ./run_local.sh tf ssd-mobilenet gpu --scenario SingleStream\n        image: aferikoglou/mlperf-inference:stable\n        name: mlperf-inference-container\n        resources:\n          limits:\n            aliyun.com/gpu-mem: 24\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04345",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: tf-ssdmobilenet-default-1024-26\nspec:\n  template:\n    metadata:\n      name: tf-ssdmobilenet-default-1024-26-pod\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - cp /root/configs/1024/mlperf.conf /root/inference/v0.5/ && cd /root/inference/v0.5/classification_and_detection\n          && MODEL_DIR=/root/models/tf-ssdmobilenet-default DATA_DIR=/root/datasets/coco-300\n          ./run_local.sh tf ssd-mobilenet gpu --scenario SingleStream\n        image: aferikoglou/mlperf-inference:stable\n        name: mlperf-inference-container\n        resources:\n          limits:\n            aliyun.com/gpu-mem: 24\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04346",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: tf-ssdmobilenet-default-1024-26\nspec:\n  template:\n    metadata:\n      name: tf-ssdmobilenet-default-1024-26-pod\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - cp /root/configs/1024/mlperf.conf /root/inference/v0.5/ && cd /root/inference/v0.5/classification_and_detection\n          && MODEL_DIR=/root/models/tf-ssdmobilenet-default DATA_DIR=/root/datasets/coco-300\n          ./run_local.sh tf ssd-mobilenet gpu --scenario SingleStream\n        image: aferikoglou/mlperf-inference:stable\n        name: mlperf-inference-container\n        resources:\n          limits:\n            aliyun.com/gpu-mem: 24\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04347",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: tf-ssdmobilenet-default-1024-26\nspec:\n  template:\n    metadata:\n      name: tf-ssdmobilenet-default-1024-26-pod\n    spec:\n      containers:\n      - command:\n        - sh\n        - -c\n        - cp /root/configs/1024/mlperf.conf /root/inference/v0.5/ && cd /root/inference/v0.5/classification_and_detection\n          && MODEL_DIR=/root/models/tf-ssdmobilenet-default DATA_DIR=/root/datasets/coco-300\n          ./run_local.sh tf ssd-mobilenet gpu --scenario SingleStream\n        image: aferikoglou/mlperf-inference:stable\n        name: mlperf-inference-container\n        resources:\n          limits:\n            aliyun.com/gpu-mem: 24\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04348",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04349",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04350",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04351",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04352",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04353",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04354",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04355",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04356",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04357",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04358",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04359",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04360",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04361",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04362",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ebs-csi-node\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-ebs-csi-driver\nspec:\n  selector:\n    matchLabels:\n      app: ebs-csi-node\n      app.kubernetes.io/name: aws-ebs-csi-driver\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-node\n        app.kubernetes.io/name: aws-ebs-csi-driver\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: eks.amazonaws.com/compute-type\n                operator: NotIn\n                values:\n                - fargate\n      serviceAccountName: ebs-csi-node-sa\n      containers:\n      - name: ebs-plugin\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        image: k8s.gcr.io/provider-aws/aws-ebs-csi-driver:stable\n        args:\n        - node\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:/csi/csi.sock\n        volumeMounts:\n        - name: kubelet-dir\n          mountPath: /var/lib/kubelet\n          mountPropagation: Bidirectional\n        - name: plugin-dir\n          mountPath: /csi\n        - name: device-dir\n          mountPath: /dev\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: node-driver-registrar\n        image: quay.io/k8scsi/csi-node-driver-registrar:v2.0.1\n        args:\n        - --csi-address=$(ADDRESS)\n        - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)\n        - --v=5\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        - name: DRIVER_REG_SOCK_PATH\n          value: /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        - name: registration-dir\n          mountPath: /registration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v2.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubelet-dir\n        hostPath:\n          path: /var/lib/kubelet\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins/ebs.csi.aws.com/\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: /var/lib/kubelet/plugins_registry/\n          type: Directory\n      - name: device-dir\n        hostPath:\n          path: /dev\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "04363",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04364",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04365",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04366",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04367",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04368",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ca-certificates-(( random.String 5 \"[a-z]\" ))\nspec:\n  template:\n    spec:\n      containers:\n      - name: certs\n        image: qlik-docker-qsefe.bintray.io/edge-auth:2.57.1\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cp /etc/ssl/certs/ca-certificates.crt /mnt/certs/ca-certificates.crt; $(CERTS_COMMAND)\n        env:\n        - name: CERTS_COMMAND\n          valueFrom:\n            configMapKeyRef:\n              key: caCommand\n              name: configs\n        - name: CUSTOM_CERTS\n          valueFrom:\n            secretKeyRef:\n              key: caCertificates\n              name: secrets\n        volumeMounts:\n        - name: ca-certificates\n          mountPath: /mnt/certs\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: ca-certificates\n        persistentVolumeClaim:\n          claimName: ca-certificates\n",
    "errors": []
  },
  {
    "id": "04369",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ca-certificates-(( random.String 5 \"[a-z]\" ))\nspec:\n  template:\n    spec:\n      containers:\n      - name: certs\n        image: qlik-docker-qsefe.bintray.io/edge-auth:2.57.1\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cp /etc/ssl/certs/ca-certificates.crt /mnt/certs/ca-certificates.crt; $(CERTS_COMMAND)\n        env:\n        - name: CERTS_COMMAND\n          valueFrom:\n            configMapKeyRef:\n              key: caCommand\n              name: configs\n        - name: CUSTOM_CERTS\n          valueFrom:\n            secretKeyRef:\n              key: caCertificates\n              name: secrets\n        volumeMounts:\n        - name: ca-certificates\n          mountPath: /mnt/certs\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: ca-certificates\n        persistentVolumeClaim:\n          claimName: ca-certificates\n",
    "errors": []
  },
  {
    "id": "04370",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ca-certificates-(( random.String 5 \"[a-z]\" ))\nspec:\n  template:\n    spec:\n      containers:\n      - name: certs\n        image: qlik-docker-qsefe.bintray.io/edge-auth:2.57.1\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cp /etc/ssl/certs/ca-certificates.crt /mnt/certs/ca-certificates.crt; $(CERTS_COMMAND)\n        env:\n        - name: CERTS_COMMAND\n          valueFrom:\n            configMapKeyRef:\n              key: caCommand\n              name: configs\n        - name: CUSTOM_CERTS\n          valueFrom:\n            secretKeyRef:\n              key: caCertificates\n              name: secrets\n        volumeMounts:\n        - name: ca-certificates\n          mountPath: /mnt/certs\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: ca-certificates\n        persistentVolumeClaim:\n          claimName: ca-certificates\n",
    "errors": []
  },
  {
    "id": "04371",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: ca-certificates-(( random.String 5 \"[a-z]\" ))\nspec:\n  template:\n    spec:\n      containers:\n      - name: certs\n        image: qlik-docker-qsefe.bintray.io/edge-auth:2.57.1\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cp /etc/ssl/certs/ca-certificates.crt /mnt/certs/ca-certificates.crt; $(CERTS_COMMAND)\n        env:\n        - name: CERTS_COMMAND\n          valueFrom:\n            configMapKeyRef:\n              key: caCommand\n              name: configs\n        - name: CUSTOM_CERTS\n          valueFrom:\n            secretKeyRef:\n              key: caCertificates\n              name: secrets\n        volumeMounts:\n        - name: ca-certificates\n          mountPath: /mnt/certs\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: ca-certificates\n        persistentVolumeClaim:\n          claimName: ca-certificates\n",
    "errors": []
  },
  {
    "id": "04372",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.8.2\n        ports:\n        - containerPort: 60000\n          name: metrics\n        args:\n        - start\n        - --platform=openshift\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04373",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.8.2\n        ports:\n        - containerPort: 60000\n          name: metrics\n        args:\n        - start\n        - --platform=openshift\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04374",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.8.2\n        ports:\n        - containerPort: 60000\n          name: metrics\n        args:\n        - start\n        - --platform=openshift\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "04375",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.8.2\n        ports:\n        - containerPort: 60000\n          name: metrics\n        args:\n        - start\n        - --platform=openshift\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  }
]