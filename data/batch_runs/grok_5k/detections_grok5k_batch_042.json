[
  {
    "id": "01681",
    "manifest_path": "data/manifests/the_stack_sample/sample_0568.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app\n  template:\n    metadata:\n      labels:\n        app: app\n    spec:\n      containers:\n      - name: app-api\n        image: gcr.io/google-samples/node-hello:1.0\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"app-api\" is not set to runAsNonRoot"
  },
  {
    "id": "01682",
    "manifest_path": "data/manifests/the_stack_sample/sample_0568.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app\n  template:\n    metadata:\n      labels:\n        app: app\n    spec:\n      containers:\n      - name: app-api\n        image: gcr.io/google-samples/node-hello:1.0\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"app-api\" has cpu request 0"
  },
  {
    "id": "01683",
    "manifest_path": "data/manifests/the_stack_sample/sample_0568.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  labels:\n    app: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app\n  template:\n    metadata:\n      labels:\n        app: app\n    spec:\n      containers:\n      - name: app-api\n        image: gcr.io/google-samples/node-hello:1.0\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"app-api\" has memory limit 0"
  },
  {
    "id": "01684",
    "manifest_path": "data/manifests/the_stack_sample/sample_0570.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    flux.weave.works/automated: 'true'\n    flux.weave.works/tag.init: glob:1.4.*\n    flux.weave.works/tag.podinfod: glob:1.4.*\n    flux.weave.works/locked: 'true'\n    flux.weave.works/locked_msg: 1.4.2 does not work for us\n    flux.weave.works/locked_user: \"Changyu Seon (\\u1109\\u1165\\u11AB\\u110E\\u1161\\u11AB\\\n      \\u1100\\u1172) <changyu.seon@bespinglobal.com>\"\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.4.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init\" does not have a read-only root file system"
  },
  {
    "id": "01685",
    "manifest_path": "data/manifests/the_stack_sample/sample_0570.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    flux.weave.works/automated: 'true'\n    flux.weave.works/tag.init: glob:1.4.*\n    flux.weave.works/tag.podinfod: glob:1.4.*\n    flux.weave.works/locked: 'true'\n    flux.weave.works/locked_msg: 1.4.2 does not work for us\n    flux.weave.works/locked_user: \"Changyu Seon (\\u1109\\u1165\\u11AB\\u110E\\u1161\\u11AB\\\n      \\u1100\\u1172) <changyu.seon@bespinglobal.com>\"\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.4.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"podinfod\" does not have a read-only root file system"
  },
  {
    "id": "01686",
    "manifest_path": "data/manifests/the_stack_sample/sample_0570.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    flux.weave.works/automated: 'true'\n    flux.weave.works/tag.init: glob:1.4.*\n    flux.weave.works/tag.podinfod: glob:1.4.*\n    flux.weave.works/locked: 'true'\n    flux.weave.works/locked_msg: 1.4.2 does not work for us\n    flux.weave.works/locked_user: \"Changyu Seon (\\u1109\\u1165\\u11AB\\u110E\\u1161\\u11AB\\\n      \\u1100\\u1172) <changyu.seon@bespinglobal.com>\"\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.4.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init\" is not set to runAsNonRoot"
  },
  {
    "id": "01687",
    "manifest_path": "data/manifests/the_stack_sample/sample_0570.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    flux.weave.works/automated: 'true'\n    flux.weave.works/tag.init: glob:1.4.*\n    flux.weave.works/tag.podinfod: glob:1.4.*\n    flux.weave.works/locked: 'true'\n    flux.weave.works/locked_msg: 1.4.2 does not work for us\n    flux.weave.works/locked_user: \"Changyu Seon (\\u1109\\u1165\\u11AB\\u110E\\u1161\\u11AB\\\n      \\u1100\\u1172) <changyu.seon@bespinglobal.com>\"\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.4.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"podinfod\" is not set to runAsNonRoot"
  },
  {
    "id": "01688",
    "manifest_path": "data/manifests/the_stack_sample/sample_0570.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    flux.weave.works/automated: 'true'\n    flux.weave.works/tag.init: glob:1.4.*\n    flux.weave.works/tag.podinfod: glob:1.4.*\n    flux.weave.works/locked: 'true'\n    flux.weave.works/locked_msg: 1.4.2 does not work for us\n    flux.weave.works/locked_user: \"Changyu Seon (\\u1109\\u1165\\u11AB\\u110E\\u1161\\u11AB\\\n      \\u1100\\u1172) <changyu.seon@bespinglobal.com>\"\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.4.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init\" has cpu request 0"
  },
  {
    "id": "01689",
    "manifest_path": "data/manifests/the_stack_sample/sample_0570.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    flux.weave.works/automated: 'true'\n    flux.weave.works/tag.init: glob:1.4.*\n    flux.weave.works/tag.podinfod: glob:1.4.*\n    flux.weave.works/locked: 'true'\n    flux.weave.works/locked_msg: 1.4.2 does not work for us\n    flux.weave.works/locked_user: \"Changyu Seon (\\u1109\\u1165\\u11AB\\u110E\\u1161\\u11AB\\\n      \\u1100\\u1172) <changyu.seon@bespinglobal.com>\"\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:1.4.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9898\n          name: http\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: green\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init\" has memory limit 0"
  },
  {
    "id": "01690",
    "manifest_path": "data/manifests/the_stack_sample/sample_0572.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: kubernetes-client\n  labels:\n    app: kubernetes-client\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubernetes-client\n  template:\n    metadata:\n      labels:\n        app: kubernetes-client\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: kubernetes-client\n        image: <KUBERNETES_CLIENT_IMAGE>\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - set -x; cd maven; java $JAVA_OPTS -Dhttp.proxyHost=$ACUMOS_HTTP_PROXY_HOST\n          -Dhttp.proxyPort=$ACUMOS_HTTP_PROXY_PORT -Dhttp.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS\n          -Dhttps.proxyHost=$ACUMOS_HTTP_PROXY_HOST -Dhttps.proxyPort=$ACUMOS_HTTP_PROXY_PORT\n          -Dhttps.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS -Djava.security.egd=file:/dev/./urandom\n          -jar *.jar\n        env:\n        - name: ACUMOS_HTTP_NON_PROXY_HOSTS\n          value: <ACUMOS_HTTP_NON_PROXY_HOSTS>|cds-service\n        - name: ACUMOS_HTTP_PROXY_HOST\n          value: <ACUMOS_HTTP_PROXY_HOST>\n        - name: ACUMOS_HTTP_PROXY_PORT\n          value: <ACUMOS_HTTP_PROXY_PORT>\n        - name: JAVA_OPTS\n          value: -Xms128m -Xmx512m\n        - name: SPRING_APPLICATION_JSON\n          value: '{ \"logging\": { \"level\": { \"root\": \"INFO\" } }, \"kube\" : { \"incrementPort\":\n            \"8557\", \"singleModelPort\": \"8556\", \"folderPath\": \"/maven/home\", \"singleNodePort\":\n            \"30333\", \"singleTargetPort\": \"8061\", \"dataBrokerModelPort\": \"8556\", \"dataBrokerNodePort\":\n            \"30556\", \"dataBrokerTargetPort\": \"8556\", \"mlTargetPort\": \"8061\", \"nginxImageName\":\n            \"nginx\", \"nexusEndPointURL\": \"http://localhost:80\" }, \"dockerproxy\": {\n            \"host\": \"<ACUMOS_DOCKER_PROXY_HOST>\", \"port\": \"<ACUMOS_DOCKER_PROXY_PORT>\"\n            }, \"blueprint\": { \"ImageName\": \"<BLUEPRINT_ORCHESTRATOR_IMAGE>\", \"name\":\n            \"blueprint-orchestrator\", \"nodePort\": \"30555\", \"port\": \"8061\" }, \"nexus\":\n            { \"url\": \"http://<ACUMOS_NEXUS_HOST>:<ACUMOS_NEXUS_API_PORT>/<ACUMOS_NEXUS_MAVEN_REPO_PATH>/<ACUMOS_NEXUS_MAVEN_REPO>/\",\n            \"password\": \"<ACUMOS_NEXUS_RW_USER_PASSWORD>\", \"username\": \"<ACUMOS_NEXUS_RW_USER>\",\n            \"groupid\": \"<ACUMOS_NEXUS_GROUP>\" }, \"cmndatasvc\": { \"cmndatasvcendpointurl\":\n            \"http://<ACUMOS_CDS_HOST>:<ACUMOS_CDS_PORT>/ccds\", \"cmndatasvcuser\": \"<ACUMOS_CDS_USER>\",\n            \"cmndatasvcpwd\": \"<ACUMOS_CDS_PASSWORD>\" }, \"probe\": { \"probeImageName\":\n            \"<PROTO_VIEWER_IMAGE>\", \"probeImagePORT\": \"5006\", \"probeModelPort\": \"5006\",\n            \"probeNodePort\": \"30800\", \"probeTargetPort\": \"5006\", \"probeApiPort\": \"5006\",\n            \"probeExternalPort\": \"30800\", \"probeSchemaPort\": \"80\" }, \"logstash\": {\n            \"host\": \"<ACUMOS_ELK_HOST>\", \"ip\": \"<ACUMOS_ELK_HOST_IP>\", \"port\": \"<ACUMOS_ELK_LOGSTASH_PORT>\"\n            }, \"server\": { \"port\": \"8082\" } }'\n        ports:\n        - containerPort: 8082\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"kubernetes-client\" is using an invalid container image, \"<KUBERNETES_CLIENT_IMAGE>\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01691",
    "manifest_path": "data/manifests/the_stack_sample/sample_0572.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: kubernetes-client\n  labels:\n    app: kubernetes-client\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubernetes-client\n  template:\n    metadata:\n      labels:\n        app: kubernetes-client\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: kubernetes-client\n        image: <KUBERNETES_CLIENT_IMAGE>\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - set -x; cd maven; java $JAVA_OPTS -Dhttp.proxyHost=$ACUMOS_HTTP_PROXY_HOST\n          -Dhttp.proxyPort=$ACUMOS_HTTP_PROXY_PORT -Dhttp.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS\n          -Dhttps.proxyHost=$ACUMOS_HTTP_PROXY_HOST -Dhttps.proxyPort=$ACUMOS_HTTP_PROXY_PORT\n          -Dhttps.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS -Djava.security.egd=file:/dev/./urandom\n          -jar *.jar\n        env:\n        - name: ACUMOS_HTTP_NON_PROXY_HOSTS\n          value: <ACUMOS_HTTP_NON_PROXY_HOSTS>|cds-service\n        - name: ACUMOS_HTTP_PROXY_HOST\n          value: <ACUMOS_HTTP_PROXY_HOST>\n        - name: ACUMOS_HTTP_PROXY_PORT\n          value: <ACUMOS_HTTP_PROXY_PORT>\n        - name: JAVA_OPTS\n          value: -Xms128m -Xmx512m\n        - name: SPRING_APPLICATION_JSON\n          value: '{ \"logging\": { \"level\": { \"root\": \"INFO\" } }, \"kube\" : { \"incrementPort\":\n            \"8557\", \"singleModelPort\": \"8556\", \"folderPath\": \"/maven/home\", \"singleNodePort\":\n            \"30333\", \"singleTargetPort\": \"8061\", \"dataBrokerModelPort\": \"8556\", \"dataBrokerNodePort\":\n            \"30556\", \"dataBrokerTargetPort\": \"8556\", \"mlTargetPort\": \"8061\", \"nginxImageName\":\n            \"nginx\", \"nexusEndPointURL\": \"http://localhost:80\" }, \"dockerproxy\": {\n            \"host\": \"<ACUMOS_DOCKER_PROXY_HOST>\", \"port\": \"<ACUMOS_DOCKER_PROXY_PORT>\"\n            }, \"blueprint\": { \"ImageName\": \"<BLUEPRINT_ORCHESTRATOR_IMAGE>\", \"name\":\n            \"blueprint-orchestrator\", \"nodePort\": \"30555\", \"port\": \"8061\" }, \"nexus\":\n            { \"url\": \"http://<ACUMOS_NEXUS_HOST>:<ACUMOS_NEXUS_API_PORT>/<ACUMOS_NEXUS_MAVEN_REPO_PATH>/<ACUMOS_NEXUS_MAVEN_REPO>/\",\n            \"password\": \"<ACUMOS_NEXUS_RW_USER_PASSWORD>\", \"username\": \"<ACUMOS_NEXUS_RW_USER>\",\n            \"groupid\": \"<ACUMOS_NEXUS_GROUP>\" }, \"cmndatasvc\": { \"cmndatasvcendpointurl\":\n            \"http://<ACUMOS_CDS_HOST>:<ACUMOS_CDS_PORT>/ccds\", \"cmndatasvcuser\": \"<ACUMOS_CDS_USER>\",\n            \"cmndatasvcpwd\": \"<ACUMOS_CDS_PASSWORD>\" }, \"probe\": { \"probeImageName\":\n            \"<PROTO_VIEWER_IMAGE>\", \"probeImagePORT\": \"5006\", \"probeModelPort\": \"5006\",\n            \"probeNodePort\": \"30800\", \"probeTargetPort\": \"5006\", \"probeApiPort\": \"5006\",\n            \"probeExternalPort\": \"30800\", \"probeSchemaPort\": \"80\" }, \"logstash\": {\n            \"host\": \"<ACUMOS_ELK_HOST>\", \"ip\": \"<ACUMOS_ELK_HOST_IP>\", \"port\": \"<ACUMOS_ELK_LOGSTASH_PORT>\"\n            }, \"server\": { \"port\": \"8082\" } }'\n        ports:\n        - containerPort: 8082\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kubernetes-client\" does not have a read-only root file system"
  },
  {
    "id": "01692",
    "manifest_path": "data/manifests/the_stack_sample/sample_0572.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: kubernetes-client\n  labels:\n    app: kubernetes-client\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubernetes-client\n  template:\n    metadata:\n      labels:\n        app: kubernetes-client\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: kubernetes-client\n        image: <KUBERNETES_CLIENT_IMAGE>\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - set -x; cd maven; java $JAVA_OPTS -Dhttp.proxyHost=$ACUMOS_HTTP_PROXY_HOST\n          -Dhttp.proxyPort=$ACUMOS_HTTP_PROXY_PORT -Dhttp.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS\n          -Dhttps.proxyHost=$ACUMOS_HTTP_PROXY_HOST -Dhttps.proxyPort=$ACUMOS_HTTP_PROXY_PORT\n          -Dhttps.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS -Djava.security.egd=file:/dev/./urandom\n          -jar *.jar\n        env:\n        - name: ACUMOS_HTTP_NON_PROXY_HOSTS\n          value: <ACUMOS_HTTP_NON_PROXY_HOSTS>|cds-service\n        - name: ACUMOS_HTTP_PROXY_HOST\n          value: <ACUMOS_HTTP_PROXY_HOST>\n        - name: ACUMOS_HTTP_PROXY_PORT\n          value: <ACUMOS_HTTP_PROXY_PORT>\n        - name: JAVA_OPTS\n          value: -Xms128m -Xmx512m\n        - name: SPRING_APPLICATION_JSON\n          value: '{ \"logging\": { \"level\": { \"root\": \"INFO\" } }, \"kube\" : { \"incrementPort\":\n            \"8557\", \"singleModelPort\": \"8556\", \"folderPath\": \"/maven/home\", \"singleNodePort\":\n            \"30333\", \"singleTargetPort\": \"8061\", \"dataBrokerModelPort\": \"8556\", \"dataBrokerNodePort\":\n            \"30556\", \"dataBrokerTargetPort\": \"8556\", \"mlTargetPort\": \"8061\", \"nginxImageName\":\n            \"nginx\", \"nexusEndPointURL\": \"http://localhost:80\" }, \"dockerproxy\": {\n            \"host\": \"<ACUMOS_DOCKER_PROXY_HOST>\", \"port\": \"<ACUMOS_DOCKER_PROXY_PORT>\"\n            }, \"blueprint\": { \"ImageName\": \"<BLUEPRINT_ORCHESTRATOR_IMAGE>\", \"name\":\n            \"blueprint-orchestrator\", \"nodePort\": \"30555\", \"port\": \"8061\" }, \"nexus\":\n            { \"url\": \"http://<ACUMOS_NEXUS_HOST>:<ACUMOS_NEXUS_API_PORT>/<ACUMOS_NEXUS_MAVEN_REPO_PATH>/<ACUMOS_NEXUS_MAVEN_REPO>/\",\n            \"password\": \"<ACUMOS_NEXUS_RW_USER_PASSWORD>\", \"username\": \"<ACUMOS_NEXUS_RW_USER>\",\n            \"groupid\": \"<ACUMOS_NEXUS_GROUP>\" }, \"cmndatasvc\": { \"cmndatasvcendpointurl\":\n            \"http://<ACUMOS_CDS_HOST>:<ACUMOS_CDS_PORT>/ccds\", \"cmndatasvcuser\": \"<ACUMOS_CDS_USER>\",\n            \"cmndatasvcpwd\": \"<ACUMOS_CDS_PASSWORD>\" }, \"probe\": { \"probeImageName\":\n            \"<PROTO_VIEWER_IMAGE>\", \"probeImagePORT\": \"5006\", \"probeModelPort\": \"5006\",\n            \"probeNodePort\": \"30800\", \"probeTargetPort\": \"5006\", \"probeApiPort\": \"5006\",\n            \"probeExternalPort\": \"30800\", \"probeSchemaPort\": \"80\" }, \"logstash\": {\n            \"host\": \"<ACUMOS_ELK_HOST>\", \"ip\": \"<ACUMOS_ELK_HOST_IP>\", \"port\": \"<ACUMOS_ELK_LOGSTASH_PORT>\"\n            }, \"server\": { \"port\": \"8082\" } }'\n        ports:\n        - containerPort: 8082\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kubernetes-client\" is not set to runAsNonRoot"
  },
  {
    "id": "01693",
    "manifest_path": "data/manifests/the_stack_sample/sample_0572.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: kubernetes-client\n  labels:\n    app: kubernetes-client\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubernetes-client\n  template:\n    metadata:\n      labels:\n        app: kubernetes-client\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: kubernetes-client\n        image: <KUBERNETES_CLIENT_IMAGE>\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - set -x; cd maven; java $JAVA_OPTS -Dhttp.proxyHost=$ACUMOS_HTTP_PROXY_HOST\n          -Dhttp.proxyPort=$ACUMOS_HTTP_PROXY_PORT -Dhttp.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS\n          -Dhttps.proxyHost=$ACUMOS_HTTP_PROXY_HOST -Dhttps.proxyPort=$ACUMOS_HTTP_PROXY_PORT\n          -Dhttps.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS -Djava.security.egd=file:/dev/./urandom\n          -jar *.jar\n        env:\n        - name: ACUMOS_HTTP_NON_PROXY_HOSTS\n          value: <ACUMOS_HTTP_NON_PROXY_HOSTS>|cds-service\n        - name: ACUMOS_HTTP_PROXY_HOST\n          value: <ACUMOS_HTTP_PROXY_HOST>\n        - name: ACUMOS_HTTP_PROXY_PORT\n          value: <ACUMOS_HTTP_PROXY_PORT>\n        - name: JAVA_OPTS\n          value: -Xms128m -Xmx512m\n        - name: SPRING_APPLICATION_JSON\n          value: '{ \"logging\": { \"level\": { \"root\": \"INFO\" } }, \"kube\" : { \"incrementPort\":\n            \"8557\", \"singleModelPort\": \"8556\", \"folderPath\": \"/maven/home\", \"singleNodePort\":\n            \"30333\", \"singleTargetPort\": \"8061\", \"dataBrokerModelPort\": \"8556\", \"dataBrokerNodePort\":\n            \"30556\", \"dataBrokerTargetPort\": \"8556\", \"mlTargetPort\": \"8061\", \"nginxImageName\":\n            \"nginx\", \"nexusEndPointURL\": \"http://localhost:80\" }, \"dockerproxy\": {\n            \"host\": \"<ACUMOS_DOCKER_PROXY_HOST>\", \"port\": \"<ACUMOS_DOCKER_PROXY_PORT>\"\n            }, \"blueprint\": { \"ImageName\": \"<BLUEPRINT_ORCHESTRATOR_IMAGE>\", \"name\":\n            \"blueprint-orchestrator\", \"nodePort\": \"30555\", \"port\": \"8061\" }, \"nexus\":\n            { \"url\": \"http://<ACUMOS_NEXUS_HOST>:<ACUMOS_NEXUS_API_PORT>/<ACUMOS_NEXUS_MAVEN_REPO_PATH>/<ACUMOS_NEXUS_MAVEN_REPO>/\",\n            \"password\": \"<ACUMOS_NEXUS_RW_USER_PASSWORD>\", \"username\": \"<ACUMOS_NEXUS_RW_USER>\",\n            \"groupid\": \"<ACUMOS_NEXUS_GROUP>\" }, \"cmndatasvc\": { \"cmndatasvcendpointurl\":\n            \"http://<ACUMOS_CDS_HOST>:<ACUMOS_CDS_PORT>/ccds\", \"cmndatasvcuser\": \"<ACUMOS_CDS_USER>\",\n            \"cmndatasvcpwd\": \"<ACUMOS_CDS_PASSWORD>\" }, \"probe\": { \"probeImageName\":\n            \"<PROTO_VIEWER_IMAGE>\", \"probeImagePORT\": \"5006\", \"probeModelPort\": \"5006\",\n            \"probeNodePort\": \"30800\", \"probeTargetPort\": \"5006\", \"probeApiPort\": \"5006\",\n            \"probeExternalPort\": \"30800\", \"probeSchemaPort\": \"80\" }, \"logstash\": {\n            \"host\": \"<ACUMOS_ELK_HOST>\", \"ip\": \"<ACUMOS_ELK_HOST_IP>\", \"port\": \"<ACUMOS_ELK_LOGSTASH_PORT>\"\n            }, \"server\": { \"port\": \"8082\" } }'\n        ports:\n        - containerPort: 8082\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"kubernetes-client\" has cpu request 0"
  },
  {
    "id": "01694",
    "manifest_path": "data/manifests/the_stack_sample/sample_0572.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: <ACUMOS_NAMESPACE>\n  name: kubernetes-client\n  labels:\n    app: kubernetes-client\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kubernetes-client\n  template:\n    metadata:\n      labels:\n        app: kubernetes-client\n        <ACUMOS_SERVICE_LABEL_KEY>: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: <ACUMOS_SERVICE_LABEL_KEY>\n                operator: NotIn\n                values:\n                - <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n            topologyKey: kubernetes.io/node\n      containers:\n      - name: kubernetes-client\n        image: <KUBERNETES_CLIENT_IMAGE>\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - set -x; cd maven; java $JAVA_OPTS -Dhttp.proxyHost=$ACUMOS_HTTP_PROXY_HOST\n          -Dhttp.proxyPort=$ACUMOS_HTTP_PROXY_PORT -Dhttp.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS\n          -Dhttps.proxyHost=$ACUMOS_HTTP_PROXY_HOST -Dhttps.proxyPort=$ACUMOS_HTTP_PROXY_PORT\n          -Dhttps.nonProxyHosts=$ACUMOS_HTTP_NON_PROXY_HOSTS -Djava.security.egd=file:/dev/./urandom\n          -jar *.jar\n        env:\n        - name: ACUMOS_HTTP_NON_PROXY_HOSTS\n          value: <ACUMOS_HTTP_NON_PROXY_HOSTS>|cds-service\n        - name: ACUMOS_HTTP_PROXY_HOST\n          value: <ACUMOS_HTTP_PROXY_HOST>\n        - name: ACUMOS_HTTP_PROXY_PORT\n          value: <ACUMOS_HTTP_PROXY_PORT>\n        - name: JAVA_OPTS\n          value: -Xms128m -Xmx512m\n        - name: SPRING_APPLICATION_JSON\n          value: '{ \"logging\": { \"level\": { \"root\": \"INFO\" } }, \"kube\" : { \"incrementPort\":\n            \"8557\", \"singleModelPort\": \"8556\", \"folderPath\": \"/maven/home\", \"singleNodePort\":\n            \"30333\", \"singleTargetPort\": \"8061\", \"dataBrokerModelPort\": \"8556\", \"dataBrokerNodePort\":\n            \"30556\", \"dataBrokerTargetPort\": \"8556\", \"mlTargetPort\": \"8061\", \"nginxImageName\":\n            \"nginx\", \"nexusEndPointURL\": \"http://localhost:80\" }, \"dockerproxy\": {\n            \"host\": \"<ACUMOS_DOCKER_PROXY_HOST>\", \"port\": \"<ACUMOS_DOCKER_PROXY_PORT>\"\n            }, \"blueprint\": { \"ImageName\": \"<BLUEPRINT_ORCHESTRATOR_IMAGE>\", \"name\":\n            \"blueprint-orchestrator\", \"nodePort\": \"30555\", \"port\": \"8061\" }, \"nexus\":\n            { \"url\": \"http://<ACUMOS_NEXUS_HOST>:<ACUMOS_NEXUS_API_PORT>/<ACUMOS_NEXUS_MAVEN_REPO_PATH>/<ACUMOS_NEXUS_MAVEN_REPO>/\",\n            \"password\": \"<ACUMOS_NEXUS_RW_USER_PASSWORD>\", \"username\": \"<ACUMOS_NEXUS_RW_USER>\",\n            \"groupid\": \"<ACUMOS_NEXUS_GROUP>\" }, \"cmndatasvc\": { \"cmndatasvcendpointurl\":\n            \"http://<ACUMOS_CDS_HOST>:<ACUMOS_CDS_PORT>/ccds\", \"cmndatasvcuser\": \"<ACUMOS_CDS_USER>\",\n            \"cmndatasvcpwd\": \"<ACUMOS_CDS_PASSWORD>\" }, \"probe\": { \"probeImageName\":\n            \"<PROTO_VIEWER_IMAGE>\", \"probeImagePORT\": \"5006\", \"probeModelPort\": \"5006\",\n            \"probeNodePort\": \"30800\", \"probeTargetPort\": \"5006\", \"probeApiPort\": \"5006\",\n            \"probeExternalPort\": \"30800\", \"probeSchemaPort\": \"80\" }, \"logstash\": {\n            \"host\": \"<ACUMOS_ELK_HOST>\", \"ip\": \"<ACUMOS_ELK_HOST_IP>\", \"port\": \"<ACUMOS_ELK_LOGSTASH_PORT>\"\n            }, \"server\": { \"port\": \"8082\" } }'\n        ports:\n        - containerPort: 8082\n        volumeMounts:\n        - mountPath: /maven/logs\n          name: logs\n      volumes:\n      - name: logs\n        persistentVolumeClaim:\n          claimName: <ACUMOS_KUBERNETES_CLIENT_SERVICE_LABEL>\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kubernetes-client\" has memory limit 0"
  },
  {
    "id": "01695",
    "manifest_path": "data/manifests/the_stack_sample/sample_0574.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: hotel-fahmi-server-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      framework: codeigniter-4\n      language: php\n      type: server\n      app: hotel-fahmi-server\n  template:\n    metadata:\n      name: hotel-fahmi-server\n      labels:\n        framework: codeigniter-4\n        language: php\n        type: server\n        app: hotel-fahmi-server\n      annotations:\n        description: merupakan aplikasi hotel fahmi yang bersifat server untuk berintaraksi\n          dengan user\n    spec:\n      containers:\n      - name: hotel-fahmi\n        image: localhost:5000/hotel-fahmi\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hotel-fahmi\" is using an invalid container image, \"localhost:5000/hotel-fahmi\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01696",
    "manifest_path": "data/manifests/the_stack_sample/sample_0574.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: hotel-fahmi-server-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      framework: codeigniter-4\n      language: php\n      type: server\n      app: hotel-fahmi-server\n  template:\n    metadata:\n      name: hotel-fahmi-server\n      labels:\n        framework: codeigniter-4\n        language: php\n        type: server\n        app: hotel-fahmi-server\n      annotations:\n        description: merupakan aplikasi hotel fahmi yang bersifat server untuk berintaraksi\n          dengan user\n    spec:\n      containers:\n      - name: hotel-fahmi\n        image: localhost:5000/hotel-fahmi\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hotel-fahmi\" does not have a read-only root file system"
  },
  {
    "id": "01697",
    "manifest_path": "data/manifests/the_stack_sample/sample_0574.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: hotel-fahmi-server-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      framework: codeigniter-4\n      language: php\n      type: server\n      app: hotel-fahmi-server\n  template:\n    metadata:\n      name: hotel-fahmi-server\n      labels:\n        framework: codeigniter-4\n        language: php\n        type: server\n        app: hotel-fahmi-server\n      annotations:\n        description: merupakan aplikasi hotel fahmi yang bersifat server untuk berintaraksi\n          dengan user\n    spec:\n      containers:\n      - name: hotel-fahmi\n        image: localhost:5000/hotel-fahmi\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hotel-fahmi\" is not set to runAsNonRoot"
  },
  {
    "id": "01698",
    "manifest_path": "data/manifests/the_stack_sample/sample_0574.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: hotel-fahmi-server-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      framework: codeigniter-4\n      language: php\n      type: server\n      app: hotel-fahmi-server\n  template:\n    metadata:\n      name: hotel-fahmi-server\n      labels:\n        framework: codeigniter-4\n        language: php\n        type: server\n        app: hotel-fahmi-server\n      annotations:\n        description: merupakan aplikasi hotel fahmi yang bersifat server untuk berintaraksi\n          dengan user\n    spec:\n      containers:\n      - name: hotel-fahmi\n        image: localhost:5000/hotel-fahmi\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"hotel-fahmi\" has cpu request 0"
  },
  {
    "id": "01699",
    "manifest_path": "data/manifests/the_stack_sample/sample_0574.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: hotel-fahmi-server-rs\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      framework: codeigniter-4\n      language: php\n      type: server\n      app: hotel-fahmi-server\n  template:\n    metadata:\n      name: hotel-fahmi-server\n      labels:\n        framework: codeigniter-4\n        language: php\n        type: server\n        app: hotel-fahmi-server\n      annotations:\n        description: merupakan aplikasi hotel fahmi yang bersifat server untuk berintaraksi\n          dengan user\n    spec:\n      containers:\n      - name: hotel-fahmi\n        image: localhost:5000/hotel-fahmi\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 0\n          periodSeconds: 10\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"hotel-fahmi\" has memory limit 0"
  },
  {
    "id": "01700",
    "manifest_path": "data/manifests/the_stack_sample/sample_0575.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-refiner-test\n  labels:\n    app: node-refiner\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: node-refiner\n  template:\n    metadata:\n      labels:\n        app: node-refiner\n    spec:\n      serviceAccountName: node-refiner-sa\n      containers:\n      - name: application\n        image: alisoliman/node-refiner:${IMAGE_TAGGED}\n        imagePullPolicy: Always\n        ports:\n        - name: health\n          containerPort: 9102\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /alive\n            port: health\n        env:\n        - name: LISTENING_PORT\n          value: '8080'\n        resources:\n          requests:\n            cpu: 50m\n            memory: 256Mi\n          limits:\n            cpu: 200m\n            memory: 512Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"application\" does not have a read-only root file system"
  },
  {
    "id": "01701",
    "manifest_path": "data/manifests/the_stack_sample/sample_0575.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-refiner-test\n  labels:\n    app: node-refiner\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: node-refiner\n  template:\n    metadata:\n      labels:\n        app: node-refiner\n    spec:\n      serviceAccountName: node-refiner-sa\n      containers:\n      - name: application\n        image: alisoliman/node-refiner:${IMAGE_TAGGED}\n        imagePullPolicy: Always\n        ports:\n        - name: health\n          containerPort: 9102\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /alive\n            port: health\n        env:\n        - name: LISTENING_PORT\n          value: '8080'\n        resources:\n          requests:\n            cpu: 50m\n            memory: 256Mi\n          limits:\n            cpu: 200m\n            memory: 512Mi\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"application\" is not set to runAsNonRoot"
  },
  {
    "id": "01702",
    "manifest_path": "data/manifests/the_stack_sample/sample_0582.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: mattermost\n    role: mattermost-worker\n  name: mattermost-worker\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: mattermost-worker\n  template:\n    metadata:\n      labels:\n        app: mattermost\n        role: mattermost-worker\n    spec:\n      containers:\n      - image: __REGISTRY_IP__/mattermost-worker:5.21.0\n        name: mattermost-worker\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        volumeMounts:\n        - name: config-volume\n          mountPath: /var/mattermost/config\n      volumes:\n      - name: config-volume\n        configMap:\n          name: mattermost-v1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mattermost-worker\" does not have a read-only root file system"
  },
  {
    "id": "01703",
    "manifest_path": "data/manifests/the_stack_sample/sample_0582.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: mattermost\n    role: mattermost-worker\n  name: mattermost-worker\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: mattermost-worker\n  template:\n    metadata:\n      labels:\n        app: mattermost\n        role: mattermost-worker\n    spec:\n      containers:\n      - image: __REGISTRY_IP__/mattermost-worker:5.21.0\n        name: mattermost-worker\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        volumeMounts:\n        - name: config-volume\n          mountPath: /var/mattermost/config\n      volumes:\n      - name: config-volume\n        configMap:\n          name: mattermost-v1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mattermost-worker\" is not set to runAsNonRoot"
  },
  {
    "id": "01704",
    "manifest_path": "data/manifests/the_stack_sample/sample_0582.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: mattermost\n    role: mattermost-worker\n  name: mattermost-worker\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: mattermost-worker\n  template:\n    metadata:\n      labels:\n        app: mattermost\n        role: mattermost-worker\n    spec:\n      containers:\n      - image: __REGISTRY_IP__/mattermost-worker:5.21.0\n        name: mattermost-worker\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        volumeMounts:\n        - name: config-volume\n          mountPath: /var/mattermost/config\n      volumes:\n      - name: config-volume\n        configMap:\n          name: mattermost-v1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"mattermost-worker\" has cpu request 0"
  },
  {
    "id": "01705",
    "manifest_path": "data/manifests/the_stack_sample/sample_0582.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: mattermost\n    role: mattermost-worker\n  name: mattermost-worker\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: mattermost-worker\n  template:\n    metadata:\n      labels:\n        app: mattermost\n        role: mattermost-worker\n    spec:\n      containers:\n      - image: __REGISTRY_IP__/mattermost-worker:5.21.0\n        name: mattermost-worker\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        volumeMounts:\n        - name: config-volume\n          mountPath: /var/mattermost/config\n      volumes:\n      - name: config-volume\n        configMap:\n          name: mattermost-v1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"mattermost-worker\" has memory limit 0"
  },
  {
    "id": "01706",
    "manifest_path": "data/manifests/the_stack_sample/sample_0583.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: aws-efa-k8s-device-plugin-daemonset\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: aws-efa-k8s-device-plugin\n  template:\n    metadata:\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aws-efa-k8s-device-plugin\n    spec:\n      serviceAccount: default\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: beta.kubernetes.io/instance-type\n                operator: In\n                values:\n                - c5n.18xlarge\n                - c5n.metal\n                - g4dn.metal\n                - i3en.24xlarge\n                - i3en.metal\n                - inf1.24xlarge\n                - m5dn.24xlarge\n                - m5n.24xlarge\n                - p3dn.24xlarge\n                - r5dn.24xlarge\n                - r5n.24xlarge\n                - p4d.24xlarge\n            - matchExpressions:\n              - key: node.kubernetes.io/instance-type\n                operator: In\n                values:\n                - c5n.18xlarge\n                - c5n.metal\n                - g4dn.metal\n                - i3en.24xlarge\n                - i3en.metal\n                - inf1.24xlarge\n                - m5dn.24xlarge\n                - m5n.24xlarge\n                - p3dn.24xlarge\n                - r5dn.24xlarge\n                - r5n.24xlarge\n                - p4d.24xlarge\n      containers:\n      - image: '%s.dkr.ecr.%s.%s/eks/aws-efa-k8s-device-plugin:v0.3.3'\n        name: aws-efa-k8s-device-plugin\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: device-plugin\n          mountPath: /var/lib/kubelet/device-plugins\n      volumes:\n      - name: device-plugin\n        hostPath:\n          path: /var/lib/kubelet/device-plugins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"aws-efa-k8s-device-plugin\" does not have a read-only root file system"
  },
  {
    "id": "01707",
    "manifest_path": "data/manifests/the_stack_sample/sample_0583.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: aws-efa-k8s-device-plugin-daemonset\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: aws-efa-k8s-device-plugin\n  template:\n    metadata:\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aws-efa-k8s-device-plugin\n    spec:\n      serviceAccount: default\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: beta.kubernetes.io/instance-type\n                operator: In\n                values:\n                - c5n.18xlarge\n                - c5n.metal\n                - g4dn.metal\n                - i3en.24xlarge\n                - i3en.metal\n                - inf1.24xlarge\n                - m5dn.24xlarge\n                - m5n.24xlarge\n                - p3dn.24xlarge\n                - r5dn.24xlarge\n                - r5n.24xlarge\n                - p4d.24xlarge\n            - matchExpressions:\n              - key: node.kubernetes.io/instance-type\n                operator: In\n                values:\n                - c5n.18xlarge\n                - c5n.metal\n                - g4dn.metal\n                - i3en.24xlarge\n                - i3en.metal\n                - inf1.24xlarge\n                - m5dn.24xlarge\n                - m5n.24xlarge\n                - p3dn.24xlarge\n                - r5dn.24xlarge\n                - r5n.24xlarge\n                - p4d.24xlarge\n      containers:\n      - image: '%s.dkr.ecr.%s.%s/eks/aws-efa-k8s-device-plugin:v0.3.3'\n        name: aws-efa-k8s-device-plugin\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: device-plugin\n          mountPath: /var/lib/kubelet/device-plugins\n      volumes:\n      - name: device-plugin\n        hostPath:\n          path: /var/lib/kubelet/device-plugins\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"aws-efa-k8s-device-plugin\" is not set to runAsNonRoot"
  },
  {
    "id": "01708",
    "manifest_path": "data/manifests/the_stack_sample/sample_0583.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: aws-efa-k8s-device-plugin-daemonset\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: aws-efa-k8s-device-plugin\n  template:\n    metadata:\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aws-efa-k8s-device-plugin\n    spec:\n      serviceAccount: default\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: beta.kubernetes.io/instance-type\n                operator: In\n                values:\n                - c5n.18xlarge\n                - c5n.metal\n                - g4dn.metal\n                - i3en.24xlarge\n                - i3en.metal\n                - inf1.24xlarge\n                - m5dn.24xlarge\n                - m5n.24xlarge\n                - p3dn.24xlarge\n                - r5dn.24xlarge\n                - r5n.24xlarge\n                - p4d.24xlarge\n            - matchExpressions:\n              - key: node.kubernetes.io/instance-type\n                operator: In\n                values:\n                - c5n.18xlarge\n                - c5n.metal\n                - g4dn.metal\n                - i3en.24xlarge\n                - i3en.metal\n                - inf1.24xlarge\n                - m5dn.24xlarge\n                - m5n.24xlarge\n                - p3dn.24xlarge\n                - r5dn.24xlarge\n                - r5n.24xlarge\n                - p4d.24xlarge\n      containers:\n      - image: '%s.dkr.ecr.%s.%s/eks/aws-efa-k8s-device-plugin:v0.3.3'\n        name: aws-efa-k8s-device-plugin\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: device-plugin\n          mountPath: /var/lib/kubelet/device-plugins\n      volumes:\n      - name: device-plugin\n        hostPath:\n          path: /var/lib/kubelet/device-plugins\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"aws-efa-k8s-device-plugin\" has cpu request 0"
  },
  {
    "id": "01709",
    "manifest_path": "data/manifests/the_stack_sample/sample_0583.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: aws-efa-k8s-device-plugin-daemonset\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      name: aws-efa-k8s-device-plugin\n  template:\n    metadata:\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aws-efa-k8s-device-plugin\n    spec:\n      serviceAccount: default\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: beta.kubernetes.io/instance-type\n                operator: In\n                values:\n                - c5n.18xlarge\n                - c5n.metal\n                - g4dn.metal\n                - i3en.24xlarge\n                - i3en.metal\n                - inf1.24xlarge\n                - m5dn.24xlarge\n                - m5n.24xlarge\n                - p3dn.24xlarge\n                - r5dn.24xlarge\n                - r5n.24xlarge\n                - p4d.24xlarge\n            - matchExpressions:\n              - key: node.kubernetes.io/instance-type\n                operator: In\n                values:\n                - c5n.18xlarge\n                - c5n.metal\n                - g4dn.metal\n                - i3en.24xlarge\n                - i3en.metal\n                - inf1.24xlarge\n                - m5dn.24xlarge\n                - m5n.24xlarge\n                - p3dn.24xlarge\n                - r5dn.24xlarge\n                - r5n.24xlarge\n                - p4d.24xlarge\n      containers:\n      - image: '%s.dkr.ecr.%s.%s/eks/aws-efa-k8s-device-plugin:v0.3.3'\n        name: aws-efa-k8s-device-plugin\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: device-plugin\n          mountPath: /var/lib/kubelet/device-plugins\n      volumes:\n      - name: device-plugin\n        hostPath:\n          path: /var/lib/kubelet/device-plugins\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"aws-efa-k8s-device-plugin\" has memory limit 0"
  },
  {
    "id": "01710",
    "manifest_path": "data/manifests/the_stack_sample/sample_0584.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210421-8709509fc9\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"crier\" does not have a read-only root file system"
  },
  {
    "id": "01711",
    "manifest_path": "data/manifests/the_stack_sample/sample_0584.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210421-8709509fc9\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"crier\" is not set to runAsNonRoot"
  },
  {
    "id": "01712",
    "manifest_path": "data/manifests/the_stack_sample/sample_0584.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210421-8709509fc9\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"crier\" has cpu request 0"
  },
  {
    "id": "01713",
    "manifest_path": "data/manifests/the_stack_sample/sample_0584.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20210421-8709509fc9\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"crier\" has memory limit 0"
  },
  {
    "id": "01714",
    "manifest_path": "data/manifests/the_stack_sample/sample_0587.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx/alpine\n    ports:\n    - containerPort: 80\n    readinessProbe:\n      httpGet:\n        path: /\n        port: 80\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 80\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx/alpine\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01715",
    "manifest_path": "data/manifests/the_stack_sample/sample_0587.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx/alpine\n    ports:\n    - containerPort: 80\n    readinessProbe:\n      httpGet:\n        path: /\n        port: 80\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 80\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "01716",
    "manifest_path": "data/manifests/the_stack_sample/sample_0587.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx/alpine\n    ports:\n    - containerPort: 80\n    readinessProbe:\n      httpGet:\n        path: /\n        port: 80\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 80\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "01717",
    "manifest_path": "data/manifests/the_stack_sample/sample_0587.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx/alpine\n    ports:\n    - containerPort: 80\n    readinessProbe:\n      httpGet:\n        path: /\n        port: 80\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 80\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "01718",
    "manifest_path": "data/manifests/the_stack_sample/sample_0587.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx/alpine\n    ports:\n    - containerPort: 80\n    readinessProbe:\n      httpGet:\n        path: /\n        port: 80\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    livenessProbe:\n      tcpSocket:\n        port: 80\n      initialDelaySeconds: 15\n      periodSeconds: 20\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "01719",
    "manifest_path": "data/manifests/the_stack_sample/sample_0588.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-flexvolume-driver-disallowed\n  labels:\n    app: nginx-flexvolume-driver\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - mountPath: /test\n      name: test\n      readOnly: true\n  volumes:\n  - name: test\n    flexVolume:\n      driver: example/customdriver\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01720",
    "manifest_path": "data/manifests/the_stack_sample/sample_0588.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-flexvolume-driver-disallowed\n  labels:\n    app: nginx-flexvolume-driver\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - mountPath: /test\n      name: test\n      readOnly: true\n  volumes:\n  - name: test\n    flexVolume:\n      driver: example/customdriver\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  }
]