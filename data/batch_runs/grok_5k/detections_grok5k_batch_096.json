[
  {
    "id": "03841",
    "manifest_path": "data/manifests/the_stack_sample/sample_1711.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n      containers:\n      - name: app\n        image: alpine\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"app\" has cpu request 0"
  },
  {
    "id": "03842",
    "manifest_path": "data/manifests/the_stack_sample/sample_1711.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n      containers:\n      - name: app\n        image: alpine\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-ubuntu\" has cpu request 0"
  },
  {
    "id": "03843",
    "manifest_path": "data/manifests/the_stack_sample/sample_1711.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n      containers:\n      - name: app\n        image: alpine\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"app\" has memory limit 0"
  },
  {
    "id": "03844",
    "manifest_path": "data/manifests/the_stack_sample/sample_1711.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app\n  namespace: app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: app\n      annotations:\n        vault.security.banzaicloud.io/vault-addr: https://vault.vault:8200\n        vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n    spec:\n      initContainers:\n      - name: init-ubuntu\n        image: ubuntu\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo initContainers ready\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n      containers:\n      - name: app\n        image: alpine\n        command:\n        - sh\n        - -c\n        - echo $AWS_SECRET_ACCESS_KEY && echo going to sleep... && sleep 10000\n        env:\n        - name: AWS_SECRET_ACCESS_KEY\n          value: vault:secret/data/accounts/aws#AWS_SECRET_ACCESS_KEY\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-ubuntu\" has memory limit 0"
  },
  {
    "id": "03845",
    "manifest_path": "data/manifests/the_stack_sample/sample_1712.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"liveness\" is using an invalid container image, \"k8s.gcr.io/liveness\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "03846",
    "manifest_path": "data/manifests/the_stack_sample/sample_1712.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"liveness\" does not have a read-only root file system"
  },
  {
    "id": "03847",
    "manifest_path": "data/manifests/the_stack_sample/sample_1712.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"liveness\" is not set to runAsNonRoot"
  },
  {
    "id": "03848",
    "manifest_path": "data/manifests/the_stack_sample/sample_1712.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"liveness\" has cpu request 0"
  },
  {
    "id": "03849",
    "manifest_path": "data/manifests/the_stack_sample/sample_1712.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n        httpHeaders:\n        - name: Custom-Header\n          value: Awesome\n      initialDelaySeconds: 3\n      periodSeconds: 3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"liveness\" has memory limit 0"
  },
  {
    "id": "03850",
    "manifest_path": "data/manifests/the_stack_sample/sample_1713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "03851",
    "manifest_path": "data/manifests/the_stack_sample/sample_1713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "03852",
    "manifest_path": "data/manifests/the_stack_sample/sample_1713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "03853",
    "manifest_path": "data/manifests/the_stack_sample/sample_1713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "03854",
    "manifest_path": "data/manifests/the_stack_sample/sample_1713.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-347\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "03855",
    "manifest_path": "data/manifests/the_stack_sample/sample_1714.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-nginx-dp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-dp\n  template:\n    metadata:\n      labels:\n        app: nginx-dp\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "03856",
    "manifest_path": "data/manifests/the_stack_sample/sample_1714.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-nginx-dp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-dp\n  template:\n    metadata:\n      labels:\n        app: nginx-dp\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "03857",
    "manifest_path": "data/manifests/the_stack_sample/sample_1714.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-nginx-dp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-dp\n  template:\n    metadata:\n      labels:\n        app: nginx-dp\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "03858",
    "manifest_path": "data/manifests/the_stack_sample/sample_1714.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-nginx-dp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-dp\n  template:\n    metadata:\n      labels:\n        app: nginx-dp\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "03859",
    "manifest_path": "data/manifests/the_stack_sample/sample_1715.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220330-40eb179576\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"horologium\" does not have a read-only root file system"
  },
  {
    "id": "03860",
    "manifest_path": "data/manifests/the_stack_sample/sample_1715.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220330-40eb179576\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"horologium\" is not set to runAsNonRoot"
  },
  {
    "id": "03861",
    "manifest_path": "data/manifests/the_stack_sample/sample_1715.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220330-40eb179576\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"horologium\" has cpu request 0"
  },
  {
    "id": "03862",
    "manifest_path": "data/manifests/the_stack_sample/sample_1715.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220330-40eb179576\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"horologium\" has memory limit 0"
  },
  {
    "id": "03863",
    "manifest_path": "data/manifests/the_stack_sample/sample_1717.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:latest\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"crime-detail-api-endpoint\" is using an invalid container image, \"usfinthere/crime_detail_api:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "03864",
    "manifest_path": "data/manifests/the_stack_sample/sample_1717.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:latest\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"crime-detail-api-endpoint\" does not have a read-only root file system"
  },
  {
    "id": "03865",
    "manifest_path": "data/manifests/the_stack_sample/sample_1717.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:latest\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"crime-detail-api-endpoint\" is not set to runAsNonRoot"
  },
  {
    "id": "03866",
    "manifest_path": "data/manifests/the_stack_sample/sample_1717.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:latest\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"crime-detail-api-endpoint\" has cpu request 0"
  },
  {
    "id": "03867",
    "manifest_path": "data/manifests/the_stack_sample/sample_1717.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crime-detail-api-endpoint\n  namespace: api-services\n  labels:\n    app: crime-detail-api-endpoint\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crime-detail-api-endpoint\n  template:\n    metadata:\n      labels:\n        app: crime-detail-api-endpoint\n    spec:\n      containers:\n      - name: crime-detail-api-endpoint\n        image: usfinthere/crime_detail_api:latest\n        imagePullPolicy: Always\n        envFrom:\n        - secretRef:\n            name: postgres-secret\n        ports:\n        - name: http\n          containerPort: 8080\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"crime-detail-api-endpoint\" has memory limit 0"
  },
  {
    "id": "03868",
    "manifest_path": "data/manifests/the_stack_sample/sample_1718.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\nspec:\n  containers:\n  - command:\n    - /bin/sh\n    - -c\n    - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns\n      --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce  --service-account-private-key-file=/srv/kubernetes/server.key\n      --v=2 1>>/var/log/kube-controller-manager.log --leader-elect 2>&1\n    image: k8s.gcr.io/kube-controller-manager:fda24638d51a48baa13c35337fcd4793\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    name: kube-controller-manager\n    volumeMounts:\n    - mountPath: /srv/kubernetes\n      name: srvkube\n      readOnly: true\n    - mountPath: /var/log/kube-controller-manager.log\n      name: logfile\n    - mountPath: /etc/ssl\n      name: etcssl\n      readOnly: true\n    - mountPath: /usr/share/ssl\n      name: usrsharessl\n      readOnly: true\n    - mountPath: /var/ssl\n      name: varssl\n      readOnly: true\n    - mountPath: /usr/ssl\n      name: usrssl\n      readOnly: true\n    - mountPath: /usr/lib/ssl\n      name: usrlibssl\n      readOnly: true\n    - mountPath: /usr/local/openssl\n      name: usrlocalopenssl\n      readOnly: true\n    - mountPath: /etc/openssl\n      name: etcopenssl\n      readOnly: true\n    - mountPath: /etc/pki/tls\n      name: etcpkitls\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /srv/kubernetes\n    name: srvkube\n  - hostPath:\n      path: /var/log/kube-controller-manager.log\n      type: FileOrCreate\n    name: logfile\n  - hostPath:\n      path: /etc/ssl\n    name: etcssl\n  - hostPath:\n      path: /usr/share/ssl\n    name: usrsharessl\n  - hostPath:\n      path: /var/ssl\n    name: varssl\n  - hostPath:\n      path: /usr/ssl\n    name: usrssl\n  - hostPath:\n      path: /usr/lib/ssl\n    name: usrlibssl\n  - hostPath:\n      path: /usr/local/openssl\n    name: usrlocalopenssl\n  - hostPath:\n      path: /etc/openssl\n    name: etcopenssl\n  - hostPath:\n      path: /etc/pki/tls\n    name: etcpkitls\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-controller-manager\" does not have a read-only root file system"
  },
  {
    "id": "03869",
    "manifest_path": "data/manifests/the_stack_sample/sample_1718.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\nspec:\n  containers:\n  - command:\n    - /bin/sh\n    - -c\n    - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns\n      --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce  --service-account-private-key-file=/srv/kubernetes/server.key\n      --v=2 1>>/var/log/kube-controller-manager.log --leader-elect 2>&1\n    image: k8s.gcr.io/kube-controller-manager:fda24638d51a48baa13c35337fcd4793\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    name: kube-controller-manager\n    volumeMounts:\n    - mountPath: /srv/kubernetes\n      name: srvkube\n      readOnly: true\n    - mountPath: /var/log/kube-controller-manager.log\n      name: logfile\n    - mountPath: /etc/ssl\n      name: etcssl\n      readOnly: true\n    - mountPath: /usr/share/ssl\n      name: usrsharessl\n      readOnly: true\n    - mountPath: /var/ssl\n      name: varssl\n      readOnly: true\n    - mountPath: /usr/ssl\n      name: usrssl\n      readOnly: true\n    - mountPath: /usr/lib/ssl\n      name: usrlibssl\n      readOnly: true\n    - mountPath: /usr/local/openssl\n      name: usrlocalopenssl\n      readOnly: true\n    - mountPath: /etc/openssl\n      name: etcopenssl\n      readOnly: true\n    - mountPath: /etc/pki/tls\n      name: etcpkitls\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /srv/kubernetes\n    name: srvkube\n  - hostPath:\n      path: /var/log/kube-controller-manager.log\n      type: FileOrCreate\n    name: logfile\n  - hostPath:\n      path: /etc/ssl\n    name: etcssl\n  - hostPath:\n      path: /usr/share/ssl\n    name: usrsharessl\n  - hostPath:\n      path: /var/ssl\n    name: varssl\n  - hostPath:\n      path: /usr/ssl\n    name: usrssl\n  - hostPath:\n      path: /usr/lib/ssl\n    name: usrlibssl\n  - hostPath:\n      path: /usr/local/openssl\n    name: usrlocalopenssl\n  - hostPath:\n      path: /etc/openssl\n    name: etcopenssl\n  - hostPath:\n      path: /etc/pki/tls\n    name: etcpkitls\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kube-controller-manager\" is not set to runAsNonRoot"
  },
  {
    "id": "03870",
    "manifest_path": "data/manifests/the_stack_sample/sample_1718.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\nspec:\n  containers:\n  - command:\n    - /bin/sh\n    - -c\n    - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns\n      --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce  --service-account-private-key-file=/srv/kubernetes/server.key\n      --v=2 1>>/var/log/kube-controller-manager.log --leader-elect 2>&1\n    image: k8s.gcr.io/kube-controller-manager:fda24638d51a48baa13c35337fcd4793\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    name: kube-controller-manager\n    volumeMounts:\n    - mountPath: /srv/kubernetes\n      name: srvkube\n      readOnly: true\n    - mountPath: /var/log/kube-controller-manager.log\n      name: logfile\n    - mountPath: /etc/ssl\n      name: etcssl\n      readOnly: true\n    - mountPath: /usr/share/ssl\n      name: usrsharessl\n      readOnly: true\n    - mountPath: /var/ssl\n      name: varssl\n      readOnly: true\n    - mountPath: /usr/ssl\n      name: usrssl\n      readOnly: true\n    - mountPath: /usr/lib/ssl\n      name: usrlibssl\n      readOnly: true\n    - mountPath: /usr/local/openssl\n      name: usrlocalopenssl\n      readOnly: true\n    - mountPath: /etc/openssl\n      name: etcopenssl\n      readOnly: true\n    - mountPath: /etc/pki/tls\n      name: etcpkitls\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /srv/kubernetes\n    name: srvkube\n  - hostPath:\n      path: /var/log/kube-controller-manager.log\n      type: FileOrCreate\n    name: logfile\n  - hostPath:\n      path: /etc/ssl\n    name: etcssl\n  - hostPath:\n      path: /usr/share/ssl\n    name: usrsharessl\n  - hostPath:\n      path: /var/ssl\n    name: varssl\n  - hostPath:\n      path: /usr/ssl\n    name: usrssl\n  - hostPath:\n      path: /usr/lib/ssl\n    name: usrlibssl\n  - hostPath:\n      path: /usr/local/openssl\n    name: usrlocalopenssl\n  - hostPath:\n      path: /etc/openssl\n    name: etcopenssl\n  - hostPath:\n      path: /etc/pki/tls\n    name: etcpkitls\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"kube-controller-manager\" has cpu request 0"
  },
  {
    "id": "03871",
    "manifest_path": "data/manifests/the_stack_sample/sample_1718.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\nspec:\n  containers:\n  - command:\n    - /bin/sh\n    - -c\n    - /usr/local/bin/kube-controller-manager --master=127.0.0.1:8080 --cluster-name=e2e-test-bburns\n      --cluster-cidr=10.245.0.0/16 --allocate-node-cidrs=true --cloud-provider=gce  --service-account-private-key-file=/srv/kubernetes/server.key\n      --v=2 1>>/var/log/kube-controller-manager.log --leader-elect 2>&1\n    image: k8s.gcr.io/kube-controller-manager:fda24638d51a48baa13c35337fcd4793\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    name: kube-controller-manager\n    volumeMounts:\n    - mountPath: /srv/kubernetes\n      name: srvkube\n      readOnly: true\n    - mountPath: /var/log/kube-controller-manager.log\n      name: logfile\n    - mountPath: /etc/ssl\n      name: etcssl\n      readOnly: true\n    - mountPath: /usr/share/ssl\n      name: usrsharessl\n      readOnly: true\n    - mountPath: /var/ssl\n      name: varssl\n      readOnly: true\n    - mountPath: /usr/ssl\n      name: usrssl\n      readOnly: true\n    - mountPath: /usr/lib/ssl\n      name: usrlibssl\n      readOnly: true\n    - mountPath: /usr/local/openssl\n      name: usrlocalopenssl\n      readOnly: true\n    - mountPath: /etc/openssl\n      name: etcopenssl\n      readOnly: true\n    - mountPath: /etc/pki/tls\n      name: etcpkitls\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /srv/kubernetes\n    name: srvkube\n  - hostPath:\n      path: /var/log/kube-controller-manager.log\n      type: FileOrCreate\n    name: logfile\n  - hostPath:\n      path: /etc/ssl\n    name: etcssl\n  - hostPath:\n      path: /usr/share/ssl\n    name: usrsharessl\n  - hostPath:\n      path: /var/ssl\n    name: varssl\n  - hostPath:\n      path: /usr/ssl\n    name: usrssl\n  - hostPath:\n      path: /usr/lib/ssl\n    name: usrlibssl\n  - hostPath:\n      path: /usr/local/openssl\n    name: usrlocalopenssl\n  - hostPath:\n      path: /etc/openssl\n    name: etcopenssl\n  - hostPath:\n      path: /etc/pki/tls\n    name: etcpkitls\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"kube-controller-manager\" has memory limit 0"
  },
  {
    "id": "03872",
    "manifest_path": "data/manifests/the_stack_sample/sample_1720.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nats\n  labels:\n    component: nats\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: nats\n  template:\n    metadata:\n      labels:\n        component: nats\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: component\n                operator: In\n                values:\n                - nats\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: nats\n        image: nats:1.1.0\n        args:\n        - --config\n        - /etc/nats/config/nats.conf\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/nats/config\n        ports:\n        - containerPort: 4222\n          name: client\n        - containerPort: 6222\n          name: cluster\n        - containerPort: 8222\n          name: monitor\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8222\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n      volumes:\n      - name: config-volume\n        configMap:\n          name: nats-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nats\" does not have a read-only root file system"
  },
  {
    "id": "03873",
    "manifest_path": "data/manifests/the_stack_sample/sample_1720.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nats\n  labels:\n    component: nats\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: nats\n  template:\n    metadata:\n      labels:\n        component: nats\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: component\n                operator: In\n                values:\n                - nats\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: nats\n        image: nats:1.1.0\n        args:\n        - --config\n        - /etc/nats/config/nats.conf\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/nats/config\n        ports:\n        - containerPort: 4222\n          name: client\n        - containerPort: 6222\n          name: cluster\n        - containerPort: 8222\n          name: monitor\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8222\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n      volumes:\n      - name: config-volume\n        configMap:\n          name: nats-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nats\" is not set to runAsNonRoot"
  },
  {
    "id": "03874",
    "manifest_path": "data/manifests/the_stack_sample/sample_1720.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nats\n  labels:\n    component: nats\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: nats\n  template:\n    metadata:\n      labels:\n        component: nats\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: component\n                operator: In\n                values:\n                - nats\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: nats\n        image: nats:1.1.0\n        args:\n        - --config\n        - /etc/nats/config/nats.conf\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/nats/config\n        ports:\n        - containerPort: 4222\n          name: client\n        - containerPort: 6222\n          name: cluster\n        - containerPort: 8222\n          name: monitor\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8222\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n      volumes:\n      - name: config-volume\n        configMap:\n          name: nats-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nats\" has cpu request 0"
  },
  {
    "id": "03875",
    "manifest_path": "data/manifests/the_stack_sample/sample_1720.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nats\n  labels:\n    component: nats\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: nats\n  template:\n    metadata:\n      labels:\n        component: nats\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: component\n                operator: In\n                values:\n                - nats\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: nats\n        image: nats:1.1.0\n        args:\n        - --config\n        - /etc/nats/config/nats.conf\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/nats/config\n        ports:\n        - containerPort: 4222\n          name: client\n        - containerPort: 6222\n          name: cluster\n        - containerPort: 8222\n          name: monitor\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 8222\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n      volumes:\n      - name: config-volume\n        configMap:\n          name: nats-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nats\" has memory limit 0"
  },
  {
    "id": "03876",
    "manifest_path": "data/manifests/the_stack_sample/sample_1721.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '14271'\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:1.18.1\n        args:\n        - --config-file=/conf/agent.yaml\n        volumeMounts:\n        - name: jaeger-configuration-volume\n          mountPath: /conf\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 14271\n          name: admin-http\n          protocol: TCP\n      volumes:\n      - configMap:\n          name: jaeger-configuration\n          items:\n          - key: agent\n            path: agent.yaml\n        name: jaeger-configuration-volume\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jaeger-agent\" does not have a read-only root file system"
  },
  {
    "id": "03877",
    "manifest_path": "data/manifests/the_stack_sample/sample_1721.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '14271'\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:1.18.1\n        args:\n        - --config-file=/conf/agent.yaml\n        volumeMounts:\n        - name: jaeger-configuration-volume\n          mountPath: /conf\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 14271\n          name: admin-http\n          protocol: TCP\n      volumes:\n      - configMap:\n          name: jaeger-configuration\n          items:\n          - key: agent\n            path: agent.yaml\n        name: jaeger-configuration-volume\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"jaeger-agent\" is not set to runAsNonRoot"
  },
  {
    "id": "03878",
    "manifest_path": "data/manifests/the_stack_sample/sample_1721.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '14271'\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:1.18.1\n        args:\n        - --config-file=/conf/agent.yaml\n        volumeMounts:\n        - name: jaeger-configuration-volume\n          mountPath: /conf\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 14271\n          name: admin-http\n          protocol: TCP\n      volumes:\n      - configMap:\n          name: jaeger-configuration\n          items:\n          - key: agent\n            path: agent.yaml\n        name: jaeger-configuration-volume\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"jaeger-agent\" has cpu request 0"
  },
  {
    "id": "03879",
    "manifest_path": "data/manifests/the_stack_sample/sample_1721.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: jaeger-agent\n  labels:\n    app: jaeger\n    app.kubernetes.io/name: jaeger\n    app.kubernetes.io/component: agent\nspec:\n  selector:\n    matchLabels:\n      app: jaeger\n      app.kubernetes.io/name: jaeger\n      app.kubernetes.io/component: agent\n  template:\n    metadata:\n      labels:\n        app: jaeger\n        app.kubernetes.io/name: jaeger\n        app.kubernetes.io/component: agent\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '14271'\n    spec:\n      containers:\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:1.18.1\n        args:\n        - --config-file=/conf/agent.yaml\n        volumeMounts:\n        - name: jaeger-configuration-volume\n          mountPath: /conf\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        - containerPort: 14271\n          name: admin-http\n          protocol: TCP\n      volumes:\n      - configMap:\n          name: jaeger-configuration\n          items:\n          - key: agent\n            path: agent.yaml\n        name: jaeger-configuration-volume\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"jaeger-agent\" has memory limit 0"
  },
  {
    "id": "03880",
    "manifest_path": "data/manifests/the_stack_sample/sample_1722.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-aws-iam-controller\n  namespace: kube-system\n  labels:\n    application: kube-aws-iam-controller\n    version: latest\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      application: kube-aws-iam-controller\n  template:\n    metadata:\n      labels:\n        application: kube-aws-iam-controller\n        version: latest\n    spec:\n      serviceAccountName: kube-aws-iam-controller\n      containers:\n      - name: kube-aws-iam-controller\n        image: registry.opensource.zalan.do/teapot/kube-aws-iam-controller:latest\n        resources:\n          limits:\n            cpu: 25m\n            memory: 100Mi\n          requests:\n            cpu: 25m\n            memory: 100Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"kube-aws-iam-controller\" is using an invalid container image, \"registry.opensource.zalan.do/teapot/kube-aws-iam-controller:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  }
]