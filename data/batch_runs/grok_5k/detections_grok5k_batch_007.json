[
  {
    "id": "00281",
    "manifest_path": "data/manifests/artifacthub/grafana/loki-stack/016_pod_release-name-loki-stack-test.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    helm.sh/hook: test-success\n  labels:\n    app: loki-stack\n    chart: loki-stack-2.10.2\n    release: release-name\n    heritage: Helm\n  name: release-name-loki-stack-test\nspec:\n  containers:\n  - name: test\n    image: bats/bats:1.8.2\n    imagePullPolicy: ''\n    args:\n    - /var/lib/loki/test.sh\n    env:\n    - name: LOKI_SERVICE\n      value: release-name-loki\n    - name: LOKI_PORT\n      value: '3100'\n    volumeMounts:\n    - name: tests\n      mountPath: /var/lib/loki\n  volumes:\n  - name: tests\n    configMap:\n      name: release-name-loki-stack-test\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"test\" does not have a read-only root file system"
  },
  {
    "id": "00282",
    "manifest_path": "data/manifests/artifacthub/grafana/loki-stack/016_pod_release-name-loki-stack-test.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    helm.sh/hook: test-success\n  labels:\n    app: loki-stack\n    chart: loki-stack-2.10.2\n    release: release-name\n    heritage: Helm\n  name: release-name-loki-stack-test\nspec:\n  containers:\n  - name: test\n    image: bats/bats:1.8.2\n    imagePullPolicy: ''\n    args:\n    - /var/lib/loki/test.sh\n    env:\n    - name: LOKI_SERVICE\n      value: release-name-loki\n    - name: LOKI_PORT\n      value: '3100'\n    volumeMounts:\n    - name: tests\n      mountPath: /var/lib/loki\n  volumes:\n  - name: tests\n    configMap:\n      name: release-name-loki-stack-test\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"test\" is not set to runAsNonRoot"
  },
  {
    "id": "00283",
    "manifest_path": "data/manifests/artifacthub/grafana/loki-stack/016_pod_release-name-loki-stack-test.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    helm.sh/hook: test-success\n  labels:\n    app: loki-stack\n    chart: loki-stack-2.10.2\n    release: release-name\n    heritage: Helm\n  name: release-name-loki-stack-test\nspec:\n  containers:\n  - name: test\n    image: bats/bats:1.8.2\n    imagePullPolicy: ''\n    args:\n    - /var/lib/loki/test.sh\n    env:\n    - name: LOKI_SERVICE\n      value: release-name-loki\n    - name: LOKI_PORT\n      value: '3100'\n    volumeMounts:\n    - name: tests\n      mountPath: /var/lib/loki\n  volumes:\n  - name: tests\n    configMap:\n      name: release-name-loki-stack-test\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"test\" has cpu request 0"
  },
  {
    "id": "00284",
    "manifest_path": "data/manifests/artifacthub/grafana/loki-stack/016_pod_release-name-loki-stack-test.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    helm.sh/hook: test-success\n  labels:\n    app: loki-stack\n    chart: loki-stack-2.10.2\n    release: release-name\n    heritage: Helm\n  name: release-name-loki-stack-test\nspec:\n  containers:\n  - name: test\n    image: bats/bats:1.8.2\n    imagePullPolicy: ''\n    args:\n    - /var/lib/loki/test.sh\n    env:\n    - name: LOKI_SERVICE\n      value: release-name-loki\n    - name: LOKI_PORT\n      value: '3100'\n    volumeMounts:\n    - name: tests\n      mountPath: /var/lib/loki\n  volumes:\n  - name: tests\n    configMap:\n      name: release-name-loki-stack-test\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"test\" has memory limit 0"
  },
  {
    "id": "00285",
    "manifest_path": "data/manifests/artifacthub/grafana/promtail/005_daemonset_release-name-promtail.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: release-name-promtail\n  namespace: default\n  labels:\n    helm.sh/chart: promtail-6.17.0\n    app.kubernetes.io/name: promtail\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 3.5.1\n    app.kubernetes.io/managed-by: Helm\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: promtail\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: promtail\n        app.kubernetes.io/instance: release-name\n      annotations:\n        checksum/config: 2ef0f14afc8ed4b72495a244ef20e42a4bc14afd488033fe94e04c341b97529a\n    spec:\n      serviceAccountName: release-name-promtail\n      securityContext:\n        runAsGroup: 0\n        runAsUser: 0\n      containers:\n      - name: promtail\n        image: docker.io/grafana/promtail:3.5.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - -config.file=/etc/promtail/promtail.yaml\n        volumeMounts:\n        - name: config\n          mountPath: /etc/promtail\n        - mountPath: /run/promtail\n          name: run\n        - mountPath: /var/lib/docker/containers\n          name: containers\n          readOnly: true\n        - mountPath: /var/log/pods\n          name: pods\n          readOnly: true\n        env:\n        - name: HOSTNAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        ports:\n        - name: http-metrics\n          containerPort: 3101\n          protocol: TCP\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /ready\n            port: http-metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n      volumes:\n      - name: config\n        secret:\n          secretName: release-name-promtail\n      - hostPath:\n          path: /run/promtail\n        name: run\n      - hostPath:\n          path: /var/lib/docker/containers\n        name: containers\n      - hostPath:\n          path: /var/log/pods\n        name: pods\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"promtail\" is not set to runAsNonRoot"
  },
  {
    "id": "00286",
    "manifest_path": "data/manifests/artifacthub/grafana/promtail/005_daemonset_release-name-promtail.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: release-name-promtail\n  namespace: default\n  labels:\n    helm.sh/chart: promtail-6.17.0\n    app.kubernetes.io/name: promtail\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 3.5.1\n    app.kubernetes.io/managed-by: Helm\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: promtail\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: promtail\n        app.kubernetes.io/instance: release-name\n      annotations:\n        checksum/config: 2ef0f14afc8ed4b72495a244ef20e42a4bc14afd488033fe94e04c341b97529a\n    spec:\n      serviceAccountName: release-name-promtail\n      securityContext:\n        runAsGroup: 0\n        runAsUser: 0\n      containers:\n      - name: promtail\n        image: docker.io/grafana/promtail:3.5.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - -config.file=/etc/promtail/promtail.yaml\n        volumeMounts:\n        - name: config\n          mountPath: /etc/promtail\n        - mountPath: /run/promtail\n          name: run\n        - mountPath: /var/lib/docker/containers\n          name: containers\n          readOnly: true\n        - mountPath: /var/log/pods\n          name: pods\n          readOnly: true\n        env:\n        - name: HOSTNAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        ports:\n        - name: http-metrics\n          containerPort: 3101\n          protocol: TCP\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /ready\n            port: http-metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n      volumes:\n      - name: config\n        secret:\n          secretName: release-name-promtail\n      - hostPath:\n          path: /run/promtail\n        name: run\n      - hostPath:\n          path: /var/lib/docker/containers\n        name: containers\n      - hostPath:\n          path: /var/log/pods\n        name: pods\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"promtail\" has cpu request 0"
  },
  {
    "id": "00287",
    "manifest_path": "data/manifests/artifacthub/grafana/promtail/005_daemonset_release-name-promtail.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: release-name-promtail\n  namespace: default\n  labels:\n    helm.sh/chart: promtail-6.17.0\n    app.kubernetes.io/name: promtail\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/version: 3.5.1\n    app.kubernetes.io/managed-by: Helm\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: promtail\n      app.kubernetes.io/instance: release-name\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: promtail\n        app.kubernetes.io/instance: release-name\n      annotations:\n        checksum/config: 2ef0f14afc8ed4b72495a244ef20e42a4bc14afd488033fe94e04c341b97529a\n    spec:\n      serviceAccountName: release-name-promtail\n      securityContext:\n        runAsGroup: 0\n        runAsUser: 0\n      containers:\n      - name: promtail\n        image: docker.io/grafana/promtail:3.5.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - -config.file=/etc/promtail/promtail.yaml\n        volumeMounts:\n        - name: config\n          mountPath: /etc/promtail\n        - mountPath: /run/promtail\n          name: run\n        - mountPath: /var/lib/docker/containers\n          name: containers\n          readOnly: true\n        - mountPath: /var/log/pods\n          name: pods\n          readOnly: true\n        env:\n        - name: HOSTNAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        ports:\n        - name: http-metrics\n          containerPort: 3101\n          protocol: TCP\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        readinessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /ready\n            port: http-metrics\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n      volumes:\n      - name: config\n        secret:\n          secretName: release-name-promtail\n      - hostPath:\n          path: /run/promtail\n        name: run\n      - hostPath:\n          path: /var/lib/docker/containers\n        name: containers\n      - hostPath:\n          path: /var/log/pods\n        name: pods\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"promtail\" has memory limit 0"
  },
  {
    "id": "00288",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/024_deployment_release-name-harbor-core.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-core\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: core\n    app.kubernetes.io/component: core\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: core\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: core\n        app.kubernetes.io/component: core\n      annotations:\n        checksum/configmap: 9f10ac573f31bb0810150a5f7c1f04fe8883b5850e0c0864ac1413792af939c2\n        checksum/secret: a96e028877820958786a1bec0806cc8371456bb27c2a090276a01f71e3ea2dd6\n        checksum/secret-jobservice: 65d7ad3b4b4e98e4243bfc35342599fa0006c75bab7916ff31b211456a37c582\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: core\n        image: goharbor/harbor-core:v2.14.0\n        imagePullPolicy: IfNotPresent\n        startupProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 360\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 2\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 2\n          periodSeconds: 10\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-core\n        - secretRef:\n            name: release-name-harbor-core\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: config\n          mountPath: /etc/core/app.conf\n          subPath: app.conf\n        - name: secret-key\n          mountPath: /etc/core/key\n          subPath: key\n        - name: token-service-private-key\n          mountPath: /etc/core/private_key.pem\n          subPath: tls.key\n        - name: ca-download\n          mountPath: /etc/core/ca\n        - name: psc\n          mountPath: /etc/core/token\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-harbor-core\n          items:\n          - key: app.conf\n            path: app.conf\n      - name: secret-key\n        secret:\n          secretName: release-name-harbor-core\n          items:\n          - key: secretKey\n            path: key\n      - name: token-service-private-key\n        secret:\n          secretName: release-name-harbor-core\n      - name: ca-download\n        secret:\n          secretName: release-name-harbor-ingress\n      - name: psc\n        emptyDir: {}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"core\" does not have a read-only root file system"
  },
  {
    "id": "00289",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/024_deployment_release-name-harbor-core.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-core\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: core\n    app.kubernetes.io/component: core\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: core\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: core\n        app.kubernetes.io/component: core\n      annotations:\n        checksum/configmap: 9f10ac573f31bb0810150a5f7c1f04fe8883b5850e0c0864ac1413792af939c2\n        checksum/secret: a96e028877820958786a1bec0806cc8371456bb27c2a090276a01f71e3ea2dd6\n        checksum/secret-jobservice: 65d7ad3b4b4e98e4243bfc35342599fa0006c75bab7916ff31b211456a37c582\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: core\n        image: goharbor/harbor-core:v2.14.0\n        imagePullPolicy: IfNotPresent\n        startupProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 360\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 2\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 2\n          periodSeconds: 10\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-core\n        - secretRef:\n            name: release-name-harbor-core\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: config\n          mountPath: /etc/core/app.conf\n          subPath: app.conf\n        - name: secret-key\n          mountPath: /etc/core/key\n          subPath: key\n        - name: token-service-private-key\n          mountPath: /etc/core/private_key.pem\n          subPath: tls.key\n        - name: ca-download\n          mountPath: /etc/core/ca\n        - name: psc\n          mountPath: /etc/core/token\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-harbor-core\n          items:\n          - key: app.conf\n            path: app.conf\n      - name: secret-key\n        secret:\n          secretName: release-name-harbor-core\n          items:\n          - key: secretKey\n            path: key\n      - name: token-service-private-key\n        secret:\n          secretName: release-name-harbor-core\n      - name: ca-download\n        secret:\n          secretName: release-name-harbor-ingress\n      - name: psc\n        emptyDir: {}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"core\" has cpu request 0"
  },
  {
    "id": "00290",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/024_deployment_release-name-harbor-core.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-core\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: core\n    app.kubernetes.io/component: core\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: core\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: core\n        app.kubernetes.io/component: core\n      annotations:\n        checksum/configmap: 9f10ac573f31bb0810150a5f7c1f04fe8883b5850e0c0864ac1413792af939c2\n        checksum/secret: a96e028877820958786a1bec0806cc8371456bb27c2a090276a01f71e3ea2dd6\n        checksum/secret-jobservice: 65d7ad3b4b4e98e4243bfc35342599fa0006c75bab7916ff31b211456a37c582\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: core\n        image: goharbor/harbor-core:v2.14.0\n        imagePullPolicy: IfNotPresent\n        startupProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 360\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 2\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v2.0/ping\n            scheme: HTTP\n            port: 8080\n          failureThreshold: 2\n          periodSeconds: 10\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-core\n        - secretRef:\n            name: release-name-harbor-core\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: config\n          mountPath: /etc/core/app.conf\n          subPath: app.conf\n        - name: secret-key\n          mountPath: /etc/core/key\n          subPath: key\n        - name: token-service-private-key\n          mountPath: /etc/core/private_key.pem\n          subPath: tls.key\n        - name: ca-download\n          mountPath: /etc/core/ca\n        - name: psc\n          mountPath: /etc/core/token\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-harbor-core\n          items:\n          - key: app.conf\n            path: app.conf\n      - name: secret-key\n        secret:\n          secretName: release-name-harbor-core\n          items:\n          - key: secretKey\n            path: key\n      - name: token-service-private-key\n        secret:\n          secretName: release-name-harbor-core\n      - name: ca-download\n        secret:\n          secretName: release-name-harbor-ingress\n      - name: psc\n        emptyDir: {}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"core\" has memory limit 0"
  },
  {
    "id": "00291",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/025_deployment_release-name-harbor-jobservice.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-jobservice\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: jobservice\n    app.kubernetes.io/component: jobservice\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: jobservice\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: jobservice\n        app.kubernetes.io/component: jobservice\n      annotations:\n        checksum/configmap: 244ec50e63efe66fc3ec84e285fa0e8c83e019830b4462a17e81bc3b0745982a\n        checksum/configmap-env: 1c2af1daccf2ab6f5e6433b5d6de46e5b3610a14ef6337b0c14980f428212ea0\n        checksum/secret: 837d754c99f5985f960d8aed969e7884560427df8584bf6d1706a2915a66b198\n        checksum/secret-core: c412b2f1985d742be1ff1d9f161c9ea9a1bf4d2b525a362636620f5ce60ad18a\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: jobservice\n        image: goharbor/harbor-jobservice:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/v1/stats\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v1/stats\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 20\n          periodSeconds: 10\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-jobservice-env\n        - secretRef:\n            name: release-name-harbor-jobservice\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: jobservice-config\n          mountPath: /etc/jobservice/config.yml\n          subPath: config.yml\n        - name: job-logs\n          mountPath: /var/log/jobs\n          subPath: null\n      volumes:\n      - name: jobservice-config\n        configMap:\n          name: release-name-harbor-jobservice\n      - name: job-logs\n        persistentVolumeClaim:\n          claimName: release-name-harbor-jobservice\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"jobservice\" does not have a read-only root file system"
  },
  {
    "id": "00292",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/025_deployment_release-name-harbor-jobservice.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-jobservice\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: jobservice\n    app.kubernetes.io/component: jobservice\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: jobservice\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: jobservice\n        app.kubernetes.io/component: jobservice\n      annotations:\n        checksum/configmap: 244ec50e63efe66fc3ec84e285fa0e8c83e019830b4462a17e81bc3b0745982a\n        checksum/configmap-env: 1c2af1daccf2ab6f5e6433b5d6de46e5b3610a14ef6337b0c14980f428212ea0\n        checksum/secret: 837d754c99f5985f960d8aed969e7884560427df8584bf6d1706a2915a66b198\n        checksum/secret-core: c412b2f1985d742be1ff1d9f161c9ea9a1bf4d2b525a362636620f5ce60ad18a\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: jobservice\n        image: goharbor/harbor-jobservice:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/v1/stats\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v1/stats\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 20\n          periodSeconds: 10\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-jobservice-env\n        - secretRef:\n            name: release-name-harbor-jobservice\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: jobservice-config\n          mountPath: /etc/jobservice/config.yml\n          subPath: config.yml\n        - name: job-logs\n          mountPath: /var/log/jobs\n          subPath: null\n      volumes:\n      - name: jobservice-config\n        configMap:\n          name: release-name-harbor-jobservice\n      - name: job-logs\n        persistentVolumeClaim:\n          claimName: release-name-harbor-jobservice\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"jobservice\" has cpu request 0"
  },
  {
    "id": "00293",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/025_deployment_release-name-harbor-jobservice.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-jobservice\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: jobservice\n    app.kubernetes.io/component: jobservice\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: jobservice\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: jobservice\n        app.kubernetes.io/component: jobservice\n      annotations:\n        checksum/configmap: 244ec50e63efe66fc3ec84e285fa0e8c83e019830b4462a17e81bc3b0745982a\n        checksum/configmap-env: 1c2af1daccf2ab6f5e6433b5d6de46e5b3610a14ef6337b0c14980f428212ea0\n        checksum/secret: 837d754c99f5985f960d8aed969e7884560427df8584bf6d1706a2915a66b198\n        checksum/secret-core: c412b2f1985d742be1ff1d9f161c9ea9a1bf4d2b525a362636620f5ce60ad18a\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: jobservice\n        image: goharbor/harbor-jobservice:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/v1/stats\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/v1/stats\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 20\n          periodSeconds: 10\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-jobservice-env\n        - secretRef:\n            name: release-name-harbor-jobservice\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: jobservice-config\n          mountPath: /etc/jobservice/config.yml\n          subPath: config.yml\n        - name: job-logs\n          mountPath: /var/log/jobs\n          subPath: null\n      volumes:\n      - name: jobservice-config\n        configMap:\n          name: release-name-harbor-jobservice\n      - name: job-logs\n        persistentVolumeClaim:\n          claimName: release-name-harbor-jobservice\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"jobservice\" has memory limit 0"
  },
  {
    "id": "00294",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/026_deployment_release-name-harbor-portal.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-portal\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: portal\n    app.kubernetes.io/component: portal\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: portal\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: portal\n        app.kubernetes.io/component: portal\n      annotations:\n        checksum/configmap: c9e04324738b148b4530aa2bd57b606d50600544b949ceef09270ef9c207bf85\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: portal\n        image: goharbor/harbor-portal:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: portal-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      volumes:\n      - name: portal-config\n        configMap:\n          name: release-name-harbor-portal\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"portal\" does not have a read-only root file system"
  },
  {
    "id": "00295",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/026_deployment_release-name-harbor-portal.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-portal\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: portal\n    app.kubernetes.io/component: portal\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: portal\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: portal\n        app.kubernetes.io/component: portal\n      annotations:\n        checksum/configmap: c9e04324738b148b4530aa2bd57b606d50600544b949ceef09270ef9c207bf85\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: portal\n        image: goharbor/harbor-portal:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: portal-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      volumes:\n      - name: portal-config\n        configMap:\n          name: release-name-harbor-portal\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"portal\" has cpu request 0"
  },
  {
    "id": "00296",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/026_deployment_release-name-harbor-portal.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-portal\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: portal\n    app.kubernetes.io/component: portal\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: portal\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: portal\n        app.kubernetes.io/component: portal\n      annotations:\n        checksum/configmap: c9e04324738b148b4530aa2bd57b606d50600544b949ceef09270ef9c207bf85\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: portal\n        image: goharbor/harbor-portal:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: portal-config\n          mountPath: /etc/nginx/nginx.conf\n          subPath: nginx.conf\n      volumes:\n      - name: portal-config\n        configMap:\n          name: release-name-harbor-portal\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"portal\" has memory limit 0"
  },
  {
    "id": "00297",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/027_deployment_release-name-harbor-registry.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-registry\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: registry\n    app.kubernetes.io/component: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: registry\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: registry\n        app.kubernetes.io/component: registry\n      annotations:\n        checksum/configmap: b2a013a32036502b320d086fb71abf4702ba64f19e1c14222e31a2824982ad92\n        checksum/secret: 3f19d74357204ca317a51986a152e29cd0315df70f7eba2dbd585fe1938fa89d\n        checksum/secret-jobservice: 1502b63330d5a64588c432e97b8166219b6868bb9fc8ca2885e9f36e44f48efd\n        checksum/secret-core: c2f598f5d58a28ad67529eec72b7814fbbfd9b8c9012c9bd48cc51eda35cb56b\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n        fsGroupChangePolicy: OnRootMismatch\n      containers:\n      - name: registry\n        image: goharbor/registry-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-registry\n        ports:\n        - containerPort: 5000\n        - containerPort: 5001\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-htpasswd\n          mountPath: /etc/registry/passwd\n          subPath: passwd\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n      - name: registryctl\n        image: goharbor/harbor-registryctl:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-registryctl\n        - secretRef:\n            name: release-name-harbor-registry\n        - secretRef:\n            name: release-name-harbor-registryctl\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n        - name: registry-config\n          mountPath: /etc/registryctl/config.yml\n          subPath: ctl-config.yml\n      volumes:\n      - name: registry-htpasswd\n        secret:\n          secretName: release-name-harbor-registry-htpasswd\n          items:\n          - key: REGISTRY_HTPASSWD\n            path: passwd\n      - name: registry-config\n        configMap:\n          name: release-name-harbor-registry\n      - name: registry-data\n        persistentVolumeClaim:\n          claimName: release-name-harbor-registry\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"registry\" does not have a read-only root file system"
  },
  {
    "id": "00298",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/027_deployment_release-name-harbor-registry.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-registry\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: registry\n    app.kubernetes.io/component: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: registry\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: registry\n        app.kubernetes.io/component: registry\n      annotations:\n        checksum/configmap: b2a013a32036502b320d086fb71abf4702ba64f19e1c14222e31a2824982ad92\n        checksum/secret: 3f19d74357204ca317a51986a152e29cd0315df70f7eba2dbd585fe1938fa89d\n        checksum/secret-jobservice: 1502b63330d5a64588c432e97b8166219b6868bb9fc8ca2885e9f36e44f48efd\n        checksum/secret-core: c2f598f5d58a28ad67529eec72b7814fbbfd9b8c9012c9bd48cc51eda35cb56b\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n        fsGroupChangePolicy: OnRootMismatch\n      containers:\n      - name: registry\n        image: goharbor/registry-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-registry\n        ports:\n        - containerPort: 5000\n        - containerPort: 5001\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-htpasswd\n          mountPath: /etc/registry/passwd\n          subPath: passwd\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n      - name: registryctl\n        image: goharbor/harbor-registryctl:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-registryctl\n        - secretRef:\n            name: release-name-harbor-registry\n        - secretRef:\n            name: release-name-harbor-registryctl\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n        - name: registry-config\n          mountPath: /etc/registryctl/config.yml\n          subPath: ctl-config.yml\n      volumes:\n      - name: registry-htpasswd\n        secret:\n          secretName: release-name-harbor-registry-htpasswd\n          items:\n          - key: REGISTRY_HTPASSWD\n            path: passwd\n      - name: registry-config\n        configMap:\n          name: release-name-harbor-registry\n      - name: registry-data\n        persistentVolumeClaim:\n          claimName: release-name-harbor-registry\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"registryctl\" does not have a read-only root file system"
  },
  {
    "id": "00299",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/027_deployment_release-name-harbor-registry.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-registry\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: registry\n    app.kubernetes.io/component: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: registry\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: registry\n        app.kubernetes.io/component: registry\n      annotations:\n        checksum/configmap: b2a013a32036502b320d086fb71abf4702ba64f19e1c14222e31a2824982ad92\n        checksum/secret: 3f19d74357204ca317a51986a152e29cd0315df70f7eba2dbd585fe1938fa89d\n        checksum/secret-jobservice: 1502b63330d5a64588c432e97b8166219b6868bb9fc8ca2885e9f36e44f48efd\n        checksum/secret-core: c2f598f5d58a28ad67529eec72b7814fbbfd9b8c9012c9bd48cc51eda35cb56b\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n        fsGroupChangePolicy: OnRootMismatch\n      containers:\n      - name: registry\n        image: goharbor/registry-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-registry\n        ports:\n        - containerPort: 5000\n        - containerPort: 5001\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-htpasswd\n          mountPath: /etc/registry/passwd\n          subPath: passwd\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n      - name: registryctl\n        image: goharbor/harbor-registryctl:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-registryctl\n        - secretRef:\n            name: release-name-harbor-registry\n        - secretRef:\n            name: release-name-harbor-registryctl\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n        - name: registry-config\n          mountPath: /etc/registryctl/config.yml\n          subPath: ctl-config.yml\n      volumes:\n      - name: registry-htpasswd\n        secret:\n          secretName: release-name-harbor-registry-htpasswd\n          items:\n          - key: REGISTRY_HTPASSWD\n            path: passwd\n      - name: registry-config\n        configMap:\n          name: release-name-harbor-registry\n      - name: registry-data\n        persistentVolumeClaim:\n          claimName: release-name-harbor-registry\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"registry\" has cpu request 0"
  },
  {
    "id": "00300",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/027_deployment_release-name-harbor-registry.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-registry\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: registry\n    app.kubernetes.io/component: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: registry\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: registry\n        app.kubernetes.io/component: registry\n      annotations:\n        checksum/configmap: b2a013a32036502b320d086fb71abf4702ba64f19e1c14222e31a2824982ad92\n        checksum/secret: 3f19d74357204ca317a51986a152e29cd0315df70f7eba2dbd585fe1938fa89d\n        checksum/secret-jobservice: 1502b63330d5a64588c432e97b8166219b6868bb9fc8ca2885e9f36e44f48efd\n        checksum/secret-core: c2f598f5d58a28ad67529eec72b7814fbbfd9b8c9012c9bd48cc51eda35cb56b\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n        fsGroupChangePolicy: OnRootMismatch\n      containers:\n      - name: registry\n        image: goharbor/registry-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-registry\n        ports:\n        - containerPort: 5000\n        - containerPort: 5001\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-htpasswd\n          mountPath: /etc/registry/passwd\n          subPath: passwd\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n      - name: registryctl\n        image: goharbor/harbor-registryctl:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-registryctl\n        - secretRef:\n            name: release-name-harbor-registry\n        - secretRef:\n            name: release-name-harbor-registryctl\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n        - name: registry-config\n          mountPath: /etc/registryctl/config.yml\n          subPath: ctl-config.yml\n      volumes:\n      - name: registry-htpasswd\n        secret:\n          secretName: release-name-harbor-registry-htpasswd\n          items:\n          - key: REGISTRY_HTPASSWD\n            path: passwd\n      - name: registry-config\n        configMap:\n          name: release-name-harbor-registry\n      - name: registry-data\n        persistentVolumeClaim:\n          claimName: release-name-harbor-registry\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"registryctl\" has cpu request 0"
  },
  {
    "id": "00301",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/027_deployment_release-name-harbor-registry.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-registry\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: registry\n    app.kubernetes.io/component: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: registry\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: registry\n        app.kubernetes.io/component: registry\n      annotations:\n        checksum/configmap: b2a013a32036502b320d086fb71abf4702ba64f19e1c14222e31a2824982ad92\n        checksum/secret: 3f19d74357204ca317a51986a152e29cd0315df70f7eba2dbd585fe1938fa89d\n        checksum/secret-jobservice: 1502b63330d5a64588c432e97b8166219b6868bb9fc8ca2885e9f36e44f48efd\n        checksum/secret-core: c2f598f5d58a28ad67529eec72b7814fbbfd9b8c9012c9bd48cc51eda35cb56b\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n        fsGroupChangePolicy: OnRootMismatch\n      containers:\n      - name: registry\n        image: goharbor/registry-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-registry\n        ports:\n        - containerPort: 5000\n        - containerPort: 5001\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-htpasswd\n          mountPath: /etc/registry/passwd\n          subPath: passwd\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n      - name: registryctl\n        image: goharbor/harbor-registryctl:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-registryctl\n        - secretRef:\n            name: release-name-harbor-registry\n        - secretRef:\n            name: release-name-harbor-registryctl\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n        - name: registry-config\n          mountPath: /etc/registryctl/config.yml\n          subPath: ctl-config.yml\n      volumes:\n      - name: registry-htpasswd\n        secret:\n          secretName: release-name-harbor-registry-htpasswd\n          items:\n          - key: REGISTRY_HTPASSWD\n            path: passwd\n      - name: registry-config\n        configMap:\n          name: release-name-harbor-registry\n      - name: registry-data\n        persistentVolumeClaim:\n          claimName: release-name-harbor-registry\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"registry\" has memory limit 0"
  },
  {
    "id": "00302",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/027_deployment_release-name-harbor-registry.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-harbor-registry\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: registry\n    app.kubernetes.io/component: registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: registry\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: registry\n        app.kubernetes.io/component: registry\n      annotations:\n        checksum/configmap: b2a013a32036502b320d086fb71abf4702ba64f19e1c14222e31a2824982ad92\n        checksum/secret: 3f19d74357204ca317a51986a152e29cd0315df70f7eba2dbd585fe1938fa89d\n        checksum/secret-jobservice: 1502b63330d5a64588c432e97b8166219b6868bb9fc8ca2885e9f36e44f48efd\n        checksum/secret-core: c2f598f5d58a28ad67529eec72b7814fbbfd9b8c9012c9bd48cc51eda35cb56b\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n        fsGroupChangePolicy: OnRootMismatch\n      containers:\n      - name: registry\n        image: goharbor/registry-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /\n            scheme: HTTP\n            port: 5000\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-registry\n        ports:\n        - containerPort: 5000\n        - containerPort: 5001\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-htpasswd\n          mountPath: /etc/registry/passwd\n          subPath: passwd\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n      - name: registryctl\n        image: goharbor/harbor-registryctl:v2.14.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /api/health\n            scheme: HTTP\n            port: 8080\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        envFrom:\n        - configMapRef:\n            name: release-name-harbor-registryctl\n        - secretRef:\n            name: release-name-harbor-registry\n        - secretRef:\n            name: release-name-harbor-registryctl\n        env:\n        - name: CORE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-core\n              key: secret\n        - name: JOBSERVICE_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-jobservice\n              key: JOBSERVICE_SECRET\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: registry-data\n          mountPath: /storage\n          subPath: null\n        - name: registry-config\n          mountPath: /etc/registry/config.yml\n          subPath: config.yml\n        - name: registry-config\n          mountPath: /etc/registryctl/config.yml\n          subPath: ctl-config.yml\n      volumes:\n      - name: registry-htpasswd\n        secret:\n          secretName: release-name-harbor-registry-htpasswd\n          items:\n          - key: REGISTRY_HTPASSWD\n            path: passwd\n      - name: registry-config\n        configMap:\n          name: release-name-harbor-registry\n      - name: registry-data\n        persistentVolumeClaim:\n          claimName: release-name-harbor-registry\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"registryctl\" has memory limit 0"
  },
  {
    "id": "00303",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/028_statefulset_release-name-harbor-database.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-database\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: database\n    app.kubernetes.io/component: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: database\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: database\n        app.kubernetes.io/component: database\n      annotations:\n        checksum/secret: dee1c88277937d69af2062f5960366add60a3730428bb1dc41b98d04e8bc57eb\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      initContainers:\n      - name: data-permissions-ensurer\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - chmod -R 700 /var/lib/postgresql/data/pgdata || true\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n      containers:\n      - name: database\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 300\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 1\n          periodSeconds: 10\n          timeoutSeconds: 1\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-database\n        env:\n        - name: PGDATA\n          value: /var/lib/postgresql/data/pgdata\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n        - name: shm-volume\n          mountPath: /dev/shm\n      volumes:\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 512Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"data-permissions-ensurer\" does not have a read-only root file system"
  },
  {
    "id": "00304",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/028_statefulset_release-name-harbor-database.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-database\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: database\n    app.kubernetes.io/component: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: database\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: database\n        app.kubernetes.io/component: database\n      annotations:\n        checksum/secret: dee1c88277937d69af2062f5960366add60a3730428bb1dc41b98d04e8bc57eb\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      initContainers:\n      - name: data-permissions-ensurer\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - chmod -R 700 /var/lib/postgresql/data/pgdata || true\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n      containers:\n      - name: database\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 300\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 1\n          periodSeconds: 10\n          timeoutSeconds: 1\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-database\n        env:\n        - name: PGDATA\n          value: /var/lib/postgresql/data/pgdata\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n        - name: shm-volume\n          mountPath: /dev/shm\n      volumes:\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 512Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"database\" does not have a read-only root file system"
  },
  {
    "id": "00305",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/028_statefulset_release-name-harbor-database.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-database\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: database\n    app.kubernetes.io/component: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: database\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: database\n        app.kubernetes.io/component: database\n      annotations:\n        checksum/secret: dee1c88277937d69af2062f5960366add60a3730428bb1dc41b98d04e8bc57eb\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      initContainers:\n      - name: data-permissions-ensurer\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - chmod -R 700 /var/lib/postgresql/data/pgdata || true\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n      containers:\n      - name: database\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 300\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 1\n          periodSeconds: 10\n          timeoutSeconds: 1\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-database\n        env:\n        - name: PGDATA\n          value: /var/lib/postgresql/data/pgdata\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n        - name: shm-volume\n          mountPath: /dev/shm\n      volumes:\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 512Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"data-permissions-ensurer\" has cpu request 0"
  },
  {
    "id": "00306",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/028_statefulset_release-name-harbor-database.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-database\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: database\n    app.kubernetes.io/component: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: database\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: database\n        app.kubernetes.io/component: database\n      annotations:\n        checksum/secret: dee1c88277937d69af2062f5960366add60a3730428bb1dc41b98d04e8bc57eb\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      initContainers:\n      - name: data-permissions-ensurer\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - chmod -R 700 /var/lib/postgresql/data/pgdata || true\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n      containers:\n      - name: database\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 300\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 1\n          periodSeconds: 10\n          timeoutSeconds: 1\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-database\n        env:\n        - name: PGDATA\n          value: /var/lib/postgresql/data/pgdata\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n        - name: shm-volume\n          mountPath: /dev/shm\n      volumes:\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 512Mi\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"database\" has cpu request 0"
  },
  {
    "id": "00307",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/028_statefulset_release-name-harbor-database.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-database\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: database\n    app.kubernetes.io/component: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: database\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: database\n        app.kubernetes.io/component: database\n      annotations:\n        checksum/secret: dee1c88277937d69af2062f5960366add60a3730428bb1dc41b98d04e8bc57eb\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      initContainers:\n      - name: data-permissions-ensurer\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - chmod -R 700 /var/lib/postgresql/data/pgdata || true\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n      containers:\n      - name: database\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 300\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 1\n          periodSeconds: 10\n          timeoutSeconds: 1\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-database\n        env:\n        - name: PGDATA\n          value: /var/lib/postgresql/data/pgdata\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n        - name: shm-volume\n          mountPath: /dev/shm\n      volumes:\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 512Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"data-permissions-ensurer\" has memory limit 0"
  },
  {
    "id": "00308",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/028_statefulset_release-name-harbor-database.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-database\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: database\n    app.kubernetes.io/component: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: database\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: database\n        app.kubernetes.io/component: database\n      annotations:\n        checksum/secret: dee1c88277937d69af2062f5960366add60a3730428bb1dc41b98d04e8bc57eb\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      initContainers:\n      - name: data-permissions-ensurer\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - chmod -R 700 /var/lib/postgresql/data/pgdata || true\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n      containers:\n      - name: database\n        image: goharbor/harbor-db:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 300\n          periodSeconds: 10\n          timeoutSeconds: 1\n        readinessProbe:\n          exec:\n            command:\n            - /docker-healthcheck.sh\n          initialDelaySeconds: 1\n          periodSeconds: 10\n          timeoutSeconds: 1\n        envFrom:\n        - secretRef:\n            name: release-name-harbor-database\n        env:\n        - name: PGDATA\n          value: /var/lib/postgresql/data/pgdata\n        volumeMounts:\n        - name: database-data\n          mountPath: /var/lib/postgresql/data\n          subPath: null\n        - name: shm-volume\n          mountPath: /dev/shm\n      volumes:\n      - name: shm-volume\n        emptyDir:\n          medium: Memory\n          sizeLimit: 512Mi\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"database\" has memory limit 0"
  },
  {
    "id": "00309",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/029_statefulset_release-name-harbor-redis.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-redis\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: redis\n    app.kubernetes.io/component: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: redis\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: redis\n        app.kubernetes.io/component: redis\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      containers:\n      - name: redis\n        image: goharbor/redis-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          tcpSocket:\n            port: 6379\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          tcpSocket:\n            port: 6379\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/redis\n          subPath: null\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"redis\" does not have a read-only root file system"
  },
  {
    "id": "00310",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/029_statefulset_release-name-harbor-redis.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-redis\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: redis\n    app.kubernetes.io/component: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: redis\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: redis\n        app.kubernetes.io/component: redis\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      containers:\n      - name: redis\n        image: goharbor/redis-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          tcpSocket:\n            port: 6379\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          tcpSocket:\n            port: 6379\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/redis\n          subPath: null\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"redis\" has cpu request 0"
  },
  {
    "id": "00311",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/029_statefulset_release-name-harbor-redis.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-redis\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: redis\n    app.kubernetes.io/component: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: redis\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: redis\n        app.kubernetes.io/component: redis\n    spec:\n      securityContext:\n        runAsUser: 999\n        fsGroup: 999\n      containers:\n      - name: redis\n        image: goharbor/redis-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        livenessProbe:\n          tcpSocket:\n            port: 6379\n          initialDelaySeconds: 300\n          periodSeconds: 10\n        readinessProbe:\n          tcpSocket:\n            port: 6379\n          initialDelaySeconds: 1\n          periodSeconds: 10\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/redis\n          subPath: null\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"redis\" has memory limit 0"
  },
  {
    "id": "00312",
    "manifest_path": "data/manifests/artifacthub/harbor/harbor/030_statefulset_release-name-harbor-trivy.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-harbor-trivy\n  namespace: default\n  labels:\n    heritage: Helm\n    release: release-name\n    chart: harbor\n    app: harbor\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/name: harbor\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/part-of: harbor\n    app.kubernetes.io/version: 2.14.0\n    component: trivy\n    app.kubernetes.io/component: trivy\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      release: release-name\n      app: harbor\n      component: trivy\n  template:\n    metadata:\n      labels:\n        heritage: Helm\n        release: release-name\n        chart: harbor\n        app: harbor\n        app.kubernetes.io/instance: release-name\n        app.kubernetes.io/name: harbor\n        app.kubernetes.io/managed-by: Helm\n        app.kubernetes.io/part-of: harbor\n        app.kubernetes.io/version: 2.14.0\n        component: trivy\n        app.kubernetes.io/component: trivy\n      annotations:\n        checksum/secret: 6fbc9db4d37c6bc53260a46776f92e1e0390c1d50cd884e19a8d0a3c73deed8f\n    spec:\n      securityContext:\n        runAsUser: 10000\n        fsGroup: 10000\n      containers:\n      - name: trivy\n        image: goharbor/trivy-adapter-photon:v2.14.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          privileged: false\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: HTTP_PROXY\n          value: ''\n        - name: HTTPS_PROXY\n          value: ''\n        - name: NO_PROXY\n          value: release-name-harbor-core,release-name-harbor-jobservice,release-name-harbor-database,release-name-harbor-registry,release-name-harbor-portal,release-name-harbor-trivy,release-name-harbor-exporter,127.0.0.1,localhost,.local,.internal\n        - name: SCANNER_LOG_LEVEL\n          value: info\n        - name: SCANNER_TRIVY_CACHE_DIR\n          value: /home/scanner/.cache/trivy\n        - name: SCANNER_TRIVY_REPORTS_DIR\n          value: /home/scanner/.cache/reports\n        - name: SCANNER_TRIVY_DEBUG_MODE\n          value: 'false'\n        - name: SCANNER_TRIVY_VULN_TYPE\n          value: os,library\n        - name: SCANNER_TRIVY_TIMEOUT\n          value: 5m0s\n        - name: SCANNER_TRIVY_GITHUB_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-trivy\n              key: gitHubToken\n        - name: SCANNER_TRIVY_SEVERITY\n          value: UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL\n        - name: SCANNER_TRIVY_IGNORE_UNFIXED\n          value: 'false'\n        - name: SCANNER_TRIVY_SKIP_UPDATE\n          value: 'false'\n        - name: SCANNER_TRIVY_SKIP_JAVA_DB_UPDATE\n          value: 'false'\n        - name: SCANNER_TRIVY_DB_REPOSITORY\n          value: mirror.gcr.io/aquasec/trivy-db,ghcr.io/aquasecurity/trivy-db\n        - name: SCANNER_TRIVY_JAVA_DB_REPOSITORY\n          value: mirror.gcr.io/aquasec/trivy-java-db,ghcr.io/aquasecurity/trivy-java-db\n        - name: SCANNER_TRIVY_OFFLINE_SCAN\n          value: 'false'\n        - name: SCANNER_TRIVY_SECURITY_CHECKS\n          value: vuln\n        - name: SCANNER_TRIVY_INSECURE\n          value: 'false'\n        - name: SCANNER_API_SERVER_ADDR\n          value: :8080\n        - name: SCANNER_REDIS_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-trivy\n              key: redisURL\n        - name: SCANNER_STORE_REDIS_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-trivy\n              key: redisURL\n        - name: SCANNER_JOB_QUEUE_REDIS_URL\n          valueFrom:\n            secretKeyRef:\n              name: release-name-harbor-trivy\n              key: redisURL\n        ports:\n        - name: api-server\n          containerPort: 8080\n        volumeMounts:\n        - name: data\n          mountPath: /home/scanner/.cache\n          subPath: null\n          readOnly: false\n        livenessProbe:\n          httpGet:\n            scheme: HTTP\n            path: /probe/healthy\n            port: api-server\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          failureThreshold: 10\n        readinessProbe:\n          httpGet:\n            scheme: HTTP\n            path: /probe/ready\n            port: api-server\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          failureThreshold: 3\n        resources:\n          limits:\n            cpu: 1\n            memory: 1Gi\n          requests:\n            cpu: 200m\n            memory: 512Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"trivy\" does not have a read-only root file system"
  },
  {
    "id": "00313",
    "manifest_path": "data/manifests/artifacthub/hashicorp/vault/010_deployment_release-name-vault-agent-injector.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-vault-agent-injector\n  namespace: default\n  labels:\n    app.kubernetes.io/name: vault-agent-injector\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    component: webhook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault-agent-injector\n      app.kubernetes.io/instance: release-name\n      component: webhook\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: vault-agent-injector\n        app.kubernetes.io/instance: release-name\n        component: webhook\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: vault-agent-injector\n                app.kubernetes.io/instance: release-name\n                component: webhook\n            topologyKey: kubernetes.io/hostname\n      serviceAccountName: release-name-vault-agent-injector\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n        fsGroup: 1000\n      containers:\n      - name: sidecar-injector\n        image: hashicorp/vault-k8s:1.7.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        env:\n        - name: AGENT_INJECT_LISTEN\n          value: :8080\n        - name: AGENT_INJECT_LOG_LEVEL\n          value: info\n        - name: AGENT_INJECT_VAULT_ADDR\n          value: http://release-name-vault.default.svc:8200\n        - name: AGENT_INJECT_VAULT_AUTH_PATH\n          value: auth/kubernetes\n        - name: AGENT_INJECT_VAULT_IMAGE\n          value: hashicorp/vault:1.20.4\n        - name: AGENT_INJECT_TLS_AUTO\n          value: release-name-vault-agent-injector-cfg\n        - name: AGENT_INJECT_TLS_AUTO_HOSTS\n          value: release-name-vault-agent-injector-svc,release-name-vault-agent-injector-svc.default,release-name-vault-agent-injector-svc.default.svc\n        - name: AGENT_INJECT_LOG_FORMAT\n          value: standard\n        - name: AGENT_INJECT_REVOKE_ON_SHUTDOWN\n          value: 'false'\n        - name: AGENT_INJECT_CPU_REQUEST\n          value: 250m\n        - name: AGENT_INJECT_CPU_LIMIT\n          value: 500m\n        - name: AGENT_INJECT_MEM_REQUEST\n          value: 64Mi\n        - name: AGENT_INJECT_MEM_LIMIT\n          value: 128Mi\n        - name: AGENT_INJECT_DEFAULT_TEMPLATE\n          value: map\n        - name: AGENT_INJECT_TEMPLATE_CONFIG_EXIT_ON_RETRY_FAILURE\n          value: 'true'\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - agent-inject\n        - 2>&1\n        livenessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        startupProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 12\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 5\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"sidecar-injector\" does not have a read-only root file system"
  },
  {
    "id": "00314",
    "manifest_path": "data/manifests/artifacthub/hashicorp/vault/010_deployment_release-name-vault-agent-injector.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-vault-agent-injector\n  namespace: default\n  labels:\n    app.kubernetes.io/name: vault-agent-injector\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    component: webhook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault-agent-injector\n      app.kubernetes.io/instance: release-name\n      component: webhook\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: vault-agent-injector\n        app.kubernetes.io/instance: release-name\n        component: webhook\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: vault-agent-injector\n                app.kubernetes.io/instance: release-name\n                component: webhook\n            topologyKey: kubernetes.io/hostname\n      serviceAccountName: release-name-vault-agent-injector\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n        fsGroup: 1000\n      containers:\n      - name: sidecar-injector\n        image: hashicorp/vault-k8s:1.7.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        env:\n        - name: AGENT_INJECT_LISTEN\n          value: :8080\n        - name: AGENT_INJECT_LOG_LEVEL\n          value: info\n        - name: AGENT_INJECT_VAULT_ADDR\n          value: http://release-name-vault.default.svc:8200\n        - name: AGENT_INJECT_VAULT_AUTH_PATH\n          value: auth/kubernetes\n        - name: AGENT_INJECT_VAULT_IMAGE\n          value: hashicorp/vault:1.20.4\n        - name: AGENT_INJECT_TLS_AUTO\n          value: release-name-vault-agent-injector-cfg\n        - name: AGENT_INJECT_TLS_AUTO_HOSTS\n          value: release-name-vault-agent-injector-svc,release-name-vault-agent-injector-svc.default,release-name-vault-agent-injector-svc.default.svc\n        - name: AGENT_INJECT_LOG_FORMAT\n          value: standard\n        - name: AGENT_INJECT_REVOKE_ON_SHUTDOWN\n          value: 'false'\n        - name: AGENT_INJECT_CPU_REQUEST\n          value: 250m\n        - name: AGENT_INJECT_CPU_LIMIT\n          value: 500m\n        - name: AGENT_INJECT_MEM_REQUEST\n          value: 64Mi\n        - name: AGENT_INJECT_MEM_LIMIT\n          value: 128Mi\n        - name: AGENT_INJECT_DEFAULT_TEMPLATE\n          value: map\n        - name: AGENT_INJECT_TEMPLATE_CONFIG_EXIT_ON_RETRY_FAILURE\n          value: 'true'\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - agent-inject\n        - 2>&1\n        livenessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        startupProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 12\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 5\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sidecar-injector\" has cpu request 0"
  },
  {
    "id": "00315",
    "manifest_path": "data/manifests/artifacthub/hashicorp/vault/010_deployment_release-name-vault-agent-injector.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: release-name-vault-agent-injector\n  namespace: default\n  labels:\n    app.kubernetes.io/name: vault-agent-injector\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\n    component: webhook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault-agent-injector\n      app.kubernetes.io/instance: release-name\n      component: webhook\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: vault-agent-injector\n        app.kubernetes.io/instance: release-name\n        component: webhook\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: vault-agent-injector\n                app.kubernetes.io/instance: release-name\n                component: webhook\n            topologyKey: kubernetes.io/hostname\n      serviceAccountName: release-name-vault-agent-injector\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n        fsGroup: 1000\n      containers:\n      - name: sidecar-injector\n        image: hashicorp/vault-k8s:1.7.0\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n        env:\n        - name: AGENT_INJECT_LISTEN\n          value: :8080\n        - name: AGENT_INJECT_LOG_LEVEL\n          value: info\n        - name: AGENT_INJECT_VAULT_ADDR\n          value: http://release-name-vault.default.svc:8200\n        - name: AGENT_INJECT_VAULT_AUTH_PATH\n          value: auth/kubernetes\n        - name: AGENT_INJECT_VAULT_IMAGE\n          value: hashicorp/vault:1.20.4\n        - name: AGENT_INJECT_TLS_AUTO\n          value: release-name-vault-agent-injector-cfg\n        - name: AGENT_INJECT_TLS_AUTO_HOSTS\n          value: release-name-vault-agent-injector-svc,release-name-vault-agent-injector-svc.default,release-name-vault-agent-injector-svc.default.svc\n        - name: AGENT_INJECT_LOG_FORMAT\n          value: standard\n        - name: AGENT_INJECT_REVOKE_ON_SHUTDOWN\n          value: 'false'\n        - name: AGENT_INJECT_CPU_REQUEST\n          value: 250m\n        - name: AGENT_INJECT_CPU_LIMIT\n          value: 500m\n        - name: AGENT_INJECT_MEM_REQUEST\n          value: 64Mi\n        - name: AGENT_INJECT_MEM_LIMIT\n          value: 128Mi\n        - name: AGENT_INJECT_DEFAULT_TEMPLATE\n          value: map\n        - name: AGENT_INJECT_TEMPLATE_CONFIG_EXIT_ON_RETRY_FAILURE\n          value: 'true'\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - agent-inject\n        - 2>&1\n        livenessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        startupProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 12\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 5\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"sidecar-injector\" has memory limit 0"
  },
  {
    "id": "00316",
    "manifest_path": "data/manifests/artifacthub/hashicorp/vault/011_statefulset_release-name-vault.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-vault\n  namespace: default\n  labels:\n    app.kubernetes.io/name: vault\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault\n      app.kubernetes.io/instance: release-name\n      component: server\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: vault-0.31.0\n        app.kubernetes.io/name: vault\n        app.kubernetes.io/instance: release-name\n        component: server\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: vault\n                app.kubernetes.io/instance: release-name\n                component: server\n            topologyKey: kubernetes.io/hostname\n      serviceAccountName: release-name-vault\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n        fsGroup: 1000\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-vault-config\n      - name: home\n        emptyDir: {}\n      containers:\n      - name: vault\n        image: hashicorp/vault:1.20.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        - -ec\n        args:\n        - \"cp /vault/config/extraconfig-from-values.hcl /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${HOST_IP}\\\" ] && sed -Ei \\\"s|HOST_IP|${HOST_IP?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${POD_IP}\\\" ] && sed -Ei \\\"s|POD_IP|${POD_IP?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${HOSTNAME}\\\" ] && sed -Ei \\\"s|HOSTNAME|${HOSTNAME?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${API_ADDR}\\\" ] && sed -Ei \\\"s|API_ADDR|${API_ADDR?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${TRANSIT_ADDR}\\\" ] && sed -Ei \\\"s|TRANSIT_ADDR|${TRANSIT_ADDR?}|g\\\"\\\n          \\ /tmp/storageconfig.hcl;\\n[ -n \\\"${RAFT_ADDR}\\\" ] && sed -Ei \\\"s|RAFT_ADDR|${RAFT_ADDR?}|g\\\"\\\n          \\ /tmp/storageconfig.hcl;\\n/usr/local/bin/docker-entrypoint.sh vault server\\\n          \\ -config=/tmp/storageconfig.hcl \\n\"\n        securityContext:\n          allowPrivilegeEscalation: false\n        env:\n        - name: HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: VAULT_K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: VAULT_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VAULT_ADDR\n          value: http://127.0.0.1:8200\n        - name: VAULT_API_ADDR\n          value: http://$(POD_IP):8200\n        - name: SKIP_CHOWN\n          value: 'true'\n        - name: SKIP_SETCAP\n          value: 'true'\n        - name: HOSTNAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: VAULT_CLUSTER_ADDR\n          value: https://$(HOSTNAME).release-name-vault-internal:8201\n        - name: HOME\n          value: /home/vault\n        volumeMounts:\n        - name: data\n          mountPath: /vault/data\n        - name: config\n          mountPath: /vault/config\n        - name: home\n          mountPath: /home/vault\n        ports:\n        - containerPort: 8200\n          name: http\n        - containerPort: 8201\n          name: https-internal\n        - containerPort: 8202\n          name: http-rep\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -ec\n            - vault status -tls-skip-verify\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"vault\" does not have a read-only root file system"
  },
  {
    "id": "00317",
    "manifest_path": "data/manifests/artifacthub/hashicorp/vault/011_statefulset_release-name-vault.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-vault\n  namespace: default\n  labels:\n    app.kubernetes.io/name: vault\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault\n      app.kubernetes.io/instance: release-name\n      component: server\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: vault-0.31.0\n        app.kubernetes.io/name: vault\n        app.kubernetes.io/instance: release-name\n        component: server\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: vault\n                app.kubernetes.io/instance: release-name\n                component: server\n            topologyKey: kubernetes.io/hostname\n      serviceAccountName: release-name-vault\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n        fsGroup: 1000\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-vault-config\n      - name: home\n        emptyDir: {}\n      containers:\n      - name: vault\n        image: hashicorp/vault:1.20.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        - -ec\n        args:\n        - \"cp /vault/config/extraconfig-from-values.hcl /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${HOST_IP}\\\" ] && sed -Ei \\\"s|HOST_IP|${HOST_IP?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${POD_IP}\\\" ] && sed -Ei \\\"s|POD_IP|${POD_IP?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${HOSTNAME}\\\" ] && sed -Ei \\\"s|HOSTNAME|${HOSTNAME?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${API_ADDR}\\\" ] && sed -Ei \\\"s|API_ADDR|${API_ADDR?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${TRANSIT_ADDR}\\\" ] && sed -Ei \\\"s|TRANSIT_ADDR|${TRANSIT_ADDR?}|g\\\"\\\n          \\ /tmp/storageconfig.hcl;\\n[ -n \\\"${RAFT_ADDR}\\\" ] && sed -Ei \\\"s|RAFT_ADDR|${RAFT_ADDR?}|g\\\"\\\n          \\ /tmp/storageconfig.hcl;\\n/usr/local/bin/docker-entrypoint.sh vault server\\\n          \\ -config=/tmp/storageconfig.hcl \\n\"\n        securityContext:\n          allowPrivilegeEscalation: false\n        env:\n        - name: HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: VAULT_K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: VAULT_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VAULT_ADDR\n          value: http://127.0.0.1:8200\n        - name: VAULT_API_ADDR\n          value: http://$(POD_IP):8200\n        - name: SKIP_CHOWN\n          value: 'true'\n        - name: SKIP_SETCAP\n          value: 'true'\n        - name: HOSTNAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: VAULT_CLUSTER_ADDR\n          value: https://$(HOSTNAME).release-name-vault-internal:8201\n        - name: HOME\n          value: /home/vault\n        volumeMounts:\n        - name: data\n          mountPath: /vault/data\n        - name: config\n          mountPath: /vault/config\n        - name: home\n          mountPath: /home/vault\n        ports:\n        - containerPort: 8200\n          name: http\n        - containerPort: 8201\n          name: https-internal\n        - containerPort: 8202\n          name: http-rep\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -ec\n            - vault status -tls-skip-verify\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 3\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"vault\" has cpu request 0"
  },
  {
    "id": "00318",
    "manifest_path": "data/manifests/artifacthub/hashicorp/vault/011_statefulset_release-name-vault.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: release-name-vault\n  namespace: default\n  labels:\n    app.kubernetes.io/name: vault\n    app.kubernetes.io/instance: release-name\n    app.kubernetes.io/managed-by: Helm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault\n      app.kubernetes.io/instance: release-name\n      component: server\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: vault-0.31.0\n        app.kubernetes.io/name: vault\n        app.kubernetes.io/instance: release-name\n        component: server\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: vault\n                app.kubernetes.io/instance: release-name\n                component: server\n            topologyKey: kubernetes.io/hostname\n      serviceAccountName: release-name-vault\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n        fsGroup: 1000\n      volumes:\n      - name: config\n        configMap:\n          name: release-name-vault-config\n      - name: home\n        emptyDir: {}\n      containers:\n      - name: vault\n        image: hashicorp/vault:1.20.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        - -ec\n        args:\n        - \"cp /vault/config/extraconfig-from-values.hcl /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${HOST_IP}\\\" ] && sed -Ei \\\"s|HOST_IP|${HOST_IP?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${POD_IP}\\\" ] && sed -Ei \\\"s|POD_IP|${POD_IP?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${HOSTNAME}\\\" ] && sed -Ei \\\"s|HOSTNAME|${HOSTNAME?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${API_ADDR}\\\" ] && sed -Ei \\\"s|API_ADDR|${API_ADDR?}|g\\\" /tmp/storageconfig.hcl;\\n\\\n          [ -n \\\"${TRANSIT_ADDR}\\\" ] && sed -Ei \\\"s|TRANSIT_ADDR|${TRANSIT_ADDR?}|g\\\"\\\n          \\ /tmp/storageconfig.hcl;\\n[ -n \\\"${RAFT_ADDR}\\\" ] && sed -Ei \\\"s|RAFT_ADDR|${RAFT_ADDR?}|g\\\"\\\n          \\ /tmp/storageconfig.hcl;\\n/usr/local/bin/docker-entrypoint.sh vault server\\\n          \\ -config=/tmp/storageconfig.hcl \\n\"\n        securityContext:\n          allowPrivilegeEscalation: false\n        env:\n        - name: HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: VAULT_K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: VAULT_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: VAULT_ADDR\n          value: http://127.0.0.1:8200\n        - name: VAULT_API_ADDR\n          value: http://$(POD_IP):8200\n        - name: SKIP_CHOWN\n          value: 'true'\n        - name: SKIP_SETCAP\n          value: 'true'\n        - name: HOSTNAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: VAULT_CLUSTER_ADDR\n          value: https://$(HOSTNAME).release-name-vault-internal:8201\n        - name: HOME\n          value: /home/vault\n        volumeMounts:\n        - name: data\n          mountPath: /vault/data\n        - name: config\n          mountPath: /vault/config\n        - name: home\n          mountPath: /home/vault\n        ports:\n        - containerPort: 8200\n          name: http\n        - containerPort: 8201\n          name: https-internal\n        - containerPort: 8202\n          name: http-rep\n        readinessProbe:\n          exec:\n            command:\n            - /bin/sh\n            - -ec\n            - vault status -tls-skip-verify\n          failureThreshold: 2\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 3\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"vault\" has memory limit 0"
  },
  {
    "id": "00319",
    "manifest_path": "data/manifests/artifacthub/hashicorp/vault/013_pod_release-name-vault-server-test.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: release-name-vault-server-test\n  namespace: default\n  annotations:\n    helm.sh/hook: test\nspec:\n  containers:\n  - name: release-name-server-test\n    image: hashicorp/vault:1.20.4\n    imagePullPolicy: IfNotPresent\n    env:\n    - name: VAULT_ADDR\n      value: http://release-name-vault.default.svc:8200\n    command:\n    - /bin/sh\n    - -c\n    - \"echo \\\"Checking for sealed info in 'vault status' output\\\"\\nATTEMPTS=10\\nn=0\\n\\\n      until [ \\\"$n\\\" -ge $ATTEMPTS ]\\ndo\\n  echo \\\"Attempt\\\" $n...\\n  vault status\\\n      \\ -format yaml | grep -E '^sealed: (true|false)' && break\\n  n=$((n+1))\\n  sleep\\\n      \\ 5\\ndone\\nif [ $n -ge $ATTEMPTS ]; then\\n  echo \\\"timed out looking for sealed\\\n      \\ info in 'vault status' output\\\"\\n  exit 1\\nfi\\n\\nexit 0\\n\"\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"release-name-server-test\" does not have a read-only root file system"
  },
  {
    "id": "00320",
    "manifest_path": "data/manifests/artifacthub/hashicorp/vault/013_pod_release-name-vault-server-test.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: release-name-vault-server-test\n  namespace: default\n  annotations:\n    helm.sh/hook: test\nspec:\n  containers:\n  - name: release-name-server-test\n    image: hashicorp/vault:1.20.4\n    imagePullPolicy: IfNotPresent\n    env:\n    - name: VAULT_ADDR\n      value: http://release-name-vault.default.svc:8200\n    command:\n    - /bin/sh\n    - -c\n    - \"echo \\\"Checking for sealed info in 'vault status' output\\\"\\nATTEMPTS=10\\nn=0\\n\\\n      until [ \\\"$n\\\" -ge $ATTEMPTS ]\\ndo\\n  echo \\\"Attempt\\\" $n...\\n  vault status\\\n      \\ -format yaml | grep -E '^sealed: (true|false)' && break\\n  n=$((n+1))\\n  sleep\\\n      \\ 5\\ndone\\nif [ $n -ge $ATTEMPTS ]; then\\n  echo \\\"timed out looking for sealed\\\n      \\ info in 'vault status' output\\\"\\n  exit 1\\nfi\\n\\nexit 0\\n\"\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"release-name-server-test\" is not set to runAsNonRoot"
  }
]