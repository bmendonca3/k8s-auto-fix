[
  {
    "id": "02601",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1497\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02602",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02603",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02604",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02605",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02606",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02607",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02608",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02609",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02610",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02611",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02612",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02613",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02614",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02615",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02616",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02617",
    "policy_id": "no_privileged",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02618",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02619",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02620",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02621",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02622",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02623",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02624",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: meu-deployment\n  labels:\n    deployment: bolado_deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      example: olx-bolada\n  template:\n    metadata:\n      labels:\n        example: olx-bolada\n    spec:\n      containers:\n      - name: meu-container\n        image: ralphavalon/kube_features:v2\n        ports:\n        - containerPort: 8081\n        env:\n        - name: API_HOST\n          value: 192.168.99.100:30934\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 250m\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8081\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8081\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02625",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: meu-deployment\n  labels:\n    deployment: bolado_deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      example: olx-bolada\n  template:\n    metadata:\n      labels:\n        example: olx-bolada\n    spec:\n      containers:\n      - name: meu-container\n        image: ralphavalon/kube_features:v2\n        ports:\n        - containerPort: 8081\n        env:\n        - name: API_HOST\n          value: 192.168.99.100:30934\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 250m\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8081\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8081\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      securityContext:\n        runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02626",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02627",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02628",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02629",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02630",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02631",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: deis-minio\n  labels:\n    heritage: deis\n    release: v2-alpha\nspec:\n  replicas: 1\n  selector:\n    app: deis-minio\n  template:\n    metadata:\n      labels:\n        app: deis-minio\n    spec:\n      containers:\n      - imagePullPolicy: Always\n        name: deis-minio\n        image: quay.io/deisci/minio:v2-alpha\n        ports:\n        - containerPort: 9000\n        command:\n        - boot\n        args:\n        - server\n        - /home/minio/\n        volumeMounts:\n        - name: minio-admin\n          mountPath: /var/run/secrets/deis/minio/admin\n          readOnly: true\n        - name: minio-user\n          mountPath: /var/run/secrets/deis/minio/user\n          readOnly: true\n        - name: minio-data\n          mountPath: /home/minio\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: minio-admin\n        secret:\n          secretName: minio-admin\n      - name: minio-user\n        secret:\n          secretName: minio-user\n      - name: minio-data\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02632",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: deis-minio\n  labels:\n    heritage: deis\n    release: v2-alpha\nspec:\n  replicas: 1\n  selector:\n    app: deis-minio\n  template:\n    metadata:\n      labels:\n        app: deis-minio\n    spec:\n      containers:\n      - imagePullPolicy: Always\n        name: deis-minio\n        image: quay.io/deisci/minio:v2-alpha\n        ports:\n        - containerPort: 9000\n        command:\n        - boot\n        args:\n        - server\n        - /home/minio/\n        volumeMounts:\n        - name: minio-admin\n          mountPath: /var/run/secrets/deis/minio/admin\n          readOnly: true\n        - name: minio-user\n          mountPath: /var/run/secrets/deis/minio/user\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: minio-admin\n        secret:\n          secretName: minio-admin\n      - name: minio-user\n        secret:\n          secretName: minio-user\n      securityContext:\n        runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02633",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: deis-minio\n  labels:\n    heritage: deis\n    release: v2-alpha\nspec:\n  replicas: 1\n  selector:\n    app: deis-minio\n  template:\n    metadata:\n      labels:\n        app: deis-minio\n    spec:\n      containers:\n      - imagePullPolicy: Always\n        name: deis-minio\n        image: quay.io/deisci/minio:v2-alpha\n        ports:\n        - containerPort: 9000\n        command:\n        - boot\n        args:\n        - server\n        - /home/minio/\n        volumeMounts:\n        - name: minio-admin\n          mountPath: /var/run/secrets/deis/minio/admin\n          readOnly: true\n        - name: minio-user\n          mountPath: /var/run/secrets/deis/minio/user\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: minio-admin\n        secret:\n          secretName: minio-admin\n      - name: minio-user\n        secret:\n          secretName: minio-user\n",
    "errors": []
  },
  {
    "id": "02634",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: deis-minio\n  labels:\n    heritage: deis\n    release: v2-alpha\nspec:\n  replicas: 1\n  selector:\n    app: deis-minio\n  template:\n    metadata:\n      labels:\n        app: deis-minio\n    spec:\n      containers:\n      - imagePullPolicy: Always\n        name: deis-minio\n        image: quay.io/deisci/minio:v2-alpha\n        ports:\n        - containerPort: 9000\n        command:\n        - boot\n        args:\n        - server\n        - /home/minio/\n        volumeMounts:\n        - name: minio-admin\n          mountPath: /var/run/secrets/deis/minio/admin\n          readOnly: true\n        - name: minio-user\n          mountPath: /var/run/secrets/deis/minio/user\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: minio-admin\n        secret:\n          secretName: minio-admin\n      - name: minio-user\n        secret:\n          secretName: minio-user\n",
    "errors": []
  },
  {
    "id": "02635",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n",
    "errors": []
  },
  {
    "id": "02636",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n      securityContext:\n        seccompProfile:\n          type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02637",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n      securityContext:\n        runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02638",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n",
    "errors": []
  },
  {
    "id": "02639",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n",
    "errors": []
  },
  {
    "id": "02640",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 8a8b833ba1b6bd7a447a0e751960deed2ecd8106c1fcc7411dada4beae187d06\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: gastonborba\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: b8c01fa3c78e49707b1664fd573cbe2d129a2b78\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  }
]