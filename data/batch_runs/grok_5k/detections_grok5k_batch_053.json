[
  {
    "id": "02121",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"head\" has cpu request 0"
  },
  {
    "id": "02122",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"rangeget\" has cpu request 0"
  },
  {
    "id": "02123",
    "manifest_path": "data/manifests/the_stack_sample/sample_0793.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: head\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 512M\n          limits:\n            memory: 512M\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5100\n        env:\n        - name: NODE_TYPE\n          value: head_node\n      - name: sn\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 1G\n          limits:\n            memory: 1G\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          value: /config/passwd.txt\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn1\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6101'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn2\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6102\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6102'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn3\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6103\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6103'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: dn4\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6104\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: DN_PORT\n          value: '6104'\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      - name: rangeget\n        image: hdfgroup/hsds:v0.7.0beta6\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 2G\n          limits:\n            memory: 2G\n        volumeMounts:\n        - name: config\n          mountPath: /config\n        ports:\n        - containerPort: 6900\n        env:\n        - name: NODE_TYPE\n          value: rangeget\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_access_key_id\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-auth-keys\n              key: aws_secret_access_key\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"sn\" has cpu request 0"
  },
  {
    "id": "02124",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable AWS_SECRET_ACCESS_KEY in container \"alpine\" found"
  },
  {
    "id": "02125",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"alpine\" is using an invalid container image, \"alpine\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02126",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"alpine\" does not have a read-only root file system"
  },
  {
    "id": "02127",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"alpine\" is not set to runAsNonRoot"
  },
  {
    "id": "02128",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"alpine\" has cpu request 0"
  },
  {
    "id": "02129",
    "manifest_path": "data/manifests/the_stack_sample/sample_0794.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: hello-secrets\n        annotations:\n          vault.security.banzaicloud.io/vault-addr: https://vault:8200\n          vault.security.banzaicloud.io/vault-tls-secret: vault-tls\n      spec:\n        containers:\n        - name: alpine\n          image: alpine\n          command:\n          - sh\n          - -c\n          - echo $AWS_SECRET_ACCESS_KEY\n          env:\n          - name: AWS_SECRET_ACCESS_KEY\n            value: vault:secret/data/accounts/aws#${.AWS_SECRET_ACCESS_KEY}\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"alpine\" has memory limit 0"
  },
  {
    "id": "02130",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"review-app-reaper\" is using an invalid container image, \"{{ .tuberImage }}\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02131",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"review-app-reaper\" does not have a read-only root file system"
  },
  {
    "id": "02132",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"review-app-reaper\" is not set to runAsNonRoot"
  },
  {
    "id": "02133",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"review-app-reaper\" has cpu request 0"
  },
  {
    "id": "02134",
    "manifest_path": "data/manifests/the_stack_sample/sample_0796.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: review-app-reaper\nspec:\n  jobTemplate:\n    template:\n      metadata:\n        annotations:\n          sidecar.istio.io/inject: 'false'\n      spec:\n        serviceAccountName: tuber\n        containers:\n        - name: review-app-reaper\n          image: '{{ .tuberImage }}'\n          command:\n          - tuber\n          - review-app-reaper\n          envFrom:\n          - secretRef:\n              name: tuber-env\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"review-app-reaper\" has memory limit 0"
  },
  {
    "id": "02135",
    "manifest_path": "data/manifests/the_stack_sample/sample_0797.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: simple-mvcboot\n  name: simple-mvcboot\n  namespace: default\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: simple-mvcboot\n    spec:\n      containers:\n      - image: sme/simple-mvc-boot:0.1\n        name: simple-mvcboot\n        ports:\n        - containerPort: 8040\n          name: http\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"simple-mvcboot\" does not have a read-only root file system"
  },
  {
    "id": "02136",
    "manifest_path": "data/manifests/the_stack_sample/sample_0797.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: simple-mvcboot\n  name: simple-mvcboot\n  namespace: default\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: simple-mvcboot\n    spec:\n      containers:\n      - image: sme/simple-mvc-boot:0.1\n        name: simple-mvcboot\n        ports:\n        - containerPort: 8040\n          name: http\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"simple-mvcboot\" is not set to runAsNonRoot"
  },
  {
    "id": "02137",
    "manifest_path": "data/manifests/the_stack_sample/sample_0797.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: simple-mvcboot\n  name: simple-mvcboot\n  namespace: default\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: simple-mvcboot\n    spec:\n      containers:\n      - image: sme/simple-mvc-boot:0.1\n        name: simple-mvcboot\n        ports:\n        - containerPort: 8040\n          name: http\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"simple-mvcboot\" has cpu request 0"
  },
  {
    "id": "02138",
    "manifest_path": "data/manifests/the_stack_sample/sample_0797.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: simple-mvcboot\n  name: simple-mvcboot\n  namespace: default\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: simple-mvcboot\n    spec:\n      containers:\n      - image: sme/simple-mvc-boot:0.1\n        name: simple-mvcboot\n        ports:\n        - containerPort: 8040\n          name: http\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"simple-mvcboot\" has memory limit 0"
  },
  {
    "id": "02139",
    "manifest_path": "data/manifests/the_stack_sample/sample_0798.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210707-32dc49e04b\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"prow-controller-manager\" does not have a read-only root file system"
  },
  {
    "id": "02140",
    "manifest_path": "data/manifests/the_stack_sample/sample_0798.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210707-32dc49e04b\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"prow-controller-manager\" is not set to runAsNonRoot"
  },
  {
    "id": "02141",
    "manifest_path": "data/manifests/the_stack_sample/sample_0798.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210707-32dc49e04b\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"prow-controller-manager\" has cpu request 0"
  },
  {
    "id": "02142",
    "manifest_path": "data/manifests/the_stack_sample/sample_0798.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: prow-controller-manager\n  labels:\n    app: prow-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow-controller-manager\n    spec:\n      serviceAccountName: prow-controller-manager\n      containers:\n      - name: prow-controller-manager\n        image: gcr.io/k8s-prow/prow-controller-manager:v20210707-32dc49e04b\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --enable-controller=plank\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"prow-controller-manager\" has memory limit 0"
  },
  {
    "id": "02143",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"init-data\" is using an invalid container image, \"gitlab-registry.nautilus.optiputer.net/prp/gsutil\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02144",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"research\" is using an invalid container image, \"gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02145",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"init-data\" does not have a read-only root file system"
  },
  {
    "id": "02146",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"research\" does not have a read-only root file system"
  },
  {
    "id": "02147",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"init-data\" is not set to runAsNonRoot"
  },
  {
    "id": "02148",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"research\" is not set to runAsNonRoot"
  },
  {
    "id": "02149",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"init-data\" has cpu request 0"
  },
  {
    "id": "02150",
    "manifest_path": "data/manifests/the_stack_sample/sample_0801.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    k8s-app: research\n    user: xueting\n  namespace: image-model\nspec:\n  template:\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: gpu-type\n                operator: In\n                values:\n                - 1080Ti\n                - 2080Ti\n                - '2080'\n              - key: kubernetes.io/hostname\n                operator: NotIn\n                values:\n                - patternlab.calit2.optiputer.net\n                - k8s-gpu-03.sdsc.optiputer.net\n      containers:\n      - name: research\n        image: gitlab-registry.nautilus.optiputer.net/sunshineatnoon/image-model:latest\n        imagePullPolicy: Always\n        command:\n        - sh\n        - -c\n        args:\n        - cd /workspace && git clone https://sunshineatnoon:49531218Lxt@github.com/sunshineatnoon/taming-transformers\n          && cd taming-transformers && python main.py --base configs/custom_simple_vqgan.yaml\n          -t True --gpus 0,1\n        resources:\n          requests:\n            cpu: '10'\n            memory: 6Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 20Gi\n          limits:\n            cpu: '24'\n            memory: 12Gi\n            nvidia.com/gpu: '2'\n            ephemeral-storage: 30Gi\n        volumeMounts:\n        - mountPath: /mnt/source\n          name: src\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /data\n          name: dst\n      initContainers:\n      - name: init-data\n        image: gitlab-registry.nautilus.optiputer.net/prp/gsutil\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /mnt/dest/coco; gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco;\n          gsutil -m rsync -erCUP /mnt/source/coco /mnt/dest/coco; exit 0\n        volumeMounts:\n        - name: src\n          mountPath: /mnt/source\n        - name: dst\n          mountPath: /mnt/dest\n      volumes:\n      - name: dst\n        emptyDir: {}\n      - name: src\n        persistentVolumeClaim:\n          claimName: image-model-pvc\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"init-data\" has memory limit 0"
  },
  {
    "id": "02151",
    "manifest_path": "data/manifests/the_stack_sample/sample_0802.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      labels:\n        app: podinfo\n    spec:\n      containers:\n      - name: podinfo\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"podinfo\" does not have a read-only root file system"
  },
  {
    "id": "02152",
    "manifest_path": "data/manifests/the_stack_sample/sample_0802.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      labels:\n        app: podinfo\n    spec:\n      containers:\n      - name: podinfo\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"podinfo\" is not set to runAsNonRoot"
  },
  {
    "id": "02153",
    "manifest_path": "data/manifests/the_stack_sample/sample_0802.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      labels:\n        app: podinfo\n    spec:\n      containers:\n      - name: podinfo\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"podinfo\" has cpu request 0"
  },
  {
    "id": "02154",
    "manifest_path": "data/manifests/the_stack_sample/sample_0802.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      labels:\n        app: podinfo\n    spec:\n      containers:\n      - name: podinfo\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 3000\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"podinfo\" has memory limit 0"
  },
  {
    "id": "02155",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"fdw-settings\" is using an invalid container image, \"catarse-deploy/catarse\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "02156",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"fdw-settings\" does not have a read-only root file system"
  },
  {
    "id": "02157",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"fdw-settings\" is not set to runAsNonRoot"
  },
  {
    "id": "02158",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"fdw-settings\" has cpu request 0"
  },
  {
    "id": "02159",
    "manifest_path": "data/manifests/the_stack_sample/sample_0803.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fdw-settings\nspec:\n  template:\n    spec:\n      containers:\n      - name: fdw-settings\n        env:\n        - name: DATABASE_URL\n          value: postgres://catarse:example@catarse-db:5432/catarse_db\n        - name: RAILS_ENV\n          value: development\n        - name: REDIS_URL\n          value: redis://catarse-redis:6379\n        image: catarse-deploy/catarse\n        command:\n        - bundle\n        - exec\n        - rake\n        - common:generate_fdw\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"fdw-settings\" has memory limit 0"
  },
  {
    "id": "02160",
    "manifest_path": "data/manifests/the_stack_sample/sample_0805.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1708\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  }
]