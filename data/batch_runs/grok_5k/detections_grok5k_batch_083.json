[
  {
    "id": "03321",
    "manifest_path": "data/manifests/the_stack_sample/sample_1431.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: community-operators-catalog-rollout\n  annotations:\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\nspec:\n  jobTemplate:\n    template:\n      spec:\n        serviceAccountName: catalog-rollout\n        containers:\n        - name: rollout\n          image: CLI_IMAGE\n          imagePullPolicy: IfNotPresent\n          command:\n          - oc\n          - rollout\n          - restart\n          - deployment/community-operators-catalog\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"rollout\" has memory limit 0"
  },
  {
    "id": "03322",
    "manifest_path": "data/manifests/the_stack_sample/sample_1433.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200619-56de83d071\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"horologium\" does not have a read-only root file system"
  },
  {
    "id": "03323",
    "manifest_path": "data/manifests/the_stack_sample/sample_1433.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200619-56de83d071\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"horologium\" is not set to runAsNonRoot"
  },
  {
    "id": "03324",
    "manifest_path": "data/manifests/the_stack_sample/sample_1433.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200619-56de83d071\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"horologium\" has cpu request 0"
  },
  {
    "id": "03325",
    "manifest_path": "data/manifests/the_stack_sample/sample_1433.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200619-56de83d071\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"horologium\" has memory limit 0"
  },
  {
    "id": "03326",
    "manifest_path": "data/manifests/the_stack_sample/sample_1434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: orders-view-app\n  namespace: default\n  labels:\n    app: orders-view-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: orders-view-app\n  template:\n    metadata:\n      labels:\n        app: orders-view-app\n    spec:\n      securityContext:\n        fsGroup: 2000\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - orders-view-app\n            topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: spring-boot-application-properties\n        secret:\n          secretName: spring-boot-application-properties\n      containers:\n      - name: orders-view-app\n        image: docker.io/gamussa/livestreams-orders-view-app\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /mnt/app\n          name: spring-boot-application-properties\n        - mountPath: /mnt/kafka-streams-store/\n          name: rocksdb\n        env:\n        - name: SPRING_CONFIG_LOCATION\n          value: /mnt/app/application.properties\n        - name: JAVA_TOOL_OPTIONS\n          value: -DLOGLEVEL=INFO\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"orders-view-app\" is using an invalid container image, \"docker.io/gamussa/livestreams-orders-view-app\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "03327",
    "manifest_path": "data/manifests/the_stack_sample/sample_1434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: orders-view-app\n  namespace: default\n  labels:\n    app: orders-view-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: orders-view-app\n  template:\n    metadata:\n      labels:\n        app: orders-view-app\n    spec:\n      securityContext:\n        fsGroup: 2000\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - orders-view-app\n            topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: spring-boot-application-properties\n        secret:\n          secretName: spring-boot-application-properties\n      containers:\n      - name: orders-view-app\n        image: docker.io/gamussa/livestreams-orders-view-app\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /mnt/app\n          name: spring-boot-application-properties\n        - mountPath: /mnt/kafka-streams-store/\n          name: rocksdb\n        env:\n        - name: SPRING_CONFIG_LOCATION\n          value: /mnt/app/application.properties\n        - name: JAVA_TOOL_OPTIONS\n          value: -DLOGLEVEL=INFO\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"orders-view-app\" does not have a read-only root file system"
  },
  {
    "id": "03328",
    "manifest_path": "data/manifests/the_stack_sample/sample_1434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: orders-view-app\n  namespace: default\n  labels:\n    app: orders-view-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: orders-view-app\n  template:\n    metadata:\n      labels:\n        app: orders-view-app\n    spec:\n      securityContext:\n        fsGroup: 2000\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - orders-view-app\n            topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: spring-boot-application-properties\n        secret:\n          secretName: spring-boot-application-properties\n      containers:\n      - name: orders-view-app\n        image: docker.io/gamussa/livestreams-orders-view-app\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /mnt/app\n          name: spring-boot-application-properties\n        - mountPath: /mnt/kafka-streams-store/\n          name: rocksdb\n        env:\n        - name: SPRING_CONFIG_LOCATION\n          value: /mnt/app/application.properties\n        - name: JAVA_TOOL_OPTIONS\n          value: -DLOGLEVEL=INFO\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"orders-view-app\" is not set to runAsNonRoot"
  },
  {
    "id": "03329",
    "manifest_path": "data/manifests/the_stack_sample/sample_1434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: orders-view-app\n  namespace: default\n  labels:\n    app: orders-view-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: orders-view-app\n  template:\n    metadata:\n      labels:\n        app: orders-view-app\n    spec:\n      securityContext:\n        fsGroup: 2000\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - orders-view-app\n            topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: spring-boot-application-properties\n        secret:\n          secretName: spring-boot-application-properties\n      containers:\n      - name: orders-view-app\n        image: docker.io/gamussa/livestreams-orders-view-app\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /mnt/app\n          name: spring-boot-application-properties\n        - mountPath: /mnt/kafka-streams-store/\n          name: rocksdb\n        env:\n        - name: SPRING_CONFIG_LOCATION\n          value: /mnt/app/application.properties\n        - name: JAVA_TOOL_OPTIONS\n          value: -DLOGLEVEL=INFO\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"orders-view-app\" has cpu request 0"
  },
  {
    "id": "03330",
    "manifest_path": "data/manifests/the_stack_sample/sample_1434.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: orders-view-app\n  namespace: default\n  labels:\n    app: orders-view-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: orders-view-app\n  template:\n    metadata:\n      labels:\n        app: orders-view-app\n    spec:\n      securityContext:\n        fsGroup: 2000\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - orders-view-app\n            topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: spring-boot-application-properties\n        secret:\n          secretName: spring-boot-application-properties\n      containers:\n      - name: orders-view-app\n        image: docker.io/gamussa/livestreams-orders-view-app\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /mnt/app\n          name: spring-boot-application-properties\n        - mountPath: /mnt/kafka-streams-store/\n          name: rocksdb\n        env:\n        - name: SPRING_CONFIG_LOCATION\n          value: /mnt/app/application.properties\n        - name: JAVA_TOOL_OPTIONS\n          value: -DLOGLEVEL=INFO\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"orders-view-app\" has memory limit 0"
  },
  {
    "id": "03331",
    "manifest_path": "data/manifests/the_stack_sample/sample_1437.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:latest\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"workload-generator\" is using an invalid container image, \"workload-generator:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "03332",
    "manifest_path": "data/manifests/the_stack_sample/sample_1437.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:latest\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"workload-generator\" does not have a read-only root file system"
  },
  {
    "id": "03333",
    "manifest_path": "data/manifests/the_stack_sample/sample_1437.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:latest\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"workload-generator\" is not set to runAsNonRoot"
  },
  {
    "id": "03334",
    "manifest_path": "data/manifests/the_stack_sample/sample_1437.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:latest\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"workload-generator\" has cpu request 0"
  },
  {
    "id": "03335",
    "manifest_path": "data/manifests/the_stack_sample/sample_1437.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:latest\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"workload-generator\" has memory limit 0"
  },
  {
    "id": "03336",
    "manifest_path": "data/manifests/the_stack_sample/sample_1438.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openvpn-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openvpn-server\n  template:\n    metadata:\n      labels:\n        app: openvpn-server\n    spec:\n      containers:\n      - name: openvpn-server\n        image: quay.io/sjenning/poc:openvpn\n        imagePullPolicy: Always\n        command:\n        - /usr/sbin/openvpn\n        - --config\n        - /etc/openvpn/server/server.conf\n        workingDir: /etc/openvpn/server\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /etc/openvpn/server\n          name: server\n        - mountPath: /etc/openvpn/ccd\n          name: ccd\n      volumes:\n      - secret:\n          secretName: openvpn-server\n        name: server\n      - secret:\n          secretName: openvpn-ccd\n        name: ccd\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"openvpn-server\" does not have a read-only root file system"
  },
  {
    "id": "03337",
    "manifest_path": "data/manifests/the_stack_sample/sample_1438.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openvpn-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openvpn-server\n  template:\n    metadata:\n      labels:\n        app: openvpn-server\n    spec:\n      containers:\n      - name: openvpn-server\n        image: quay.io/sjenning/poc:openvpn\n        imagePullPolicy: Always\n        command:\n        - /usr/sbin/openvpn\n        - --config\n        - /etc/openvpn/server/server.conf\n        workingDir: /etc/openvpn/server\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /etc/openvpn/server\n          name: server\n        - mountPath: /etc/openvpn/ccd\n          name: ccd\n      volumes:\n      - secret:\n          secretName: openvpn-server\n        name: server\n      - secret:\n          secretName: openvpn-ccd\n        name: ccd\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"openvpn-server\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "03338",
    "manifest_path": "data/manifests/the_stack_sample/sample_1438.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openvpn-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openvpn-server\n  template:\n    metadata:\n      labels:\n        app: openvpn-server\n    spec:\n      containers:\n      - name: openvpn-server\n        image: quay.io/sjenning/poc:openvpn\n        imagePullPolicy: Always\n        command:\n        - /usr/sbin/openvpn\n        - --config\n        - /etc/openvpn/server/server.conf\n        workingDir: /etc/openvpn/server\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /etc/openvpn/server\n          name: server\n        - mountPath: /etc/openvpn/ccd\n          name: ccd\n      volumes:\n      - secret:\n          secretName: openvpn-server\n        name: server\n      - secret:\n          secretName: openvpn-ccd\n        name: ccd\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"openvpn-server\" is privileged"
  },
  {
    "id": "03339",
    "manifest_path": "data/manifests/the_stack_sample/sample_1438.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openvpn-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openvpn-server\n  template:\n    metadata:\n      labels:\n        app: openvpn-server\n    spec:\n      containers:\n      - name: openvpn-server\n        image: quay.io/sjenning/poc:openvpn\n        imagePullPolicy: Always\n        command:\n        - /usr/sbin/openvpn\n        - --config\n        - /etc/openvpn/server/server.conf\n        workingDir: /etc/openvpn/server\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /etc/openvpn/server\n          name: server\n        - mountPath: /etc/openvpn/ccd\n          name: ccd\n      volumes:\n      - secret:\n          secretName: openvpn-server\n        name: server\n      - secret:\n          secretName: openvpn-ccd\n        name: ccd\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"openvpn-server\" is not set to runAsNonRoot"
  },
  {
    "id": "03340",
    "manifest_path": "data/manifests/the_stack_sample/sample_1438.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openvpn-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openvpn-server\n  template:\n    metadata:\n      labels:\n        app: openvpn-server\n    spec:\n      containers:\n      - name: openvpn-server\n        image: quay.io/sjenning/poc:openvpn\n        imagePullPolicy: Always\n        command:\n        - /usr/sbin/openvpn\n        - --config\n        - /etc/openvpn/server/server.conf\n        workingDir: /etc/openvpn/server\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /etc/openvpn/server\n          name: server\n        - mountPath: /etc/openvpn/ccd\n          name: ccd\n      volumes:\n      - secret:\n          secretName: openvpn-server\n        name: server\n      - secret:\n          secretName: openvpn-ccd\n        name: ccd\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"openvpn-server\" has cpu request 0"
  },
  {
    "id": "03341",
    "manifest_path": "data/manifests/the_stack_sample/sample_1438.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openvpn-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openvpn-server\n  template:\n    metadata:\n      labels:\n        app: openvpn-server\n    spec:\n      containers:\n      - name: openvpn-server\n        image: quay.io/sjenning/poc:openvpn\n        imagePullPolicy: Always\n        command:\n        - /usr/sbin/openvpn\n        - --config\n        - /etc/openvpn/server/server.conf\n        workingDir: /etc/openvpn/server\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /etc/openvpn/server\n          name: server\n        - mountPath: /etc/openvpn/ccd\n          name: ccd\n      volumes:\n      - secret:\n          secretName: openvpn-server\n        name: server\n      - secret:\n          secretName: openvpn-ccd\n        name: ccd\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"openvpn-server\" has memory limit 0"
  },
  {
    "id": "03342",
    "manifest_path": "data/manifests/the_stack_sample/sample_1440.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7631\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "03343",
    "manifest_path": "data/manifests/the_stack_sample/sample_1440.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7631\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "03344",
    "manifest_path": "data/manifests/the_stack_sample/sample_1440.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7631\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "03345",
    "manifest_path": "data/manifests/the_stack_sample/sample_1440.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7631\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "03346",
    "manifest_path": "data/manifests/the_stack_sample/sample_1440.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7631\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "03347",
    "manifest_path": "data/manifests/the_stack_sample/sample_1444.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: branchprotector\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: branchprotector\n          image: gcr.io/k8s-prow/branchprotector:v20180622-df01a7f2b\n          args:\n          - --config-path=/etc/config/config\n          - --job-config-path=/etc/job-config\n          - --github-token-path=/etc/github/oauth\n          - --confirm\n          - --github-endpoint=http://ghproxy\n          - --github-endpoint=https://api.github.com\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n          - name: job-config\n            mountPath: /etc/job-config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: config\n        - name: job-config\n          configMap:\n            name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"branchprotector\" does not have a read-only root file system"
  },
  {
    "id": "03348",
    "manifest_path": "data/manifests/the_stack_sample/sample_1444.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: branchprotector\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: branchprotector\n          image: gcr.io/k8s-prow/branchprotector:v20180622-df01a7f2b\n          args:\n          - --config-path=/etc/config/config\n          - --job-config-path=/etc/job-config\n          - --github-token-path=/etc/github/oauth\n          - --confirm\n          - --github-endpoint=http://ghproxy\n          - --github-endpoint=https://api.github.com\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n          - name: job-config\n            mountPath: /etc/job-config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: config\n        - name: job-config\n          configMap:\n            name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"branchprotector\" is not set to runAsNonRoot"
  },
  {
    "id": "03349",
    "manifest_path": "data/manifests/the_stack_sample/sample_1444.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: branchprotector\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: branchprotector\n          image: gcr.io/k8s-prow/branchprotector:v20180622-df01a7f2b\n          args:\n          - --config-path=/etc/config/config\n          - --job-config-path=/etc/job-config\n          - --github-token-path=/etc/github/oauth\n          - --confirm\n          - --github-endpoint=http://ghproxy\n          - --github-endpoint=https://api.github.com\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n          - name: job-config\n            mountPath: /etc/job-config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: config\n        - name: job-config\n          configMap:\n            name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"branchprotector\" has cpu request 0"
  },
  {
    "id": "03350",
    "manifest_path": "data/manifests/the_stack_sample/sample_1444.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: branchprotector\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: branchprotector\n          image: gcr.io/k8s-prow/branchprotector:v20180622-df01a7f2b\n          args:\n          - --config-path=/etc/config/config\n          - --job-config-path=/etc/job-config\n          - --github-token-path=/etc/github/oauth\n          - --confirm\n          - --github-endpoint=http://ghproxy\n          - --github-endpoint=https://api.github.com\n          volumeMounts:\n          - name: oauth\n            mountPath: /etc/github\n            readOnly: true\n          - name: config\n            mountPath: /etc/config\n            readOnly: true\n          - name: job-config\n            mountPath: /etc/job-config\n            readOnly: true\n        volumes:\n        - name: oauth\n          secret:\n            secretName: oauth-token\n        - name: config\n          configMap:\n            name: config\n        - name: job-config\n          configMap:\n            name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"branchprotector\" has memory limit 0"
  },
  {
    "id": "03351",
    "manifest_path": "data/manifests/the_stack_sample/sample_1448.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: nightly-test-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: SINK_URL\n            value: http://el-test-nightly.default.svc.cluster.local:8080\n          - name: TARGET_PROJECT\n            value: operator\n          - name: NAMESPACE\n            value: bastion-p\n          - name: REGISTRY\n            value: ppc64le-cluster.bastion-p.svc.cluster.local:443\n          - name: TARGET_ARCH\n            value: ppc64le\n          - name: REMOTE_SECRET_NAME\n            value: ppc64le-kubeconfig\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable REMOTE_SECRET_NAME in container \"trigger\" found"
  },
  {
    "id": "03352",
    "manifest_path": "data/manifests/the_stack_sample/sample_1448.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: nightly-test-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: SINK_URL\n            value: http://el-test-nightly.default.svc.cluster.local:8080\n          - name: TARGET_PROJECT\n            value: operator\n          - name: NAMESPACE\n            value: bastion-p\n          - name: REGISTRY\n            value: ppc64le-cluster.bastion-p.svc.cluster.local:443\n          - name: TARGET_ARCH\n            value: ppc64le\n          - name: REMOTE_SECRET_NAME\n            value: ppc64le-kubeconfig\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"trigger\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "03353",
    "manifest_path": "data/manifests/the_stack_sample/sample_1448.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: nightly-test-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: SINK_URL\n            value: http://el-test-nightly.default.svc.cluster.local:8080\n          - name: TARGET_PROJECT\n            value: operator\n          - name: NAMESPACE\n            value: bastion-p\n          - name: REGISTRY\n            value: ppc64le-cluster.bastion-p.svc.cluster.local:443\n          - name: TARGET_ARCH\n            value: ppc64le\n          - name: REMOTE_SECRET_NAME\n            value: ppc64le-kubeconfig\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"trigger\" does not have a read-only root file system"
  },
  {
    "id": "03354",
    "manifest_path": "data/manifests/the_stack_sample/sample_1448.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: nightly-test-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: SINK_URL\n            value: http://el-test-nightly.default.svc.cluster.local:8080\n          - name: TARGET_PROJECT\n            value: operator\n          - name: NAMESPACE\n            value: bastion-p\n          - name: REGISTRY\n            value: ppc64le-cluster.bastion-p.svc.cluster.local:443\n          - name: TARGET_ARCH\n            value: ppc64le\n          - name: REMOTE_SECRET_NAME\n            value: ppc64le-kubeconfig\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"trigger\" is not set to runAsNonRoot"
  },
  {
    "id": "03355",
    "manifest_path": "data/manifests/the_stack_sample/sample_1448.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: nightly-test-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: SINK_URL\n            value: http://el-test-nightly.default.svc.cluster.local:8080\n          - name: TARGET_PROJECT\n            value: operator\n          - name: NAMESPACE\n            value: bastion-p\n          - name: REGISTRY\n            value: ppc64le-cluster.bastion-p.svc.cluster.local:443\n          - name: TARGET_ARCH\n            value: ppc64le\n          - name: REMOTE_SECRET_NAME\n            value: ppc64le-kubeconfig\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"trigger\" has cpu request 0"
  },
  {
    "id": "03356",
    "manifest_path": "data/manifests/the_stack_sample/sample_1448.yaml",
    "manifest_yaml": "apiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: nightly-test-trigger\nspec:\n  jobTemplate:\n    template:\n      spec:\n        containers:\n        - name: trigger\n          env:\n          - name: SINK_URL\n            value: http://el-test-nightly.default.svc.cluster.local:8080\n          - name: TARGET_PROJECT\n            value: operator\n          - name: NAMESPACE\n            value: bastion-p\n          - name: REGISTRY\n            value: ppc64le-cluster.bastion-p.svc.cluster.local:443\n          - name: TARGET_ARCH\n            value: ppc64le\n          - name: REMOTE_SECRET_NAME\n            value: ppc64le-kubeconfig\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"trigger\" has memory limit 0"
  },
  {
    "id": "03357",
    "manifest_path": "data/manifests/the_stack_sample/sample_1450.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20220510-5840068ce9\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"statusreconciler\" does not have a read-only root file system"
  },
  {
    "id": "03358",
    "manifest_path": "data/manifests/the_stack_sample/sample_1450.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20220510-5840068ce9\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"statusreconciler\" is not set to runAsNonRoot"
  },
  {
    "id": "03359",
    "manifest_path": "data/manifests/the_stack_sample/sample_1450.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20220510-5840068ce9\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"statusreconciler\" has cpu request 0"
  },
  {
    "id": "03360",
    "manifest_path": "data/manifests/the_stack_sample/sample_1450.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20220510-5840068ce9\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"statusreconciler\" has memory limit 0"
  }
]