[
  {
    "id": "01241",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"component-nodejs-dependence-npm\" is invalid: spec.containers[0].resources.requests: Invalid value: \"4G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01242",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"component-nodejs-dependence-npm\" is invalid: spec.containers[0].resources.requests: Invalid value: \"4G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01243",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"component-nodejs-dependence-npm\" is invalid: spec.containers[0].resources.requests: Invalid value: \"4G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01244",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01245",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01246",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01247",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01248",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      limits:\n        cpu: 500m\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      limits:\n        cpu: 500m\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01249",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01250",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01251",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01252",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "01253",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "01254",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "01255",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"fb-user-datastore-api-{{ .Values.environmentName }}\" is invalid: \n* metadata.name: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.selector.matchLabels: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"fb-user-datastore-api-{{ .Values.environmentName }}\"}}: invalid label selector"
    ]
  },
  {
    "id": "01256",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"fb-user-datastore-api-{{ .Values.environmentName }}\" is invalid: \n* metadata.name: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.selector.matchLabels: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"fb-user-datastore-api-{{ .Values.environmentName }}\"}}: invalid label selector"
    ]
  },
  {
    "id": "01257",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"fb-user-datastore-api-{{ .Values.environmentName }}\" is invalid: \n* metadata.name: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.selector.matchLabels: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"fb-user-datastore-api-{{ .Values.environmentName }}\"}}: invalid label selector"
    ]
  },
  {
    "id": "01258",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01259",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01260",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      securityContext:\n        runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01261",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01262",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01263",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"e2e\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "01264",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"e2e\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "01265",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"e2e\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "01266",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"e2e\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "01267",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "01268",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "01269",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "01270",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01271",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01272",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01273",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01274",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n      securityContext:\n        runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01275",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n      securityContext:\n        runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01276",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"openmcp-analytic-engine\" is invalid: spec.template.spec.containers[0].imagePullPolicy: Unsupported value: \"REPLACE_DOCKERIMAGEPULLPOLICY\": supported values: \"Always\", \"IfNotPresent\", \"Never\""
    ]
  },
  {
    "id": "01277",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"openmcp-analytic-engine\" is invalid: spec.template.spec.containers[0].imagePullPolicy: Unsupported value: \"REPLACE_DOCKERIMAGEPULLPOLICY\": supported values: \"Always\", \"IfNotPresent\", \"Never\""
    ]
  },
  {
    "id": "01278",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"openmcp-analytic-engine\" is invalid: spec.template.spec.containers[0].imagePullPolicy: Unsupported value: \"REPLACE_DOCKERIMAGEPULLPOLICY\": supported values: \"Always\", \"IfNotPresent\", \"Never\""
    ]
  },
  {
    "id": "01279",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"openmcp-analytic-engine\" is invalid: spec.template.spec.containers[0].imagePullPolicy: Unsupported value: \"REPLACE_DOCKERIMAGEPULLPOLICY\": supported values: \"Always\", \"IfNotPresent\", \"Never\""
    ]
  },
  {
    "id": "01280",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    control-plane: controller-manager\n  name: special-resource-controller-manager\n  namespace: openshift-special-resource-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        - --tls-cert-file=/etc/secrets/tls.crt\n        - --tls-private-key-file=/etc/secrets/tls.key\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        image: registry.redhat.io/openshift4/ose-kube-rbac-proxy:stable\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        resources:\n          limits:\n            cpu: 500m\n            memory: 128Mi\n          requests:\n            cpu: 250m\n            memory: 64Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/secrets\n          name: special-resource-operator-tls\n      - args:\n        - --metrics-addr=127.0.0.1:8080\n        - --enable-leader-election\n        command:\n        - /manager\n        env:\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: SSL_CERT_DIR\n          value: /etc/pki/tls/certs\n        image: quay.io/openshift-psap/special-resource-operator:chart-as-asset\n        imagePullPolicy: Always\n        name: manager\n        resources:\n          limits:\n            cpu: 300m\n            memory: 500Mi\n          requests:\n            cpu: 300m\n            memory: 500Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /cache\n          name: cache-volume\n      securityContext:\n        runAsGroup: 499\n        runAsNonRoot: true\n        runAsUser: 499\n      volumes:\n      - name: special-resource-operator-tls\n        secret:\n          secretName: special-resource-operator-tls\n      - emptyDir: {}\n        name: cache-volume\n",
    "errors": []
  }
]