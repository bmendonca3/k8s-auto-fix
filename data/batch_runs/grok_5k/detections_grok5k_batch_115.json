[
  {
    "id": "04601",
    "manifest_path": "data/manifests/the_stack_sample/sample_2112.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "04602",
    "manifest_path": "data/manifests/the_stack_sample/sample_2112.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "04603",
    "manifest_path": "data/manifests/the_stack_sample/sample_2112.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "04604",
    "manifest_path": "data/manifests/the_stack_sample/sample_2112.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "04605",
    "manifest_path": "data/manifests/the_stack_sample/sample_2113.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: example\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "04606",
    "manifest_path": "data/manifests/the_stack_sample/sample_2113.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: example\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "04607",
    "manifest_path": "data/manifests/the_stack_sample/sample_2113.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: example\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "04608",
    "manifest_path": "data/manifests/the_stack_sample/sample_2113.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: example\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "04609",
    "manifest_path": "data/manifests/the_stack_sample/sample_2115.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: transmission\n  labels:\n    app.kubernetes.io/name: transmission\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: transmission\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: transmission\n    spec:\n      containers:\n      - name: transmission\n        image: ghcr.io/k8s-at-home/transmission:v3.00\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 50Mi\n        ports:\n        - name: gui-port\n          protocol: TCP\n          containerPort: 9091\n        - name: tcp-port\n          protocol: TCP\n          containerPort: 51413\n        - name: udp-port\n          protocol: UDP\n          containerPort: 51413\n        volumeMounts:\n        - name: transmission-configs\n          mountPath: /config/settings.json\n          subPath: settings.json\n        - name: transmission-config\n          mountPath: /config\n        - name: transmission-downloads\n          mountPath: /downloads\n        livenessProbe:\n          tcpSocket:\n            port: tcp-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          tcpSocket:\n            port: tcp-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        env:\n        - name: TZ\n          value: ${CONFIG_TIMEZONE}\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n        fsGroupChangePolicy: OnRootMismatch\n      volumes:\n      - name: transmission-configs\n        configMap:\n          name: transmission-configs\n      - name: transmission-config\n        persistentVolumeClaim:\n          claimName: transmission-config\n      - name: transmission-downloads\n        persistentVolumeClaim:\n          claimName: shared-downloads\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"transmission\" does not have a read-only root file system"
  },
  {
    "id": "04610",
    "manifest_path": "data/manifests/the_stack_sample/sample_2115.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: transmission\n  labels:\n    app.kubernetes.io/name: transmission\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: transmission\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: transmission\n    spec:\n      containers:\n      - name: transmission\n        image: ghcr.io/k8s-at-home/transmission:v3.00\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 50Mi\n        ports:\n        - name: gui-port\n          protocol: TCP\n          containerPort: 9091\n        - name: tcp-port\n          protocol: TCP\n          containerPort: 51413\n        - name: udp-port\n          protocol: UDP\n          containerPort: 51413\n        volumeMounts:\n        - name: transmission-configs\n          mountPath: /config/settings.json\n          subPath: settings.json\n        - name: transmission-config\n          mountPath: /config\n        - name: transmission-downloads\n          mountPath: /downloads\n        livenessProbe:\n          tcpSocket:\n            port: tcp-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          tcpSocket:\n            port: tcp-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        env:\n        - name: TZ\n          value: ${CONFIG_TIMEZONE}\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n        fsGroupChangePolicy: OnRootMismatch\n      volumes:\n      - name: transmission-configs\n        configMap:\n          name: transmission-configs\n      - name: transmission-config\n        persistentVolumeClaim:\n          claimName: transmission-config\n      - name: transmission-downloads\n        persistentVolumeClaim:\n          claimName: shared-downloads\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"transmission\" has memory limit 0"
  },
  {
    "id": "04611",
    "manifest_path": "data/manifests/the_stack_sample/sample_2116.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-dns-metrics-bash\n  namespace: kube-system\n  labels:\n    application: kube-dns-metrics-bash\n    version: v0.0.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      application: kube-dns-metrics-bash\n  template:\n    metadata:\n      labels:\n        application: kube-dns-metrics-bash\n        version: v0.0.4\n    spec:\n      containers:\n      - image: pierone.stups.zalan.do/teapot/kube-dns-metrics-bash:v0.0.5\n        name: kube-dns-metrics-bash\n        resources:\n          limits:\n            memory: 100Mi\n          requests:\n            cpu: 25m\n            memory: 100Mi\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kube-dns-metrics-bash\" does not have a read-only root file system"
  },
  {
    "id": "04612",
    "manifest_path": "data/manifests/the_stack_sample/sample_2116.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-dns-metrics-bash\n  namespace: kube-system\n  labels:\n    application: kube-dns-metrics-bash\n    version: v0.0.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      application: kube-dns-metrics-bash\n  template:\n    metadata:\n      labels:\n        application: kube-dns-metrics-bash\n        version: v0.0.4\n    spec:\n      containers:\n      - image: pierone.stups.zalan.do/teapot/kube-dns-metrics-bash:v0.0.5\n        name: kube-dns-metrics-bash\n        resources:\n          limits:\n            memory: 100Mi\n          requests:\n            cpu: 25m\n            memory: 100Mi\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kube-dns-metrics-bash\" is not set to runAsNonRoot"
  },
  {
    "id": "04613",
    "manifest_path": "data/manifests/the_stack_sample/sample_2118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis-master\n  namespace: default\n  labels:\n    name: redis-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis-master\n  template:\n    metadata:\n      labels:\n        app: redis-master\n        redis-master: 'true'\n      annotations:\n        security.alpha.kubernetes.io/sysctls: net.ipv4.tcp_syncookies=0,net.ipv4.ip_local_port_range=10000\n          65535\n        security.alpha.kubernetes.io/unsafe-sysctls: net.core.somaxconn=65535,net.ipv4.tcp_tw_reuse=1,net.ipv4.tcp_fin_timeout=30,net.ipv4.tcp_keepalive_intvl=4,net.ipv4.tcp_keepalive_probes=3,net.ipv4.tcp_keepalive_time=120,net.ipv4.tcp_max_syn_backlog=65535,net.ipv4.tcp_rfc1337=1,net.ipv4.tcp_slow_start_after_idle=0,net.ipv4.tcp_fack=1,net.ipv4.tcp_fwmark_accept=1,net.ipv4.fwmark_reflect=1\n    spec:\n      containers:\n      - name: redis\n        image: slpcat/redis-3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 6379\n        env:\n        - name: MASTER\n          value: 'true'\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 250m\n          limits:\n            memory: 2Gi\n            cpu: 2000m\n        volumeMounts:\n        - name: redis-master-volume\n          mountPath: /var/lib/redis\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"redis\" is using an invalid container image, \"slpcat/redis-3.2\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04614",
    "manifest_path": "data/manifests/the_stack_sample/sample_2118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis-master\n  namespace: default\n  labels:\n    name: redis-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis-master\n  template:\n    metadata:\n      labels:\n        app: redis-master\n        redis-master: 'true'\n      annotations:\n        security.alpha.kubernetes.io/sysctls: net.ipv4.tcp_syncookies=0,net.ipv4.ip_local_port_range=10000\n          65535\n        security.alpha.kubernetes.io/unsafe-sysctls: net.core.somaxconn=65535,net.ipv4.tcp_tw_reuse=1,net.ipv4.tcp_fin_timeout=30,net.ipv4.tcp_keepalive_intvl=4,net.ipv4.tcp_keepalive_probes=3,net.ipv4.tcp_keepalive_time=120,net.ipv4.tcp_max_syn_backlog=65535,net.ipv4.tcp_rfc1337=1,net.ipv4.tcp_slow_start_after_idle=0,net.ipv4.tcp_fack=1,net.ipv4.tcp_fwmark_accept=1,net.ipv4.fwmark_reflect=1\n    spec:\n      containers:\n      - name: redis\n        image: slpcat/redis-3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 6379\n        env:\n        - name: MASTER\n          value: 'true'\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 250m\n          limits:\n            memory: 2Gi\n            cpu: 2000m\n        volumeMounts:\n        - name: redis-master-volume\n          mountPath: /var/lib/redis\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"redis\" does not have a read-only root file system"
  },
  {
    "id": "04615",
    "manifest_path": "data/manifests/the_stack_sample/sample_2118.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis-master\n  namespace: default\n  labels:\n    name: redis-master\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis-master\n  template:\n    metadata:\n      labels:\n        app: redis-master\n        redis-master: 'true'\n      annotations:\n        security.alpha.kubernetes.io/sysctls: net.ipv4.tcp_syncookies=0,net.ipv4.ip_local_port_range=10000\n          65535\n        security.alpha.kubernetes.io/unsafe-sysctls: net.core.somaxconn=65535,net.ipv4.tcp_tw_reuse=1,net.ipv4.tcp_fin_timeout=30,net.ipv4.tcp_keepalive_intvl=4,net.ipv4.tcp_keepalive_probes=3,net.ipv4.tcp_keepalive_time=120,net.ipv4.tcp_max_syn_backlog=65535,net.ipv4.tcp_rfc1337=1,net.ipv4.tcp_slow_start_after_idle=0,net.ipv4.tcp_fack=1,net.ipv4.tcp_fwmark_accept=1,net.ipv4.fwmark_reflect=1\n    spec:\n      containers:\n      - name: redis\n        image: slpcat/redis-3.2\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 6379\n        env:\n        - name: MASTER\n          value: 'true'\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 250m\n          limits:\n            memory: 2Gi\n            cpu: 2000m\n        volumeMounts:\n        - name: redis-master-volume\n          mountPath: /var/lib/redis\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"redis\" is not set to runAsNonRoot"
  },
  {
    "id": "04616",
    "manifest_path": "data/manifests/the_stack_sample/sample_2119.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: kuard\n  name: kuard\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      run: kuard\n  template:\n    metadata:\n      labels:\n        run: kuard\n    spec:\n      containers:\n      - image: gcr.io/kuar-demo/kuard-amd64:blue\n        name: kuard\n        resources:\n          limits:\n            cpu: 50m\n            memory: 0.1G\n          requests:\n            cpu: 50m\n            memory: 0.1G\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"kuard\" does not have a read-only root file system"
  },
  {
    "id": "04617",
    "manifest_path": "data/manifests/the_stack_sample/sample_2119.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: kuard\n  name: kuard\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      run: kuard\n  template:\n    metadata:\n      labels:\n        run: kuard\n    spec:\n      containers:\n      - image: gcr.io/kuar-demo/kuard-amd64:blue\n        name: kuard\n        resources:\n          limits:\n            cpu: 50m\n            memory: 0.1G\n          requests:\n            cpu: 50m\n            memory: 0.1G\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"kuard\" is not set to runAsNonRoot"
  },
  {
    "id": "04618",
    "manifest_path": "data/manifests/the_stack_sample/sample_2120.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:latest\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"iap\" is using an invalid container image, \"gcr.io/kubeflow-images-public/ingress-setup:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04619",
    "manifest_path": "data/manifests/the_stack_sample/sample_2120.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:latest\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"iap\" does not have a read-only root file system"
  },
  {
    "id": "04620",
    "manifest_path": "data/manifests/the_stack_sample/sample_2120.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:latest\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"iap\" is not set to runAsNonRoot"
  },
  {
    "id": "04621",
    "manifest_path": "data/manifests/the_stack_sample/sample_2120.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:latest\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"iap\" has cpu request 0"
  },
  {
    "id": "04622",
    "manifest_path": "data/manifests/the_stack_sample/sample_2120.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:latest\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"iap\" has memory limit 0"
  },
  {
    "id": "04623",
    "manifest_path": "data/manifests/the_stack_sample/sample_2121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04624",
    "manifest_path": "data/manifests/the_stack_sample/sample_2121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "04625",
    "manifest_path": "data/manifests/the_stack_sample/sample_2121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "04626",
    "manifest_path": "data/manifests/the_stack_sample/sample_2121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "04627",
    "manifest_path": "data/manifests/the_stack_sample/sample_2121.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "04628",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"packageserver\" is using an invalid container image, \"OLM_OPERATOR_IMAGE\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04629",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"socks5-proxy\" is using an invalid container image, \"SOCKS5_PROXY_IMAGE\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04630",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"packageserver\" does not have a read-only root file system"
  },
  {
    "id": "04631",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"socks5-proxy\" does not have a read-only root file system"
  },
  {
    "id": "04632",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"packageserver\" is not set to runAsNonRoot"
  },
  {
    "id": "04633",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"socks5-proxy\" is not set to runAsNonRoot"
  },
  {
    "id": "04634",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"socks5-proxy\" has cpu request 0"
  },
  {
    "id": "04635",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"packageserver\" has memory limit 0"
  },
  {
    "id": "04636",
    "manifest_path": "data/manifests/the_stack_sample/sample_2124.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"socks5-proxy\" has memory limit 0"
  },
  {
    "id": "04637",
    "manifest_path": "data/manifests/the_stack_sample/sample_2131.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - name: hello\n    image: raelga/hello\n    resources:\n      limits:\n        cpu: 50m\n        memory: 0.1G\n      requests:\n        cpu: 50m\n        memory: 0.1G\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"hello\" is using an invalid container image, \"raelga/hello\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04638",
    "manifest_path": "data/manifests/the_stack_sample/sample_2131.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - name: hello\n    image: raelga/hello\n    resources:\n      limits:\n        cpu: 50m\n        memory: 0.1G\n      requests:\n        cpu: 50m\n        memory: 0.1G\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"hello\" does not have a read-only root file system"
  },
  {
    "id": "04639",
    "manifest_path": "data/manifests/the_stack_sample/sample_2131.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - name: hello\n    image: raelga/hello\n    resources:\n      limits:\n        cpu: 50m\n        memory: 0.1G\n      requests:\n        cpu: 50m\n        memory: 0.1G\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"hello\" is not set to runAsNonRoot"
  },
  {
    "id": "04640",
    "manifest_path": "data/manifests/the_stack_sample/sample_2132.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\n  namespace: workshop-303\nspec:\n  containers:\n  - name: first-container\n    image: fedora:29\n    command:\n    - sleep\n    - '36000'\n    env:\n    - name: SECRET_USERNAME\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: username\n    - name: SECRET_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: password\n    volumeMounts:\n    - name: my-configmap\n      mountPath: /config\n  volumes:\n  - name: my-configmap\n    configMap:\n      name: my-configmap\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"first-container\" does not have a read-only root file system"
  }
]