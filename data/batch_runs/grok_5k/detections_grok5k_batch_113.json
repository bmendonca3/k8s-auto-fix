[
  {
    "id": "04521",
    "manifest_path": "data/manifests/the_stack_sample/sample_2074.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: true\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"buildkitd\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "04522",
    "manifest_path": "data/manifests/the_stack_sample/sample_2074.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: true\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"buildkitd\" is privileged"
  },
  {
    "id": "04523",
    "manifest_path": "data/manifests/the_stack_sample/sample_2074.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: true\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"buildkitd\" is not set to runAsNonRoot"
  },
  {
    "id": "04524",
    "manifest_path": "data/manifests/the_stack_sample/sample_2074.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: true\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"buildkitd\" has cpu request 0"
  },
  {
    "id": "04525",
    "manifest_path": "data/manifests/the_stack_sample/sample_2074.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: true\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"buildkitd\" has memory limit 0"
  },
  {
    "id": "04526",
    "manifest_path": "data/manifests/the_stack_sample/sample_2075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-test\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql-test\n  template:\n    metadata:\n      labels:\n        app: mysql-test\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: key\n                operator: In\n                values:\n                - value\n      containers:\n      - name: mysql-test\n        image: statemood/mysql:5.7.21\n        imagePullPolicy: Always\n        env:\n        - name: MYSQL_CONFIG_FILE\n          value: /var/lib/mysql/my.cnf\n        - name: MYSQL_ROOT_PASSWORD\n          value: ''\n        volumeMounts:\n        - mountPath: /var/lib/mysql\n          name: data\n        ports:\n        - containerPort: 3306\n        resources:\n          limits:\n            cpu: 900m\n            memory: 2Gi\n          requests:\n            cpu: 900m\n            memory: 2Gi\n        livenessProbe:\n          tcpSocket:\n            port: 3306\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          periodSeconds: 20\n        readinessProbe:\n          tcpSocket:\n            port: 3306\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          periodSeconds: 20\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: data-mysql-test\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"mysql-test\" does not have a read-only root file system"
  },
  {
    "id": "04527",
    "manifest_path": "data/manifests/the_stack_sample/sample_2075.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-test\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql-test\n  template:\n    metadata:\n      labels:\n        app: mysql-test\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: key\n                operator: In\n                values:\n                - value\n      containers:\n      - name: mysql-test\n        image: statemood/mysql:5.7.21\n        imagePullPolicy: Always\n        env:\n        - name: MYSQL_CONFIG_FILE\n          value: /var/lib/mysql/my.cnf\n        - name: MYSQL_ROOT_PASSWORD\n          value: ''\n        volumeMounts:\n        - mountPath: /var/lib/mysql\n          name: data\n        ports:\n        - containerPort: 3306\n        resources:\n          limits:\n            cpu: 900m\n            memory: 2Gi\n          requests:\n            cpu: 900m\n            memory: 2Gi\n        livenessProbe:\n          tcpSocket:\n            port: 3306\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          periodSeconds: 20\n        readinessProbe:\n          tcpSocket:\n            port: 3306\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          periodSeconds: 20\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: data-mysql-test\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"mysql-test\" is not set to runAsNonRoot"
  },
  {
    "id": "04528",
    "manifest_path": "data/manifests/the_stack_sample/sample_2076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-client\n  labels:\n    app: echo-client\n    group: sample\n    version: 0.0.1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: echo-client\n      group: sample\n      version: 0.0.1\n  template:\n    metadata:\n      labels:\n        app: echo-client\n        group: sample\n        version: 0.0.1\n    spec:\n      containers:\n      - name: echo-client\n        image: echo-client:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 7001\n        - name: http-metrics\n          containerPort: 7090\n        resources:\n          limits:\n            cpu: 250m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        livenessProbe:\n          httpGet:\n            path: /live\n            port: 7090\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 7090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"echo-client\" is using an invalid container image, \"echo-client:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04529",
    "manifest_path": "data/manifests/the_stack_sample/sample_2076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-client\n  labels:\n    app: echo-client\n    group: sample\n    version: 0.0.1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: echo-client\n      group: sample\n      version: 0.0.1\n  template:\n    metadata:\n      labels:\n        app: echo-client\n        group: sample\n        version: 0.0.1\n    spec:\n      containers:\n      - name: echo-client\n        image: echo-client:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 7001\n        - name: http-metrics\n          containerPort: 7090\n        resources:\n          limits:\n            cpu: 250m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        livenessProbe:\n          httpGet:\n            path: /live\n            port: 7090\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 7090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"echo-client\" does not have a read-only root file system"
  },
  {
    "id": "04530",
    "manifest_path": "data/manifests/the_stack_sample/sample_2076.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-client\n  labels:\n    app: echo-client\n    group: sample\n    version: 0.0.1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: echo-client\n      group: sample\n      version: 0.0.1\n  template:\n    metadata:\n      labels:\n        app: echo-client\n        group: sample\n        version: 0.0.1\n    spec:\n      containers:\n      - name: echo-client\n        image: echo-client:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 7001\n        - name: http-metrics\n          containerPort: 7090\n        resources:\n          limits:\n            cpu: 250m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        livenessProbe:\n          httpGet:\n            path: /live\n            port: 7090\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 7090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"echo-client\" is not set to runAsNonRoot"
  },
  {
    "id": "04531",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"read-du\" is using an invalid container image, \"giantswarm/tiny-tools\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04532",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"caddy\" does not have a read-only root file system"
  },
  {
    "id": "04533",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"read-du\" does not have a read-only root file system"
  },
  {
    "id": "04534",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"caddy\" is not set to runAsNonRoot"
  },
  {
    "id": "04535",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"read-du\" is not set to runAsNonRoot"
  },
  {
    "id": "04536",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"caddy\" has cpu request 0"
  },
  {
    "id": "04537",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"read-du\" has cpu request 0"
  },
  {
    "id": "04538",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"caddy\" has memory limit 0"
  },
  {
    "id": "04539",
    "manifest_path": "data/manifests/the_stack_sample/sample_2078.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"read-du\" has memory limit 0"
  },
  {
    "id": "04540",
    "manifest_path": "data/manifests/the_stack_sample/sample_2082.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: localingress-ds\n  namespace: localingress\n  labels:\n    component: localingress\nspec:\n  selector:\n    matchLabels:\n      component: localingress\n  template:\n    metadata:\n      labels:\n        component: localingress\n    spec:\n      volumes:\n      - name: localingress-config\n        configMap:\n          name: localingress-config\n      containers:\n      - name: ingress\n        image: docker.io/library/haproxy:2.2.4\n        volumeMounts:\n        - name: localingress-config\n          mountPath: /usr/local/etc/haproxy/\n        ports:\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 80\n          hostPort: 80\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ingress\" does not have a read-only root file system"
  },
  {
    "id": "04541",
    "manifest_path": "data/manifests/the_stack_sample/sample_2082.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: localingress-ds\n  namespace: localingress\n  labels:\n    component: localingress\nspec:\n  selector:\n    matchLabels:\n      component: localingress\n  template:\n    metadata:\n      labels:\n        component: localingress\n    spec:\n      volumes:\n      - name: localingress-config\n        configMap:\n          name: localingress-config\n      containers:\n      - name: ingress\n        image: docker.io/library/haproxy:2.2.4\n        volumeMounts:\n        - name: localingress-config\n          mountPath: /usr/local/etc/haproxy/\n        ports:\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 80\n          hostPort: 80\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ingress\" is not set to runAsNonRoot"
  },
  {
    "id": "04542",
    "manifest_path": "data/manifests/the_stack_sample/sample_2082.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: localingress-ds\n  namespace: localingress\n  labels:\n    component: localingress\nspec:\n  selector:\n    matchLabels:\n      component: localingress\n  template:\n    metadata:\n      labels:\n        component: localingress\n    spec:\n      volumes:\n      - name: localingress-config\n        configMap:\n          name: localingress-config\n      containers:\n      - name: ingress\n        image: docker.io/library/haproxy:2.2.4\n        volumeMounts:\n        - name: localingress-config\n          mountPath: /usr/local/etc/haproxy/\n        ports:\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 80\n          hostPort: 80\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ingress\" has cpu request 0"
  },
  {
    "id": "04543",
    "manifest_path": "data/manifests/the_stack_sample/sample_2082.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: localingress-ds\n  namespace: localingress\n  labels:\n    component: localingress\nspec:\n  selector:\n    matchLabels:\n      component: localingress\n  template:\n    metadata:\n      labels:\n        component: localingress\n    spec:\n      volumes:\n      - name: localingress-config\n        configMap:\n          name: localingress-config\n      containers:\n      - name: ingress\n        image: docker.io/library/haproxy:2.2.4\n        volumeMounts:\n        - name: localingress-config\n          mountPath: /usr/local/etc/haproxy/\n        ports:\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 80\n          hostPort: 80\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ingress\" has memory limit 0"
  },
  {
    "id": "04544",
    "manifest_path": "data/manifests/the_stack_sample/sample_2083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"rook-direct-mount\" does not have a read-only root file system"
  },
  {
    "id": "04545",
    "manifest_path": "data/manifests/the_stack_sample/sample_2083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "policy_id": "privilege-escalation-container",
    "violation_text": "container \"rook-direct-mount\" is Privileged hence allows privilege escalation."
  },
  {
    "id": "04546",
    "manifest_path": "data/manifests/the_stack_sample/sample_2083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "policy_id": "privileged-container",
    "violation_text": "container \"rook-direct-mount\" is privileged"
  },
  {
    "id": "04547",
    "manifest_path": "data/manifests/the_stack_sample/sample_2083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"rook-direct-mount\" is not set to runAsNonRoot"
  },
  {
    "id": "04548",
    "manifest_path": "data/manifests/the_stack_sample/sample_2083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"rook-direct-mount\" has cpu request 0"
  },
  {
    "id": "04549",
    "manifest_path": "data/manifests/the_stack_sample/sample_2083.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"rook-direct-mount\" has memory limit 0"
  },
  {
    "id": "04550",
    "manifest_path": "data/manifests/the_stack_sample/sample_2088.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cassandra-stress-normal\n  labels:\n    app: cassandra-stress\nspec:\n  volumes:\n  - name: cassandra-stress-profile-volume\n    configMap:\n      name: cassandra-stress-normal\n  securityContext:\n    fsGroup: 1\n    runAsNonRoot: true\n    runAsUser: 1006\n    supplementalGroups:\n    - 1\n  containers:\n  - name: cassie1-cassandra-stress\n    image: cassandra\n    imagePullPolicy: IfNotPresent\n    securityContext:\n      capabilities:\n        add:\n        - IPC_LOCK\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - cassandra-stress 'user profile=/opt/cassandra-stress/normal_stress.yaml ops(insert=10,query_by_sub_id=8)\n      duration=120m cl=one -node cassandra-demo -mode native cql3 user=bench password=monbench\n      -rate threads=30 -pop seq=0..100M -tokenrange -graph file=/tmp/stress-normal.html'\n      && echo END && while true ; do sleep 60; done\n    resources:\n      limits:\n        cpu: '3'\n        memory: 8Gi\n      requests:\n        cpu: '3'\n        memory: 8Gi\n    volumeMounts:\n    - name: cassandra-stress-profile-volume\n      mountPath: /opt/cassandra-stress\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"cassie1-cassandra-stress\" is using an invalid container image, \"cassandra\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04551",
    "manifest_path": "data/manifests/the_stack_sample/sample_2088.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cassandra-stress-normal\n  labels:\n    app: cassandra-stress\nspec:\n  volumes:\n  - name: cassandra-stress-profile-volume\n    configMap:\n      name: cassandra-stress-normal\n  securityContext:\n    fsGroup: 1\n    runAsNonRoot: true\n    runAsUser: 1006\n    supplementalGroups:\n    - 1\n  containers:\n  - name: cassie1-cassandra-stress\n    image: cassandra\n    imagePullPolicy: IfNotPresent\n    securityContext:\n      capabilities:\n        add:\n        - IPC_LOCK\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - cassandra-stress 'user profile=/opt/cassandra-stress/normal_stress.yaml ops(insert=10,query_by_sub_id=8)\n      duration=120m cl=one -node cassandra-demo -mode native cql3 user=bench password=monbench\n      -rate threads=30 -pop seq=0..100M -tokenrange -graph file=/tmp/stress-normal.html'\n      && echo END && while true ; do sleep 60; done\n    resources:\n      limits:\n        cpu: '3'\n        memory: 8Gi\n      requests:\n        cpu: '3'\n        memory: 8Gi\n    volumeMounts:\n    - name: cassandra-stress-profile-volume\n      mountPath: /opt/cassandra-stress\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cassie1-cassandra-stress\" does not have a read-only root file system"
  },
  {
    "id": "04552",
    "manifest_path": "data/manifests/the_stack_sample/sample_2089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:latest\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          value: cassandra\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable AGENTS_JWT_SECRET in container \"imicros-users\" found"
  },
  {
    "id": "04553",
    "manifest_path": "data/manifests/the_stack_sample/sample_2089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:latest\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          value: cassandra\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable JWT_SECRET in container \"imicros-users\" found"
  },
  {
    "id": "04554",
    "manifest_path": "data/manifests/the_stack_sample/sample_2089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:latest\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          value: cassandra\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"imicros-users\" is using an invalid container image, \"al66/imicros-backend:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04555",
    "manifest_path": "data/manifests/the_stack_sample/sample_2089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:latest\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          value: cassandra\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"imicros-users\" does not have a read-only root file system"
  },
  {
    "id": "04556",
    "manifest_path": "data/manifests/the_stack_sample/sample_2089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:latest\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          value: cassandra\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"imicros-users\" is not set to runAsNonRoot"
  },
  {
    "id": "04557",
    "manifest_path": "data/manifests/the_stack_sample/sample_2089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:latest\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          value: cassandra\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"imicros-users\" has cpu request 0"
  },
  {
    "id": "04558",
    "manifest_path": "data/manifests/the_stack_sample/sample_2089.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:latest\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          value: cassandra\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"imicros-users\" has memory limit 0"
  },
  {
    "id": "04559",
    "manifest_path": "data/manifests/the_stack_sample/sample_2090.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: test\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 1\n            memory: 500Mi\n          limits:\n            cpu: 2\n            memory: 1024Mi\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04560",
    "manifest_path": "data/manifests/the_stack_sample/sample_2090.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: test\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 1\n            memory: 500Mi\n          limits:\n            cpu: 2\n            memory: 1024Mi\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  }
]