[
  {
    "id": "01241",
    "manifest_path": "data/manifests/the_stack_sample/sample_0343.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: component-nodejs-dependence-npm\nspec:\n  containers:\n  - name: npm\n    image: hub.opshub.sh/containerops/dependence-nodejs-npm:latest\n    env:\n    - name: CO_DATA\n      value: git_url=https://github.com/WildDogTeam/demo-js-wildchat.git\n    resources:\n      requests:\n        cpu: 2\n        memory: 4G\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"npm\" does not have a read-only root file system"
  },
  {
    "id": "01242",
    "manifest_path": "data/manifests/the_stack_sample/sample_0343.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: component-nodejs-dependence-npm\nspec:\n  containers:\n  - name: npm\n    image: hub.opshub.sh/containerops/dependence-nodejs-npm:latest\n    env:\n    - name: CO_DATA\n      value: git_url=https://github.com/WildDogTeam/demo-js-wildchat.git\n    resources:\n      requests:\n        cpu: 2\n        memory: 4G\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"npm\" is not set to runAsNonRoot"
  },
  {
    "id": "01243",
    "manifest_path": "data/manifests/the_stack_sample/sample_0343.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: component-nodejs-dependence-npm\nspec:\n  containers:\n  - name: npm\n    image: hub.opshub.sh/containerops/dependence-nodejs-npm:latest\n    env:\n    - name: CO_DATA\n      value: git_url=https://github.com/WildDogTeam/demo-js-wildchat.git\n    resources:\n      requests:\n        cpu: 2\n        memory: 4G\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"npm\" has memory limit 0"
  },
  {
    "id": "01244",
    "manifest_path": "data/manifests/the_stack_sample/sample_0345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n  initContainers:\n  - image: k8s.gcr.io/pause\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"container1\" is using an invalid container image, \"k8s.gcr.io/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01245",
    "manifest_path": "data/manifests/the_stack_sample/sample_0345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n  initContainers:\n  - image: k8s.gcr.io/pause\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"initcontainer1\" is using an invalid container image, \"k8s.gcr.io/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01246",
    "manifest_path": "data/manifests/the_stack_sample/sample_0345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n  initContainers:\n  - image: k8s.gcr.io/pause\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"container1\" does not have a read-only root file system"
  },
  {
    "id": "01247",
    "manifest_path": "data/manifests/the_stack_sample/sample_0345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n  initContainers:\n  - image: k8s.gcr.io/pause\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"initcontainer1\" does not have a read-only root file system"
  },
  {
    "id": "01248",
    "manifest_path": "data/manifests/the_stack_sample/sample_0345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n  initContainers:\n  - image: k8s.gcr.io/pause\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"container1\" has cpu request 0"
  },
  {
    "id": "01249",
    "manifest_path": "data/manifests/the_stack_sample/sample_0345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n  initContainers:\n  - image: k8s.gcr.io/pause\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"initcontainer1\" has cpu request 0"
  },
  {
    "id": "01250",
    "manifest_path": "data/manifests/the_stack_sample/sample_0345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n  initContainers:\n  - image: k8s.gcr.io/pause\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"container1\" has memory limit 0"
  },
  {
    "id": "01251",
    "manifest_path": "data/manifests/the_stack_sample/sample_0345.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n  initContainers:\n  - image: k8s.gcr.io/pause\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"initcontainer1\" has memory limit 0"
  },
  {
    "id": "01252",
    "manifest_path": "data/manifests/the_stack_sample/sample_0350.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy-kotsadm\n  labels:\n    app: kurl-proxy-kotsadm\n    kots.io/kotsadm: \\\"true\\\"\n    kots.io/backup: velero\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy-kotsadm\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy-kotsadm\n        kots.io/kotsadm: \\\"true\\\"\n        kots.io/backup: velero\n    spec:\n      containers:\n      - name: proxy\n        image: kotsadm/kurl-proxy:v1.38.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NODE_PORT\n          value: \\\"8800\\\"\n        - name: UPSTREAM_ORIGIN\n          value: http://kotsadm:3000\n        - name: DEX_UPSTREAM_ORIGIN\n          value: http://kotsadm-dex:5556\n        - name: TLS_SECRET_NAME\n          value: kotsadm-tls\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 50m\n            memory: 50Mi\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "policy_id": "env-var-secret",
    "violation_text": "environment variable TLS_SECRET_NAME in container \"proxy\" found"
  },
  {
    "id": "01253",
    "manifest_path": "data/manifests/the_stack_sample/sample_0350.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy-kotsadm\n  labels:\n    app: kurl-proxy-kotsadm\n    kots.io/kotsadm: \\\"true\\\"\n    kots.io/backup: velero\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy-kotsadm\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy-kotsadm\n        kots.io/kotsadm: \\\"true\\\"\n        kots.io/backup: velero\n    spec:\n      containers:\n      - name: proxy\n        image: kotsadm/kurl-proxy:v1.38.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NODE_PORT\n          value: \\\"8800\\\"\n        - name: UPSTREAM_ORIGIN\n          value: http://kotsadm:3000\n        - name: DEX_UPSTREAM_ORIGIN\n          value: http://kotsadm-dex:5556\n        - name: TLS_SECRET_NAME\n          value: kotsadm-tls\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 50m\n            memory: 50Mi\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"proxy\" does not have a read-only root file system"
  },
  {
    "id": "01254",
    "manifest_path": "data/manifests/the_stack_sample/sample_0350.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy-kotsadm\n  labels:\n    app: kurl-proxy-kotsadm\n    kots.io/kotsadm: \\\"true\\\"\n    kots.io/backup: velero\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy-kotsadm\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy-kotsadm\n        kots.io/kotsadm: \\\"true\\\"\n        kots.io/backup: velero\n    spec:\n      containers:\n      - name: proxy\n        image: kotsadm/kurl-proxy:v1.38.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: NODE_PORT\n          value: \\\"8800\\\"\n        - name: UPSTREAM_ORIGIN\n          value: http://kotsadm:3000\n        - name: DEX_UPSTREAM_ORIGIN\n          value: http://kotsadm-dex:5556\n        - name: TLS_SECRET_NAME\n          value: kotsadm-tls\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 50m\n            memory: 50Mi\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"proxy\" is not set to runAsNonRoot"
  },
  {
    "id": "01255",
    "manifest_path": "data/manifests/the_stack_sample/sample_0352.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fb-user-datastore-api-{{ .Values.environmentName }}\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: fb-user-datastore-api-{{ .Values.environmentName }}\n  template:\n    metadata:\n      labels:\n        app: fb-user-datastore-api-{{ .Values.environmentName }}\n        appGroup: fb-user-datastore\n        fb-service-token-cache-access: 'true'\n        tier: frontend\n    spec:\n      serviceAccountName: formbuilder-user-datastore-{{ .Values.environmentName }}\n      containers:\n      - name: fb-user-datastore-api-{{ .Values.environmentName }}\n        image: 754256621582.dkr.ecr.eu-west-2.amazonaws.com/formbuilder/fb-user-datastore-api:{{\n          .Values.circleSha1 }}\n        securityContext:\n          runAsUser: 1001\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 3000\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n        envFrom:\n        - configMapRef:\n            name: fb-user-datastore-api-env-{{ .Values.environmentName }}\n        env:\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: rds-instance-formbuilder-user-datastore-{{ .Values.environmentName\n                }}\n              key: url\n        - name: SECRET_KEY_BASE\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: secret_key_base\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: fb-platform-datastore-token-{{ .Values.environmentName }}\n              key: token\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: sentry_dsn\n        - name: METRICS_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: metrics_access_key\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"fb-user-datastore-api-{{ .Values.environmentName }}\" does not have a read-only root file system"
  },
  {
    "id": "01256",
    "manifest_path": "data/manifests/the_stack_sample/sample_0352.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fb-user-datastore-api-{{ .Values.environmentName }}\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: fb-user-datastore-api-{{ .Values.environmentName }}\n  template:\n    metadata:\n      labels:\n        app: fb-user-datastore-api-{{ .Values.environmentName }}\n        appGroup: fb-user-datastore\n        fb-service-token-cache-access: 'true'\n        tier: frontend\n    spec:\n      serviceAccountName: formbuilder-user-datastore-{{ .Values.environmentName }}\n      containers:\n      - name: fb-user-datastore-api-{{ .Values.environmentName }}\n        image: 754256621582.dkr.ecr.eu-west-2.amazonaws.com/formbuilder/fb-user-datastore-api:{{\n          .Values.circleSha1 }}\n        securityContext:\n          runAsUser: 1001\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 3000\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n        envFrom:\n        - configMapRef:\n            name: fb-user-datastore-api-env-{{ .Values.environmentName }}\n        env:\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: rds-instance-formbuilder-user-datastore-{{ .Values.environmentName\n                }}\n              key: url\n        - name: SECRET_KEY_BASE\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: secret_key_base\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: fb-platform-datastore-token-{{ .Values.environmentName }}\n              key: token\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: sentry_dsn\n        - name: METRICS_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: metrics_access_key\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"fb-user-datastore-api-{{ .Values.environmentName }}\" has cpu request 0"
  },
  {
    "id": "01257",
    "manifest_path": "data/manifests/the_stack_sample/sample_0352.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fb-user-datastore-api-{{ .Values.environmentName }}\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: fb-user-datastore-api-{{ .Values.environmentName }}\n  template:\n    metadata:\n      labels:\n        app: fb-user-datastore-api-{{ .Values.environmentName }}\n        appGroup: fb-user-datastore\n        fb-service-token-cache-access: 'true'\n        tier: frontend\n    spec:\n      serviceAccountName: formbuilder-user-datastore-{{ .Values.environmentName }}\n      containers:\n      - name: fb-user-datastore-api-{{ .Values.environmentName }}\n        image: 754256621582.dkr.ecr.eu-west-2.amazonaws.com/formbuilder/fb-user-datastore-api:{{\n          .Values.circleSha1 }}\n        securityContext:\n          runAsUser: 1001\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 3000\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n        envFrom:\n        - configMapRef:\n            name: fb-user-datastore-api-env-{{ .Values.environmentName }}\n        env:\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: rds-instance-formbuilder-user-datastore-{{ .Values.environmentName\n                }}\n              key: url\n        - name: SECRET_KEY_BASE\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: secret_key_base\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: fb-platform-datastore-token-{{ .Values.environmentName }}\n              key: token\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: sentry_dsn\n        - name: METRICS_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: fb-user-datastore-api-secrets-{{ .Values.environmentName }}\n              key: metrics_access_key\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"fb-user-datastore-api-{{ .Values.environmentName }}\" has memory limit 0"
  },
  {
    "id": "01258",
    "manifest_path": "data/manifests/the_stack_sample/sample_0353.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"echo\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "01259",
    "manifest_path": "data/manifests/the_stack_sample/sample_0353.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"echo\" does not have a read-only root file system"
  },
  {
    "id": "01260",
    "manifest_path": "data/manifests/the_stack_sample/sample_0353.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"echo\" is not set to runAsNonRoot"
  },
  {
    "id": "01261",
    "manifest_path": "data/manifests/the_stack_sample/sample_0353.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"echo\" has cpu request 0"
  },
  {
    "id": "01262",
    "manifest_path": "data/manifests/the_stack_sample/sample_0353.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"echo\" has memory limit 0"
  },
  {
    "id": "01263",
    "manifest_path": "data/manifests/the_stack_sample/sample_0354.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: e2e\nspec:\n  template:\n    metadata:\n      labels:\n        test: device-localpv-upgrade\n    spec:\n      serviceAccountName: e2e\n      containers:\n      - name: ansibletest\n        image: openebs/device-localpv-e2e:ci\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: TO_VERSION_DEVICE_BRANCH\n          value: ''\n        - name: TO_VERSION_DEVICE_DRIVER_IMAGE\n          value: ''\n        - name: DEVICE_OPERATOR_NAMESPACE\n          value: openebs\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./e2e-tests/experiments/upgrade-device-localpv/test.yml\n          -i /etc/ansible/hosts -v; exit 0\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"ansibletest\" does not have a read-only root file system"
  },
  {
    "id": "01264",
    "manifest_path": "data/manifests/the_stack_sample/sample_0354.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: e2e\nspec:\n  template:\n    metadata:\n      labels:\n        test: device-localpv-upgrade\n    spec:\n      serviceAccountName: e2e\n      containers:\n      - name: ansibletest\n        image: openebs/device-localpv-e2e:ci\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: TO_VERSION_DEVICE_BRANCH\n          value: ''\n        - name: TO_VERSION_DEVICE_DRIVER_IMAGE\n          value: ''\n        - name: DEVICE_OPERATOR_NAMESPACE\n          value: openebs\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./e2e-tests/experiments/upgrade-device-localpv/test.yml\n          -i /etc/ansible/hosts -v; exit 0\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"ansibletest\" is not set to runAsNonRoot"
  },
  {
    "id": "01265",
    "manifest_path": "data/manifests/the_stack_sample/sample_0354.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: e2e\nspec:\n  template:\n    metadata:\n      labels:\n        test: device-localpv-upgrade\n    spec:\n      serviceAccountName: e2e\n      containers:\n      - name: ansibletest\n        image: openebs/device-localpv-e2e:ci\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: TO_VERSION_DEVICE_BRANCH\n          value: ''\n        - name: TO_VERSION_DEVICE_DRIVER_IMAGE\n          value: ''\n        - name: DEVICE_OPERATOR_NAMESPACE\n          value: openebs\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./e2e-tests/experiments/upgrade-device-localpv/test.yml\n          -i /etc/ansible/hosts -v; exit 0\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"ansibletest\" has cpu request 0"
  },
  {
    "id": "01266",
    "manifest_path": "data/manifests/the_stack_sample/sample_0354.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: e2e\nspec:\n  template:\n    metadata:\n      labels:\n        test: device-localpv-upgrade\n    spec:\n      serviceAccountName: e2e\n      containers:\n      - name: ansibletest\n        image: openebs/device-localpv-e2e:ci\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ANSIBLE_STDOUT_CALLBACK\n          value: default\n        - name: TO_VERSION_DEVICE_BRANCH\n          value: ''\n        - name: TO_VERSION_DEVICE_DRIVER_IMAGE\n          value: ''\n        - name: DEVICE_OPERATOR_NAMESPACE\n          value: openebs\n        command:\n        - /bin/bash\n        args:\n        - -c\n        - ansible-playbook ./e2e-tests/experiments/upgrade-device-localpv/test.yml\n          -i /etc/ansible/hosts -v; exit 0\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"ansibletest\" has memory limit 0"
  },
  {
    "id": "01267",
    "manifest_path": "data/manifests/the_stack_sample/sample_0358.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"olm-operator\" does not have a read-only root file system"
  },
  {
    "id": "01268",
    "manifest_path": "data/manifests/the_stack_sample/sample_0358.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"olm-operator\" is not set to runAsNonRoot"
  },
  {
    "id": "01269",
    "manifest_path": "data/manifests/the_stack_sample/sample_0358.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"olm-operator\" has memory limit 0"
  },
  {
    "id": "01270",
    "manifest_path": "data/manifests/the_stack_sample/sample_0359.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"liveness-probe\" does not have a read-only root file system"
  },
  {
    "id": "01271",
    "manifest_path": "data/manifests/the_stack_sample/sample_0359.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"node-driver-registrar\" does not have a read-only root file system"
  },
  {
    "id": "01272",
    "manifest_path": "data/manifests/the_stack_sample/sample_0359.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"secrets-store\" does not have a read-only root file system"
  },
  {
    "id": "01273",
    "manifest_path": "data/manifests/the_stack_sample/sample_0359.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"liveness-probe\" is not set to runAsNonRoot"
  },
  {
    "id": "01274",
    "manifest_path": "data/manifests/the_stack_sample/sample_0359.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"node-driver-registrar\" is not set to runAsNonRoot"
  },
  {
    "id": "01275",
    "manifest_path": "data/manifests/the_stack_sample/sample_0359.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"secrets-store\" is not set to runAsNonRoot"
  },
  {
    "id": "01276",
    "manifest_path": "data/manifests/the_stack_sample/sample_0369.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: REPLACE_DOCKER_REPO_NAME/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: REPLACE_DOCKERIMAGEPULLPOLICY\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: REPLACE_INFLUXDBIP\n        - name: INFLUX_PORT\n          value: REPLACE_INFLUXDBPORT\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"openmcp-analytic-engine\" does not have a read-only root file system"
  },
  {
    "id": "01277",
    "manifest_path": "data/manifests/the_stack_sample/sample_0369.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: REPLACE_DOCKER_REPO_NAME/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: REPLACE_DOCKERIMAGEPULLPOLICY\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: REPLACE_INFLUXDBIP\n        - name: INFLUX_PORT\n          value: REPLACE_INFLUXDBPORT\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"openmcp-analytic-engine\" is not set to runAsNonRoot"
  },
  {
    "id": "01278",
    "manifest_path": "data/manifests/the_stack_sample/sample_0369.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: REPLACE_DOCKER_REPO_NAME/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: REPLACE_DOCKERIMAGEPULLPOLICY\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: REPLACE_INFLUXDBIP\n        - name: INFLUX_PORT\n          value: REPLACE_INFLUXDBPORT\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"openmcp-analytic-engine\" has cpu request 0"
  },
  {
    "id": "01279",
    "manifest_path": "data/manifests/the_stack_sample/sample_0369.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openmcp-analytic-engine\n  namespace: openmcp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: openmcp-analytic-engine\n  template:\n    metadata:\n      labels:\n        name: openmcp-analytic-engine\n    spec:\n      serviceAccountName: openmcp-analytic-engine\n      containers:\n      - name: openmcp-analytic-engine\n        image: REPLACE_DOCKER_REPO_NAME/openmcp-analytic-engine:v0.0.1\n        command:\n        - openmcp-analytic-engine\n        imagePullPolicy: REPLACE_DOCKERIMAGEPULLPOLICY\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: INFLUX_IP\n          value: REPLACE_INFLUXDBIP\n        - name: INFLUX_PORT\n          value: REPLACE_INFLUXDBPORT\n        - name: INFLUX_USERNAME\n          value: root\n        - name: INFLUX_PASSWORD\n          value: root\n        - name: OPERATOR_NAME\n          value: openmcp-analytic-engine\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"openmcp-analytic-engine\" has memory limit 0"
  },
  {
    "id": "01280",
    "manifest_path": "data/manifests/the_stack_sample/sample_0372.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    control-plane: controller-manager\n  name: special-resource-controller-manager\n  namespace: openshift-special-resource-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        - --tls-cert-file=/etc/secrets/tls.crt\n        - --tls-private-key-file=/etc/secrets/tls.key\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        image: registry.redhat.io/openshift4/ose-kube-rbac-proxy\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        resources:\n          limits:\n            cpu: 500m\n            memory: 128Mi\n          requests:\n            cpu: 250m\n            memory: 64Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/secrets\n          name: special-resource-operator-tls\n      - args:\n        - --metrics-addr=127.0.0.1:8080\n        - --enable-leader-election\n        command:\n        - /manager\n        env:\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: SSL_CERT_DIR\n          value: /etc/pki/tls/certs\n        image: quay.io/openshift-psap/special-resource-operator:chart-as-asset\n        imagePullPolicy: Always\n        name: manager\n        resources:\n          limits:\n            cpu: 300m\n            memory: 500Mi\n          requests:\n            cpu: 300m\n            memory: 500Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /cache\n          name: cache-volume\n      securityContext:\n        runAsGroup: 499\n        runAsNonRoot: true\n        runAsUser: 499\n      volumes:\n      - name: special-resource-operator-tls\n        secret:\n          secretName: special-resource-operator-tls\n      - emptyDir: {}\n        name: cache-volume\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"kube-rbac-proxy\" is using an invalid container image, \"registry.redhat.io/openshift4/ose-kube-rbac-proxy\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  }
]