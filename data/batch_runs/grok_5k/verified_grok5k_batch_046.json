[
  {
    "id": "01841",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01842",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01843",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01844",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01845",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01846",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01847",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01848",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01849",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01850",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01851",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01852",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01853",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01854",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01855",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01856",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01857",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01858",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: cockroachdb\n  name: cockroachdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      containers:\n      - command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        name: cockroachdb\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      initContainers:\n      - args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        name: bootstrap\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n",
    "errors": []
  },
  {
    "id": "01859",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: cockroachdb\n  name: cockroachdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      containers:\n      - command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        name: cockroachdb\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      initContainers:\n      - args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        name: bootstrap\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n",
    "errors": []
  },
  {
    "id": "01860",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: cockroachdb\n  name: cockroachdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      containers:\n      - command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        name: cockroachdb\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      initContainers:\n      - args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        name: bootstrap\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n",
    "errors": []
  },
  {
    "id": "01861",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: cockroachdb\n  name: cockroachdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      containers:\n      - command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        name: cockroachdb\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      initContainers:\n      - args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        name: bootstrap\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n",
    "errors": []
  },
  {
    "id": "01862",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: cockroachdb\n  name: cockroachdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      containers:\n      - command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        name: cockroachdb\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      initContainers:\n      - args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        name: bootstrap\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n",
    "errors": []
  },
  {
    "id": "01863",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: cockroachdb\n  name: cockroachdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      containers:\n      - command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        name: cockroachdb\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      initContainers:\n      - args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        name: bootstrap\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n",
    "errors": []
  },
  {
    "id": "01864",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: cockroachdb\n  name: cockroachdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      containers:\n      - command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        name: cockroachdb\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      initContainers:\n      - args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        name: bootstrap\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n",
    "errors": []
  },
  {
    "id": "01865",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app: cockroachdb\n  name: cockroachdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      containers:\n      - command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        name: cockroachdb\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      initContainers:\n      - args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        name: bootstrap\n        volumeMounts:\n        - mountPath: /cockroach/cockroach-data\n          name: datadir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n",
    "errors": []
  },
  {
    "id": "01866",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable JX_SECRET_TMP_DIR must use secretKeyRef",
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01867",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable JX_SECRET_TMP_DIR must use secretKeyRef",
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01868",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01869",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01870",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01871",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01872",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01873",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01874",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01875",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01876",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01877",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01878",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01879",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed"
    ]
  },
  {
    "id": "01880",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210615-cf184f2204\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  }
]