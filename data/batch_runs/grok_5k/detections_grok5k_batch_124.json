[
  {
    "id": "04961",
    "manifest_path": "data/manifests/the_stack_sample/sample_2253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_PASSWORD\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"airbyte-seed\" does not have a read-only root file system"
  },
  {
    "id": "04962",
    "manifest_path": "data/manifests/the_stack_sample/sample_2253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_PASSWORD\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"airbyte-scheduler-container\" is not set to runAsNonRoot"
  },
  {
    "id": "04963",
    "manifest_path": "data/manifests/the_stack_sample/sample_2253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_PASSWORD\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"airbyte-seed\" is not set to runAsNonRoot"
  },
  {
    "id": "04964",
    "manifest_path": "data/manifests/the_stack_sample/sample_2253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_PASSWORD\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"airbyte-scheduler-container\" has cpu request 0"
  },
  {
    "id": "04965",
    "manifest_path": "data/manifests/the_stack_sample/sample_2253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_PASSWORD\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"airbyte-seed\" has cpu request 0"
  },
  {
    "id": "04966",
    "manifest_path": "data/manifests/the_stack_sample/sample_2253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_PASSWORD\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"airbyte-scheduler-container\" has memory limit 0"
  },
  {
    "id": "04967",
    "manifest_path": "data/manifests/the_stack_sample/sample_2253.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_PASSWORD\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"airbyte-seed\" has memory limit 0"
  },
  {
    "id": "04968",
    "manifest_path": "data/manifests/the_stack_sample/sample_2258.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: slack-post-message\n  labels:\n    app: slack-post-message\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: slack-post-message\n  template:\n    metadata:\n      labels:\n        app: slack-post-message\n    spec:\n      containers:\n      - name: slack-post-message\n        image: gcr.io/k8s-staging-slack-infra/slack-post-message:v20200901-117c06f\n        args:\n        - --config-path=/etc/slack-post-message/config.json\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: PATH_PREFIX\n          value: /infra/post-message\n        volumeMounts:\n        - mountPath: /etc/slack-post-message\n          name: config\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            scheme: HTTP\n            port: 8080\n      volumes:\n      - name: config\n        secret:\n          secretName: slack-post-message-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"slack-post-message\" does not have a read-only root file system"
  },
  {
    "id": "04969",
    "manifest_path": "data/manifests/the_stack_sample/sample_2258.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: slack-post-message\n  labels:\n    app: slack-post-message\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: slack-post-message\n  template:\n    metadata:\n      labels:\n        app: slack-post-message\n    spec:\n      containers:\n      - name: slack-post-message\n        image: gcr.io/k8s-staging-slack-infra/slack-post-message:v20200901-117c06f\n        args:\n        - --config-path=/etc/slack-post-message/config.json\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: PATH_PREFIX\n          value: /infra/post-message\n        volumeMounts:\n        - mountPath: /etc/slack-post-message\n          name: config\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            scheme: HTTP\n            port: 8080\n      volumes:\n      - name: config\n        secret:\n          secretName: slack-post-message-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"slack-post-message\" is not set to runAsNonRoot"
  },
  {
    "id": "04970",
    "manifest_path": "data/manifests/the_stack_sample/sample_2258.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: slack-post-message\n  labels:\n    app: slack-post-message\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: slack-post-message\n  template:\n    metadata:\n      labels:\n        app: slack-post-message\n    spec:\n      containers:\n      - name: slack-post-message\n        image: gcr.io/k8s-staging-slack-infra/slack-post-message:v20200901-117c06f\n        args:\n        - --config-path=/etc/slack-post-message/config.json\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: PATH_PREFIX\n          value: /infra/post-message\n        volumeMounts:\n        - mountPath: /etc/slack-post-message\n          name: config\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            scheme: HTTP\n            port: 8080\n      volumes:\n      - name: config\n        secret:\n          secretName: slack-post-message-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"slack-post-message\" has cpu request 0"
  },
  {
    "id": "04971",
    "manifest_path": "data/manifests/the_stack_sample/sample_2258.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: slack-post-message\n  labels:\n    app: slack-post-message\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: slack-post-message\n  template:\n    metadata:\n      labels:\n        app: slack-post-message\n    spec:\n      containers:\n      - name: slack-post-message\n        image: gcr.io/k8s-staging-slack-infra/slack-post-message:v20200901-117c06f\n        args:\n        - --config-path=/etc/slack-post-message/config.json\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: PATH_PREFIX\n          value: /infra/post-message\n        volumeMounts:\n        - mountPath: /etc/slack-post-message\n          name: config\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            scheme: HTTP\n            port: 8080\n      volumes:\n      - name: config\n        secret:\n          secretName: slack-post-message-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"slack-post-message\" has memory limit 0"
  },
  {
    "id": "04972",
    "manifest_path": "data/manifests/the_stack_sample/sample_2259.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: scc-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scc-broker\n  template:\n    metadata:\n      labels:\n        component: scc-broker\n    spec:\n      containers:\n      - name: scc-broker\n        image: socketcluster/scc-broker:v6.0.1\n        ports:\n        - containerPort: 8888\n        env:\n        - name: SCC_STATE_SERVER_HOST\n          value: scc-state\n        - name: SOCKETCLUSTER_WORKERS\n          value: '1'\n        - name: SOCKETCLUSTER_BROKERS\n          value: '1'\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: SCC_BROKER_SERVER_LOG_LEVEL\n          value: '2'\n        livenessProbe:\n          httpGet:\n            path: /health-check\n            port: 8888\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"scc-broker\" does not have a read-only root file system"
  },
  {
    "id": "04973",
    "manifest_path": "data/manifests/the_stack_sample/sample_2259.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: scc-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scc-broker\n  template:\n    metadata:\n      labels:\n        component: scc-broker\n    spec:\n      containers:\n      - name: scc-broker\n        image: socketcluster/scc-broker:v6.0.1\n        ports:\n        - containerPort: 8888\n        env:\n        - name: SCC_STATE_SERVER_HOST\n          value: scc-state\n        - name: SOCKETCLUSTER_WORKERS\n          value: '1'\n        - name: SOCKETCLUSTER_BROKERS\n          value: '1'\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: SCC_BROKER_SERVER_LOG_LEVEL\n          value: '2'\n        livenessProbe:\n          httpGet:\n            path: /health-check\n            port: 8888\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"scc-broker\" is not set to runAsNonRoot"
  },
  {
    "id": "04974",
    "manifest_path": "data/manifests/the_stack_sample/sample_2259.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: scc-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scc-broker\n  template:\n    metadata:\n      labels:\n        component: scc-broker\n    spec:\n      containers:\n      - name: scc-broker\n        image: socketcluster/scc-broker:v6.0.1\n        ports:\n        - containerPort: 8888\n        env:\n        - name: SCC_STATE_SERVER_HOST\n          value: scc-state\n        - name: SOCKETCLUSTER_WORKERS\n          value: '1'\n        - name: SOCKETCLUSTER_BROKERS\n          value: '1'\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: SCC_BROKER_SERVER_LOG_LEVEL\n          value: '2'\n        livenessProbe:\n          httpGet:\n            path: /health-check\n            port: 8888\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"scc-broker\" has cpu request 0"
  },
  {
    "id": "04975",
    "manifest_path": "data/manifests/the_stack_sample/sample_2259.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: scc-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scc-broker\n  template:\n    metadata:\n      labels:\n        component: scc-broker\n    spec:\n      containers:\n      - name: scc-broker\n        image: socketcluster/scc-broker:v6.0.1\n        ports:\n        - containerPort: 8888\n        env:\n        - name: SCC_STATE_SERVER_HOST\n          value: scc-state\n        - name: SOCKETCLUSTER_WORKERS\n          value: '1'\n        - name: SOCKETCLUSTER_BROKERS\n          value: '1'\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: SCC_BROKER_SERVER_LOG_LEVEL\n          value: '2'\n        livenessProbe:\n          httpGet:\n            path: /health-check\n            port: 8888\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"scc-broker\" has memory limit 0"
  },
  {
    "id": "04976",
    "manifest_path": "data/manifests/the_stack_sample/sample_2261.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210602-c9da972437\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-prow/tide-history.json\n        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"tide\" does not have a read-only root file system"
  },
  {
    "id": "04977",
    "manifest_path": "data/manifests/the_stack_sample/sample_2261.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210602-c9da972437\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-prow/tide-history.json\n        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"tide\" is not set to runAsNonRoot"
  },
  {
    "id": "04978",
    "manifest_path": "data/manifests/the_stack_sample/sample_2261.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210602-c9da972437\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-prow/tide-history.json\n        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"tide\" has cpu request 0"
  },
  {
    "id": "04979",
    "manifest_path": "data/manifests/the_stack_sample/sample_2261.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210602-c9da972437\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-prow/tide-history.json\n        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"tide\" has memory limit 0"
  },
  {
    "id": "04980",
    "manifest_path": "data/manifests/the_stack_sample/sample_2267.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"od\" is using an invalid container image, \"gcr.io/instructor-partition/od-fasterrcnn\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04981",
    "manifest_path": "data/manifests/the_stack_sample/sample_2267.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"od\" does not have a read-only root file system"
  },
  {
    "id": "04982",
    "manifest_path": "data/manifests/the_stack_sample/sample_2267.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"od\" is not set to runAsNonRoot"
  },
  {
    "id": "04983",
    "manifest_path": "data/manifests/the_stack_sample/sample_2267.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"od\" has cpu request 0"
  },
  {
    "id": "04984",
    "manifest_path": "data/manifests/the_stack_sample/sample_2267.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"od\" has memory limit 0"
  },
  {
    "id": "04985",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"service\" is using an invalid container image, \"ghcr.io/drogue-iot/user-auth-service:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04986",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"wait-for-client-secret\" is using an invalid container image, \"registry.access.redhat.com/ubi8-minimal\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04987",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"service\" does not have a read-only root file system"
  },
  {
    "id": "04988",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"wait-for-client-secret\" does not have a read-only root file system"
  },
  {
    "id": "04989",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"service\" is not set to runAsNonRoot"
  },
  {
    "id": "04990",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"wait-for-client-secret\" is not set to runAsNonRoot"
  },
  {
    "id": "04991",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"service\" has cpu request 0"
  },
  {
    "id": "04992",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"wait-for-client-secret\" has cpu request 0"
  },
  {
    "id": "04993",
    "manifest_path": "data/manifests/the_stack_sample/sample_2270.yaml",
    "manifest_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:latest\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"wait-for-client-secret\" has memory limit 0"
  },
  {
    "id": "04994",
    "manifest_path": "data/manifests/the_stack_sample/sample_2274.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "latest-tag",
    "violation_text": "The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"]"
  },
  {
    "id": "04995",
    "manifest_path": "data/manifests/the_stack_sample/sample_2274.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"nginx\" does not have a read-only root file system"
  },
  {
    "id": "04996",
    "manifest_path": "data/manifests/the_stack_sample/sample_2274.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"nginx\" is not set to runAsNonRoot"
  },
  {
    "id": "04997",
    "manifest_path": "data/manifests/the_stack_sample/sample_2274.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-cpu-requirements",
    "violation_text": "container \"nginx\" has cpu request 0"
  },
  {
    "id": "04998",
    "manifest_path": "data/manifests/the_stack_sample/sample_2274.yaml",
    "manifest_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n",
    "policy_id": "unset-memory-requirements",
    "violation_text": "container \"nginx\" has memory limit 0"
  },
  {
    "id": "04999",
    "manifest_path": "data/manifests/the_stack_sample/sample_2275.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-keycloak-integration\n  namespace: sso-integration\nspec:\n  template:\n    spec:\n      containers:\n      - name: cluster-keycloak-integration\n        image: quay.io/leoliu2011/cluster-keycloak-integration:v1\n        imagePullPolicy: Always\n        envFrom:\n        - configMapRef:\n            name: argocd-configs\n        - secretRef:\n            name: sso-configs\n",
    "policy_id": "no-read-only-root-fs",
    "violation_text": "container \"cluster-keycloak-integration\" does not have a read-only root file system"
  },
  {
    "id": "05000",
    "manifest_path": "data/manifests/the_stack_sample/sample_2275.yaml",
    "manifest_yaml": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: cluster-keycloak-integration\n  namespace: sso-integration\nspec:\n  template:\n    spec:\n      containers:\n      - name: cluster-keycloak-integration\n        image: quay.io/leoliu2011/cluster-keycloak-integration:v1\n        imagePullPolicy: Always\n        envFrom:\n        - configMapRef:\n            name: argocd-configs\n        - secretRef:\n            name: sso-configs\n",
    "policy_id": "run-as-non-root",
    "violation_text": "container \"cluster-keycloak-integration\" is not set to runAsNonRoot"
  }
]