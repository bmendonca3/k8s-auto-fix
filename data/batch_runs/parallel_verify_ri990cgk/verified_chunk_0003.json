[
  {
    "id": "02503",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: goapp-deployment\nspec:\n  selector:\n    matchLabels:\n      app: goapp\n  template:\n    metadata:\n      labels:\n        app: goapp\n    spec:\n      containers:\n      - name: goapp\n        image: docker.pkg.github.com/ynishi18/cicd-handson-2021-code/go-image:base\n        ports:\n        - containerPort: 9090\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02504",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"module2-ex1\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02505",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"module2-ex1\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02506",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"module2-ex1\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02507",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"module2-ex1\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02508",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20220203-ad9c38e2b5\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-infra-prow-results/tide-history.json\n        - --status-path=gs://k8s-infra-prow-results/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: gcs-credentials\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-prow-sa-key\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "02509",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20220203-ad9c38e2b5\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-infra-prow-results/tide-history.json\n        - --status-path=gs://k8s-infra-prow-results/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: gcs-credentials\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-prow-sa-key\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "02510",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20220203-ad9c38e2b5\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-infra-prow-results/tide-history.json\n        - --status-path=gs://k8s-infra-prow-results/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: gcs-credentials\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-prow-sa-key\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "02511",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20220203-ad9c38e2b5\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy.prow.svc.cluster.local\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/token\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-infra-prow-results/tide-history.json\n        - --status-path=gs://k8s-infra-prow-results/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: github-token\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-ci-robot-github-token\n      - name: gcs-credentials\n        secret:\n          defaultMode: 420\n          secretName: k8s-infra-prow-sa-key\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "02512",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: howtos-api\n  namespace: howtos-prod\n  labels:\n    app: howtos-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: howtos-api\n  template:\n    metadata:\n      labels:\n        app: howtos-api\n    spec:\n      containers:\n      - image: registry.digitalocean.com/tiveritz/howtos-api:{{version}}\n        name: howtos-api\n        env:\n        - name: VERSION\n          value: '{{version}}'\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: secret-key\n        - name: DEBUG\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: debug\n        - name: ALLOWED_HOSTS\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: allowed-hosts\n        - name: SECURE_SSL_REDIRECT\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: secure-ssl-redirect\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-name\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-user\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-pass\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-host\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-port\n        - name: AWS_S3_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: aws-s3-access-key-id\n        - name: AWS_S3_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: aws-s3-secret-access-key\n        ports:\n        - containerPort: 8080\n          name: gunicorn\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02513",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: howtos-api\n  namespace: howtos-prod\n  labels:\n    app: howtos-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: howtos-api\n  template:\n    metadata:\n      labels:\n        app: howtos-api\n    spec:\n      containers:\n      - image: registry.digitalocean.com/tiveritz/howtos-api:{{version}}\n        name: howtos-api\n        env:\n        - name: VERSION\n          value: '{{version}}'\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: secret-key\n        - name: DEBUG\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: debug\n        - name: ALLOWED_HOSTS\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: allowed-hosts\n        - name: SECURE_SSL_REDIRECT\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: secure-ssl-redirect\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-name\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-user\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-pass\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-host\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-port\n        - name: AWS_S3_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: aws-s3-access-key-id\n        - name: AWS_S3_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: aws-s3-secret-access-key\n        ports:\n        - containerPort: 8080\n          name: gunicorn\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02514",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: howtos-api\n  namespace: howtos-prod\n  labels:\n    app: howtos-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: howtos-api\n  template:\n    metadata:\n      labels:\n        app: howtos-api\n    spec:\n      containers:\n      - image: registry.digitalocean.com/tiveritz/howtos-api:{{version}}\n        name: howtos-api\n        env:\n        - name: VERSION\n          value: '{{version}}'\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: secret-key\n        - name: DEBUG\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: debug\n        - name: ALLOWED_HOSTS\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: allowed-hosts\n        - name: SECURE_SSL_REDIRECT\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: secure-ssl-redirect\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-name\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-user\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-pass\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-host\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: db-port\n        - name: AWS_S3_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: aws-s3-access-key-id\n        - name: AWS_S3_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: howtos-api-env\n              key: aws-s3-secret-access-key\n        ports:\n        - containerPort: 8080\n          name: gunicorn\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02515",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when creating \"STDIN\": stream error when reading response body, may be caused by closed connection. Please retry. Original error: stream error: stream ID 7; INTERNAL_ERROR; received from peer"
    ]
  },
  {
    "id": "02516",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    kompose.cmd: kompose convert -f docker-compose.prod.yaml\n    kompose.version: 1.21.0 ()\n  labels:\n    io.kompose.service: reporter\n  name: reporter\n  namespace: reporter\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.kompose.service: reporter\n  template:\n    metadata:\n      annotations:\n        kompose.cmd: kompose convert -f docker-compose.prod.yaml\n        kompose.version: 1.21.0 ()\n      labels:\n        io.kompose.network/redis-net: 'true'\n        io.kompose.service: reporter\n    spec:\n      containers:\n      - env:\n        - name: GITHUB_TOKEN\n          valueFrom:\n            configMapKeyRef:\n              key: GITHUB_TOKEN\n              name: env\n        - name: REDIS_HOST\n          valueFrom:\n            configMapKeyRef:\n              key: REDIS_HOST\n              name: env\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-password-secret\n              key: redis_password\n        - name: REDIS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: REDIS_PORT\n              name: env\n        - name: ZENHUB_TOKEN\n          valueFrom:\n            configMapKeyRef:\n              key: ZENHUB_TOKEN\n              name: env\n        image: docker.greymatter.io/internal/reporter:stable\n        imagePullPolicy: Always\n        name: reporter\n        ports:\n        - containerPort: 3000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02517",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when creating \"STDIN\": Post \"https://127.0.0.1:55768/apis/apps/v1/namespaces/reporter/deployments?dryRun=All&fieldManager=kubectl-client-side-apply&fieldValidation=Strict\": http2: client connection lost"
    ]
  },
  {
    "id": "02518",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error validating \"STDIN\": error validating data: failed to download openapi: Get \"https://127.0.0.1:55768/openapi/v2?timeout=32s\": net/http: TLS handshake timeout; if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "02519",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when creating \"STDIN\": Post \"https://127.0.0.1:55768/apis/apps/v1/namespaces/reporter/deployments?dryRun=All&fieldManager=kubectl-client-side-apply&fieldValidation=Strict\": EOF"
    ]
  },
  {
    "id": "02520",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error validating \"STDIN\": error validating data: failed to download openapi: unknown; if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "02521",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: table-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: table-manager\n  template:\n    metadata:\n      labels:\n        name: table-manager\n    spec:\n      containers:\n      - name: table-manager\n        image: quay.io/cortexproject/cortex:v1.8.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - -target=table-manager\n        - -server.http-listen-port=80\n        - -dynamodb.url=dynamodb://user:pass@dynamodb.default.svc.cluster.local:8000\n        - -schema-config-file=/etc/cortex/schema.yaml\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/cortex\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config-volume\n        configMap:\n          name: schema-config\n",
    "errors": []
  },
  {
    "id": "02522",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: table-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: table-manager\n  template:\n    metadata:\n      labels:\n        name: table-manager\n    spec:\n      containers:\n      - name: table-manager\n        image: quay.io/cortexproject/cortex:v1.8.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - -target=table-manager\n        - -server.http-listen-port=80\n        - -dynamodb.url=dynamodb://user:pass@dynamodb.default.svc.cluster.local:8000\n        - -schema-config-file=/etc/cortex/schema.yaml\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/cortex\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config-volume\n        configMap:\n          name: schema-config\n",
    "errors": []
  },
  {
    "id": "02523",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: table-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: table-manager\n  template:\n    metadata:\n      labels:\n        name: table-manager\n    spec:\n      containers:\n      - name: table-manager\n        image: quay.io/cortexproject/cortex:v1.8.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - -target=table-manager\n        - -server.http-listen-port=80\n        - -dynamodb.url=dynamodb://user:pass@dynamodb.default.svc.cluster.local:8000\n        - -schema-config-file=/etc/cortex/schema.yaml\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/cortex\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config-volume\n        configMap:\n          name: schema-config\n",
    "errors": []
  },
  {
    "id": "02524",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: table-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: table-manager\n  template:\n    metadata:\n      labels:\n        name: table-manager\n    spec:\n      containers:\n      - name: table-manager\n        image: quay.io/cortexproject/cortex:v1.8.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - -target=table-manager\n        - -server.http-listen-port=80\n        - -dynamodb.url=dynamodb://user:pass@dynamodb.default.svc.cluster.local:8000\n        - -schema-config-file=/etc/cortex/schema.yaml\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/cortex\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config-volume\n        configMap:\n          name: schema-config\n",
    "errors": []
  },
  {
    "id": "02525",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress:4.8-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: mysql-lb\n        - name: WORDPRESS_DB_USER\n          value: wpuser\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: wordpress-db-password-secret\n              key: wordpress_db_password\n        - name: WORDPRESS_DB_NAME\n          value: wordpress\n        ports:\n        - containerPort: 80\n          name: wordpress\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02526",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress:4.8-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: mysql-lb\n        - name: WORDPRESS_DB_USER\n          value: wpuser\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: wordpress-db-password-secret\n              key: wordpress_db_password\n        - name: WORDPRESS_DB_NAME\n          value: wordpress\n        ports:\n        - containerPort: 80\n          name: wordpress\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02527",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress:4.8-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: mysql-lb\n        - name: WORDPRESS_DB_USER\n          value: wpuser\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: wordpress-db-password-secret\n              key: wordpress_db_password\n        - name: WORDPRESS_DB_NAME\n          value: wordpress\n        ports:\n        - containerPort: 80\n          name: wordpress\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02528",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: wordpress\n  template:\n    metadata:\n      labels:\n        app: wordpress\n    spec:\n      containers:\n      - image: wordpress:4.8-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: mysql-lb\n        - name: WORDPRESS_DB_USER\n          value: wpuser\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: wordpress-db-password-secret\n              key: wordpress_db_password\n        - name: WORDPRESS_DB_NAME\n          value: wordpress\n        ports:\n        - containerPort: 80\n          name: wordpress\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02529",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-cloud-sdk-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: elibixby/jenkins-cloud-sdk-slave:stable\n    imagePullPolicy: Always\n    args:\n    - -name\n    - my-cloud-sdk-slave\n    - -labels\n    - image=google/cloud-sdk\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02530",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-cloud-sdk-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: elibixby/jenkins-cloud-sdk-slave:stable\n    imagePullPolicy: Always\n    args:\n    - -name\n    - my-cloud-sdk-slave\n    - -labels\n    - image=google/cloud-sdk\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02531",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-cloud-sdk-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: elibixby/jenkins-cloud-sdk-slave:stable\n    imagePullPolicy: Always\n    args:\n    - -name\n    - my-cloud-sdk-slave\n    - -labels\n    - image=google/cloud-sdk\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02532",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-cloud-sdk-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: elibixby/jenkins-cloud-sdk-slave:stable\n    imagePullPolicy: Always\n    args:\n    - -name\n    - my-cloud-sdk-slave\n    - -labels\n    - image=google/cloud-sdk\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02533",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-cloud-sdk-slave\nspec:\n  containers:\n  - name: jenkins-slave\n    image: elibixby/jenkins-cloud-sdk-slave:stable\n    imagePullPolicy: Always\n    args:\n    - -name\n    - my-cloud-sdk-slave\n    - -labels\n    - image=google/cloud-sdk\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02534",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210712-9b395cf3fb\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "02535",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210712-9b395cf3fb\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "02536",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210712-9b395cf3fb\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "02537",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210712-9b395cf3fb\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "02538",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02539",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02540",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02541",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02542",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02543",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02544",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02545",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02546",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.0.0\n  name: kube-state-metrics\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: 2.0.0\n    spec:\n      containers:\n      - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        name: kube-state-metrics\n        ports:\n        - containerPort: 8080\n          name: http-metrics\n        - containerPort: 8081\n          name: telemetry\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8081\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        securityContext:\n          runAsUser: 65534\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: kube-state-metrics\n",
    "errors": []
  },
  {
    "id": "02547",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.0.0\n  name: kube-state-metrics\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: 2.0.0\n    spec:\n      containers:\n      - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        name: kube-state-metrics\n        ports:\n        - containerPort: 8080\n          name: http-metrics\n        - containerPort: 8081\n          name: telemetry\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8081\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        securityContext:\n          runAsUser: 65534\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: kube-state-metrics\n",
    "errors": []
  },
  {
    "id": "02548",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.0.0\n  name: kube-state-metrics\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: 2.0.0\n    spec:\n      containers:\n      - image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        name: kube-state-metrics\n        ports:\n        - containerPort: 8080\n          name: http-metrics\n        - containerPort: 8081\n          name: telemetry\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8081\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        securityContext:\n          runAsUser: 65534\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: kube-state-metrics\n",
    "errors": []
  },
  {
    "id": "02549",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: sergii703/frontend:stable\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: Test\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02550",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: sergii703/frontend:stable\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: Test\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02551",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: sergii703/frontend:stable\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: Test\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02552",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: sergii703/frontend:stable\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: Test\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02553",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - name: server\n        image: sergii703/frontend:stable\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: Test\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02554",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210601-df2711fc5c\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "02555",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210601-df2711fc5c\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "02556",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210601-df2711fc5c\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "02557",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210601-df2711fc5c\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "02558",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prod1\n  labels:\n    app: prod1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: prod1\n  template:\n    metadata:\n      labels:\n        app: prod1\n    spec:\n      containers:\n      - name: prod1-container\n        image: paulfdunn/prod1:v0.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8000\n        volumeMounts:\n        - mountPath: /opt/prod1/data\n          name: data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: prod1-pvc\n",
    "errors": []
  },
  {
    "id": "02559",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prod1\n  labels:\n    app: prod1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: prod1\n  template:\n    metadata:\n      labels:\n        app: prod1\n    spec:\n      containers:\n      - name: prod1-container\n        image: paulfdunn/prod1:v0.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8000\n        volumeMounts:\n        - mountPath: /opt/prod1/data\n          name: data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: prod1-pvc\n",
    "errors": []
  },
  {
    "id": "02560",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prod1\n  labels:\n    app: prod1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: prod1\n  template:\n    metadata:\n      labels:\n        app: prod1\n    spec:\n      containers:\n      - name: prod1-container\n        image: paulfdunn/prod1:v0.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8000\n        volumeMounts:\n        - mountPath: /opt/prod1/data\n          name: data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: prod1-pvc\n",
    "errors": []
  },
  {
    "id": "02561",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prod1\n  labels:\n    app: prod1\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: prod1\n  template:\n    metadata:\n      labels:\n        app: prod1\n    spec:\n      containers:\n      - name: prod1-container\n        image: paulfdunn/prod1:v0.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8000\n        volumeMounts:\n        - mountPath: /opt/prod1/data\n          name: data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: prod1-pvc\n",
    "errors": []
  },
  {
    "id": "02562",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kctl\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kctl\n  template:\n    metadata:\n      labels:\n        app: kctl\n    spec:\n      containers:\n      - name: kctl\n        image: kg8s-local/kctl:v21.12.1\n        command:\n        - sh\n        args:\n        - -c\n        - 'cat /opt/ca.crt\n\n          cp /opt/ca.crt /usr/local/share/ca-certificates/nip-io-ca.crt\n\n          update-ca-certificates\n\n          echo \"\"\n\n          echo \"[UPDATE CA CERTIFICATE] check ca certificates\"\n\n          tail -n 20 /etc/ssl/certs/ca-certificates.crt\n\n          echo $(date) ; tail -f /dev/null\n\n          '\n        resources:\n          limits:\n            cpu: '1'\n            memory: 256Mi\n          requests:\n            cpu: 200m\n            memory: 128Mi\n        volumeMounts:\n        - name: cm-ca-nip\n          mountPath: /opt/ca.crt\n          subPath: ca.crt\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: cm-ca-nip\n        configMap:\n          name: ca-nip\n",
    "errors": []
  },
  {
    "id": "02563",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kctl\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kctl\n  template:\n    metadata:\n      labels:\n        app: kctl\n    spec:\n      containers:\n      - name: kctl\n        image: kg8s-local/kctl:v21.12.1\n        command:\n        - sh\n        args:\n        - -c\n        - 'cat /opt/ca.crt\n\n          cp /opt/ca.crt /usr/local/share/ca-certificates/nip-io-ca.crt\n\n          update-ca-certificates\n\n          echo \"\"\n\n          echo \"[UPDATE CA CERTIFICATE] check ca certificates\"\n\n          tail -n 20 /etc/ssl/certs/ca-certificates.crt\n\n          echo $(date) ; tail -f /dev/null\n\n          '\n        resources:\n          limits:\n            cpu: '1'\n            memory: 256Mi\n          requests:\n            cpu: 200m\n            memory: 128Mi\n        volumeMounts:\n        - name: cm-ca-nip\n          mountPath: /opt/ca.crt\n          subPath: ca.crt\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: cm-ca-nip\n        configMap:\n          name: ca-nip\n",
    "errors": []
  },
  {
    "id": "02564",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: naoyoshi/mb-ui:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02565",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: naoyoshi/mb-ui:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02566",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: naoyoshi/mb-ui:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02567",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: naoyoshi/mb-ui:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02568",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"server\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02569",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"server\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02570",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"server\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02571",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"server\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02572",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"server\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02573",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"server\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02574",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"server\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02575",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"server\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].resources.requests: Invalid value: \"8Gi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02576",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: load-balancer-example\n  name: hello-world\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: load-balancer-example\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: load-balancer-example\n    spec:\n      containers:\n      - image: nikhil101/django-k8s:2.1\n        name: hello-world\n        ports:\n        - containerPort: 8000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02577",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: load-balancer-example\n  name: hello-world\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: load-balancer-example\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: load-balancer-example\n    spec:\n      containers:\n      - image: nikhil101/django-k8s:2.1\n        name: hello-world\n        ports:\n        - containerPort: 8000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02578",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: load-balancer-example\n  name: hello-world\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: load-balancer-example\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: load-balancer-example\n    spec:\n      containers:\n      - image: nikhil101/django-k8s:2.1\n        name: hello-world\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02579",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: load-balancer-example\n  name: hello-world\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: load-balancer-example\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: load-balancer-example\n    spec:\n      containers:\n      - image: nikhil101/django-k8s:2.1\n        name: hello-world\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02580",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3665\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02581",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3665\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02582",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3665\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02583",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3665\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02584",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3665\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02585",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02586",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02587",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02588",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02589",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02590",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02591",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02592",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02593",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02594",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02595",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02596",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.5-shapemask-conv-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02597",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1497\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02598",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1497\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02599",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1497\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02600",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1497\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02601",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1497\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02602",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02603",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02604",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02605",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02606",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02607",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02608",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02609",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"hadoop-namenode\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"hadoop-nn-volume\""
    ]
  },
  {
    "id": "02610",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02611",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02612",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02613",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02614",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02615",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02616",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02617",
    "policy_id": "no_privileged",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02618",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02619",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02620",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02621",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02622",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02623",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": ReplicaSet in version \"v1\" cannot be handled as a ReplicaSet: strict decoding error: unknown field \"spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "02624",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: meu-deployment\n  labels:\n    deployment: bolado_deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      example: olx-bolada\n  template:\n    metadata:\n      labels:\n        example: olx-bolada\n    spec:\n      containers:\n      - name: meu-container\n        image: ralphavalon/kube_features:v2\n        ports:\n        - containerPort: 8081\n        env:\n        - name: API_HOST\n          value: 192.168.99.100:30934\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 250m\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8081\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8081\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02625",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: meu-deployment\n  labels:\n    deployment: bolado_deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      example: olx-bolada\n  template:\n    metadata:\n      labels:\n        example: olx-bolada\n    spec:\n      containers:\n      - name: meu-container\n        image: ralphavalon/kube_features:v2\n        ports:\n        - containerPort: 8081\n        env:\n        - name: API_HOST\n          value: 192.168.99.100:30934\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 250m\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8081\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8081\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02626",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02627",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02628",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02629",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02630",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02631",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: deis-minio\n  labels:\n    heritage: deis\n    release: v2-alpha\nspec:\n  replicas: 1\n  selector:\n    app: deis-minio\n  template:\n    metadata:\n      labels:\n        app: deis-minio\n    spec:\n      containers:\n      - imagePullPolicy: Always\n        name: deis-minio\n        image: quay.io/deisci/minio:v2-alpha\n        ports:\n        - containerPort: 9000\n        command:\n        - boot\n        args:\n        - server\n        - /home/minio/\n        volumeMounts:\n        - name: minio-admin\n          mountPath: /var/run/secrets/deis/minio/admin\n          readOnly: true\n        - name: minio-user\n          mountPath: /var/run/secrets/deis/minio/user\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: minio-admin\n        secret:\n          secretName: minio-admin\n      - name: minio-user\n        secret:\n          secretName: minio-user\n",
    "errors": []
  },
  {
    "id": "02632",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: deis-minio\n  labels:\n    heritage: deis\n    release: v2-alpha\nspec:\n  replicas: 1\n  selector:\n    app: deis-minio\n  template:\n    metadata:\n      labels:\n        app: deis-minio\n    spec:\n      containers:\n      - imagePullPolicy: Always\n        name: deis-minio\n        image: quay.io/deisci/minio:v2-alpha\n        ports:\n        - containerPort: 9000\n        command:\n        - boot\n        args:\n        - server\n        - /home/minio/\n        volumeMounts:\n        - name: minio-admin\n          mountPath: /var/run/secrets/deis/minio/admin\n          readOnly: true\n        - name: minio-user\n          mountPath: /var/run/secrets/deis/minio/user\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: minio-admin\n        secret:\n          secretName: minio-admin\n      - name: minio-user\n        secret:\n          secretName: minio-user\n",
    "errors": []
  },
  {
    "id": "02633",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: deis-minio\n  labels:\n    heritage: deis\n    release: v2-alpha\nspec:\n  replicas: 1\n  selector:\n    app: deis-minio\n  template:\n    metadata:\n      labels:\n        app: deis-minio\n    spec:\n      containers:\n      - imagePullPolicy: Always\n        name: deis-minio\n        image: quay.io/deisci/minio:v2-alpha\n        ports:\n        - containerPort: 9000\n        command:\n        - boot\n        args:\n        - server\n        - /home/minio/\n        volumeMounts:\n        - name: minio-admin\n          mountPath: /var/run/secrets/deis/minio/admin\n          readOnly: true\n        - name: minio-user\n          mountPath: /var/run/secrets/deis/minio/user\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: minio-admin\n        secret:\n          secretName: minio-admin\n      - name: minio-user\n        secret:\n          secretName: minio-user\n",
    "errors": []
  },
  {
    "id": "02634",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: deis-minio\n  labels:\n    heritage: deis\n    release: v2-alpha\nspec:\n  replicas: 1\n  selector:\n    app: deis-minio\n  template:\n    metadata:\n      labels:\n        app: deis-minio\n    spec:\n      containers:\n      - imagePullPolicy: Always\n        name: deis-minio\n        image: quay.io/deisci/minio:v2-alpha\n        ports:\n        - containerPort: 9000\n        command:\n        - boot\n        args:\n        - server\n        - /home/minio/\n        volumeMounts:\n        - name: minio-admin\n          mountPath: /var/run/secrets/deis/minio/admin\n          readOnly: true\n        - name: minio-user\n          mountPath: /var/run/secrets/deis/minio/user\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: minio-admin\n        secret:\n          secretName: minio-admin\n      - name: minio-user\n        secret:\n          secretName: minio-user\n",
    "errors": []
  },
  {
    "id": "02635",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n",
    "errors": []
  },
  {
    "id": "02636",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n",
    "errors": []
  },
  {
    "id": "02637",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n",
    "errors": []
  },
  {
    "id": "02638",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n",
    "errors": []
  },
  {
    "id": "02639",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pmu-dummy\n  labels:\n    app: pmu-dummy\nspec:\n  selector:\n    matchLabels:\n      app: pmu-dummy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: pmu-dummy\n    spec:\n      containers:\n      - name: pmu-dummy\n        image: registry.example.com/pmu-kafka-timescale-demo/kafka-connect-cluster/pmu-dummy:stable\n        volumeMounts:\n        - name: pmu-dummy-template-config\n          mountPath: /usr/src/app/device_template.json\n          subPath: device_template.json\n        env:\n        - name: JSON_TEMPLATE\n          value: /usr/src/app/device_template.json\n        - name: PRODUCER_TYPE\n          value: kafka\n        - name: BROKER_URL\n          value: strimzi-cluster-kafka-bootstrap.demo\n        - name: BROKER_PORT\n          value: '9092'\n        - name: TOPIC_NAME\n          value: pmu-dummy-in\n        - name: MQTT_USER\n          value: admin\n        - name: MQTT_PWD\n          value: admin\n        - name: MQTT_SSL\n          value: 'false'\n        - name: MQTT_CAFILE\n          value: /etc/ssl/certs/DST_Root_CA_X3.pem\n        - name: MQTT_DEVICE_NAME\n          value: device1-dummy\n        ports:\n        - containerPort: 3000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: pmu-dummy-template-config\n        configMap:\n          name: pmu-dummy-template-config\n          items:\n          - key: device_template.json\n            path: device_template.json\n",
    "errors": []
  },
  {
    "id": "02640",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 8a8b833ba1b6bd7a447a0e751960deed2ecd8106c1fcc7411dada4beae187d06\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: gastonborba\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: b8c01fa3c78e49707b1664fd573cbe2d129a2b78\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02641",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 8a8b833ba1b6bd7a447a0e751960deed2ecd8106c1fcc7411dada4beae187d06\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: gastonborba\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: b8c01fa3c78e49707b1664fd573cbe2d129a2b78\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02642",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubu\nspec:\n  selector:\n    matchLabels:\n      app: ubu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ubu\n    spec:\n      containers:\n      - name: ubu\n        image: ubuntu:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - /bin/sleep\n        - 3650d\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02643",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubu\nspec:\n  selector:\n    matchLabels:\n      app: ubu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ubu\n    spec:\n      containers:\n      - name: ubu\n        image: ubuntu:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - /bin/sleep\n        - 3650d\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02644",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubu\nspec:\n  selector:\n    matchLabels:\n      app: ubu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ubu\n    spec:\n      containers:\n      - name: ubu\n        image: ubuntu:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - /bin/sleep\n        - 3650d\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02645",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubu\nspec:\n  selector:\n    matchLabels:\n      app: ubu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ubu\n    spec:\n      containers:\n      - name: ubu\n        image: ubuntu:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - /bin/sleep\n        - 3650d\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02646",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubu\nspec:\n  selector:\n    matchLabels:\n      app: ubu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ubu\n    spec:\n      containers:\n      - name: ubu\n        image: ubuntu:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - /bin/sleep\n        - 3650d\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02647",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02648",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02649",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02650",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02651",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02652",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02653",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02654",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02655",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02656",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02657",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.6-python-ops-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02658",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: skydive-test-replicaset\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n    matchExpressions:\n    - key: tier\n      operator: In\n      values:\n      - frontend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: skydive-test-replicaset-php-redis\n        image: gcr.io/google_samples/gb-frontend:v3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02659",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: skydive-test-replicaset\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n    matchExpressions:\n    - key: tier\n      operator: In\n      values:\n      - frontend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: skydive-test-replicaset-php-redis\n        image: gcr.io/google_samples/gb-frontend:v3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02660",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: skydive-test-replicaset\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n    matchExpressions:\n    - key: tier\n      operator: In\n      values:\n      - frontend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: skydive-test-replicaset-php-redis\n        image: gcr.io/google_samples/gb-frontend:v3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02661",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-1\nspec:\n  selector:\n    matchLabels:\n      app: echo-1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: echo-1\n    spec:\n      containers:\n      - name: echo-1\n        image: hashicorp/http-echo:stable\n        args:\n        - -text=echo-1\n        ports:\n        - containerPort: 5678\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02662",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-1\nspec:\n  selector:\n    matchLabels:\n      app: echo-1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: echo-1\n    spec:\n      containers:\n      - name: echo-1\n        image: hashicorp/http-echo:stable\n        args:\n        - -text=echo-1\n        ports:\n        - containerPort: 5678\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02663",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-1\nspec:\n  selector:\n    matchLabels:\n      app: echo-1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: echo-1\n    spec:\n      containers:\n      - name: echo-1\n        image: hashicorp/http-echo:stable\n        args:\n        - -text=echo-1\n        ports:\n        - containerPort: 5678\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02664",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-1\nspec:\n  selector:\n    matchLabels:\n      app: echo-1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: echo-1\n    spec:\n      containers:\n      - name: echo-1\n        image: hashicorp/http-echo:stable\n        args:\n        - -text=echo-1\n        ports:\n        - containerPort: 5678\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02665",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-1\nspec:\n  selector:\n    matchLabels:\n      app: echo-1\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: echo-1\n    spec:\n      containers:\n      - name: echo-1\n        image: hashicorp/http-echo:stable\n        args:\n        - -text=echo-1\n        ports:\n        - containerPort: 5678\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02666",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02667",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02668",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02669",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02670",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ember-csi-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: ember-csi-operator\n  template:\n    metadata:\n      labels:\n        name: ember-csi-operator\n    spec:\n      serviceAccountName: ember-csi-operator\n      containers:\n      - name: ember-csi-operator\n        image: docker.io/embercsi/ember-csi-operator:stable\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - ember-csi-operator\n        args:\n        - -v=3\n        imagePullPolicy: Always\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 4\n          periodSeconds: 10\n          failureThreshold: 1\n        env:\n        - name: X_EMBER_OPERATOR_CLUSTER\n          value: default\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: ember-csi-operator\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02671",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ember-csi-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: ember-csi-operator\n  template:\n    metadata:\n      labels:\n        name: ember-csi-operator\n    spec:\n      serviceAccountName: ember-csi-operator\n      containers:\n      - name: ember-csi-operator\n        image: docker.io/embercsi/ember-csi-operator:stable\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - ember-csi-operator\n        args:\n        - -v=3\n        imagePullPolicy: Always\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 4\n          periodSeconds: 10\n          failureThreshold: 1\n        env:\n        - name: X_EMBER_OPERATOR_CLUSTER\n          value: default\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: ember-csi-operator\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02672",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ember-csi-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: ember-csi-operator\n  template:\n    metadata:\n      labels:\n        name: ember-csi-operator\n    spec:\n      serviceAccountName: ember-csi-operator\n      containers:\n      - name: ember-csi-operator\n        image: docker.io/embercsi/ember-csi-operator:stable\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - ember-csi-operator\n        args:\n        - -v=3\n        imagePullPolicy: Always\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 4\n          periodSeconds: 10\n          failureThreshold: 1\n        env:\n        - name: X_EMBER_OPERATOR_CLUSTER\n          value: default\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: ember-csi-operator\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02673",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ember-csi-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: ember-csi-operator\n  template:\n    metadata:\n      labels:\n        name: ember-csi-operator\n    spec:\n      serviceAccountName: ember-csi-operator\n      containers:\n      - name: ember-csi-operator\n        image: docker.io/embercsi/ember-csi-operator:stable\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - ember-csi-operator\n        args:\n        - -v=3\n        imagePullPolicy: Always\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 4\n          periodSeconds: 10\n          failureThreshold: 1\n        env:\n        - name: X_EMBER_OPERATOR_CLUSTER\n          value: default\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: ember-csi-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02674",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ember-csi-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: ember-csi-operator\n  template:\n    metadata:\n      labels:\n        name: ember-csi-operator\n    spec:\n      serviceAccountName: ember-csi-operator\n      containers:\n      - name: ember-csi-operator\n        image: docker.io/embercsi/ember-csi-operator:stable\n        ports:\n        - containerPort: 60000\n          name: metrics\n        command:\n        - ember-csi-operator\n        args:\n        - -v=3\n        imagePullPolicy: Always\n        readinessProbe:\n          exec:\n            command:\n            - stat\n            - /tmp/operator-sdk-ready\n          initialDelaySeconds: 4\n          periodSeconds: 10\n          failureThreshold: 1\n        env:\n        - name: X_EMBER_OPERATOR_CLUSTER\n          value: default\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: ember-csi-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02675",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"test-${storageClass}\" is invalid: \n* metadata.name: Invalid value: \"test-${storageClass}\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')\n* spec.selector.matchLabels: Invalid value: \"test-${storageClass}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"test-${storageClass}\"}}"
    ]
  },
  {
    "id": "02676",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"test-${storageClass}\" is invalid: \n* metadata.name: Invalid value: \"test-${storageClass}\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')\n* spec.selector.matchLabels: Invalid value: \"test-${storageClass}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"test-${storageClass}\"}}"
    ]
  },
  {
    "id": "02677",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"test-${storageClass}\" is invalid: \n* metadata.name: Invalid value: \"test-${storageClass}\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')\n* spec.selector.matchLabels: Invalid value: \"test-${storageClass}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"test-${storageClass}\"}}"
    ]
  },
  {
    "id": "02678",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"test-${storageClass}\" is invalid: \n* metadata.name: Invalid value: \"test-${storageClass}\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')\n* spec.selector.matchLabels: Invalid value: \"test-${storageClass}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"test-${storageClass}\"}}"
    ]
  },
  {
    "id": "02679",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"test-${storageClass}\" is invalid: \n* metadata.name: Invalid value: \"test-${storageClass}\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')\n* spec.selector.matchLabels: Invalid value: \"test-${storageClass}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"test-${storageClass}\"}}"
    ]
  },
  {
    "id": "02680",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": false,
    "patched_yaml": null,
    "errors": []
  },
  {
    "id": "02681",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tool-wrk\n  labels:\n    app: tool-wrk\n    rel: dev\nspec:\n  containers:\n  - name: wrk\n    image: williamyeh/wrk:stable\n    command:\n    - /bin/sh\n    - -c\n    - --\n    args:\n    - while :; do sleep 365d; done\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02682",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tool-wrk\n  labels:\n    app: tool-wrk\n    rel: dev\nspec:\n  containers:\n  - name: wrk\n    image: williamyeh/wrk:stable\n    command:\n    - /bin/sh\n    - -c\n    - --\n    args:\n    - while :; do sleep 365d; done\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02683",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tool-wrk\n  labels:\n    app: tool-wrk\n    rel: dev\nspec:\n  containers:\n  - name: wrk\n    image: williamyeh/wrk:stable\n    command:\n    - /bin/sh\n    - -c\n    - --\n    args:\n    - while :; do sleep 365d; done\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02684",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tool-wrk\n  labels:\n    app: tool-wrk\n    rel: dev\nspec:\n  containers:\n  - name: wrk\n    image: williamyeh/wrk:stable\n    command:\n    - /bin/sh\n    - -c\n    - --\n    args:\n    - while :; do sleep 365d; done\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02685",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tool-wrk\n  labels:\n    app: tool-wrk\n    rel: dev\nspec:\n  containers:\n  - name: wrk\n    image: williamyeh/wrk:stable\n    command:\n    - /bin/sh\n    - -c\n    - --\n    args:\n    - while :; do sleep 365d; done\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02686",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02687",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02688",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02689",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02690",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02691",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02692",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02693",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02694",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02695",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02696",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  labels:\n    app: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      volumes:\n      - name: dind-storage\n        emptyDir: {}\n      containers:\n      - name: jenkins\n        image: andreamendoza/modified-jenkins:stable\n        ports:\n        - containerPort: 8080\n        - containerPort: 50000\n        env:\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: dind\n        image: docker:18.05-dind\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dind-storage\n          mountPath: /var/lib/docker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02697",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"canary-demo\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 128M"
    ]
  },
  {
    "id": "02698",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"canary-demo\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 128M"
    ]
  },
  {
    "id": "02699",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"canary-demo\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 128M"
    ]
  },
  {
    "id": "02700",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"cronjob\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02701",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"cronjob\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02702",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"cronjob\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02703",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"cronjob\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02704",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: swe-app-api\n  namespace: swe\nspec:\n  selector:\n    matchLabels:\n      app: swe-app-api\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: swe-app-api\n    spec:\n      containers:\n      - image: datadaddy/swe-api-k8s:0.1\n        imagePullPolicy: Always\n        name: swe-app-api\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-db-password\n              key: password\n        - name: POSTGRES_DB_URL\n          value: jdbc:postgresql://postgres.swe.svc.cluster.local:5432/postgres\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 250m\n          limits:\n            memory: 750Mi\n            cpu: 500m\n        ports:\n        - containerPort: 3000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02705",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: swe-app-api\n  namespace: swe\nspec:\n  selector:\n    matchLabels:\n      app: swe-app-api\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: swe-app-api\n    spec:\n      containers:\n      - image: datadaddy/swe-api-k8s:0.1\n        imagePullPolicy: Always\n        name: swe-app-api\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-db-password\n              key: password\n        - name: POSTGRES_DB_URL\n          value: jdbc:postgresql://postgres.swe.svc.cluster.local:5432/postgres\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 250m\n          limits:\n            memory: 750Mi\n            cpu: 500m\n        ports:\n        - containerPort: 3000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02706",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: redis\nspec:\n  containers:\n  - name: redis\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: data\n    - mountPath: /redis-master\n      name: config\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n  volumes:\n  - name: data\n    emptyDir: {}\n  - name: config\n    configMap:\n      name: example-redis-config\n      items:\n      - key: redis-config\n        path: redis.conf\n",
    "errors": []
  },
  {
    "id": "02707",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: redis\nspec:\n  containers:\n  - name: redis\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: data\n    - mountPath: /redis-master\n      name: config\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: data\n    emptyDir: {}\n  - name: config\n    configMap:\n      name: example-redis-config\n      items:\n      - key: redis-config\n        path: redis.conf\n",
    "errors": []
  },
  {
    "id": "02708",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: redis\nspec:\n  containers:\n  - name: redis\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: data\n    - mountPath: /redis-master\n      name: config\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: data\n    emptyDir: {}\n  - name: config\n    configMap:\n      name: example-redis-config\n      items:\n      - key: redis-config\n        path: redis.conf\n",
    "errors": []
  },
  {
    "id": "02709",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: redis\nspec:\n  containers:\n  - name: redis\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n        memory: 256Mi\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: data\n    - mountPath: /redis-master\n      name: config\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: data\n    emptyDir: {}\n  - name: config\n    configMap:\n      name: example-redis-config\n      items:\n      - key: redis-config\n        path: redis.conf\n",
    "errors": []
  },
  {
    "id": "02710",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jysinakscluster-dfd5\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: jysinakscluster-dfd5\n  template:\n    metadata:\n      labels:\n        app: jysinakscluster-dfd5\n    spec:\n      containers:\n      - name: jysinakscluster-dfd5\n        image: jysintestrigistry.azurecr.io/jysinakscluster:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02711",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jysinakscluster-dfd5\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: jysinakscluster-dfd5\n  template:\n    metadata:\n      labels:\n        app: jysinakscluster-dfd5\n    spec:\n      containers:\n      - name: jysinakscluster-dfd5\n        image: jysintestrigistry.azurecr.io/jysinakscluster:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02712",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jysinakscluster-dfd5\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: jysinakscluster-dfd5\n  template:\n    metadata:\n      labels:\n        app: jysinakscluster-dfd5\n    spec:\n      containers:\n      - name: jysinakscluster-dfd5\n        image: jysintestrigistry.azurecr.io/jysinakscluster:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02713",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jysinakscluster-dfd5\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: jysinakscluster-dfd5\n  template:\n    metadata:\n      labels:\n        app: jysinakscluster-dfd5\n    spec:\n      containers:\n      - name: jysinakscluster-dfd5\n        image: jysintestrigistry.azurecr.io/jysinakscluster:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02714",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jysinakscluster-dfd5\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: jysinakscluster-dfd5\n  template:\n    metadata:\n      labels:\n        app: jysinakscluster-dfd5\n    spec:\n      containers:\n      - name: jysinakscluster-dfd5\n        image: jysintestrigistry.azurecr.io/jysinakscluster:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02715",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibmliberty-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ibmliberty\n  template:\n    metadata:\n      labels:\n        app: ibmliberty\n    spec:\n      containers:\n      - name: ibmliberty\n        image: icr.io/ibmliberty:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02716",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibmliberty-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ibmliberty\n  template:\n    metadata:\n      labels:\n        app: ibmliberty\n    spec:\n      containers:\n      - name: ibmliberty\n        image: icr.io/ibmliberty:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02717",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibmliberty-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ibmliberty\n  template:\n    metadata:\n      labels:\n        app: ibmliberty\n    spec:\n      containers:\n      - name: ibmliberty\n        image: icr.io/ibmliberty:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02718",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibmliberty-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ibmliberty\n  template:\n    metadata:\n      labels:\n        app: ibmliberty\n    spec:\n      containers:\n      - name: ibmliberty\n        image: icr.io/ibmliberty:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02719",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ibmliberty-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ibmliberty\n  template:\n    metadata:\n      labels:\n        app: ibmliberty\n    spec:\n      containers:\n      - name: ibmliberty\n        image: icr.io/ibmliberty:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02720",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"/v1, Resource=pods\", GroupVersionKind: \"/v1, Kind=Pod\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02721",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"/v1, Resource=pods\", GroupVersionKind: \"/v1, Kind=Pod\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02722",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"/v1, Resource=pods\", GroupVersionKind: \"/v1, Kind=Pod\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02723",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"/v1, Resource=pods\", GroupVersionKind: \"/v1, Kind=Pod\"\nName: \"\", Namespace: \"default\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "02724",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7391\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02725",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7391\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02726",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7391\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02727",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7391\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02728",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7391\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02729",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-test-1\nspec:\n  containers:\n  - name: foobar\n    image: foo/bar:123\n    resources:\n      limits:\n        cpu: 200m\n        memory: 1Gi\n        ephemeral-storage: 2Gi\n      requests:\n        cpu: 200m\n        memory: 1Gi\n        ephemeral-storage: 1Gi\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02730",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-test-1\nspec:\n  containers:\n  - name: foobar\n    image: foo/bar:123\n    resources:\n      limits:\n        cpu: 200m\n        memory: 1Gi\n        ephemeral-storage: 2Gi\n      requests:\n        cpu: 200m\n        memory: 1Gi\n        ephemeral-storage: 1Gi\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02731",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"syntribos-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02732",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"syntribos-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02733",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"syntribos-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02734",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"syntribos-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02735",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"syntribos-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02736",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    chart: lighthouse-1.5.4\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: 67c776bf82621e022317a40d90de6ff011c91691631856781119358c252609d4\n      labels:\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: ghcr.io/jenkins-x/lighthouse-keeper:1.5.4\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: mk-gh-bot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: stackdriver\n        - name: LOGRUS_FORMAT\n          value: stackdriver\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.5.4\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        - name: LIGHTHOUSE_TRIGGER_ON_MISSING\n          value: enable\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02737",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    chart: lighthouse-1.5.4\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: 67c776bf82621e022317a40d90de6ff011c91691631856781119358c252609d4\n      labels:\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: ghcr.io/jenkins-x/lighthouse-keeper:1.5.4\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: mk-gh-bot\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: stackdriver\n        - name: LOGRUS_FORMAT\n          value: stackdriver\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.5.4\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        - name: LIGHTHOUSE_TRIGGER_ON_MISSING\n          value: enable\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02738",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"process-item-$ITEM\" is invalid: \n* metadata.name: Invalid value: \"process-item-$ITEM\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"process-item-$ITEM\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02739",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"process-item-$ITEM\" is invalid: \n* metadata.name: Invalid value: \"process-item-$ITEM\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"process-item-$ITEM\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02740",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"process-item-$ITEM\" is invalid: \n* metadata.name: Invalid value: \"process-item-$ITEM\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"process-item-$ITEM\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02741",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"process-item-$ITEM\" is invalid: \n* metadata.name: Invalid value: \"process-item-$ITEM\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"process-item-$ITEM\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02742",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"process-item-$ITEM\" is invalid: \n* metadata.name: Invalid value: \"process-item-$ITEM\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"process-item-$ITEM\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02743",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: prometheus-operator\n    app.kubernetes.io/version: 0.53.1\n  name: prometheus-operator\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/name: prometheus-operator\n  template:\n    metadata:\n      annotations:\n        kubectl.kubernetes.io/default-container: prometheus-operator\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/name: prometheus-operator\n        app.kubernetes.io/version: 0.53.1\n    spec:\n      containers:\n      - args:\n        - --kubelet-service=kube-system/kubelet\n        - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.53.1\n        image: quay.io/prometheus-operator/prometheus-operator:v0.53.1\n        name: prometheus-operator\n        ports:\n        - containerPort: 8080\n          name: http\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 65534\n      serviceAccountName: prometheus-operator\n",
    "errors": []
  },
  {
    "id": "02744",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: product-price-service-deployment\n  labels:\n    app: product-price-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: product-price-service\n  template:\n    metadata:\n      labels:\n        app: product-price-service\n    spec:\n      containers:\n      - name: product-price-service\n        image: ra0k/microservice:productprice\n        ports:\n        - containerPort: 9003\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02745",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: product-price-service-deployment\n  labels:\n    app: product-price-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: product-price-service\n  template:\n    metadata:\n      labels:\n        app: product-price-service\n    spec:\n      containers:\n      - name: product-price-service\n        image: ra0k/microservice:productprice\n        ports:\n        - containerPort: 9003\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02746",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: product-price-service-deployment\n  labels:\n    app: product-price-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: product-price-service\n  template:\n    metadata:\n      labels:\n        app: product-price-service\n    spec:\n      containers:\n      - name: product-price-service\n        image: ra0k/microservice:productprice\n        ports:\n        - containerPort: 9003\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02747",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: product-price-service-deployment\n  labels:\n    app: product-price-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: product-price-service\n  template:\n    metadata:\n      labels:\n        app: product-price-service\n    spec:\n      containers:\n      - name: product-price-service\n        image: ra0k/microservice:productprice\n        ports:\n        - containerPort: 9003\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02748",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"statefulset-blobfuse\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"persistent-storage\""
    ]
  },
  {
    "id": "02749",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"statefulset-blobfuse\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"persistent-storage\""
    ]
  },
  {
    "id": "02750",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"statefulset-blobfuse\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"persistent-storage\""
    ]
  },
  {
    "id": "02751",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"statefulset-blobfuse\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"persistent-storage\""
    ]
  },
  {
    "id": "02752",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"statefulset-blobfuse\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"persistent-storage\""
    ]
  },
  {
    "id": "02753",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: ezyakaeagle442registry.azurecr.io/captureorder:stable\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: placeholder\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02754",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: ezyakaeagle442registry.azurecr.io/captureorder:stable\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: placeholder\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02755",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: ezyakaeagle442registry.azurecr.io/captureorder:stable\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: placeholder\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02756",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-context-demo\nspec:\n  securityContext:\n    runAsUser: 1000\n    runAsGroup: 3000\n    fsGroup: 2000\n  volumes:\n  - name: sec-ctx-vol\n    emptyDir: {}\n  containers:\n  - name: sec-ctx-demo\n    image: busybox:1.28\n    command:\n    - sh\n    - -c\n    - sleep 1h\n    volumeMounts:\n    - name: sec-ctx-vol\n      mountPath: /data/demo\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02757",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-context-demo\nspec:\n  securityContext:\n    runAsUser: 1000\n    runAsGroup: 3000\n    fsGroup: 2000\n  volumes:\n  - name: sec-ctx-vol\n    emptyDir: {}\n  containers:\n  - name: sec-ctx-demo\n    image: busybox:1.28\n    command:\n    - sh\n    - -c\n    - sleep 1h\n    volumeMounts:\n    - name: sec-ctx-vol\n      mountPath: /data/demo\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02758",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-context-demo\nspec:\n  securityContext:\n    runAsUser: 1000\n    runAsGroup: 3000\n    fsGroup: 2000\n  volumes:\n  - name: sec-ctx-vol\n    emptyDir: {}\n  containers:\n  - name: sec-ctx-demo\n    image: busybox:1.28\n    command:\n    - sh\n    - -c\n    - sleep 1h\n    volumeMounts:\n    - name: sec-ctx-vol\n      mountPath: /data/demo\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02759",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02760",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02761",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02762",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02763",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02764",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02765",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02766",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02767",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02768",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02769",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.2-bert-mnli-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02770",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pytorch-operator\n  namespace: kubeflow\n  labels:\n    app.kubernetes.io/component: pytorch\n    app.kubernetes.io/name: pytorch-operator\n    kustomize.component: pytorch-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: pytorch-operator\n      app.kubernetes.io/component: pytorch\n      app.kubernetes.io/name: pytorch-operator\n      kustomize.component: pytorch-operator\n  template:\n    metadata:\n      labels:\n        name: pytorch-operator\n        app.kubernetes.io/component: pytorch\n        app.kubernetes.io/name: pytorch-operator\n        kustomize.component: pytorch-operator\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: pytorch-operator\n      containers:\n      - name: pytorch-operator\n        image: gcr.io/gcp-private-dev/mirror/gcr.io/kubeflow-images-public/pytorch-operator:vmaster-gd596e904\n        command:\n        - /pytorch-operator.v1\n        - --alsologtostderr\n        - -v=1\n        - --monitoring-port=8443\n        env:\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02771",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pytorch-operator\n  namespace: kubeflow\n  labels:\n    app.kubernetes.io/component: pytorch\n    app.kubernetes.io/name: pytorch-operator\n    kustomize.component: pytorch-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: pytorch-operator\n      app.kubernetes.io/component: pytorch\n      app.kubernetes.io/name: pytorch-operator\n      kustomize.component: pytorch-operator\n  template:\n    metadata:\n      labels:\n        name: pytorch-operator\n        app.kubernetes.io/component: pytorch\n        app.kubernetes.io/name: pytorch-operator\n        kustomize.component: pytorch-operator\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: pytorch-operator\n      containers:\n      - name: pytorch-operator\n        image: gcr.io/gcp-private-dev/mirror/gcr.io/kubeflow-images-public/pytorch-operator:vmaster-gd596e904\n        command:\n        - /pytorch-operator.v1\n        - --alsologtostderr\n        - -v=1\n        - --monitoring-port=8443\n        env:\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02772",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pytorch-operator\n  namespace: kubeflow\n  labels:\n    app.kubernetes.io/component: pytorch\n    app.kubernetes.io/name: pytorch-operator\n    kustomize.component: pytorch-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: pytorch-operator\n      app.kubernetes.io/component: pytorch\n      app.kubernetes.io/name: pytorch-operator\n      kustomize.component: pytorch-operator\n  template:\n    metadata:\n      labels:\n        name: pytorch-operator\n        app.kubernetes.io/component: pytorch\n        app.kubernetes.io/name: pytorch-operator\n        kustomize.component: pytorch-operator\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: pytorch-operator\n      containers:\n      - name: pytorch-operator\n        image: gcr.io/gcp-private-dev/mirror/gcr.io/kubeflow-images-public/pytorch-operator:vmaster-gd596e904\n        command:\n        - /pytorch-operator.v1\n        - --alsologtostderr\n        - -v=1\n        - --monitoring-port=8443\n        env:\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02773",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pytorch-operator\n  namespace: kubeflow\n  labels:\n    app.kubernetes.io/component: pytorch\n    app.kubernetes.io/name: pytorch-operator\n    kustomize.component: pytorch-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: pytorch-operator\n      app.kubernetes.io/component: pytorch\n      app.kubernetes.io/name: pytorch-operator\n      kustomize.component: pytorch-operator\n  template:\n    metadata:\n      labels:\n        name: pytorch-operator\n        app.kubernetes.io/component: pytorch\n        app.kubernetes.io/name: pytorch-operator\n        kustomize.component: pytorch-operator\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: pytorch-operator\n      containers:\n      - name: pytorch-operator\n        image: gcr.io/gcp-private-dev/mirror/gcr.io/kubeflow-images-public/pytorch-operator:vmaster-gd596e904\n        command:\n        - /pytorch-operator.v1\n        - --alsologtostderr\n        - -v=1\n        - --monitoring-port=8443\n        env:\n        - name: MY_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02774",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"minio\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "02775",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"minio\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "02776",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"minio\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "02777",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"minio\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "02778",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ui\n  template:\n    metadata:\n      labels:\n        app: ui\n    spec:\n      containers:\n      - name: ui\n        image: target/consensource-ui:stable\n        imagePullPolicy: Always\n        resources:\n          limits:\n            cpu: 50m\n            memory: 100Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: http\n          containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02779",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ui\n  template:\n    metadata:\n      labels:\n        app: ui\n    spec:\n      containers:\n      - name: ui\n        image: target/consensource-ui:stable\n        imagePullPolicy: Always\n        resources:\n          limits:\n            cpu: 50m\n            memory: 100Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: http\n          containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02780",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ui\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ui\n  template:\n    metadata:\n      labels:\n        app: ui\n    spec:\n      containers:\n      - name: ui\n        image: target/consensource-ui:stable\n        imagePullPolicy: Always\n        resources:\n          limits:\n            cpu: 50m\n            memory: 100Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        ports:\n        - name: http\n          containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02781",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hashgenerator\n  name: hashgenerator\n  namespace: other-app-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hashgenerator\n  template:\n    metadata:\n      labels:\n        app: hashgenerator\n    spec:\n      containers:\n      - image: lnsth/logoutput:exercise_2.03\n        imagePullPolicy: Always\n        name: logoutput\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: pingpong\n        image: lnsth/pingpong:exercise_2.03\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "02782",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hashgenerator\n  name: hashgenerator\n  namespace: other-app-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hashgenerator\n  template:\n    metadata:\n      labels:\n        app: hashgenerator\n    spec:\n      containers:\n      - image: lnsth/logoutput:exercise_2.03\n        imagePullPolicy: Always\n        name: logoutput\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: pingpong\n        image: lnsth/pingpong:exercise_2.03\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "02783",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hashgenerator\n  name: hashgenerator\n  namespace: other-app-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hashgenerator\n  template:\n    metadata:\n      labels:\n        app: hashgenerator\n    spec:\n      containers:\n      - image: lnsth/logoutput:exercise_2.03\n        imagePullPolicy: Always\n        name: logoutput\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: pingpong\n        image: lnsth/pingpong:exercise_2.03\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "02784",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hashgenerator\n  name: hashgenerator\n  namespace: other-app-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hashgenerator\n  template:\n    metadata:\n      labels:\n        app: hashgenerator\n    spec:\n      containers:\n      - image: lnsth/logoutput:exercise_2.03\n        imagePullPolicy: Always\n        name: logoutput\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: pingpong\n        image: lnsth/pingpong:exercise_2.03\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "02785",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hashgenerator\n  name: hashgenerator\n  namespace: other-app-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hashgenerator\n  template:\n    metadata:\n      labels:\n        app: hashgenerator\n    spec:\n      containers:\n      - image: lnsth/logoutput:exercise_2.03\n        imagePullPolicy: Always\n        name: logoutput\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: pingpong\n        image: lnsth/pingpong:exercise_2.03\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "02786",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hashgenerator\n  name: hashgenerator\n  namespace: other-app-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hashgenerator\n  template:\n    metadata:\n      labels:\n        app: hashgenerator\n    spec:\n      containers:\n      - image: lnsth/logoutput:exercise_2.03\n        imagePullPolicy: Always\n        name: logoutput\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: pingpong\n        image: lnsth/pingpong:exercise_2.03\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "02787",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hashgenerator\n  name: hashgenerator\n  namespace: other-app-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hashgenerator\n  template:\n    metadata:\n      labels:\n        app: hashgenerator\n    spec:\n      containers:\n      - image: lnsth/logoutput:exercise_2.03\n        imagePullPolicy: Always\n        name: logoutput\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: pingpong\n        image: lnsth/pingpong:exercise_2.03\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "02788",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hashgenerator\n  name: hashgenerator\n  namespace: other-app-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hashgenerator\n  template:\n    metadata:\n      labels:\n        app: hashgenerator\n    spec:\n      containers:\n      - image: lnsth/logoutput:exercise_2.03\n        imagePullPolicy: Always\n        name: logoutput\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: pingpong\n        image: lnsth/pingpong:exercise_2.03\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n",
    "errors": []
  },
  {
    "id": "02789",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02790",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02791",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02792",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02793",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02794",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02795",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02796",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02797",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02798",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02799",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02800",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02801",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02802",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02803",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"verifier-vcs-add-profiles\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "02804",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (Forbidden): error when creating \"STDIN\": pods \"cockroachdb-client-secure\" is forbidden: error looking up service account default/cockroachdb: serviceaccount \"cockroachdb\" not found"
    ]
  },
  {
    "id": "02805",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (Forbidden): error when creating \"STDIN\": pods \"cockroachdb-client-secure\" is forbidden: error looking up service account default/cockroachdb: serviceaccount \"cockroachdb\" not found"
    ]
  },
  {
    "id": "02806",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (Forbidden): error when creating \"STDIN\": pods \"cockroachdb-client-secure\" is forbidden: error looking up service account default/cockroachdb: serviceaccount \"cockroachdb\" not found"
    ]
  },
  {
    "id": "02807",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (Forbidden): error when creating \"STDIN\": pods \"cockroachdb-client-secure\" is forbidden: error looking up service account default/cockroachdb: serviceaccount \"cockroachdb\" not found"
    ]
  },
  {
    "id": "02808",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-4\nspec:\n  containers:\n  - image: ubuntu:stable\n    name: ubuntu\n    command:\n    - /bin/bash\n    - -c\n    args:\n    - sleep 3600\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02809",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-4\nspec:\n  containers:\n  - image: ubuntu:stable\n    name: ubuntu\n    command:\n    - /bin/bash\n    - -c\n    args:\n    - sleep 3600\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02810",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-4\nspec:\n  containers:\n  - image: ubuntu:stable\n    name: ubuntu\n    command:\n    - /bin/bash\n    - -c\n    args:\n    - sleep 3600\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02811",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-4\nspec:\n  containers:\n  - image: ubuntu:stable\n    name: ubuntu\n    command:\n    - /bin/bash\n    - -c\n    args:\n    - sleep 3600\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02812",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-4\nspec:\n  containers:\n  - image: ubuntu:stable\n    name: ubuntu\n    command:\n    - /bin/bash\n    - -c\n    args:\n    - sleep 3600\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02813",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: phpmyadmin\nspec:\n  selector:\n    matchLabels:\n      app: phpmyadmin\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: phpmyadmin\n    spec:\n      containers:\n      - image: my_phpmyadmin:stable\n        name: phpmyadmin\n        imagePullPolicy: Never\n        ports:\n        - name: php-port\n          containerPort: 5000\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - service telegraf status && service nginx status && service mariadb status\n              && service php-fpm7 status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02814",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: phpmyadmin\nspec:\n  selector:\n    matchLabels:\n      app: phpmyadmin\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: phpmyadmin\n    spec:\n      containers:\n      - image: my_phpmyadmin:stable\n        name: phpmyadmin\n        imagePullPolicy: Never\n        ports:\n        - name: php-port\n          containerPort: 5000\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - service telegraf status && service nginx status && service mariadb status\n              && service php-fpm7 status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02815",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: phpmyadmin\nspec:\n  selector:\n    matchLabels:\n      app: phpmyadmin\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: phpmyadmin\n    spec:\n      containers:\n      - image: my_phpmyadmin:stable\n        name: phpmyadmin\n        imagePullPolicy: Never\n        ports:\n        - name: php-port\n          containerPort: 5000\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - service telegraf status && service nginx status && service mariadb status\n              && service php-fpm7 status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02816",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: phpmyadmin\nspec:\n  selector:\n    matchLabels:\n      app: phpmyadmin\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: phpmyadmin\n    spec:\n      containers:\n      - image: my_phpmyadmin:stable\n        name: phpmyadmin\n        imagePullPolicy: Never\n        ports:\n        - name: php-port\n          containerPort: 5000\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - service telegraf status && service nginx status && service mariadb status\n              && service php-fpm7 status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02817",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: phpmyadmin\nspec:\n  selector:\n    matchLabels:\n      app: phpmyadmin\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: phpmyadmin\n    spec:\n      containers:\n      - image: my_phpmyadmin:stable\n        name: phpmyadmin\n        imagePullPolicy: Never\n        ports:\n        - name: php-port\n          containerPort: 5000\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - service telegraf status && service nginx status && service mariadb status\n              && service php-fpm7 status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02818",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hrz\nspec:\n  selector:\n    matchLabels:\n      app: hrz\n  template:\n    metadata:\n      labels:\n        app: hrz\n    spec:\n      containers:\n      - name: sitecore-horizon\n        env:\n        - name: Sitecore_Plugins__Filters__ContentHub\n          value: +ContentHub\n        image: busybox:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02819",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hrz\nspec:\n  selector:\n    matchLabels:\n      app: hrz\n  template:\n    metadata:\n      labels:\n        app: hrz\n    spec:\n      containers:\n      - name: sitecore-horizon\n        env:\n        - name: Sitecore_Plugins__Filters__ContentHub\n          value: +ContentHub\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        image: busybox:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02820",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hrz\nspec:\n  selector:\n    matchLabels:\n      app: hrz\n  template:\n    metadata:\n      labels:\n        app: hrz\n    spec:\n      containers:\n      - name: sitecore-horizon\n        env:\n        - name: Sitecore_Plugins__Filters__ContentHub\n          value: +ContentHub\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        image: busybox:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02821",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hrz\nspec:\n  selector:\n    matchLabels:\n      app: hrz\n  template:\n    metadata:\n      labels:\n        app: hrz\n    spec:\n      containers:\n      - name: sitecore-horizon\n        env:\n        - name: Sitecore_Plugins__Filters__ContentHub\n          value: +ContentHub\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        image: busybox:stable\n",
    "errors": []
  },
  {
    "id": "02822",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hrz\nspec:\n  selector:\n    matchLabels:\n      app: hrz\n  template:\n    metadata:\n      labels:\n        app: hrz\n    spec:\n      containers:\n      - name: sitecore-horizon\n        env:\n        - name: Sitecore_Plugins__Filters__ContentHub\n          value: +ContentHub\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        image: busybox:stable\n",
    "errors": []
  },
  {
    "id": "02823",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gcsb-run\n  namespace: gcsb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcsb-run\n  template:\n    metadata:\n      labels:\n        app: gcsb-run\n    spec:\n      serviceAccountName: gcsb\n      containers:\n      - name: gcsb-run\n        image: gcr.io/<project>/gcsb:stable\n        command:\n        - /gcsb\n        - run\n        args:\n        - --project=YOUR_PROJECT_ID\n        - --instance=YOUR_INSTANCE_ID\n        - --database=YOUR_DATABASE\n        - --table=YOUR_TABLE\n        - --operations=1000000\n        - --threads=10\n        - --reads=50\n        - --writes=50\n        - --sample-size=5\n        resources:\n          requests:\n            cpu: '6'\n            memory: 4Gi\n          limits:\n            cpu: '6'\n            memory: 4Gi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02824",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gcsb-run\n  namespace: gcsb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcsb-run\n  template:\n    metadata:\n      labels:\n        app: gcsb-run\n    spec:\n      serviceAccountName: gcsb\n      containers:\n      - name: gcsb-run\n        image: gcr.io/<project>/gcsb:stable\n        command:\n        - /gcsb\n        - run\n        args:\n        - --project=YOUR_PROJECT_ID\n        - --instance=YOUR_INSTANCE_ID\n        - --database=YOUR_DATABASE\n        - --table=YOUR_TABLE\n        - --operations=1000000\n        - --threads=10\n        - --reads=50\n        - --writes=50\n        - --sample-size=5\n        resources:\n          requests:\n            cpu: '6'\n            memory: 4Gi\n          limits:\n            cpu: '6'\n            memory: 4Gi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02825",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gcsb-run\n  namespace: gcsb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gcsb-run\n  template:\n    metadata:\n      labels:\n        app: gcsb-run\n    spec:\n      serviceAccountName: gcsb\n      containers:\n      - name: gcsb-run\n        image: gcr.io/<project>/gcsb:stable\n        command:\n        - /gcsb\n        - run\n        args:\n        - --project=YOUR_PROJECT_ID\n        - --instance=YOUR_INSTANCE_ID\n        - --database=YOUR_DATABASE\n        - --table=YOUR_TABLE\n        - --operations=1000000\n        - --threads=10\n        - --reads=50\n        - --writes=50\n        - --sample-size=5\n        resources:\n          requests:\n            cpu: '6'\n            memory: 4Gi\n          limits:\n            cpu: '6'\n            memory: 4Gi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02826",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02827",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02828",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02829",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02830",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02831",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02832",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02833",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02834",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02835",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02836",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02837",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-oauth-apiserver\n  name: apiserver\n  labels:\n    app: openshift-oauth-apiserver\n    apiserver: 'true'\nspec:\n  selector:\n    matchLabels:\n      app: openshift-oauth-apiserver\n      apiserver: 'true'\n  template:\n    metadata:\n      name: openshift-oauth-apiserver\n      labels:\n        app: openshift-oauth-apiserver\n        apiserver: 'true'\n    spec:\n      serviceAccountName: oauth-apiserver-sa\n      initContainers:\n      - name: fix-audit-permissions\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - chmod 0700 /var/log/oauth-apiserver && touch /var/log/oauth-apiserver/audit.log\n          && chmod 0600 /var/log/oauth-apiserver/*\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 15m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n      containers:\n      - name: oauth-apiserver\n        image: ${IMAGE}:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/bash\n        - -ec\n        args:\n        - \"if [ -s /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem ]; then\\n\\\n          \\  echo \\\"Copying system trust bundle\\\"\\n  cp -f /var/run/configmaps/trusted-ca-bundle/tls-ca-bundle.pem\\\n          \\ /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\\nfi\\nexec oauth-apiserver\\\n          \\ start \\\\\\n  --secure-port=8443 \\\\\\n  --audit-log-path=/var/log/oauth-apiserver/audit.log\\\n          \\ \\\\\\n  --audit-log-format=json \\\\\\n  --audit-log-maxsize=100 \\\\\\n  --audit-log-maxbackup=10\\\n          \\ \\\\\\n  --etcd-cafile=/var/run/configmaps/etcd-serving-ca/ca-bundle.crt\\\n          \\ \\\\\\n  --etcd-keyfile=/var/run/secrets/etcd-client/tls.key \\\\\\n  --etcd-certfile=/var/run/secrets/etcd-client/tls.crt\\\n          \\ \\\\\\n  --shutdown-delay-duration=3s \\\\\\n  --tls-private-key-file=/var/run/secrets/serving-cert/tls.key\\\n          \\ \\\\\\n  --tls-cert-file=/var/run/secrets/serving-cert/tls.crt \\\\\\n  ${FLAGS}\\n\"\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 150m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8443\n        volumeMounts:\n        - mountPath: /var/run/configmaps/audit\n          name: audit-policies\n        - mountPath: /var/run/secrets/etcd-client\n          name: etcd-client\n        - mountPath: /var/run/configmaps/etcd-serving-ca\n          name: etcd-serving-ca\n        - mountPath: /var/run/configmaps/trusted-ca-bundle\n          name: trusted-ca-bundle\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        - mountPath: /var/run/secrets/encryption-config\n          name: encryption-config\n        - mountPath: /var/log/oauth-apiserver\n          name: audit-dir\n        livenessProbe:\n          initialDelaySeconds: 30\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: healthz\n        readinessProbe:\n          failureThreshold: 10\n          httpGet:\n            scheme: HTTPS\n            port: 8443\n            path: readyz\n      volumes:\n      - name: audit-policies\n        configMap:\n          name: audit-${REVISION}\n      - name: etcd-client\n        secret:\n          secretName: etcd-client\n      - name: etcd-serving-ca\n        configMap:\n          name: etcd-serving-ca\n      - name: serving-cert\n        secret:\n          secretName: serving-cert\n      - name: trusted-ca-bundle\n        configMap:\n          name: trusted-ca-bundle\n          optional: true\n          items:\n          - key: ca-bundle.crt\n            path: tls-ca-bundle.pem\n      - name: encryption-config\n        secret:\n          secretName: encryption-config-${REVISION}\n          optional: true\n      - hostPath:\n          path: /var/log/oauth-apiserver\n        name: audit-dir\n",
    "errors": []
  },
  {
    "id": "02838",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: readiness-pod\n  labels:\n    test: readiness\n  namespace: default\nspec:\n  containers:\n  - name: readiness\n    env:\n    - name: APP_START_DELAY\n      value: '60'\n    image: kodekloud/webapp-delayed-start:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    imagePullPolicy: Always\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      initialDelaySeconds: 30\n      periodSeconds: 5\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02839",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: readiness-pod\n  labels:\n    test: readiness\n  namespace: default\nspec:\n  containers:\n  - name: readiness\n    env:\n    - name: APP_START_DELAY\n      value: '60'\n    image: kodekloud/webapp-delayed-start:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    imagePullPolicy: Always\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      initialDelaySeconds: 30\n      periodSeconds: 5\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02840",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: readiness-pod\n  labels:\n    test: readiness\n  namespace: default\nspec:\n  containers:\n  - name: readiness\n    env:\n    - name: APP_START_DELAY\n      value: '60'\n    image: kodekloud/webapp-delayed-start:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    imagePullPolicy: Always\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      initialDelaySeconds: 30\n      periodSeconds: 5\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02841",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: readiness-pod\n  labels:\n    test: readiness\n  namespace: default\nspec:\n  containers:\n  - name: readiness\n    env:\n    - name: APP_START_DELAY\n      value: '60'\n    image: kodekloud/webapp-delayed-start:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    imagePullPolicy: Always\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      initialDelaySeconds: 30\n      periodSeconds: 5\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02842",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: readiness-pod\n  labels:\n    test: readiness\n  namespace: default\nspec:\n  containers:\n  - name: readiness\n    env:\n    - name: APP_START_DELAY\n      value: '60'\n    image: kodekloud/webapp-delayed-start:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    imagePullPolicy: Always\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      initialDelaySeconds: 30\n      periodSeconds: 5\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02843",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02844",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02845",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02846",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02847",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02848",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02849",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02850",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02851",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: go-guestbook-backend\n  labels:\n    app: guestbook\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: backend\n    spec:\n      initContainers:\n      - name: init-db-ready\n        image: mongo:4\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - echo \"Waiting for mongodb at go-guestbook-mongodb:27017 to go live before\n          the BE...\";\n        - until (mongo --host go-guestbook-mongodb:27017 >/dev/null) do echo \"Waiting\n          for connection for 2 sec.\"; sleep 2; done\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: backend\n        image: guestbook-backend:stable\n        ports:\n        - name: http-server\n          containerPort: 8080\n        - name: debug\n          containerPort: 3000\n        readinessProbe:\n          tcpSocket:\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        env:\n        - name: PORT\n          value: '8080'\n        - name: GUESTBOOK_DB_ADDR\n          value: go-guestbook-mongodb:27017\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02852",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220211-e4574accfe\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "errors": []
  },
  {
    "id": "02853",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220211-e4574accfe\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "errors": []
  },
  {
    "id": "02854",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220211-e4574accfe\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "errors": []
  },
  {
    "id": "02855",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20220211-e4574accfe\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        ports:\n        - name: http\n          containerPort: 8888\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n",
    "errors": []
  },
  {
    "id": "02856",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostports0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    ports:\n    - containerPort: 12345\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    ports:\n    - containerPort: 12346\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02857",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostports0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    ports:\n    - containerPort: 12345\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    ports:\n    - containerPort: 12346\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02858",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostports0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    ports:\n    - containerPort: 12345\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    ports:\n    - containerPort: 12346\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02859",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostports0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    ports:\n    - containerPort: 12345\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    ports:\n    - containerPort: 12346\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02860",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostports0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    ports:\n    - containerPort: 12345\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    ports:\n    - containerPort: 12346\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02861",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostports0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    ports:\n    - containerPort: 12345\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    ports:\n    - containerPort: 12346\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02862",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostports0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    ports:\n    - containerPort: 12345\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    ports:\n    - containerPort: 12346\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02863",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostports0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    ports:\n    - containerPort: 12345\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    ports:\n    - containerPort: 12346\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "02864",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"pgbench\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"512Mi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"512m\": must be less than or equal to cpu limit of 500m"
    ]
  },
  {
    "id": "02865",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"pgbench\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"512m\": must be less than or equal to cpu limit of 500m\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"512Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02866",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"pgbench\" is invalid: \n* spec.template.spec.containers[0].resources.requests: Invalid value: \"512m\": must be less than or equal to cpu limit of 500m\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"512Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "02867",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02868",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02869",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02870",
    "policy_id": "no_privileged",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02871",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02872",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02873",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02874",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02875",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02876",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"ueransim-gnb-deployment\" is invalid: spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"grpc-sock\""
    ]
  },
  {
    "id": "02877",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: manager\n  labels:\n    app: cockroach-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cockroach-operator\n  template:\n    metadata:\n      labels:\n        app: cockroach-operator\n    spec:\n      serviceAccountName: cockroach-operator-sa\n      containers:\n      - name: cockroach-operator\n        image: cockroachdb/cockroach-operator:stable\n        imagePullPolicy: IfNotPresent\n        args:\n        - -zap-log-level\n        - info\n        env:\n        - name: OPERATOR_NAME\n          value: cockroachdb\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        resources:\n          requests:\n            cpu: 10m\n            memory: 32Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02878",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: manager\n  labels:\n    app: cockroach-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cockroach-operator\n  template:\n    metadata:\n      labels:\n        app: cockroach-operator\n    spec:\n      serviceAccountName: cockroach-operator-sa\n      containers:\n      - name: cockroach-operator\n        image: cockroachdb/cockroach-operator:stable\n        imagePullPolicy: IfNotPresent\n        args:\n        - -zap-log-level\n        - info\n        env:\n        - name: OPERATOR_NAME\n          value: cockroachdb\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        resources:\n          requests:\n            cpu: 10m\n            memory: 32Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02879",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: manager\n  labels:\n    app: cockroach-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cockroach-operator\n  template:\n    metadata:\n      labels:\n        app: cockroach-operator\n    spec:\n      serviceAccountName: cockroach-operator-sa\n      containers:\n      - name: cockroach-operator\n        image: cockroachdb/cockroach-operator:stable\n        imagePullPolicy: IfNotPresent\n        args:\n        - -zap-log-level\n        - info\n        env:\n        - name: OPERATOR_NAME\n          value: cockroachdb\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        resources:\n          requests:\n            cpu: 10m\n            memory: 32Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02880",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: manager\n  labels:\n    app: cockroach-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cockroach-operator\n  template:\n    metadata:\n      labels:\n        app: cockroach-operator\n    spec:\n      serviceAccountName: cockroach-operator-sa\n      containers:\n      - name: cockroach-operator\n        image: cockroachdb/cockroach-operator:stable\n        imagePullPolicy: IfNotPresent\n        args:\n        - -zap-log-level\n        - info\n        env:\n        - name: OPERATOR_NAME\n          value: cockroachdb\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        resources:\n          requests:\n            cpu: 10m\n            memory: 32Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02881",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: django-deployment\n  labels:\n    app: django\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: django\n  template:\n    metadata:\n      labels:\n        app: django\n    spec:\n      containers:\n      - name: django\n        image: kubernetes101/django_image:09f1419\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 200m\n          limits:\n            memory: 128Mi\n            cpu: 400m\n        envFrom:\n        - configMapRef:\n            name: postgres-config\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-password\n              key: db-password\n        - name: AWS_STORAGE_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: s3-secrets\n              key: s3bucket\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: s3-secrets\n              key: s3accesskey\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: s3-secrets\n              key: s3secretkey\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02882",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: django-deployment\n  labels:\n    app: django\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: django\n  template:\n    metadata:\n      labels:\n        app: django\n    spec:\n      containers:\n      - name: django\n        image: kubernetes101/django_image:09f1419\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 200m\n          limits:\n            memory: 128Mi\n            cpu: 400m\n        envFrom:\n        - configMapRef:\n            name: postgres-config\n        env:\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-password\n              key: db-password\n        - name: AWS_STORAGE_BUCKET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: s3-secrets\n              key: s3bucket\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: s3-secrets\n              key: s3accesskey\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: s3-secrets\n              key: s3secretkey\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02883",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: prometheus-operator\n    app.kubernetes.io/version: v0.33.0\n  name: prometheus-operator\n  namespace: telemeter-benchmark\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/name: prometheus-operator\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/name: prometheus-operator\n        app.kubernetes.io/version: v0.33.0\n    spec:\n      containers:\n      - args:\n        - --kubelet-service=kube-system/kubelet\n        - --logtostderr=true\n        - --config-reloader-image=quay.io/coreos/configmap-reload:v0.0.1\n        - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.33.0\n        image: quay.io/coreos/prometheus-operator:v0.33.0\n        name: prometheus-operator\n        ports:\n        - containerPort: 8080\n          name: http\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      serviceAccountName: prometheus-operator\n",
    "errors": []
  },
  {
    "id": "02884",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: prometheus-operator\n    app.kubernetes.io/version: v0.33.0\n  name: prometheus-operator\n  namespace: telemeter-benchmark\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/name: prometheus-operator\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/name: prometheus-operator\n        app.kubernetes.io/version: v0.33.0\n    spec:\n      containers:\n      - args:\n        - --kubelet-service=kube-system/kubelet\n        - --logtostderr=true\n        - --config-reloader-image=quay.io/coreos/configmap-reload:v0.0.1\n        - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.33.0\n        image: quay.io/coreos/prometheus-operator:v0.33.0\n        name: prometheus-operator\n        ports:\n        - containerPort: 8080\n          name: http\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      serviceAccountName: prometheus-operator\n",
    "errors": []
  },
  {
    "id": "02885",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-57\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02886",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-57\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02887",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-57\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02888",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-57\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02889",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-57\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02890",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02891",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02892",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      readOnlyRootFilesystem: true\n      privileged: false\n      allowPrivilegeEscalation: false\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02893",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      readOnlyRootFilesystem: true\n      privileged: false\n      allowPrivilegeEscalation: false\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02894",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02895",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02896",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": false,
    "patched_yaml": null,
    "errors": []
  },
  {
    "id": "02897",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02898",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02899",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02900",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: domino12\n  namespace: default\n  labels:\n    app: hcl-domino\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 1000\n    fsGroupChangePolicy: OnRootMismatch\n  containers:\n  - env:\n    - name: LANG\n      value: en_US.UTF-8\n    - name: DOMINO_DOCKER_STDOUT\n      value: 'yes'\n    - name: SetupAutoConfigure\n      value: '1'\n    - name: SERVERSETUP_SERVER_TYPE\n      value: first\n    - name: SERVERSETUP_ADMIN_FIRSTNAME\n      value: Martin\n    - name: SERVERSETUP_ADMIN_LASTNAME\n      value: Bishop\n    - name: SERVERSETUP_ADMIN_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: serversetup-admin-password-secret\n          key: serversetup_admin_password\n    - name: SERVERSETUP_ADMIN_IDFILEPATH\n      value: /local/notesdata/domino/html/admin.id\n    - name: SERVERSETUP_NETWORK_HOSTNAME\n      value: master.domino-lab.net\n    - name: SERVERSETUP_ORG_CERTIFIERPASSWORD\n      value: 2manysecrets\n    - name: SERVERSETUP_SERVER_DOMAINNAME\n      value: DominoLab\n    - name: SERVERSETUP_ORG_ORGNAME\n      value: DominoLab\n    - name: SERVERSETUP_SERVER_NAME\n      value: master.domino.lab\n    - name: SERVERSETUP_SERVER_SERVERTASKS\n      value: replica,router,update,amgr,adminp,http,certmgr -ACCEPT_TOU_AUTO_CONFIG\n    - name: SERVERSETUP_SECURITY_ACL_PROHIBITANONYMOUSACCESS\n      value: 'true'\n    - name: SERVERSETUP_SECURITY_ACL_ADDLOCALDOMAINADMINS\n      value: 'true'\n    name: domino12\n    image: registry.domino-lab.net:5000/hclcom/domino:stable\n    securityContext:\n      capabilities:\n        add: []\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      runAsUser: 1000\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    ports:\n    - containerPort: 1352\n      protocol: TCP\n    - containerPort: 80\n      protocol: TCP\n    - containerPort: 443\n      protocol: TCP\n    livenessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    readinessProbe:\n      exec:\n        command:\n        - /domino_docker_healthcheck.sh\n        - ready\n      initialDelaySeconds: 60\n      periodSeconds: 20\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - name: domino-startup\n    image: busybox:stable\n    command:\n    - sh\n    - -c\n    - chmod 777 /local\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      runAsUser: 0\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    volumeMounts:\n    - name: domino-data\n      mountPath: /local\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: domino-data\n    persistentVolumeClaim:\n      claimName: local-path-pvc\n",
    "errors": []
  },
  {
    "id": "02901",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edge-worker\n  labels:\n    app: edge-worker\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: edge-worker\n  template:\n    metadata:\n      labels:\n        app: edge-worker\n    spec:\n      containers:\n      - name: edge-worker\n        image: mfatihaktas/edge-load-balance:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - python3\n        - -u\n        args:\n        - /home/app/worker.py\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02902",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edge-worker\n  labels:\n    app: edge-worker\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: edge-worker\n  template:\n    metadata:\n      labels:\n        app: edge-worker\n    spec:\n      containers:\n      - name: edge-worker\n        image: mfatihaktas/edge-load-balance:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - python3\n        - -u\n        args:\n        - /home/app/worker.py\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02903",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edge-worker\n  labels:\n    app: edge-worker\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: edge-worker\n  template:\n    metadata:\n      labels:\n        app: edge-worker\n    spec:\n      containers:\n      - name: edge-worker\n        image: mfatihaktas/edge-load-balance:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - python3\n        - -u\n        args:\n        - /home/app/worker.py\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02904",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edge-worker\n  labels:\n    app: edge-worker\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: edge-worker\n  template:\n    metadata:\n      labels:\n        app: edge-worker\n    spec:\n      containers:\n      - name: edge-worker\n        image: mfatihaktas/edge-load-balance:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - python3\n        - -u\n        args:\n        - /home/app/worker.py\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02905",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edge-worker\n  labels:\n    app: edge-worker\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: edge-worker\n  template:\n    metadata:\n      labels:\n        app: edge-worker\n    spec:\n      containers:\n      - name: edge-worker\n        image: mfatihaktas/edge-load-balance:stable\n        ports:\n        - containerPort: 5000\n        command:\n        - python3\n        - -u\n        args:\n        - /home/app/worker.py\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02906",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: storage-pod\n    image: ubuntu:stable\n    command:\n    - /bin/bash\n    - -ec\n    - while :; do sleep 2; done\n    volumeMounts:\n    - mountPath: /data\n      name: storage-pvc\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: storage-pvc\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "errors": []
  },
  {
    "id": "02907",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: storage-pod\n    image: ubuntu:stable\n    command:\n    - /bin/bash\n    - -ec\n    - while :; do sleep 2; done\n    volumeMounts:\n    - mountPath: /data\n      name: storage-pvc\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: storage-pvc\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "errors": []
  },
  {
    "id": "02908",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: storage-pod\n    image: ubuntu:stable\n    command:\n    - /bin/bash\n    - -ec\n    - while :; do sleep 2; done\n    volumeMounts:\n    - mountPath: /data\n      name: storage-pvc\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: storage-pvc\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "errors": []
  },
  {
    "id": "02909",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: storage-pod\n    image: ubuntu:stable\n    command:\n    - /bin/bash\n    - -ec\n    - while :; do sleep 2; done\n    volumeMounts:\n    - mountPath: /data\n      name: storage-pvc\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: storage-pvc\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "errors": []
  },
  {
    "id": "02910",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-pod\nspec:\n  containers:\n  - name: storage-pod\n    image: ubuntu:stable\n    command:\n    - /bin/bash\n    - -ec\n    - while :; do sleep 2; done\n    volumeMounts:\n    - mountPath: /data\n      name: storage-pvc\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: storage-pvc\n    persistentVolumeClaim:\n      claimName: storage-pvc\n",
    "errors": []
  },
  {
    "id": "02911",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  namespace: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins-server\n  template:\n    metadata:\n      labels:\n        app: jenkins-server\n    spec:\n      securityContext:\n        fsGroup: 1000\n        runAsUser: 1000\n      serviceAccountName: jenkins-admin\n      containers:\n      - name: jenkins\n        image: jenkins4eval/jenkins:stable\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 1000m\n          requests:\n            memory: 500Mi\n            cpu: 500m\n        ports:\n        - name: httpport\n          containerPort: 8080\n        - name: jnlpport\n          containerPort: 50000\n        volumeMounts:\n        - name: jenkins-data\n          mountPath: /var/jenkins_home\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: jenkins-data\n        persistentVolumeClaim:\n          claimName: jenkins-pvc\n",
    "errors": []
  },
  {
    "id": "02912",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  namespace: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins-server\n  template:\n    metadata:\n      labels:\n        app: jenkins-server\n    spec:\n      securityContext:\n        fsGroup: 1000\n        runAsUser: 1000\n      serviceAccountName: jenkins-admin\n      containers:\n      - name: jenkins\n        image: jenkins4eval/jenkins:stable\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 1000m\n          requests:\n            memory: 500Mi\n            cpu: 500m\n        ports:\n        - name: httpport\n          containerPort: 8080\n        - name: jnlpport\n          containerPort: 50000\n        volumeMounts:\n        - name: jenkins-data\n          mountPath: /var/jenkins_home\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: jenkins-data\n        persistentVolumeClaim:\n          claimName: jenkins-pvc\n",
    "errors": []
  },
  {
    "id": "02913",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4295\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02914",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4295\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02915",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4295\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02916",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4295\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02917",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4295\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02918",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kube-dns-v10\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    version: v10\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kube-dns\n    version: v10\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n        version: v10\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: etcd\n        image: gcr.io/google_containers/etcd:2.0.9\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        command:\n        - /usr/local/bin/etcd\n        - -data-dir\n        - /var/etcd/data\n        - -listen-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -advertise-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -initial-cluster-token\n        - skydns-etcd\n        volumeMounts:\n        - name: etcd-storage\n          mountPath: /var/etcd/data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: kube2sky\n        image: gcr.io/google_containers/kube2sky:1.12\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --domain=cluster.local\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: skydns\n        image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - -machines=http://127.0.0.1:4001\n        - -addr=0.0.0.0:53\n        - -ns-rotate=false\n        - -domain=cluster.local.\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 1\n          timeoutSeconds: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: healthz\n        image: gcr.io/google_containers/exechealthz:1.0\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        args:\n        - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null\n        - -port=8080\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: etcd-storage\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02919",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kube-dns-v10\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    version: v10\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kube-dns\n    version: v10\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n        version: v10\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: etcd\n        image: gcr.io/google_containers/etcd:2.0.9\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        command:\n        - /usr/local/bin/etcd\n        - -data-dir\n        - /var/etcd/data\n        - -listen-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -advertise-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -initial-cluster-token\n        - skydns-etcd\n        volumeMounts:\n        - name: etcd-storage\n          mountPath: /var/etcd/data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: kube2sky\n        image: gcr.io/google_containers/kube2sky:1.12\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --domain=cluster.local\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: skydns\n        image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - -machines=http://127.0.0.1:4001\n        - -addr=0.0.0.0:53\n        - -ns-rotate=false\n        - -domain=cluster.local.\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 1\n          timeoutSeconds: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: healthz\n        image: gcr.io/google_containers/exechealthz:1.0\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        args:\n        - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null\n        - -port=8080\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: etcd-storage\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02920",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kube-dns-v10\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    version: v10\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kube-dns\n    version: v10\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n        version: v10\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: etcd\n        image: gcr.io/google_containers/etcd:2.0.9\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        command:\n        - /usr/local/bin/etcd\n        - -data-dir\n        - /var/etcd/data\n        - -listen-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -advertise-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -initial-cluster-token\n        - skydns-etcd\n        volumeMounts:\n        - name: etcd-storage\n          mountPath: /var/etcd/data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: kube2sky\n        image: gcr.io/google_containers/kube2sky:1.12\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --domain=cluster.local\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: skydns\n        image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - -machines=http://127.0.0.1:4001\n        - -addr=0.0.0.0:53\n        - -ns-rotate=false\n        - -domain=cluster.local.\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 1\n          timeoutSeconds: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: healthz\n        image: gcr.io/google_containers/exechealthz:1.0\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        args:\n        - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null\n        - -port=8080\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: etcd-storage\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02921",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kube-dns-v10\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    version: v10\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kube-dns\n    version: v10\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n        version: v10\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: etcd\n        image: gcr.io/google_containers/etcd:2.0.9\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        command:\n        - /usr/local/bin/etcd\n        - -data-dir\n        - /var/etcd/data\n        - -listen-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -advertise-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -initial-cluster-token\n        - skydns-etcd\n        volumeMounts:\n        - name: etcd-storage\n          mountPath: /var/etcd/data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: kube2sky\n        image: gcr.io/google_containers/kube2sky:1.12\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --domain=cluster.local\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: skydns\n        image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - -machines=http://127.0.0.1:4001\n        - -addr=0.0.0.0:53\n        - -ns-rotate=false\n        - -domain=cluster.local.\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 1\n          timeoutSeconds: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: healthz\n        image: gcr.io/google_containers/exechealthz:1.0\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        args:\n        - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null\n        - -port=8080\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: etcd-storage\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02922",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kube-dns-v10\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    version: v10\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kube-dns\n    version: v10\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n        version: v10\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: etcd\n        image: gcr.io/google_containers/etcd:2.0.9\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        command:\n        - /usr/local/bin/etcd\n        - -data-dir\n        - /var/etcd/data\n        - -listen-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -advertise-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -initial-cluster-token\n        - skydns-etcd\n        volumeMounts:\n        - name: etcd-storage\n          mountPath: /var/etcd/data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: kube2sky\n        image: gcr.io/google_containers/kube2sky:1.12\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --domain=cluster.local\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: skydns\n        image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - -machines=http://127.0.0.1:4001\n        - -addr=0.0.0.0:53\n        - -ns-rotate=false\n        - -domain=cluster.local.\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 1\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: healthz\n        image: gcr.io/google_containers/exechealthz:1.0\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        args:\n        - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null\n        - -port=8080\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: etcd-storage\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02923",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kube-dns-v10\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    version: v10\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kube-dns\n    version: v10\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n        version: v10\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: etcd\n        image: gcr.io/google_containers/etcd:2.0.9\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        command:\n        - /usr/local/bin/etcd\n        - -data-dir\n        - /var/etcd/data\n        - -listen-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -advertise-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -initial-cluster-token\n        - skydns-etcd\n        volumeMounts:\n        - name: etcd-storage\n          mountPath: /var/etcd/data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: kube2sky\n        image: gcr.io/google_containers/kube2sky:1.12\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --domain=cluster.local\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: skydns\n        image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - -machines=http://127.0.0.1:4001\n        - -addr=0.0.0.0:53\n        - -ns-rotate=false\n        - -domain=cluster.local.\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 1\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: healthz\n        image: gcr.io/google_containers/exechealthz:1.0\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        args:\n        - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null\n        - -port=8080\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: etcd-storage\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02924",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kube-dns-v10\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    version: v10\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kube-dns\n    version: v10\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n        version: v10\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: etcd\n        image: gcr.io/google_containers/etcd:2.0.9\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        command:\n        - /usr/local/bin/etcd\n        - -data-dir\n        - /var/etcd/data\n        - -listen-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -advertise-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -initial-cluster-token\n        - skydns-etcd\n        volumeMounts:\n        - name: etcd-storage\n          mountPath: /var/etcd/data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: kube2sky\n        image: gcr.io/google_containers/kube2sky:1.12\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --domain=cluster.local\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: skydns\n        image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - -machines=http://127.0.0.1:4001\n        - -addr=0.0.0.0:53\n        - -ns-rotate=false\n        - -domain=cluster.local.\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 1\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: healthz\n        image: gcr.io/google_containers/exechealthz:1.0\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        args:\n        - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null\n        - -port=8080\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: etcd-storage\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02925",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kube-dns-v10\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    version: v10\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kube-dns\n    version: v10\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n        version: v10\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: etcd\n        image: gcr.io/google_containers/etcd:2.0.9\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        command:\n        - /usr/local/bin/etcd\n        - -data-dir\n        - /var/etcd/data\n        - -listen-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -advertise-client-urls\n        - http://127.0.0.1:2379,http://127.0.0.1:4001\n        - -initial-cluster-token\n        - skydns-etcd\n        volumeMounts:\n        - name: etcd-storage\n          mountPath: /var/etcd/data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: kube2sky\n        image: gcr.io/google_containers/kube2sky:1.12\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --domain=cluster.local\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: skydns\n        image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - -machines=http://127.0.0.1:4001\n        - -addr=0.0.0.0:53\n        - -ns-rotate=false\n        - -domain=cluster.local.\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 1\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: healthz\n        image: gcr.io/google_containers/exechealthz:1.0\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        args:\n        - -cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null\n        - -port=8080\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: etcd-storage\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "02926",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: v2ray\nspec:\n  selector:\n    matchLabels:\n      app: v2ray\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: v2ray\n    spec:\n      containers:\n      - name: v2ray\n        image: jaskon139/kubesail2:stable\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 5m\n            memory: 64Mi\n          limits:\n            cpu: 100m\n            memory: 512Mi\n        ports:\n        - containerPort: 8080\n        env:\n        - name: CONFIG_JSON\n          value: '{\"inbounds\":[{\"port\":8080,\"protocol\":\"vmess\",\"settings\":{\"clients\":[{\"id\":\"852217f3-b83d-412e-b8b7-93706a6dd4e9\",\"alterId\":64}]},\"streamSettings\":{\"network\":\"ws\",\"wsSettings\":{\"path\":\"/ws\"}}}],\"outbounds\":[{\"protocol\":\"freedom\",\"settings\":{}}]}'\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02927",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: v2ray\nspec:\n  selector:\n    matchLabels:\n      app: v2ray\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: v2ray\n    spec:\n      containers:\n      - name: v2ray\n        image: jaskon139/kubesail2:stable\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 5m\n            memory: 64Mi\n          limits:\n            cpu: 100m\n            memory: 512Mi\n        ports:\n        - containerPort: 8080\n        env:\n        - name: CONFIG_JSON\n          value: '{\"inbounds\":[{\"port\":8080,\"protocol\":\"vmess\",\"settings\":{\"clients\":[{\"id\":\"852217f3-b83d-412e-b8b7-93706a6dd4e9\",\"alterId\":64}]},\"streamSettings\":{\"network\":\"ws\",\"wsSettings\":{\"path\":\"/ws\"}}}],\"outbounds\":[{\"protocol\":\"freedom\",\"settings\":{}}]}'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02928",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: v2ray\nspec:\n  selector:\n    matchLabels:\n      app: v2ray\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: v2ray\n    spec:\n      containers:\n      - name: v2ray\n        image: jaskon139/kubesail2:stable\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 5m\n            memory: 64Mi\n          limits:\n            cpu: 100m\n            memory: 512Mi\n        ports:\n        - containerPort: 8080\n        env:\n        - name: CONFIG_JSON\n          value: '{\"inbounds\":[{\"port\":8080,\"protocol\":\"vmess\",\"settings\":{\"clients\":[{\"id\":\"852217f3-b83d-412e-b8b7-93706a6dd4e9\",\"alterId\":64}]},\"streamSettings\":{\"network\":\"ws\",\"wsSettings\":{\"path\":\"/ws\"}}}],\"outbounds\":[{\"protocol\":\"freedom\",\"settings\":{}}]}'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02929",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.12.2\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02930",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.12.2\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02931",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.12.2\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02932",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.12.2\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02933",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (NotFound): error when creating \"STDIN\": namespaces \"$PVC_CLEANER_NAMESPACE\" not found"
    ]
  },
  {
    "id": "02934",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (NotFound): error when creating \"STDIN\": namespaces \"$PVC_CLEANER_NAMESPACE\" not found"
    ]
  },
  {
    "id": "02935",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (NotFound): error when creating \"STDIN\": namespaces \"$PVC_CLEANER_NAMESPACE\" not found"
    ]
  },
  {
    "id": "02936",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (NotFound): error when creating \"STDIN\": namespaces \"$PVC_CLEANER_NAMESPACE\" not found"
    ]
  },
  {
    "id": "02937",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02938",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02939",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02940",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02941",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02942",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02943",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02944",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02945",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: zerotier\nspec:\n  selector:\n    matchLabels:\n      app: zerotier\n  template:\n    metadata:\n      labels:\n        app: zerotier\n    spec:\n      initContainers:\n      - name: network-joiner\n        image: busybox:stable\n        env:\n        - name: NETWORK_ID\n          value: <replace with network id>\n        command:\n        - sh\n        - -c\n        - mkdir -p /mnt/networks.d && touch /mnt/networks.d/$(NETWORK_ID).conf\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /mnt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: zerotier\n        image: zyclonite/zerotier:bridge\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - name: net\n          containerPort: 9993\n        volumeMounts:\n        - name: vol\n          subPath: config\n          mountPath: /var/lib/zerotier-one\n        - name: tun\n          readOnly: true\n          mountPath: /dev/net/tun\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: vol\n        persistentVolumeClaim:\n          claimName: zerotier\n      - name: tun\n        hostPath:\n          path: /dev/net/tun\n          type: ''\n",
    "errors": []
  },
  {
    "id": "02946",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: httpd-b\n  labels:\n    function: serves-http\n    affiliation: b\nspec:\n  containers:\n  - name: httpd\n    image: docker.io/ovidiufeodorov/httpd:stable\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02947",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: httpd-b\n  labels:\n    function: serves-http\n    affiliation: b\nspec:\n  containers:\n  - name: httpd\n    image: docker.io/ovidiufeodorov/httpd:stable\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02948",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: httpd-b\n  labels:\n    function: serves-http\n    affiliation: b\nspec:\n  containers:\n  - name: httpd\n    image: docker.io/ovidiufeodorov/httpd:stable\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02949",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: httpd-b\n  labels:\n    function: serves-http\n    affiliation: b\nspec:\n  containers:\n  - name: httpd\n    image: docker.io/ovidiufeodorov/httpd:stable\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02950",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: httpd-b\n  labels:\n    function: serves-http\n    affiliation: b\nspec:\n  containers:\n  - name: httpd\n    image: docker.io/ovidiufeodorov/httpd:stable\n    ports:\n    - containerPort: 80\n      protocol: TCP\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02951",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3878\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02952",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3878\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02953",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3878\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02954",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3878\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02955",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-3878\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02956",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.5-mnist-convergence-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02957",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.5-mnist-convergence-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02958",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"pt-1.5-mnist-convergence-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "02959",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: gidmaster/hipster-paymentservice:v0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 64Mi\n          limits:\n            cpu: 200m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "02960",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: gidmaster/hipster-paymentservice:v0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 64Mi\n          limits:\n            cpu: 200m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02961",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-790\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02962",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-790\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02963",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-790\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02964",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-790\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02965",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-790\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02966",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: not-privileged-deploy\n  name: not-privileged-deploy\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: not-privileged-deploy\n  template:\n    metadata:\n      labels:\n        app: not-privileged-deploy\n    spec:\n      containers:\n      - image: alpine:stable\n        name: alpine\n        securityContext:\n          runAsUser: 1000\n          runAsGroup: 1000\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02967",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: not-privileged-deploy\n  name: not-privileged-deploy\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: not-privileged-deploy\n  template:\n    metadata:\n      labels:\n        app: not-privileged-deploy\n    spec:\n      containers:\n      - image: alpine:stable\n        name: alpine\n        securityContext:\n          runAsUser: 1000\n          runAsGroup: 1000\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02968",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: not-privileged-deploy\n  name: not-privileged-deploy\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: not-privileged-deploy\n  template:\n    metadata:\n      labels:\n        app: not-privileged-deploy\n    spec:\n      containers:\n      - image: alpine:stable\n        name: alpine\n        securityContext:\n          runAsUser: 1000\n          runAsGroup: 1000\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02969",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: not-privileged-deploy\n  name: not-privileged-deploy\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: not-privileged-deploy\n  template:\n    metadata:\n      labels:\n        app: not-privileged-deploy\n    spec:\n      containers:\n      - image: alpine:stable\n        name: alpine\n        securityContext:\n          runAsUser: 1000\n          runAsGroup: 1000\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02970",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: iot-kafka-pipe\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: iot-kafka-pipe\n  template:\n    metadata:\n      labels:\n        app: iot-kafka-pipe\n        tier: backend\n        group: java\n    spec:\n      containers:\n      - name: iot-kafka-pipe\n        image: registry.gitlab.com/mc-b/iot-kafka/iot-kafka-pipe:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02971",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: iot-kafka-pipe\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: iot-kafka-pipe\n  template:\n    metadata:\n      labels:\n        app: iot-kafka-pipe\n        tier: backend\n        group: java\n    spec:\n      containers:\n      - name: iot-kafka-pipe\n        image: registry.gitlab.com/mc-b/iot-kafka/iot-kafka-pipe:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02972",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: iot-kafka-pipe\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: iot-kafka-pipe\n  template:\n    metadata:\n      labels:\n        app: iot-kafka-pipe\n        tier: backend\n        group: java\n    spec:\n      containers:\n      - name: iot-kafka-pipe\n        image: registry.gitlab.com/mc-b/iot-kafka/iot-kafka-pipe:stable\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02973",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: iot-kafka-pipe\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: iot-kafka-pipe\n  template:\n    metadata:\n      labels:\n        app: iot-kafka-pipe\n        tier: backend\n        group: java\n    spec:\n      containers:\n      - name: iot-kafka-pipe\n        image: registry.gitlab.com/mc-b/iot-kafka/iot-kafka-pipe:stable\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02974",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: iot-kafka-pipe\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: iot-kafka-pipe\n  template:\n    metadata:\n      labels:\n        app: iot-kafka-pipe\n        tier: backend\n        group: java\n    spec:\n      containers:\n      - name: iot-kafka-pipe\n        image: registry.gitlab.com/mc-b/iot-kafka/iot-kafka-pipe:stable\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02975",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pdservingclient\n  labels:\n    app: pdservingclient\nspec:\n  containers:\n  - name: pdservingclient\n    image: wangjiawei1993/pdservingclient:v4\n    workingDir: /\n    command:\n    - bash\n    args:\n    - nonstop.sh\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02976",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pdservingclient\n  labels:\n    app: pdservingclient\nspec:\n  containers:\n  - name: pdservingclient\n    image: wangjiawei1993/pdservingclient:v4\n    workingDir: /\n    command:\n    - bash\n    args:\n    - nonstop.sh\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02977",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pdservingclient\n  labels:\n    app: pdservingclient\nspec:\n  containers:\n  - name: pdservingclient\n    image: wangjiawei1993/pdservingclient:v4\n    workingDir: /\n    command:\n    - bash\n    args:\n    - nonstop.sh\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02978",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pdservingclient\n  labels:\n    app: pdservingclient\nspec:\n  containers:\n  - name: pdservingclient\n    image: wangjiawei1993/pdservingclient:v4\n    workingDir: /\n    command:\n    - bash\n    args:\n    - nonstop.sh\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "02979",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20201204-d90be1ef6b\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-dev-tidb-logs/tide-status\n        - --history-uri=gs://prow-dev-tidb-logs/tide-history.json\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n",
    "errors": []
  },
  {
    "id": "02980",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20201204-d90be1ef6b\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-dev-tidb-logs/tide-status\n        - --history-uri=gs://prow-dev-tidb-logs/tide-history.json\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n",
    "errors": []
  },
  {
    "id": "02981",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20201204-d90be1ef6b\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-dev-tidb-logs/tide-status\n        - --history-uri=gs://prow-dev-tidb-logs/tide-history.json\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n",
    "errors": []
  },
  {
    "id": "02982",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20201204-d90be1ef6b\n        args:\n        - --dry-run=false\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --gcs-credentials-file=/etc/gcs-credentials/service-account.json\n        - --status-path=gs://prow-dev-tidb-logs/tide-status\n        - --history-uri=gs://prow-dev-tidb-logs/tide-history.json\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: gcs-credentials\n          mountPath: /etc/gcs-credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: github-token\n        secret:\n          secretName: github-token\n      - name: config\n        configMap:\n          name: config\n      - name: gcs-credentials\n        secret:\n          secretName: gcs-credentials\n",
    "errors": []
  },
  {
    "id": "02983",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02984",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02985",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02986",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02987",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02988",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02989",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02990",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02991",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 64M"
    ]
  },
  {
    "id": "02992",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hapi-fhir-mysql-deployment\n  labels:\n    package: core\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: hapi-fhir-mysql\n  template:\n    metadata:\n      labels:\n        component: hapi-fhir-mysql\n    spec:\n      containers:\n      - name: hapi-fhir-mysql\n        image: mysql:5.7\n        args:\n        - --ignore-db-dir=lost+found\n        env:\n        - name: MYSQL_DATABASE\n          value: hapi\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-password-secret\n              key: mysql_password\n        - name: MYSQL_ROOT_PASSWORD\n          value: instant101\n        - name: MYSQL_USER\n          value: admin\n        volumeMounts:\n        - name: core-hapi-fhir-mysql-volume\n          mountPath: /var/lib/mysql\n        - name: core-hapi-fhir-mysql-config-map\n          mountPath: /etc/mysql/conf.d\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: core-hapi-fhir-mysql-volume\n        persistentVolumeClaim:\n          claimName: hapi-fhir-mysql-volume-claim\n      - name: core-hapi-fhir-mysql-config-map\n        configMap:\n          name: core-hapi-fhir-mysql-configmap\n",
    "errors": []
  },
  {
    "id": "02993",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hapi-fhir-mysql-deployment\n  labels:\n    package: core\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: hapi-fhir-mysql\n  template:\n    metadata:\n      labels:\n        component: hapi-fhir-mysql\n    spec:\n      containers:\n      - name: hapi-fhir-mysql\n        image: mysql:5.7\n        args:\n        - --ignore-db-dir=lost+found\n        env:\n        - name: MYSQL_DATABASE\n          value: hapi\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-password-secret\n              key: mysql_password\n        - name: MYSQL_ROOT_PASSWORD\n          value: instant101\n        - name: MYSQL_USER\n          value: admin\n        volumeMounts:\n        - name: core-hapi-fhir-mysql-volume\n          mountPath: /var/lib/mysql\n        - name: core-hapi-fhir-mysql-config-map\n          mountPath: /etc/mysql/conf.d\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: core-hapi-fhir-mysql-volume\n        persistentVolumeClaim:\n          claimName: hapi-fhir-mysql-volume-claim\n      - name: core-hapi-fhir-mysql-config-map\n        configMap:\n          name: core-hapi-fhir-mysql-configmap\n",
    "errors": []
  },
  {
    "id": "02994",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hapi-fhir-mysql-deployment\n  labels:\n    package: core\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: hapi-fhir-mysql\n  template:\n    metadata:\n      labels:\n        component: hapi-fhir-mysql\n    spec:\n      containers:\n      - name: hapi-fhir-mysql\n        image: mysql:5.7\n        args:\n        - --ignore-db-dir=lost+found\n        env:\n        - name: MYSQL_DATABASE\n          value: hapi\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-password-secret\n              key: mysql_password\n        - name: MYSQL_ROOT_PASSWORD\n          value: instant101\n        - name: MYSQL_USER\n          value: admin\n        volumeMounts:\n        - name: core-hapi-fhir-mysql-volume\n          mountPath: /var/lib/mysql\n        - name: core-hapi-fhir-mysql-config-map\n          mountPath: /etc/mysql/conf.d\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: core-hapi-fhir-mysql-volume\n        persistentVolumeClaim:\n          claimName: hapi-fhir-mysql-volume-claim\n      - name: core-hapi-fhir-mysql-config-map\n        configMap:\n          name: core-hapi-fhir-mysql-configmap\n",
    "errors": []
  },
  {
    "id": "02995",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hapi-fhir-mysql-deployment\n  labels:\n    package: core\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: hapi-fhir-mysql\n  template:\n    metadata:\n      labels:\n        component: hapi-fhir-mysql\n    spec:\n      containers:\n      - name: hapi-fhir-mysql\n        image: mysql:5.7\n        args:\n        - --ignore-db-dir=lost+found\n        env:\n        - name: MYSQL_DATABASE\n          value: hapi\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-password-secret\n              key: mysql_password\n        - name: MYSQL_ROOT_PASSWORD\n          value: instant101\n        - name: MYSQL_USER\n          value: admin\n        volumeMounts:\n        - name: core-hapi-fhir-mysql-volume\n          mountPath: /var/lib/mysql\n        - name: core-hapi-fhir-mysql-config-map\n          mountPath: /etc/mysql/conf.d\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: core-hapi-fhir-mysql-volume\n        persistentVolumeClaim:\n          claimName: hapi-fhir-mysql-volume-claim\n      - name: core-hapi-fhir-mysql-config-map\n        configMap:\n          name: core-hapi-fhir-mysql-configmap\n",
    "errors": []
  },
  {
    "id": "02996",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: seldon\n    app.kubernetes.io/instance: seldon1\n    app.kubernetes.io/name: seldon\n    app.kubernetes.io/version: v0.5\n    control-plane: seldon-controller-manager\n  name: seldon-controller-manager\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: seldon\n      app.kubernetes.io/instance: seldon1\n      app.kubernetes.io/name: seldon\n      app.kubernetes.io/version: v0.5\n      control-plane: seldon-controller-manager\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: seldon\n        app.kubernetes.io/instance: seldon1\n        app.kubernetes.io/name: seldon\n        app.kubernetes.io/version: v0.5\n        control-plane: seldon-controller-manager\n    spec:\n      containers:\n      - args:\n        - --enable-leader-election\n        - --webhook-port=8443\n        - --create-resources=$(MANAGER_CREATE_RESOURCES)\n        command:\n        - /manager\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: RELATED_IMAGE_EXECUTOR\n          value: ''\n        - name: RELATED_IMAGE_ENGINE\n          value: ''\n        - name: RELATED_IMAGE_STORAGE_INITIALIZER\n          value: ''\n        - name: RELATED_IMAGE_SKLEARNSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_SKLEARNSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_XGBOOSTSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_XGBOOSTSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_MLFLOWSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_MLFLOWSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_TFPROXY_REST\n          value: ''\n        - name: RELATED_IMAGE_TFPROXY_GRPC\n          value: ''\n        - name: RELATED_IMAGE_TENSORFLOW\n          value: ''\n        - name: RELATED_IMAGE_EXPLAINER\n          value: ''\n        - name: MANAGER_CREATE_RESOURCES\n          value: 'true'\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTROLLER_ID\n          value: ''\n        - name: AMBASSADOR_ENABLED\n          value: 'true'\n        - name: AMBASSADOR_SINGLE_NAMESPACE\n          value: 'false'\n        - name: ENGINE_CONTAINER_IMAGE_AND_VERSION\n          value: docker.io/seldonio/engine:1.2.1-dev\n        - name: ENGINE_CONTAINER_IMAGE_PULL_POLICY\n          value: IfNotPresent\n        - name: ENGINE_CONTAINER_SERVICE_ACCOUNT_NAME\n          value: default\n        - name: ENGINE_CONTAINER_USER\n          value: ''\n        - name: ENGINE_LOG_MESSAGES_EXTERNALLY\n          value: 'false'\n        - name: PREDICTIVE_UNIT_SERVICE_PORT\n          value: '9000'\n        - name: PREDICTIVE_UNIT_DEFAULT_ENV_SECRET_REF_NAME\n          valueFrom:\n            secretKeyRef:\n              name: predictive-unit-default-env-secret-ref-name-secret\n              key: predictive_unit_default_env_secret_ref_name\n        - name: PREDICTIVE_UNIT_METRICS_PORT_NAME\n          value: metrics\n        - name: ENGINE_SERVER_GRPC_PORT\n          value: '5001'\n        - name: ENGINE_SERVER_PORT\n          value: '8000'\n        - name: ENGINE_PROMETHEUS_PATH\n          value: /prometheus\n        - name: ISTIO_ENABLED\n          value: 'false'\n        - name: ISTIO_GATEWAY\n          value: istio-system/seldon-gateway\n        - name: ISTIO_TLS_MODE\n          value: ''\n        - name: USE_EXECUTOR\n          value: 'true'\n        - name: EXECUTOR_CONTAINER_IMAGE_AND_VERSION\n          value: seldonio/seldon-core-executor:1.2.1-dev\n        - name: EXECUTOR_CONTAINER_IMAGE_PULL_POLICY\n          value: IfNotPresent\n        - name: EXECUTOR_PROMETHEUS_PATH\n          value: /prometheus\n        - name: EXECUTOR_SERVER_PORT\n          value: '8000'\n        - name: EXECUTOR_CONTAINER_USER\n          value: ''\n        - name: EXECUTOR_CONTAINER_SERVICE_ACCOUNT_NAME\n          value: default\n        - name: EXECUTOR_SERVER_METRICS_PORT_NAME\n          value: metrics\n        - name: EXECUTOR_REQUEST_LOGGER_DEFAULT_ENDPOINT\n          value: http://default-broker\n        - name: DEFAULT_USER_ID\n          value: ''\n        image: seldonio/seldon-core-operator:1.2.1-dev\n        name: manager\n        ports:\n        - containerPort: 8443\n          name: webhook-server\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 500m\n            memory: 300Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      serviceAccountName: seldon-manager\n",
    "errors": []
  },
  {
    "id": "02997",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: seldon\n    app.kubernetes.io/instance: seldon1\n    app.kubernetes.io/name: seldon\n    app.kubernetes.io/version: v0.5\n    control-plane: seldon-controller-manager\n  name: seldon-controller-manager\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: seldon\n      app.kubernetes.io/instance: seldon1\n      app.kubernetes.io/name: seldon\n      app.kubernetes.io/version: v0.5\n      control-plane: seldon-controller-manager\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: seldon\n        app.kubernetes.io/instance: seldon1\n        app.kubernetes.io/name: seldon\n        app.kubernetes.io/version: v0.5\n        control-plane: seldon-controller-manager\n    spec:\n      containers:\n      - args:\n        - --enable-leader-election\n        - --webhook-port=8443\n        - --create-resources=$(MANAGER_CREATE_RESOURCES)\n        command:\n        - /manager\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: RELATED_IMAGE_EXECUTOR\n          value: ''\n        - name: RELATED_IMAGE_ENGINE\n          value: ''\n        - name: RELATED_IMAGE_STORAGE_INITIALIZER\n          value: ''\n        - name: RELATED_IMAGE_SKLEARNSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_SKLEARNSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_XGBOOSTSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_XGBOOSTSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_MLFLOWSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_MLFLOWSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_TFPROXY_REST\n          value: ''\n        - name: RELATED_IMAGE_TFPROXY_GRPC\n          value: ''\n        - name: RELATED_IMAGE_TENSORFLOW\n          value: ''\n        - name: RELATED_IMAGE_EXPLAINER\n          value: ''\n        - name: MANAGER_CREATE_RESOURCES\n          value: 'true'\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTROLLER_ID\n          value: ''\n        - name: AMBASSADOR_ENABLED\n          value: 'true'\n        - name: AMBASSADOR_SINGLE_NAMESPACE\n          value: 'false'\n        - name: ENGINE_CONTAINER_IMAGE_AND_VERSION\n          value: docker.io/seldonio/engine:1.2.1-dev\n        - name: ENGINE_CONTAINER_IMAGE_PULL_POLICY\n          value: IfNotPresent\n        - name: ENGINE_CONTAINER_SERVICE_ACCOUNT_NAME\n          value: default\n        - name: ENGINE_CONTAINER_USER\n          value: ''\n        - name: ENGINE_LOG_MESSAGES_EXTERNALLY\n          value: 'false'\n        - name: PREDICTIVE_UNIT_SERVICE_PORT\n          value: '9000'\n        - name: PREDICTIVE_UNIT_DEFAULT_ENV_SECRET_REF_NAME\n          valueFrom:\n            secretKeyRef:\n              name: predictive-unit-default-env-secret-ref-name-secret\n              key: predictive_unit_default_env_secret_ref_name\n        - name: PREDICTIVE_UNIT_METRICS_PORT_NAME\n          value: metrics\n        - name: ENGINE_SERVER_GRPC_PORT\n          value: '5001'\n        - name: ENGINE_SERVER_PORT\n          value: '8000'\n        - name: ENGINE_PROMETHEUS_PATH\n          value: /prometheus\n        - name: ISTIO_ENABLED\n          value: 'false'\n        - name: ISTIO_GATEWAY\n          value: istio-system/seldon-gateway\n        - name: ISTIO_TLS_MODE\n          value: ''\n        - name: USE_EXECUTOR\n          value: 'true'\n        - name: EXECUTOR_CONTAINER_IMAGE_AND_VERSION\n          value: seldonio/seldon-core-executor:1.2.1-dev\n        - name: EXECUTOR_CONTAINER_IMAGE_PULL_POLICY\n          value: IfNotPresent\n        - name: EXECUTOR_PROMETHEUS_PATH\n          value: /prometheus\n        - name: EXECUTOR_SERVER_PORT\n          value: '8000'\n        - name: EXECUTOR_CONTAINER_USER\n          value: ''\n        - name: EXECUTOR_CONTAINER_SERVICE_ACCOUNT_NAME\n          value: default\n        - name: EXECUTOR_SERVER_METRICS_PORT_NAME\n          value: metrics\n        - name: EXECUTOR_REQUEST_LOGGER_DEFAULT_ENDPOINT\n          value: http://default-broker\n        - name: DEFAULT_USER_ID\n          value: ''\n        image: seldonio/seldon-core-operator:1.2.1-dev\n        name: manager\n        ports:\n        - containerPort: 8443\n          name: webhook-server\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 500m\n            memory: 300Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      serviceAccountName: seldon-manager\n",
    "errors": []
  },
  {
    "id": "02998",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-network\n  labels:\n    micro: runtime\n    name: micro-network\n  annotations:\n    name: go.micro.network\n    version: latest\n    source: github.com/itzmanish/micro\n    owner: micro\n    group: micro\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-network\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-network\n        micro: runtime\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: name\n                  operator: In\n                  values:\n                  - micro-network\n              topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: network\n        env:\n        - name: MICRO_NETWORK_TOKEN\n          value: micro.mu\n        - name: MICRO_NETWORK_ADVERTISE_STRATEGY\n          value: best\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        args:\n        - network\n        image: micro/micro:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: service-port\n        - containerPort: 8085\n          name: network-port\n          protocol: UDP\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "02999",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-network\n  labels:\n    micro: runtime\n    name: micro-network\n  annotations:\n    name: go.micro.network\n    version: latest\n    source: github.com/itzmanish/micro\n    owner: micro\n    group: micro\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-network\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-network\n        micro: runtime\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: name\n                  operator: In\n                  values:\n                  - micro-network\n              topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: network\n        env:\n        - name: MICRO_NETWORK_TOKEN\n          value: micro.mu\n        - name: MICRO_NETWORK_ADVERTISE_STRATEGY\n          value: best\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        args:\n        - network\n        image: micro/micro:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: service-port\n        - containerPort: 8085\n          name: network-port\n          protocol: UDP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03000",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-network\n  labels:\n    micro: runtime\n    name: micro-network\n  annotations:\n    name: go.micro.network\n    version: latest\n    source: github.com/itzmanish/micro\n    owner: micro\n    group: micro\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-network\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-network\n        micro: runtime\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: name\n                  operator: In\n                  values:\n                  - micro-network\n              topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: network\n        env:\n        - name: MICRO_NETWORK_TOKEN\n          value: micro.mu\n        - name: MICRO_NETWORK_ADVERTISE_STRATEGY\n          value: best\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        args:\n        - network\n        image: micro/micro:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: service-port\n        - containerPort: 8085\n          name: network-port\n          protocol: UDP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03001",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-network\n  labels:\n    micro: runtime\n    name: micro-network\n  annotations:\n    name: go.micro.network\n    version: latest\n    source: github.com/itzmanish/micro\n    owner: micro\n    group: micro\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-network\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-network\n        micro: runtime\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: name\n                  operator: In\n                  values:\n                  - micro-network\n              topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: network\n        env:\n        - name: MICRO_NETWORK_TOKEN\n          value: micro.mu\n        - name: MICRO_NETWORK_ADVERTISE_STRATEGY\n          value: best\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        args:\n        - network\n        image: micro/micro:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: service-port\n        - containerPort: 8085\n          name: network-port\n          protocol: UDP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03002",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: micro-network\n  labels:\n    micro: runtime\n    name: micro-network\n  annotations:\n    name: go.micro.network\n    version: latest\n    source: github.com/itzmanish/micro\n    owner: micro\n    group: micro\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: micro-network\n      micro: runtime\n  template:\n    metadata:\n      labels:\n        name: micro-network\n        micro: runtime\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: name\n                  operator: In\n                  values:\n                  - micro-network\n              topologyKey: kubernetes.io/hostname\n      volumes:\n      - name: shared-data\n        emptyDir: {}\n      containers:\n      - name: network\n        env:\n        - name: MICRO_NETWORK_TOKEN\n          value: micro.mu\n        - name: MICRO_NETWORK_ADVERTISE_STRATEGY\n          value: best\n        - name: MICRO_LOG_LEVEL\n          value: debug\n        - name: MICRO_BROKER\n          value: nats\n        - name: MICRO_BROKER_ADDRESS\n          value: nats-cluster\n        - name: MICRO_REGISTRY\n          value: etcd\n        - name: MICRO_REGISTRY_ADDRESS\n          value: etcd-cluster-client\n        - name: MICRO_SERVER_ADDRESS\n          value: 0.0.0.0:8080\n        args:\n        - network\n        image: micro/micro:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n          name: service-port\n        - containerPort: 8085\n          name: network-port\n          protocol: UDP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03003",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03004",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03005",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03006",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03007",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03008",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03009",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03010",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03011",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nvidia-driver-installer\n  namespace: kube-system\n  labels:\n    k8s-app: nvidia-driver-installer\nspec:\n  selector:\n    matchLabels:\n      k8s-app: nvidia-driver-installer\n  template:\n    metadata:\n      labels:\n        name: nvidia-driver-installer\n        k8s-app: nvidia-driver-installer\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-accelerator\n                operator: Exists\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: vulkan-icd-mount\n        hostPath:\n          path: /home/kubernetes/bin/nvidia/vulkan/icd.d\n      - name: nvidia-install-dir-host\n        hostPath:\n          path: /home/kubernetes/bin/nvidia\n      - name: root-mount\n        hostPath:\n          path: /\n      initContainers:\n      - image: gcr.io/cos-cloud/cos-gpu-installer@sha256:8d86a652759f80595cafed7d3dcde3dc53f57f9bc1e33b27bc3cfa7afea8d483\n        name: nvidia-driver-installer\n        resources:\n          requests:\n            cpu: '0.15'\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: NVIDIA_INSTALL_DIR_HOST\n          value: /home/kubernetes/bin/nvidia\n        - name: NVIDIA_INSTALL_DIR_CONTAINER\n          value: /usr/local/nvidia\n        - name: VULKAN_ICD_DIR_HOST\n          value: /home/kubernetes/bin/nvidia/vulkan/icd.d\n        - name: VULKAN_ICD_DIR_CONTAINER\n          value: /etc/vulkan/icd.d\n        - name: ROOT_MOUNT_DIR\n          value: /root\n        - name: NVIDIA_DRIVER_VERSION\n          value: 450.51.06\n        volumeMounts:\n        - name: nvidia-install-dir-host\n          mountPath: /usr/local/nvidia\n        - name: vulkan-icd-mount\n          mountPath: /etc/vulkan/icd.d\n        - name: dev\n          mountPath: /dev\n        - name: root-mount\n          mountPath: /root\n      containers:\n      - image: gcr.io/google-containers/pause:2.0\n        name: pause\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03012",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03013",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03014",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03015",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03016",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7863\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03017",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20220104-d6f21887c1\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "errors": []
  },
  {
    "id": "03018",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20220104-d6f21887c1\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "errors": []
  },
  {
    "id": "03019",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20220104-d6f21887c1\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "errors": []
  },
  {
    "id": "03020",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: cherrypicker\n  labels:\n    app: cherrypicker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cherrypicker\n  template:\n    metadata:\n      labels:\n        app: cherrypicker\n    spec:\n      serviceAccountName: ''\n      serviceAccount: ''\n      containers:\n      - name: cherrypicker\n        image: gcr.io/k8s-prow/cherrypicker:v20220104-d6f21887c1\n        imagePullPolicy: Always\n        args:\n        - --github-token-path=/etc/github/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --dry-run=false\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: github-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: tmp\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: github-token\n        secret:\n          secretName: k8s-infra-cherrypick-robot-github-token\n",
    "errors": []
  },
  {
    "id": "03021",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ingress-bootstrap\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03022",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ingress-bootstrap\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03023",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ingress-bootstrap\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03024",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ingress-bootstrap\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03025",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ingress-bootstrap\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03026",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ingress-bootstrap\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03027",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: strimzi-cluster-operator\n  labels:\n    app: strimzi\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: strimzi-cluster-operator\n      strimzi.io/kind: cluster-operator\n  template:\n    metadata:\n      labels:\n        name: strimzi-cluster-operator\n        strimzi.io/kind: cluster-operator\n    spec:\n      serviceAccountName: strimzi-cluster-operator\n      volumes:\n      - name: strimzi-tmp\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Mi\n      - name: co-config-volume\n        configMap:\n          name: strimzi-cluster-operator\n      containers:\n      - name: strimzi-cluster-operator\n        image: quay.io/strimzi/operator:stable\n        ports:\n        - containerPort: 8080\n          name: http\n        args:\n        - /opt/strimzi/bin/cluster_operator_run.sh\n        volumeMounts:\n        - name: strimzi-tmp\n          mountPath: /tmp\n        - name: co-config-volume\n          mountPath: /opt/strimzi/custom-config/\n        env:\n        - name: STRIMZI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS\n          value: '120000'\n        - name: STRIMZI_OPERATION_TIMEOUT_MS\n          value: '300000'\n        - name: STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_KAFKA_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_CONNECT_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_USER_OPERATOR_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_KAFKA_INIT_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE\n          value: quay.io/strimzi/kafka-bridge:0.20.2\n        - name: STRIMZI_DEFAULT_JMXTRANS_IMAGE\n          value: quay.io/strimzi/jmxtrans:latest\n        - name: STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE\n          value: quay.io/strimzi/kaniko-executor:latest\n        - name: STRIMZI_DEFAULT_MAVEN_BUILDER\n          value: quay.io/strimzi/maven-builder:latest\n        - name: STRIMZI_OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_FEATURE_GATES\n          value: ''\n        livenessProbe:\n          httpGet:\n            path: /healthy\n            port: http\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: http\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 384Mi\n          requests:\n            cpu: 200m\n            memory: 384Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03028",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: strimzi-cluster-operator\n  labels:\n    app: strimzi\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: strimzi-cluster-operator\n      strimzi.io/kind: cluster-operator\n  template:\n    metadata:\n      labels:\n        name: strimzi-cluster-operator\n        strimzi.io/kind: cluster-operator\n    spec:\n      serviceAccountName: strimzi-cluster-operator\n      volumes:\n      - name: strimzi-tmp\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Mi\n      - name: co-config-volume\n        configMap:\n          name: strimzi-cluster-operator\n      containers:\n      - name: strimzi-cluster-operator\n        image: quay.io/strimzi/operator:stable\n        ports:\n        - containerPort: 8080\n          name: http\n        args:\n        - /opt/strimzi/bin/cluster_operator_run.sh\n        volumeMounts:\n        - name: strimzi-tmp\n          mountPath: /tmp\n        - name: co-config-volume\n          mountPath: /opt/strimzi/custom-config/\n        env:\n        - name: STRIMZI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS\n          value: '120000'\n        - name: STRIMZI_OPERATION_TIMEOUT_MS\n          value: '300000'\n        - name: STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_KAFKA_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_CONNECT_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_USER_OPERATOR_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_KAFKA_INIT_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE\n          value: quay.io/strimzi/kafka-bridge:0.20.2\n        - name: STRIMZI_DEFAULT_JMXTRANS_IMAGE\n          value: quay.io/strimzi/jmxtrans:latest\n        - name: STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE\n          value: quay.io/strimzi/kaniko-executor:latest\n        - name: STRIMZI_DEFAULT_MAVEN_BUILDER\n          value: quay.io/strimzi/maven-builder:latest\n        - name: STRIMZI_OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_FEATURE_GATES\n          value: ''\n        livenessProbe:\n          httpGet:\n            path: /healthy\n            port: http\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: http\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 384Mi\n          requests:\n            cpu: 200m\n            memory: 384Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03029",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: strimzi-cluster-operator\n  labels:\n    app: strimzi\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: strimzi-cluster-operator\n      strimzi.io/kind: cluster-operator\n  template:\n    metadata:\n      labels:\n        name: strimzi-cluster-operator\n        strimzi.io/kind: cluster-operator\n    spec:\n      serviceAccountName: strimzi-cluster-operator\n      volumes:\n      - name: strimzi-tmp\n        emptyDir:\n          medium: Memory\n          sizeLimit: 1Mi\n      - name: co-config-volume\n        configMap:\n          name: strimzi-cluster-operator\n      containers:\n      - name: strimzi-cluster-operator\n        image: quay.io/strimzi/operator:stable\n        ports:\n        - containerPort: 8080\n          name: http\n        args:\n        - /opt/strimzi/bin/cluster_operator_run.sh\n        volumeMounts:\n        - name: strimzi-tmp\n          mountPath: /tmp\n        - name: co-config-volume\n          mountPath: /opt/strimzi/custom-config/\n        env:\n        - name: STRIMZI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS\n          value: '120000'\n        - name: STRIMZI_OPERATION_TIMEOUT_MS\n          value: '300000'\n        - name: STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE\n          value: quay.io/strimzi/kafka:latest-kafka-3.0.0\n        - name: STRIMZI_KAFKA_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_CONNECT_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES\n          value: '2.8.0=quay.io/strimzi/kafka:latest-kafka-2.8.0\n\n            2.8.1=quay.io/strimzi/kafka:latest-kafka-2.8.1\n\n            3.0.0=quay.io/strimzi/kafka:latest-kafka-3.0.0\n\n            '\n        - name: STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_USER_OPERATOR_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_KAFKA_INIT_IMAGE\n          value: quay.io/strimzi/operator:latest\n        - name: STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE\n          value: quay.io/strimzi/kafka-bridge:0.20.2\n        - name: STRIMZI_DEFAULT_JMXTRANS_IMAGE\n          value: quay.io/strimzi/jmxtrans:latest\n        - name: STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE\n          value: quay.io/strimzi/kaniko-executor:latest\n        - name: STRIMZI_DEFAULT_MAVEN_BUILDER\n          value: quay.io/strimzi/maven-builder:latest\n        - name: STRIMZI_OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_FEATURE_GATES\n          value: ''\n        livenessProbe:\n          httpGet:\n            path: /healthy\n            port: http\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: http\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 384Mi\n          requests:\n            cpu: 200m\n            memory: 384Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03030",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: hello-node\n  name: hello-node\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hello-node\n  template:\n    metadata:\n      labels:\n        name: hello-node\n    spec:\n      containers:\n      - image: asia.gcr.io/<project id>/hello-node:v1\n        name: hello-node\n        ports:\n        - containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03031",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: hello-node\n  name: hello-node\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hello-node\n  template:\n    metadata:\n      labels:\n        name: hello-node\n    spec:\n      containers:\n      - image: asia.gcr.io/<project id>/hello-node:v1\n        name: hello-node\n        ports:\n        - containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03032",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: hello-node\n  name: hello-node\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hello-node\n  template:\n    metadata:\n      labels:\n        name: hello-node\n    spec:\n      containers:\n      - image: asia.gcr.io/<project id>/hello-node:v1\n        name: hello-node\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03033",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: hello-node\n  name: hello-node\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: hello-node\n  template:\n    metadata:\n      labels:\n        name: hello-node\n    spec:\n      containers:\n      - image: asia.gcr.io/<project id>/hello-node:v1\n        name: hello-node\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03034",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mock-ai\n  labels:\n    app: mock-ai\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mock-ai\n  template:\n    metadata:\n      name: mock-ai\n      labels:\n        app: mock-ai\n    spec:\n      containers:\n      - name: mock-ai\n        image: europe-west2-docker.pkg.dev/ons-ci-int/int-docker-snapshot/mock-ai:Fix_file_listing_in_help_endpoint\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: '0.1'\n            memory: 512Mi\n          limits:\n            cpu: 0.5M\n            memory: 1024Mi\n        readinessProbe:\n          httpGet:\n            path: /info\n            port: 8162\n          initialDelaySeconds: 20\n          periodSeconds: 10\n          failureThreshold: 3\n          successThreshold: 1\n        livenessProbe:\n          httpGet:\n            path: /info\n            port: 8162\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          failureThreshold: 3\n          successThreshold: 1\n        ports:\n        - name: http-server\n          containerPort: 8162\n        env:\n        - name: JAVA_TOOL_OPTIONS\n          value: -Dspring.profiles.active=dev -Dlogging.level.uk.gov.ons.ctp=DEBUG\n            -Dlogging.level.org.springframework=WARN -Dendpoints.autoconfig.enabled=false\n            -Dendpoints.beans.enabled=false -Dendpoints.configprops.enabled=false\n            -Dendpoints.dump.enabled=false -Dendpoints.env.enabled=false -Dendpoints.metrics.enabled=false\n            -Dendpoints.mapping.enabled=false -Dendpoints.shutdown.enabled=false -Dendpoints.trace.enabled=false\n            -Dmanagement.health.rabbit.enabled=false\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03035",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mock-ai\n  labels:\n    app: mock-ai\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mock-ai\n  template:\n    metadata:\n      name: mock-ai\n      labels:\n        app: mock-ai\n    spec:\n      containers:\n      - name: mock-ai\n        image: europe-west2-docker.pkg.dev/ons-ci-int/int-docker-snapshot/mock-ai:Fix_file_listing_in_help_endpoint\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: '0.1'\n            memory: 512Mi\n          limits:\n            cpu: 0.5M\n            memory: 1024Mi\n        readinessProbe:\n          httpGet:\n            path: /info\n            port: 8162\n          initialDelaySeconds: 20\n          periodSeconds: 10\n          failureThreshold: 3\n          successThreshold: 1\n        livenessProbe:\n          httpGet:\n            path: /info\n            port: 8162\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          failureThreshold: 3\n          successThreshold: 1\n        ports:\n        - name: http-server\n          containerPort: 8162\n        env:\n        - name: JAVA_TOOL_OPTIONS\n          value: -Dspring.profiles.active=dev -Dlogging.level.uk.gov.ons.ctp=DEBUG\n            -Dlogging.level.org.springframework=WARN -Dendpoints.autoconfig.enabled=false\n            -Dendpoints.beans.enabled=false -Dendpoints.configprops.enabled=false\n            -Dendpoints.dump.enabled=false -Dendpoints.env.enabled=false -Dendpoints.metrics.enabled=false\n            -Dendpoints.mapping.enabled=false -Dendpoints.shutdown.enabled=false -Dendpoints.trace.enabled=false\n            -Dmanagement.health.rabbit.enabled=false\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03036",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selinuxoptions0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      seLinuxOptions: {}\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      seLinuxOptions: {}\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seLinuxOptions:\n      type: somevalue\n",
    "errors": []
  },
  {
    "id": "03037",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selinuxoptions0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      seLinuxOptions: {}\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      seLinuxOptions: {}\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seLinuxOptions:\n      type: somevalue\n",
    "errors": []
  },
  {
    "id": "03038",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selinuxoptions0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      seLinuxOptions: {}\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      seLinuxOptions: {}\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seLinuxOptions:\n      type: somevalue\n",
    "errors": []
  },
  {
    "id": "03039",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selinuxoptions0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      seLinuxOptions: {}\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      seLinuxOptions: {}\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seLinuxOptions:\n      type: somevalue\n",
    "errors": []
  },
  {
    "id": "03040",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selinuxoptions0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      seLinuxOptions: {}\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      seLinuxOptions: {}\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seLinuxOptions:\n      type: somevalue\n",
    "errors": []
  },
  {
    "id": "03041",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selinuxoptions0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      seLinuxOptions: {}\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      seLinuxOptions: {}\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seLinuxOptions:\n      type: somevalue\n",
    "errors": []
  },
  {
    "id": "03042",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selinuxoptions0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      seLinuxOptions: {}\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      seLinuxOptions: {}\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seLinuxOptions:\n      type: somevalue\n",
    "errors": []
  },
  {
    "id": "03043",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: selinuxoptions0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      seLinuxOptions: {}\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      seLinuxOptions: {}\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seLinuxOptions:\n      type: somevalue\n",
    "errors": []
  },
  {
    "id": "03044",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03045",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03046",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03047",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03048",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03049",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03050",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03051",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03052",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vizier-query-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: vizier-query-broker\n  template:\n    metadata:\n      labels:\n        name: vizier-query-broker\n        plane: control\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: mds-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-metadata\n        - name: SERVICE_PORT\n          value: '50400'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/query_broker_server_image:stable\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_POD_IP_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        ports:\n        - containerPort: 50300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 50300\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n",
    "errors": []
  },
  {
    "id": "03053",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: schedulepod\n  name: schedulepod\nspec:\n  containers:\n  - args:\n    - /bin/sleep\n    - '3600'\n    image: busybox:stable\n    name: schedulepod\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03054",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: schedulepod\n  name: schedulepod\nspec:\n  containers:\n  - args:\n    - /bin/sleep\n    - '3600'\n    image: busybox:stable\n    name: schedulepod\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03055",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: schedulepod\n  name: schedulepod\nspec:\n  containers:\n  - args:\n    - /bin/sleep\n    - '3600'\n    image: busybox:stable\n    name: schedulepod\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03056",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: schedulepod\n  name: schedulepod\nspec:\n  containers:\n  - args:\n    - /bin/sleep\n    - '3600'\n    image: busybox:stable\n    name: schedulepod\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03057",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: schedulepod\n  name: schedulepod\nspec:\n  containers:\n  - args:\n    - /bin/sleep\n    - '3600'\n    image: busybox:stable\n    name: schedulepod\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03058",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7152\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03059",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7152\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03060",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7152\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03061",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7152\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03062",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7152\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03063",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wrkflw-tools\n  namespace: argo\n  labels:\n    app: wrkflw-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wrkflw-tools\n  template:\n    metadata:\n      labels:\n        app: wrkflw-tools\n    spec:\n      containers:\n      - name: wrkflw-tools\n        image: docker.cancerdb.io/mcdb-bots/bootstrap:mgbio\n        env:\n        - name: FASTQR1\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_1.fastq.gz\n        - name: FASTQR2\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_2.fastq.gz\n        - name: OUTPUTDIR\n          value: /data/output\n        - name: DATATYPE\n          value: tumor-exome\n        - name: SAMPLEID\n          value: mcdb010\n        - name: PLATFORMUNIT\n          value: HJC52BBXX.1\n        - name: PLATFORM\n          value: /data/output/mcdb005/hla/hla_calls/combined_calls.txt\n        - name: SEQHOUSE\n          value: Tempus\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /ref-hg38\n          name: workflow-ref-hg38-dev\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: workflow-ref-hg38-dev\n        persistentVolumeClaim:\n          claimName: workflow-ref-hg38-dev\n          readOnly: false\n",
    "errors": []
  },
  {
    "id": "03064",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wrkflw-tools\n  namespace: argo\n  labels:\n    app: wrkflw-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wrkflw-tools\n  template:\n    metadata:\n      labels:\n        app: wrkflw-tools\n    spec:\n      containers:\n      - name: wrkflw-tools\n        image: docker.cancerdb.io/mcdb-bots/bootstrap:mgbio\n        env:\n        - name: FASTQR1\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_1.fastq.gz\n        - name: FASTQR2\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_2.fastq.gz\n        - name: OUTPUTDIR\n          value: /data/output\n        - name: DATATYPE\n          value: tumor-exome\n        - name: SAMPLEID\n          value: mcdb010\n        - name: PLATFORMUNIT\n          value: HJC52BBXX.1\n        - name: PLATFORM\n          value: /data/output/mcdb005/hla/hla_calls/combined_calls.txt\n        - name: SEQHOUSE\n          value: Tempus\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /ref-hg38\n          name: workflow-ref-hg38-dev\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: workflow-ref-hg38-dev\n        persistentVolumeClaim:\n          claimName: workflow-ref-hg38-dev\n          readOnly: false\n",
    "errors": []
  },
  {
    "id": "03065",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wrkflw-tools\n  namespace: argo\n  labels:\n    app: wrkflw-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wrkflw-tools\n  template:\n    metadata:\n      labels:\n        app: wrkflw-tools\n    spec:\n      containers:\n      - name: wrkflw-tools\n        image: docker.cancerdb.io/mcdb-bots/bootstrap:mgbio\n        env:\n        - name: FASTQR1\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_1.fastq.gz\n        - name: FASTQR2\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_2.fastq.gz\n        - name: OUTPUTDIR\n          value: /data/output\n        - name: DATATYPE\n          value: tumor-exome\n        - name: SAMPLEID\n          value: mcdb010\n        - name: PLATFORMUNIT\n          value: HJC52BBXX.1\n        - name: PLATFORM\n          value: /data/output/mcdb005/hla/hla_calls/combined_calls.txt\n        - name: SEQHOUSE\n          value: Tempus\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /ref-hg38\n          name: workflow-ref-hg38-dev\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: workflow-ref-hg38-dev\n        persistentVolumeClaim:\n          claimName: workflow-ref-hg38-dev\n          readOnly: false\n",
    "errors": []
  },
  {
    "id": "03066",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wrkflw-tools\n  namespace: argo\n  labels:\n    app: wrkflw-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wrkflw-tools\n  template:\n    metadata:\n      labels:\n        app: wrkflw-tools\n    spec:\n      containers:\n      - name: wrkflw-tools\n        image: docker.cancerdb.io/mcdb-bots/bootstrap:mgbio\n        env:\n        - name: FASTQR1\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_1.fastq.gz\n        - name: FASTQR2\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_2.fastq.gz\n        - name: OUTPUTDIR\n          value: /data/output\n        - name: DATATYPE\n          value: tumor-exome\n        - name: SAMPLEID\n          value: mcdb010\n        - name: PLATFORMUNIT\n          value: HJC52BBXX.1\n        - name: PLATFORM\n          value: /data/output/mcdb005/hla/hla_calls/combined_calls.txt\n        - name: SEQHOUSE\n          value: Tempus\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /ref-hg38\n          name: workflow-ref-hg38-dev\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: workflow-ref-hg38-dev\n        persistentVolumeClaim:\n          claimName: workflow-ref-hg38-dev\n          readOnly: false\n",
    "errors": []
  },
  {
    "id": "03067",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wrkflw-tools\n  namespace: argo\n  labels:\n    app: wrkflw-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wrkflw-tools\n  template:\n    metadata:\n      labels:\n        app: wrkflw-tools\n    spec:\n      containers:\n      - name: wrkflw-tools\n        image: docker.cancerdb.io/mcdb-bots/bootstrap:mgbio\n        env:\n        - name: FASTQR1\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_1.fastq.gz\n        - name: FASTQR2\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_2.fastq.gz\n        - name: OUTPUTDIR\n          value: /data/output\n        - name: DATATYPE\n          value: tumor-exome\n        - name: SAMPLEID\n          value: mcdb010\n        - name: PLATFORMUNIT\n          value: HJC52BBXX.1\n        - name: PLATFORM\n          value: /data/output/mcdb005/hla/hla_calls/combined_calls.txt\n        - name: SEQHOUSE\n          value: Tempus\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /ref-hg38\n          name: workflow-ref-hg38-dev\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: workflow-ref-hg38-dev\n        persistentVolumeClaim:\n          claimName: workflow-ref-hg38-dev\n          readOnly: false\n",
    "errors": []
  },
  {
    "id": "03068",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wrkflw-tools\n  namespace: argo\n  labels:\n    app: wrkflw-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: wrkflw-tools\n  template:\n    metadata:\n      labels:\n        app: wrkflw-tools\n    spec:\n      containers:\n      - name: wrkflw-tools\n        image: docker.cancerdb.io/mcdb-bots/bootstrap:mgbio\n        env:\n        - name: FASTQR1\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_1.fastq.gz\n        - name: FASTQR2\n          value: /data/samples/tumor-exome/TL-21-3AMURU27_T_DSQ1_2.fastq.gz\n        - name: OUTPUTDIR\n          value: /data/output\n        - name: DATATYPE\n          value: tumor-exome\n        - name: SAMPLEID\n          value: mcdb010\n        - name: PLATFORMUNIT\n          value: HJC52BBXX.1\n        - name: PLATFORM\n          value: /data/output/mcdb005/hla/hla_calls/combined_calls.txt\n        - name: SEQHOUSE\n          value: Tempus\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /ref-hg38\n          name: workflow-ref-hg38-dev\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: workflow-ref-hg38-dev\n        persistentVolumeClaim:\n          claimName: workflow-ref-hg38-dev\n          readOnly: false\n",
    "errors": []
  },
  {
    "id": "03069",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-rc\nspec:\n  replicas: 1\n  selector:\n    app: reverse-proxy\n  template:\n    metadata:\n      labels:\n        app: reverse-proxy\n        tier: frontend\n    spec:\n      containers:\n      - name: nginx\n        image: dynatrace/easytravel-nginx:stable\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03070",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-rc\nspec:\n  replicas: 1\n  selector:\n    app: reverse-proxy\n  template:\n    metadata:\n      labels:\n        app: reverse-proxy\n        tier: frontend\n    spec:\n      containers:\n      - name: nginx\n        image: dynatrace/easytravel-nginx:stable\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03071",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-rc\nspec:\n  replicas: 1\n  selector:\n    app: reverse-proxy\n  template:\n    metadata:\n      labels:\n        app: reverse-proxy\n        tier: frontend\n    spec:\n      containers:\n      - name: nginx\n        image: dynatrace/easytravel-nginx:stable\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03072",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-rc\nspec:\n  replicas: 1\n  selector:\n    app: reverse-proxy\n  template:\n    metadata:\n      labels:\n        app: reverse-proxy\n        tier: frontend\n    spec:\n      containers:\n      - name: nginx\n        image: dynatrace/easytravel-nginx:stable\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03073",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-rc\nspec:\n  replicas: 1\n  selector:\n    app: reverse-proxy\n  template:\n    metadata:\n      labels:\n        app: reverse-proxy\n        tier: frontend\n    spec:\n      containers:\n      - name: nginx\n        image: dynatrace/easytravel-nginx:stable\n        ports:\n        - containerPort: 80\n        - containerPort: 443\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03074",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: insurance-deployment\n  namespace: insurance\n  labels:\n    deploy: insurance\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: insurance\n  template:\n    metadata:\n      labels:\n        app: insurance\n    spec:\n      containers:\n      - image: registrysiq8419.azurecr.io/insurance:1.0\n        imagePullPolicy: Always\n        name: insurance\n        resources:\n          limits:\n            memory: 2048Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - containerPort: 8081\n          name: http\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03075",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: insurance-deployment\n  namespace: insurance\n  labels:\n    deploy: insurance\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: insurance\n  template:\n    metadata:\n      labels:\n        app: insurance\n    spec:\n      containers:\n      - image: registrysiq8419.azurecr.io/insurance:1.0\n        imagePullPolicy: Always\n        name: insurance\n        resources:\n          limits:\n            memory: 2048Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - containerPort: 8081\n          name: http\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03076",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: insurance-deployment\n  namespace: insurance\n  labels:\n    deploy: insurance\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: insurance\n  template:\n    metadata:\n      labels:\n        app: insurance\n    spec:\n      containers:\n      - image: registrysiq8419.azurecr.io/insurance:1.0\n        imagePullPolicy: Always\n        name: insurance\n        resources:\n          limits:\n            memory: 2048Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - containerPort: 8081\n          name: http\n          protocol: TCP\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03077",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5910\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03078",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5910\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03079",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5910\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03080",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5910\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03081",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5910\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03082",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15.4\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03083",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15.4\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03084",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15.4\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03085",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15.4\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03086",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pi\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03087",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pi\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03088",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pi\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03089",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pi\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03090",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pi\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03091",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kindle-weather\n  labels:\n    app: kindle-weather\n    name: kindle-weather\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kindle-weather\n  template:\n    metadata:\n      labels:\n        app: kindle-weather\n        name: kindle-weather\n    spec:\n      containers:\n      - name: kindle-weather\n        image: quay.io/bostrt/kindle-weather-display:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03092",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kindle-weather\n  labels:\n    app: kindle-weather\n    name: kindle-weather\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kindle-weather\n  template:\n    metadata:\n      labels:\n        app: kindle-weather\n        name: kindle-weather\n    spec:\n      containers:\n      - name: kindle-weather\n        image: quay.io/bostrt/kindle-weather-display:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03093",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kindle-weather\n  labels:\n    app: kindle-weather\n    name: kindle-weather\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kindle-weather\n  template:\n    metadata:\n      labels:\n        app: kindle-weather\n        name: kindle-weather\n    spec:\n      containers:\n      - name: kindle-weather\n        image: quay.io/bostrt/kindle-weather-display:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03094",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kindle-weather\n  labels:\n    app: kindle-weather\n    name: kindle-weather\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kindle-weather\n  template:\n    metadata:\n      labels:\n        app: kindle-weather\n        name: kindle-weather\n    spec:\n      containers:\n      - name: kindle-weather\n        image: quay.io/bostrt/kindle-weather-display:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03095",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kindle-weather\n  labels:\n    app: kindle-weather\n    name: kindle-weather\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kindle-weather\n  template:\n    metadata:\n      labels:\n        app: kindle-weather\n        name: kindle-weather\n    spec:\n      containers:\n      - name: kindle-weather\n        image: quay.io/bostrt/kindle-weather-display:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03096",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello\n  labels:\n    app: hello\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: hello\n        image: registry.gitlab.com/gitops-heros/sith:0.1\n        ports:\n        - name: web\n          containerPort: 8080\n        resources:\n          limits:\n            cpu: '1'\n            memory: 16Mi\n          requests:\n            cpu: '0.2'\n            memory: 8Mi\n        livenessProbe:\n          httpGet:\n            path: /\n            port: web\n        readinessProbe:\n          httpGet:\n            path: /\n            port: web\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03097",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello\n  labels:\n    app: hello\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: hello\n        image: registry.gitlab.com/gitops-heros/sith:0.1\n        ports:\n        - name: web\n          containerPort: 8080\n        resources:\n          limits:\n            cpu: '1'\n            memory: 16Mi\n          requests:\n            cpu: '0.2'\n            memory: 8Mi\n        livenessProbe:\n          httpGet:\n            path: /\n            port: web\n        readinessProbe:\n          httpGet:\n            path: /\n            port: web\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03098",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-seccomp-allowed\n  annotations:\n    container.seccomp.security.alpha.kubernetes.io/nginx: runtime/default\n  labels:\n    app: nginx-seccomp\nspec:\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03099",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-seccomp-allowed\n  annotations:\n    container.seccomp.security.alpha.kubernetes.io/nginx: runtime/default\n  labels:\n    app: nginx-seccomp\nspec:\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03100",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-seccomp-allowed\n  annotations:\n    container.seccomp.security.alpha.kubernetes.io/nginx: runtime/default\n  labels:\n    app: nginx-seccomp\nspec:\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03101",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-seccomp-allowed\n  annotations:\n    container.seccomp.security.alpha.kubernetes.io/nginx: runtime/default\n  labels:\n    app: nginx-seccomp\nspec:\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03102",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-seccomp-allowed\n  annotations:\n    container.seccomp.security.alpha.kubernetes.io/nginx: runtime/default\n  labels:\n    app: nginx-seccomp\nspec:\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03103",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2536\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03104",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2536\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03105",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2536\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03106",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2536\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03107",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2536\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03108",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: demo\n    appType: spring-boot\n  name: demo\n  namespace: foremast-examples\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: demo\n  template:\n    metadata:\n      labels:\n        app: demo\n        version: v1\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/scheme: http\n        prometheus.io/port: '8080'\n        prometheus.io/path: /actuator/prometheus\n    spec:\n      containers:\n      - name: app\n        image: docker.io/foremast/k8s-metrics-demo:0.1.5\n        imagePullPolicy: Always\n        env:\n        - name: APP_NAME\n          value: demo\n        ports:\n        - name: http\n          containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03109",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: demo\n    appType: spring-boot\n  name: demo\n  namespace: foremast-examples\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: demo\n  template:\n    metadata:\n      labels:\n        app: demo\n        version: v1\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/scheme: http\n        prometheus.io/port: '8080'\n        prometheus.io/path: /actuator/prometheus\n    spec:\n      containers:\n      - name: app\n        image: docker.io/foremast/k8s-metrics-demo:0.1.5\n        imagePullPolicy: Always\n        env:\n        - name: APP_NAME\n          value: demo\n        ports:\n        - name: http\n          containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03110",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: demo\n    appType: spring-boot\n  name: demo\n  namespace: foremast-examples\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: demo\n  template:\n    metadata:\n      labels:\n        app: demo\n        version: v1\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/scheme: http\n        prometheus.io/port: '8080'\n        prometheus.io/path: /actuator/prometheus\n    spec:\n      containers:\n      - name: app\n        image: docker.io/foremast/k8s-metrics-demo:0.1.5\n        imagePullPolicy: Always\n        env:\n        - name: APP_NAME\n          value: demo\n        ports:\n        - name: http\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03111",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: demo\n    appType: spring-boot\n  name: demo\n  namespace: foremast-examples\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: demo\n  template:\n    metadata:\n      labels:\n        app: demo\n        version: v1\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/scheme: http\n        prometheus.io/port: '8080'\n        prometheus.io/path: /actuator/prometheus\n    spec:\n      containers:\n      - name: app\n        image: docker.io/foremast/k8s-metrics-demo:0.1.5\n        imagePullPolicy: Always\n        env:\n        - name: APP_NAME\n          value: demo\n        ports:\n        - name: http\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03112",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: timewarp\n  labels:\n    app: timewarp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: timewarp\n  template:\n    metadata:\n      labels:\n        app: timewarp\n    spec:\n      containers:\n      - name: timewarp\n        image: cordelltech/timewarp:stable\n        ports:\n        - containerPort: 8000\n          name: http\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03113",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: timewarp\n  labels:\n    app: timewarp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: timewarp\n  template:\n    metadata:\n      labels:\n        app: timewarp\n    spec:\n      containers:\n      - name: timewarp\n        image: cordelltech/timewarp:stable\n        ports:\n        - containerPort: 8000\n          name: http\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03114",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: timewarp\n  labels:\n    app: timewarp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: timewarp\n  template:\n    metadata:\n      labels:\n        app: timewarp\n    spec:\n      containers:\n      - name: timewarp\n        image: cordelltech/timewarp:stable\n        ports:\n        - containerPort: 8000\n          name: http\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03115",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: timewarp\n  labels:\n    app: timewarp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: timewarp\n  template:\n    metadata:\n      labels:\n        app: timewarp\n    spec:\n      containers:\n      - name: timewarp\n        image: cordelltech/timewarp:stable\n        ports:\n        - containerPort: 8000\n          name: http\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03116",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: timewarp\n  labels:\n    app: timewarp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: timewarp\n  template:\n    metadata:\n      labels:\n        app: timewarp\n    spec:\n      containers:\n      - name: timewarp\n        image: cordelltech/timewarp:stable\n        ports:\n        - containerPort: 8000\n          name: http\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03117",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03118",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03119",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03120",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03121",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03122",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kubernetes-dashboard-v1.0.1\n  namespace: kube-system\n  labels:\n    k8s-app: kubernetes-dashboard\n    version: v1.0.1\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n        version: v1.0.1\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.0.1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 9090\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 9090\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03123",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: kubernetes-dashboard-v1.0.1\n  namespace: kube-system\n  labels:\n    k8s-app: kubernetes-dashboard\n    version: v1.0.1\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n        version: v1.0.1\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.0.1\n        resources:\n          limits:\n            cpu: 100m\n            memory: 50Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        ports:\n        - containerPort: 9090\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 9090\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03124",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03125",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03126",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03127",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03128",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03129",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03130",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03131",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03132",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03133",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03134",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03135",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03136",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03137",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: benchmark-operator\n  namespace: my-ripsaw\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: benchmark-operator\n  template:\n    metadata:\n      labels:\n        name: benchmark-operator\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            preference:\n              matchExpressions:\n              - key: node-role.kubernetes.io/workload\n                operator: In\n                values:\n                - ''\n      serviceAccountName: benchmark-operator\n      containers:\n      - name: ansible\n        command:\n        - /usr/local/bin/ao-logs\n        - /tmp/ansible-operator/runner\n        - stdout\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: benchmark-operator\n        image: quay.io/multi-arch/benchmark-operator:stable\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: benchmark-operator\n        - name: WORKER_BENCHMARK_RIPSAW_CLOUDBULLDOZER_IO\n          value: '1'\n        - name: ANSIBLE_VERBOSITY\n          value: '4'\n        volumeMounts:\n        - mountPath: /tmp/ansible-operator/runner\n          name: runner\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: redis-master\n        image: k8s.gcr.io/redis:v1\n        env:\n        - name: MASTER\n          value: 'true'\n        ports:\n        - containerPort: 6379\n        resources:\n          limits:\n            cpu: '0.1'\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /redis-master-data\n          name: data\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        emptyDir: {}\n      - name: runner\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03138",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"jobs\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "03139",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"jobs\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "03140",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20220114-6a6ac6b4e0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03141",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20220114-6a6ac6b4e0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03142",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20220114-6a6ac6b4e0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03143",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20220114-6a6ac6b4e0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        - name: metrics\n          containerPort: 9090\n        args:\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config:/etc/kubeconfig-build-test-infra-trusted/kubeconfig\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - mountPath: /etc/kubeconfig-build-test-infra-trusted\n          name: kubeconfig-build-test-infra-trusted\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: kubeconfig-build-test-infra-trusted\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig-build-test-infra-trusted\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03144",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4249\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03145",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4249\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03146",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4249\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03147",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4249\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03148",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4249\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03149",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: example\n  template:\n    metadata:\n      labels:\n        app: example\n    spec:\n      containers:\n      - name: example\n        image: ealen/echo-server:stable\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 80\n        resources:\n          requests:\n            cpu: 50m\n            memory: 128Mi\n          limits:\n            cpu: 100m\n            memory: 256Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03150",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: example\n  template:\n    metadata:\n      labels:\n        app: example\n    spec:\n      containers:\n      - name: example\n        image: ealen/echo-server:stable\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 80\n        resources:\n          requests:\n            cpu: 50m\n            memory: 128Mi\n          limits:\n            cpu: 100m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03151",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: example\n  template:\n    metadata:\n      labels:\n        app: example\n    spec:\n      containers:\n      - name: example\n        image: ealen/echo-server:stable\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 80\n        resources:\n          requests:\n            cpu: 50m\n            memory: 128Mi\n          limits:\n            cpu: 100m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03152",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210318-ffb8032f91\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=status-dev.prow.build.kyma-project.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03153",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210318-ffb8032f91\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=status-dev.prow.build.kyma-project.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03154",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210318-ffb8032f91\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=status-dev.prow.build.kyma-project.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03155",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210318-ffb8032f91\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=status-dev.prow.build.kyma-project.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "03156",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03157",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03158",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03159",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03160",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03161",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03162",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03163",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03164",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kelvin\nspec:\n  selector:\n    matchLabels:\n      name: kelvin\n  template:\n    metadata:\n      labels:\n        name: kelvin\n        plane: data\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: Exists\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n            - matchExpressions:\n              - key: beta.kubernetes.io/os\n                operator: Exists\n              - key: beta.kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      initContainers:\n      - name: qb-wait\n        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0\n        command:\n        - sh\n        - -c\n        - 'set -x; URL=\"https://${SERVICE_NAME}:${SERVICE_PORT}/healthz\"; until [\n          $(curl -m 0.5 -s -o /dev/null -w \"%{http_code}\" -k ${URL}) -eq 200 ]; do\n          echo \"waiting for ${URL}\" sleep 2; done; '\n        env:\n        - name: SERVICE_NAME\n          value: vizier-query-broker\n        - name: SERVICE_PORT\n          value: '50300'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: app\n        image: gcr.io/pixie-oss/pixie-dev/vizier/kelvin_image:stable\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        env:\n        - name: PL_HOST_PATH\n          value: /host\n        - name: PL_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: PL_POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: PL_HOST_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.hostIP\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              key: jwt-signing-key\n              name: pl-cluster-secrets\n        - name: PL_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: TCMALLOC_SAMPLE_PARAMETER\n          value: '1048576'\n        ports:\n        - containerPort: 59300\n        volumeMounts:\n        - mountPath: /certs\n          name: certs\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: sys\n        hostPath:\n          path: /sys\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "03165",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kraken.service: redis\n  name: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kraken.service: redis\n  template:\n    metadata:\n      labels:\n        kraken.service: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:6\n        ports:\n        - name: redis\n          containerPort: 6379\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03166",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kraken.service: redis\n  name: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kraken.service: redis\n  template:\n    metadata:\n      labels:\n        kraken.service: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:6\n        ports:\n        - name: redis\n          containerPort: 6379\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03167",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kraken.service: redis\n  name: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kraken.service: redis\n  template:\n    metadata:\n      labels:\n        kraken.service: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:6\n        ports:\n        - name: redis\n          containerPort: 6379\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03168",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kraken.service: redis\n  name: redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kraken.service: redis\n  template:\n    metadata:\n      labels:\n        kraken.service: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:6\n        ports:\n        - name: redis\n          containerPort: 6379\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03169",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"serviceCenter\" is invalid: \n* metadata.name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.containers[0].name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
    ]
  },
  {
    "id": "03170",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"serviceCenter\" is invalid: \n* metadata.name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.containers[0].name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
    ]
  },
  {
    "id": "03171",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"serviceCenter\" is invalid: \n* metadata.name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.containers[0].name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
    ]
  },
  {
    "id": "03172",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"serviceCenter\" is invalid: \n* metadata.name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.containers[0].name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
    ]
  },
  {
    "id": "03173",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"serviceCenter\" is invalid: \n* metadata.name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.containers[0].name: Invalid value: \"serviceCenter\": a lowercase RFC 1123 label must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?')"
    ]
  },
  {
    "id": "03174",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"eventstore\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"eventstore-pv-storage\""
    ]
  },
  {
    "id": "03175",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"eventstore\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"eventstore-pv-storage\""
    ]
  },
  {
    "id": "03176",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"eventstore\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"eventstore-pv-storage\""
    ]
  },
  {
    "id": "03177",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"eventstore\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"eventstore-pv-storage\""
    ]
  },
  {
    "id": "03178",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"certbotdns\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03179",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"certbotdns\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03180",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"certbotdns\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03181",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"certbotdns\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03182",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"certbotdns\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03183",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03184",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03185",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03186",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03187",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03188",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03189",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03190",
    "policy_id": "no_privileged",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03191",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03192",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03193",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03194",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03195",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03196",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"openstack-cinder-csi-driver-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "03197",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds-bucket-watch\n  name: hsds-bucket-watch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds-bucket-watch\n  template:\n    metadata:\n      labels:\n        app: hsds-bucket-watch\n    spec:\n      serviceAccountName: hsds-eks-policy\n      containers:\n      - name: watch\n        image: hdfgroup/bucket_loader:v0.3\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 128M\n            cpu: 100m\n          limits:\n            memory: 256M\n            cpu: 500m\n        volumeMounts:\n        - name: bucket-config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        env:\n        - name: RUN_COMMAND\n          value: watch\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: HS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: hs-loader-keys\n              key: hs_username\n        - name: HS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: hs-loader-keys\n              key: hs_password\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: bucket-config\n        configMap:\n          name: hsds-bucket-loader-config\n      - name: hsds-config\n        configMap:\n          name: hsds-config\n      - name: hsds-override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "03198",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds-bucket-watch\n  name: hsds-bucket-watch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds-bucket-watch\n  template:\n    metadata:\n      labels:\n        app: hsds-bucket-watch\n    spec:\n      serviceAccountName: hsds-eks-policy\n      containers:\n      - name: watch\n        image: hdfgroup/bucket_loader:v0.3\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 128M\n            cpu: 100m\n          limits:\n            memory: 256M\n            cpu: 500m\n        volumeMounts:\n        - name: bucket-config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        env:\n        - name: RUN_COMMAND\n          value: watch\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: HS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: hs-loader-keys\n              key: hs_username\n        - name: HS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: hs-loader-keys\n              key: hs_password\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: bucket-config\n        configMap:\n          name: hsds-bucket-loader-config\n      - name: hsds-config\n        configMap:\n          name: hsds-config\n      - name: hsds-override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "03199",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds-bucket-watch\n  name: hsds-bucket-watch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds-bucket-watch\n  template:\n    metadata:\n      labels:\n        app: hsds-bucket-watch\n    spec:\n      serviceAccountName: hsds-eks-policy\n      containers:\n      - name: watch\n        image: hdfgroup/bucket_loader:v0.3\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            memory: 128M\n            cpu: 100m\n          limits:\n            memory: 256M\n            cpu: 500m\n        volumeMounts:\n        - name: bucket-config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        env:\n        - name: RUN_COMMAND\n          value: watch\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: HS_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: hs-loader-keys\n              key: hs_username\n        - name: HS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: hs-loader-keys\n              key: hs_password\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: bucket-config\n        configMap:\n          name: hsds-bucket-loader-config\n      - name: hsds-config\n        configMap:\n          name: hsds-config\n      - name: hsds-override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "03200",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: red\n  labels:\n    app: red\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: red\n  template:\n    metadata:\n      labels:\n        app: red\n    spec:\n      containers:\n      - name: red\n        image: nginx:1.19.2\n        volumeMounts:\n        - name: html\n          mountPath: /usr/share/nginx/html\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: html\n        configMap:\n          name: red\n          items:\n          - key: body\n            path: index.html\n",
    "errors": []
  },
  {
    "id": "03201",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: red\n  labels:\n    app: red\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: red\n  template:\n    metadata:\n      labels:\n        app: red\n    spec:\n      containers:\n      - name: red\n        image: nginx:1.19.2\n        volumeMounts:\n        - name: html\n          mountPath: /usr/share/nginx/html\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: html\n        configMap:\n          name: red\n          items:\n          - key: body\n            path: index.html\n",
    "errors": []
  },
  {
    "id": "03202",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"blockvalidator\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03203",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"blockvalidator\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03204",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"blockvalidator\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03205",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"blockvalidator\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03206",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"blockvalidator\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03207",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"reefer-itgtests-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03208",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"reefer-itgtests-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03209",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"reefer-itgtests-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03210",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"reefer-itgtests-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03211",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: portal-noticias-replicaset\nspec:\n  template:\n    metadata:\n      name: portal-de-noticias\n      labels:\n        app: portal-noticias\n    spec:\n      containers:\n      - name: portal-conainer\n        image: aluracursos/portal-noticias:1\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: portal-configmap\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n  replicas: 3\n  selector:\n    matchLabels:\n      app: portal-noticias\n",
    "errors": []
  },
  {
    "id": "03212",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: portal-noticias-replicaset\nspec:\n  template:\n    metadata:\n      name: portal-de-noticias\n      labels:\n        app: portal-noticias\n    spec:\n      containers:\n      - name: portal-conainer\n        image: aluracursos/portal-noticias:1\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: portal-configmap\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n  replicas: 3\n  selector:\n    matchLabels:\n      app: portal-noticias\n",
    "errors": []
  },
  {
    "id": "03213",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: portal-noticias-replicaset\nspec:\n  template:\n    metadata:\n      name: portal-de-noticias\n      labels:\n        app: portal-noticias\n    spec:\n      containers:\n      - name: portal-conainer\n        image: aluracursos/portal-noticias:1\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: portal-configmap\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n  replicas: 3\n  selector:\n    matchLabels:\n      app: portal-noticias\n",
    "errors": []
  },
  {
    "id": "03214",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: portal-noticias-replicaset\nspec:\n  template:\n    metadata:\n      name: portal-de-noticias\n      labels:\n        app: portal-noticias\n    spec:\n      containers:\n      - name: portal-conainer\n        image: aluracursos/portal-noticias:1\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: portal-configmap\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n  replicas: 3\n  selector:\n    matchLabels:\n      app: portal-noticias\n",
    "errors": []
  },
  {
    "id": "03215",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      securityContext:\n        runAsUser: 0\n        fsGroup: 0\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:lts\n        ports:\n        - name: http-port\n          containerPort: 8080\n        - name: jnlp-port\n          containerPort: 50000\n        volumeMounts:\n        - name: jenkins-storage\n          mountPath: /var/jenkins_home\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: jenkins-storage\n        persistentVolumeClaim:\n          claimName: jenkins-pvc\n",
    "errors": []
  },
  {
    "id": "03216",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": false,
    "patched_yaml": null,
    "errors": []
  },
  {
    "id": "03217",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      securityContext:\n        runAsUser: 0\n        fsGroup: 0\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:lts\n        ports:\n        - name: http-port\n          containerPort: 8080\n        - name: jnlp-port\n          containerPort: 50000\n        volumeMounts:\n        - name: jenkins-storage\n          mountPath: /var/jenkins_home\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: jenkins-storage\n        persistentVolumeClaim:\n          claimName: jenkins-pvc\n",
    "errors": []
  },
  {
    "id": "03218",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins\n  template:\n    metadata:\n      labels:\n        app: jenkins\n    spec:\n      securityContext:\n        runAsUser: 0\n        fsGroup: 0\n      containers:\n      - name: jenkins\n        image: jenkins/jenkins:lts\n        ports:\n        - name: http-port\n          containerPort: 8080\n        - name: jnlp-port\n          containerPort: 50000\n        volumeMounts:\n        - name: jenkins-storage\n          mountPath: /var/jenkins_home\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: jenkins-storage\n        persistentVolumeClaim:\n          claimName: jenkins-pvc\n",
    "errors": []
  },
  {
    "id": "03219",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: updateservice-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: updateservice-operator\n  template:\n    metadata:\n      labels:\n        name: updateservice-operator\n    spec:\n      serviceAccountName: updateservice-operator\n      containers:\n      - name: updateservice-operator\n        image: controller:stable\n        imagePullPolicy: Always\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: updateservice-operator\n        - name: RELATED_IMAGE_OPERAND\n          value: quay.io/cincinnati/cincinnati:latest\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03220",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: updateservice-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: updateservice-operator\n  template:\n    metadata:\n      labels:\n        name: updateservice-operator\n    spec:\n      serviceAccountName: updateservice-operator\n      containers:\n      - name: updateservice-operator\n        image: controller:stable\n        imagePullPolicy: Always\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: updateservice-operator\n        - name: RELATED_IMAGE_OPERAND\n          value: quay.io/cincinnati/cincinnati:latest\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03221",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: updateservice-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: updateservice-operator\n  template:\n    metadata:\n      labels:\n        name: updateservice-operator\n    spec:\n      serviceAccountName: updateservice-operator\n      containers:\n      - name: updateservice-operator\n        image: controller:stable\n        imagePullPolicy: Always\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: updateservice-operator\n        - name: RELATED_IMAGE_OPERAND\n          value: quay.io/cincinnati/cincinnati:latest\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03222",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: updateservice-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: updateservice-operator\n  template:\n    metadata:\n      labels:\n        name: updateservice-operator\n    spec:\n      serviceAccountName: updateservice-operator\n      containers:\n      - name: updateservice-operator\n        image: controller:stable\n        imagePullPolicy: Always\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: updateservice-operator\n        - name: RELATED_IMAGE_OPERAND\n          value: quay.io/cincinnati/cincinnati:latest\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03223",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: updateservice-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: updateservice-operator\n  template:\n    metadata:\n      labels:\n        name: updateservice-operator\n    spec:\n      serviceAccountName: updateservice-operator\n      containers:\n      - name: updateservice-operator\n        image: controller:stable\n        imagePullPolicy: Always\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: updateservice-operator\n        - name: RELATED_IMAGE_OPERAND\n          value: quay.io/cincinnati/cincinnati:latest\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03224",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pbft-keys\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03225",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pbft-keys\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03226",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pbft-keys\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03227",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pbft-keys\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03228",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"pbft-keys\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "03229",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-server\nspec:\n  replicas: 1\n  selector:\n    role: nfs-server\n  template:\n    metadata:\n      labels:\n        role: nfs-server\n    spec:\n      containers:\n      - name: nfs-server\n        image: gcr.io/google_containers/volume-nfs:0.8\n        ports:\n        - name: nfs\n          containerPort: 2049\n        - name: mountd\n          containerPort: 20048\n        - name: rpcbind\n          containerPort: 111\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /exports\n          name: nfs-export-fast\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: nfs-export-fast\n        persistentVolumeClaim:\n          claimName: nfs-server-pvc-fast\n",
    "errors": []
  },
  {
    "id": "03230",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-server\nspec:\n  replicas: 1\n  selector:\n    role: nfs-server\n  template:\n    metadata:\n      labels:\n        role: nfs-server\n    spec:\n      containers:\n      - name: nfs-server\n        image: gcr.io/google_containers/volume-nfs:0.8\n        ports:\n        - name: nfs\n          containerPort: 2049\n        - name: mountd\n          containerPort: 20048\n        - name: rpcbind\n          containerPort: 111\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /exports\n          name: nfs-export-fast\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: nfs-export-fast\n        persistentVolumeClaim:\n          claimName: nfs-server-pvc-fast\n",
    "errors": []
  },
  {
    "id": "03231",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-server\nspec:\n  replicas: 1\n  selector:\n    role: nfs-server\n  template:\n    metadata:\n      labels:\n        role: nfs-server\n    spec:\n      containers:\n      - name: nfs-server\n        image: gcr.io/google_containers/volume-nfs:0.8\n        ports:\n        - name: nfs\n          containerPort: 2049\n        - name: mountd\n          containerPort: 20048\n        - name: rpcbind\n          containerPort: 111\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /exports\n          name: nfs-export-fast\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: nfs-export-fast\n        persistentVolumeClaim:\n          claimName: nfs-server-pvc-fast\n",
    "errors": []
  },
  {
    "id": "03232",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-server\nspec:\n  replicas: 1\n  selector:\n    role: nfs-server\n  template:\n    metadata:\n      labels:\n        role: nfs-server\n    spec:\n      containers:\n      - name: nfs-server\n        image: gcr.io/google_containers/volume-nfs:0.8\n        ports:\n        - name: nfs\n          containerPort: 2049\n        - name: mountd\n          containerPort: 20048\n        - name: rpcbind\n          containerPort: 111\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /exports\n          name: nfs-export-fast\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: nfs-export-fast\n        persistentVolumeClaim:\n          claimName: nfs-server-pvc-fast\n",
    "errors": []
  },
  {
    "id": "03233",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-server\nspec:\n  replicas: 1\n  selector:\n    role: nfs-server\n  template:\n    metadata:\n      labels:\n        role: nfs-server\n    spec:\n      containers:\n      - name: nfs-server\n        image: gcr.io/google_containers/volume-nfs:0.8\n        ports:\n        - name: nfs\n          containerPort: 2049\n        - name: mountd\n          containerPort: 20048\n        - name: rpcbind\n          containerPort: 111\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /exports\n          name: nfs-export-fast\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: nfs-export-fast\n        persistentVolumeClaim:\n          claimName: nfs-server-pvc-fast\n",
    "errors": []
  },
  {
    "id": "03234",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nfs-server\nspec:\n  replicas: 1\n  selector:\n    role: nfs-server\n  template:\n    metadata:\n      labels:\n        role: nfs-server\n    spec:\n      containers:\n      - name: nfs-server\n        image: gcr.io/google_containers/volume-nfs:0.8\n        ports:\n        - name: nfs\n          containerPort: 2049\n        - name: mountd\n          containerPort: 20048\n        - name: rpcbind\n          containerPort: 111\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /exports\n          name: nfs-export-fast\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: nfs-export-fast\n        persistentVolumeClaim:\n          claimName: nfs-server-pvc-fast\n",
    "errors": []
  },
  {
    "id": "03235",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: intel-fpga-webhook-deployment\n  labels:\n    app: intel-fpga-webhook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: intel-fpga-webhook\n  template:\n    metadata:\n      labels:\n        app: intel-fpga-webhook\n    spec:\n      containers:\n      - name: fpga-mutator\n        image: intel/intel-fpga-admissionwebhook:devel\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 3210\n          runAsGroup: 3210\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - -tls-cert-file=/etc/webhook/certs/cert.pem\n        - -tls-private-key-file=/etc/webhook/certs/key.pem\n        - -mode=preprogrammed\n        - -v=1\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /etc/webhook/certs\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-certs\n        secret:\n          secretName: intel-fpga-webhook-certs\n",
    "errors": []
  },
  {
    "id": "03236",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: intel-fpga-webhook-deployment\n  labels:\n    app: intel-fpga-webhook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: intel-fpga-webhook\n  template:\n    metadata:\n      labels:\n        app: intel-fpga-webhook\n    spec:\n      containers:\n      - name: fpga-mutator\n        image: intel/intel-fpga-admissionwebhook:devel\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 3210\n          runAsGroup: 3210\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n        args:\n        - -tls-cert-file=/etc/webhook/certs/cert.pem\n        - -tls-private-key-file=/etc/webhook/certs/key.pem\n        - -mode=preprogrammed\n        - -v=1\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /etc/webhook/certs\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-certs\n        secret:\n          secretName: intel-fpga-webhook-certs\n",
    "errors": []
  },
  {
    "id": "03237",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeder-qualifiers-nrfin00033\n  labels:\n    type: cyborg-seeder\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeder-qualifiers-nrfin00033\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeder.py qualifiers NRFIN_00033\n      3600 6\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 500m\n        memory: 10Gi\n      requests:\n        cpu: 100m\n        memory: 10Gi\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03238",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeder-qualifiers-nrfin00033\n  labels:\n    type: cyborg-seeder\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeder-qualifiers-nrfin00033\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeder.py qualifiers NRFIN_00033\n      3600 6\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 500m\n        memory: 10Gi\n      requests:\n        cpu: 100m\n        memory: 10Gi\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03239",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1000\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03240",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1000\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03241",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1000\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03242",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1000\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03243",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1000\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03244",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"gpt2-post-tweet\" namespace: \"gpt2-twitter\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03245",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"gpt2-post-tweet\" namespace: \"gpt2-twitter\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03246",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"gpt2-post-tweet\" namespace: \"gpt2-twitter\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03247",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"gpt2-post-tweet\" namespace: \"gpt2-twitter\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03248",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"gpt2-post-tweet\" namespace: \"gpt2-twitter\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "03249",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeder-examples-nrfin00079\n  labels:\n    type: cyborg-seeder\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeder-examples-nrfin00079\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeder.py examples NRFIN_00079\n      3600 6\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 500m\n        memory: 10Gi\n      requests:\n        cpu: 100m\n        memory: 10Gi\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03250",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeder-examples-nrfin00079\n  labels:\n    type: cyborg-seeder\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeder-examples-nrfin00079\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeder.py examples NRFIN_00079\n      3600 6\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 500m\n        memory: 10Gi\n      requests:\n        cpu: 100m\n        memory: 10Gi\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03251",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: proxy-deployment-canary\n  labels:\n    app: proxy-canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-canary\n  template:\n    metadata:\n      labels:\n        app: proxy-canary\n    spec:\n      containers:\n      - name: proxy-canary\n        image: gcr.io/GCP_PROJECT/proxy:stable\n        ports:\n        - containerPort: 30000\n          name: health-check\n        - containerPort: 30001\n          name: whois\n        - containerPort: 30002\n          name: epp\n        - containerPort: 30010\n          name: http-whois\n        - containerPort: 30011\n          name: https-whois\n        readinessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        imagePullPolicy: Always\n        args:\n        - --env\n        - crash_canary\n        - --log\n        env:\n        - name: POD_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTAINER_NAME\n          value: proxy-canary\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03252",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: proxy-deployment-canary\n  labels:\n    app: proxy-canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-canary\n  template:\n    metadata:\n      labels:\n        app: proxy-canary\n    spec:\n      containers:\n      - name: proxy-canary\n        image: gcr.io/GCP_PROJECT/proxy:stable\n        ports:\n        - containerPort: 30000\n          name: health-check\n        - containerPort: 30001\n          name: whois\n        - containerPort: 30002\n          name: epp\n        - containerPort: 30010\n          name: http-whois\n        - containerPort: 30011\n          name: https-whois\n        readinessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        imagePullPolicy: Always\n        args:\n        - --env\n        - crash_canary\n        - --log\n        env:\n        - name: POD_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTAINER_NAME\n          value: proxy-canary\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03253",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: proxy-deployment-canary\n  labels:\n    app: proxy-canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-canary\n  template:\n    metadata:\n      labels:\n        app: proxy-canary\n    spec:\n      containers:\n      - name: proxy-canary\n        image: gcr.io/GCP_PROJECT/proxy:stable\n        ports:\n        - containerPort: 30000\n          name: health-check\n        - containerPort: 30001\n          name: whois\n        - containerPort: 30002\n          name: epp\n        - containerPort: 30010\n          name: http-whois\n        - containerPort: 30011\n          name: https-whois\n        readinessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        imagePullPolicy: Always\n        args:\n        - --env\n        - crash_canary\n        - --log\n        env:\n        - name: POD_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTAINER_NAME\n          value: proxy-canary\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03254",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: proxy-deployment-canary\n  labels:\n    app: proxy-canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-canary\n  template:\n    metadata:\n      labels:\n        app: proxy-canary\n    spec:\n      containers:\n      - name: proxy-canary\n        image: gcr.io/GCP_PROJECT/proxy:stable\n        ports:\n        - containerPort: 30000\n          name: health-check\n        - containerPort: 30001\n          name: whois\n        - containerPort: 30002\n          name: epp\n        - containerPort: 30010\n          name: http-whois\n        - containerPort: 30011\n          name: https-whois\n        readinessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        imagePullPolicy: Always\n        args:\n        - --env\n        - crash_canary\n        - --log\n        env:\n        - name: POD_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTAINER_NAME\n          value: proxy-canary\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03255",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: proxy-deployment-canary\n  labels:\n    app: proxy-canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-canary\n  template:\n    metadata:\n      labels:\n        app: proxy-canary\n    spec:\n      containers:\n      - name: proxy-canary\n        image: gcr.io/GCP_PROJECT/proxy:stable\n        ports:\n        - containerPort: 30000\n          name: health-check\n        - containerPort: 30001\n          name: whois\n        - containerPort: 30002\n          name: epp\n        - containerPort: 30010\n          name: http-whois\n        - containerPort: 30011\n          name: https-whois\n        readinessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          tcpSocket:\n            port: health-check\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        imagePullPolicy: Always\n        args:\n        - --env\n        - crash_canary\n        - --log\n        env:\n        - name: POD_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NAMESPACE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTAINER_NAME\n          value: proxy-canary\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03256",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/instance: flux-system\n    app.kubernetes.io/version: v0.2.0\n    control-plane: controller\n  name: helm-controller\n  namespace: flux-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: helm-controller\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '8080'\n        prometheus.io/scrape: 'true'\n      labels:\n        app: helm-controller\n    spec:\n      containers:\n      - args:\n        - --events-addr=\n        - --watch-all-namespaces=true\n        - --log-level=info\n        - --log-json\n        - --enable-leader-election\n        env:\n        - name: RUNTIME_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: ghcr.io/fluxcd/helm-controller:v0.1.3\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: http-prom\n        name: manager\n        ports:\n        - containerPort: 8080\n          name: http-prom\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 1Gi\n          requests:\n            cpu: 100m\n            memory: 64Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n        volumeMounts:\n        - mountPath: /tmp\n          name: temp\n      volumes:\n      - emptyDir: {}\n        name: temp\n",
    "errors": []
  },
  {
    "id": "03257",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: devops-flask-pod\n  labels:\n    app: devops-flask\n    env: dev\n    tech: python\nspec:\n  containers:\n  - image: kannanc70/devops-flask:stable\n    name: devops-flask\n    ports:\n    - containerPort: 5000\n      protocol: TCP\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03258",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: devops-flask-pod\n  labels:\n    app: devops-flask\n    env: dev\n    tech: python\nspec:\n  containers:\n  - image: kannanc70/devops-flask:stable\n    name: devops-flask\n    ports:\n    - containerPort: 5000\n      protocol: TCP\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03259",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: devops-flask-pod\n  labels:\n    app: devops-flask\n    env: dev\n    tech: python\nspec:\n  containers:\n  - image: kannanc70/devops-flask:stable\n    name: devops-flask\n    ports:\n    - containerPort: 5000\n      protocol: TCP\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03260",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: devops-flask-pod\n  labels:\n    app: devops-flask\n    env: dev\n    tech: python\nspec:\n  containers:\n  - image: kannanc70/devops-flask:stable\n    name: devops-flask\n    ports:\n    - containerPort: 5000\n      protocol: TCP\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03261",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: devops-flask-pod\n  labels:\n    app: devops-flask\n    env: dev\n    tech: python\nspec:\n  containers:\n  - image: kannanc70/devops-flask:stable\n    name: devops-flask\n    ports:\n    - containerPort: 5000\n      protocol: TCP\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03262",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: allien/web:0.1\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init\n        image: busybox:1.32.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03263",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: allien/web:0.1\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init\n        image: busybox:1.32.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03264",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: allien/web:0.1\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init\n        image: busybox:1.32.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03265",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: allien/web:0.1\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init\n        image: busybox:1.32.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03266",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: allien/web:0.1\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init\n        image: busybox:1.32.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03267",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: allien/web:0.1\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init\n        image: busybox:1.32.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03268",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: allien/web:0.1\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init\n        image: busybox:1.32.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03269",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: allien/web:0.1\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init\n        image: busybox:1.32.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "03270",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: strimzi-user-operator\n  labels:\n    app: strimzi\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: strimzi-user-operator\n  template:\n    metadata:\n      labels:\n        name: strimzi-user-operator\n    spec:\n      serviceAccountName: strimzi-user-operator\n      containers:\n      - name: strimzi-user-operator\n        image: quay.io/strimzi/operator:0.27.1\n        args:\n        - /opt/strimzi/bin/user_operator_run.sh\n        env:\n        - name: STRIMZI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_LABELS\n          value: strimzi.io/cluster=my-cluster\n        - name: STRIMZI_CA_CERT_NAME\n          value: my-cluster-clients-ca-cert\n        - name: STRIMZI_CA_KEY_NAME\n          value: my-cluster-clients-ca\n        - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS\n          value: '120000'\n        - name: STRIMZI_LOG_LEVEL\n          value: INFO\n        - name: STRIMZI_GC_LOG_ENABLED\n          value: 'true'\n        - name: STRIMZI_CA_VALIDITY\n          value: '365'\n        - name: STRIMZI_CA_RENEWAL\n          value: '30'\n        livenessProbe:\n          httpGet:\n            path: /healthy\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        resources:\n          limits:\n            memory: 256Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03271",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: strimzi-user-operator\n  labels:\n    app: strimzi\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: strimzi-user-operator\n  template:\n    metadata:\n      labels:\n        name: strimzi-user-operator\n    spec:\n      serviceAccountName: strimzi-user-operator\n      containers:\n      - name: strimzi-user-operator\n        image: quay.io/strimzi/operator:0.27.1\n        args:\n        - /opt/strimzi/bin/user_operator_run.sh\n        env:\n        - name: STRIMZI_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: STRIMZI_LABELS\n          value: strimzi.io/cluster=my-cluster\n        - name: STRIMZI_CA_CERT_NAME\n          value: my-cluster-clients-ca-cert\n        - name: STRIMZI_CA_KEY_NAME\n          value: my-cluster-clients-ca\n        - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS\n          value: '120000'\n        - name: STRIMZI_LOG_LEVEL\n          value: INFO\n        - name: STRIMZI_GC_LOG_ENABLED\n          value: 'true'\n        - name: STRIMZI_CA_VALIDITY\n          value: '365'\n        - name: STRIMZI_CA_RENEWAL\n          value: '30'\n        livenessProbe:\n          httpGet:\n            path: /healthy\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        resources:\n          limits:\n            memory: 256Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03272",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd-ds-syslog\n  namespace: kube-system\n  labels:\n    name: fluentd-logging\n    k8s-app: fluentd-logging\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      name: fluentd-logging\n      k8s-app: fluentd-logging\n      version: v1\n  template:\n    metadata:\n      labels:\n        name: fluentd-logging\n        k8s-app: fluentd-logging\n        version: v1\n    spec:\n      serviceAccount: fluentd\n      serviceAccountName: fluentd\n      containers:\n      - name: fluentd\n        image: fluent/fluentd-kubernetes-daemonset:v1-debian-syslog\n        env:\n        - name: SYSLOG_HOST\n          value: sysloghost\n        - name: SYSLOG_PORT\n          value: '514'\n        - name: SYSLOG_PROTOCOL\n          value: udp\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n",
    "errors": []
  },
  {
    "id": "03273",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd-ds-syslog\n  namespace: kube-system\n  labels:\n    name: fluentd-logging\n    k8s-app: fluentd-logging\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      name: fluentd-logging\n      k8s-app: fluentd-logging\n      version: v1\n  template:\n    metadata:\n      labels:\n        name: fluentd-logging\n        k8s-app: fluentd-logging\n        version: v1\n    spec:\n      serviceAccount: fluentd\n      serviceAccountName: fluentd\n      containers:\n      - name: fluentd\n        image: fluent/fluentd-kubernetes-daemonset:v1-debian-syslog\n        env:\n        - name: SYSLOG_HOST\n          value: sysloghost\n        - name: SYSLOG_PORT\n          value: '514'\n        - name: SYSLOG_PROTOCOL\n          value: udp\n        resources:\n          limits:\n            memory: 200Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n",
    "errors": []
  },
  {
    "id": "03274",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gitlab-runner-medium\n  namespace: spack\n  labels:\n    app: gitlab\n    svc: runner\n    size: medium\nspec:\n  selector:\n    matchLabels:\n      app: gitlab\n      svc: runner\n      size: medium\n  replicas: 10\n  template:\n    metadata:\n      labels:\n        app: gitlab\n        svc: runner\n        size: medium\n    spec:\n      serviceAccountName: gitlab-runner\n      containers:\n      - name: runner\n        image: gitlab/gitlab-runner:stable\n        imagePullPolicy: Always\n        env:\n        - name: KUBERNETES_IMAGE\n          value: ghcr.io/scottwittenburg/ubuntu:18.04\n        - name: KUBERNETES_HELPER_IMAGE\n          value: ghcr.io/scottwittenburg/gitlab-gitlab-runner-helper:x86_64-ece86343\n        - name: CI_SERVER_URL\n          value: http://gitlab\n        - name: REGISTRATION_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: gitlab-secrets\n              key: gitlab-runner-token\n        - name: ELASTIC_SEARCH_URL\n          value: http://elastic-search-es-http.spack.svc:9200\n        - name: ELASTIC_SEARCH_USER\n          value: elastic\n        - name: ELASTIC_SEARCH_PASS\n          valueFrom:\n            secretKeyRef:\n              name: elastic-search-es-elastic-user\n              key: elastic\n        - name: RUNNER_EXECUTOR\n          value: kubernetes\n        - name: KUBERNETES_CPU_REQUEST\n          value: '1.7'\n        - name: KUBERNETES_PULL_POLICY\n          value: if-not-present\n        - name: KUBERNETES_POLL_TIMEOUT\n          value: '3600'\n        - name: KUBERNETES_SERVICE_ACCOUNT\n          value: gitlab-runner\n        - name: KUBERNETES_NAMESPACE\n          value: spack\n        - name: REGISTER_NON_INTERACTIVE\n          value: 'true'\n        - name: RUNNER_REQUEST_CONCURRENCY\n          value: '32'\n        - name: RUNNER_LIMIT\n          value: '32'\n        - name: RUNNER_TAG_LIST\n          value: spack-kube,medium\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 1m\n          limits:\n            memory: 100Mi\n            cpu: 100m\n        volumeMounts:\n        - name: runner-scripts\n          mountPath: /runner-scripts\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: runner-scripts\n        configMap:\n          name: gitlab-runner-scripts\n          defaultMode: 448\n",
    "errors": []
  },
  {
    "id": "03275",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gitlab-runner-medium\n  namespace: spack\n  labels:\n    app: gitlab\n    svc: runner\n    size: medium\nspec:\n  selector:\n    matchLabels:\n      app: gitlab\n      svc: runner\n      size: medium\n  replicas: 10\n  template:\n    metadata:\n      labels:\n        app: gitlab\n        svc: runner\n        size: medium\n    spec:\n      serviceAccountName: gitlab-runner\n      containers:\n      - name: runner\n        image: gitlab/gitlab-runner:stable\n        imagePullPolicy: Always\n        env:\n        - name: KUBERNETES_IMAGE\n          value: ghcr.io/scottwittenburg/ubuntu:18.04\n        - name: KUBERNETES_HELPER_IMAGE\n          value: ghcr.io/scottwittenburg/gitlab-gitlab-runner-helper:x86_64-ece86343\n        - name: CI_SERVER_URL\n          value: http://gitlab\n        - name: REGISTRATION_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: gitlab-secrets\n              key: gitlab-runner-token\n        - name: ELASTIC_SEARCH_URL\n          value: http://elastic-search-es-http.spack.svc:9200\n        - name: ELASTIC_SEARCH_USER\n          value: elastic\n        - name: ELASTIC_SEARCH_PASS\n          valueFrom:\n            secretKeyRef:\n              name: elastic-search-es-elastic-user\n              key: elastic\n        - name: RUNNER_EXECUTOR\n          value: kubernetes\n        - name: KUBERNETES_CPU_REQUEST\n          value: '1.7'\n        - name: KUBERNETES_PULL_POLICY\n          value: if-not-present\n        - name: KUBERNETES_POLL_TIMEOUT\n          value: '3600'\n        - name: KUBERNETES_SERVICE_ACCOUNT\n          value: gitlab-runner\n        - name: KUBERNETES_NAMESPACE\n          value: spack\n        - name: REGISTER_NON_INTERACTIVE\n          value: 'true'\n        - name: RUNNER_REQUEST_CONCURRENCY\n          value: '32'\n        - name: RUNNER_LIMIT\n          value: '32'\n        - name: RUNNER_TAG_LIST\n          value: spack-kube,medium\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 1m\n          limits:\n            memory: 100Mi\n            cpu: 100m\n        volumeMounts:\n        - name: runner-scripts\n          mountPath: /runner-scripts\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: runner-scripts\n        configMap:\n          name: gitlab-runner-scripts\n          defaultMode: 448\n",
    "errors": []
  },
  {
    "id": "03276",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gitlab-runner-medium\n  namespace: spack\n  labels:\n    app: gitlab\n    svc: runner\n    size: medium\nspec:\n  selector:\n    matchLabels:\n      app: gitlab\n      svc: runner\n      size: medium\n  replicas: 10\n  template:\n    metadata:\n      labels:\n        app: gitlab\n        svc: runner\n        size: medium\n    spec:\n      serviceAccountName: gitlab-runner\n      containers:\n      - name: runner\n        image: gitlab/gitlab-runner:stable\n        imagePullPolicy: Always\n        env:\n        - name: KUBERNETES_IMAGE\n          value: ghcr.io/scottwittenburg/ubuntu:18.04\n        - name: KUBERNETES_HELPER_IMAGE\n          value: ghcr.io/scottwittenburg/gitlab-gitlab-runner-helper:x86_64-ece86343\n        - name: CI_SERVER_URL\n          value: http://gitlab\n        - name: REGISTRATION_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: gitlab-secrets\n              key: gitlab-runner-token\n        - name: ELASTIC_SEARCH_URL\n          value: http://elastic-search-es-http.spack.svc:9200\n        - name: ELASTIC_SEARCH_USER\n          value: elastic\n        - name: ELASTIC_SEARCH_PASS\n          valueFrom:\n            secretKeyRef:\n              name: elastic-search-es-elastic-user\n              key: elastic\n        - name: RUNNER_EXECUTOR\n          value: kubernetes\n        - name: KUBERNETES_CPU_REQUEST\n          value: '1.7'\n        - name: KUBERNETES_PULL_POLICY\n          value: if-not-present\n        - name: KUBERNETES_POLL_TIMEOUT\n          value: '3600'\n        - name: KUBERNETES_SERVICE_ACCOUNT\n          value: gitlab-runner\n        - name: KUBERNETES_NAMESPACE\n          value: spack\n        - name: REGISTER_NON_INTERACTIVE\n          value: 'true'\n        - name: RUNNER_REQUEST_CONCURRENCY\n          value: '32'\n        - name: RUNNER_LIMIT\n          value: '32'\n        - name: RUNNER_TAG_LIST\n          value: spack-kube,medium\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 1m\n          limits:\n            memory: 100Mi\n            cpu: 100m\n        volumeMounts:\n        - name: runner-scripts\n          mountPath: /runner-scripts\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: runner-scripts\n        configMap:\n          name: gitlab-runner-scripts\n          defaultMode: 448\n",
    "errors": []
  },
  {
    "id": "03277",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03278",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03279",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03280",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03281",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03282",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03283",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03284",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03285",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03286",
    "policy_id": "no_privileged",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03287",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03288",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03289",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03290",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03291",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03292",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (BadRequest): error when creating \"STDIN\": CronJob in version \"v1\" cannot be handled as a CronJob: strict decoding error: unknown field \"spec.jobTemplate.spec.template.spec.volumes[0].ephemeral.volumeClaimTemplate.metadata.clusterName\""
    ]
  },
  {
    "id": "03293",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8749\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03294",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8749\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03295",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8749\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03296",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8749\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03297",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8749\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03298",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2839\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03299",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2839\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03300",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2839\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03301",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2839\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03302",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2839\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03303",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1948\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03304",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1948\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03305",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1948\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03306",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1948\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03307",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1948\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03308",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crimson\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crimson\n  template:\n    metadata:\n      labels:\n        app: crimson\n    spec:\n      containers:\n      - name: app\n        image: localhost:32000/crimson:stable\n        env:\n        - name: TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: discord-secrets\n              key: token\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbPassword\n        - name: REST_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: userName\n        - name: REST_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: password\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: port\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: user\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: name\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbHost\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /logs\n          name: logs\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: logs\n        hostPath:\n          path: /opt/kubernetes/logs\n",
    "errors": []
  },
  {
    "id": "03309",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crimson\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crimson\n  template:\n    metadata:\n      labels:\n        app: crimson\n    spec:\n      containers:\n      - name: app\n        image: localhost:32000/crimson:stable\n        env:\n        - name: TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: discord-secrets\n              key: token\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbPassword\n        - name: REST_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: userName\n        - name: REST_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: password\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: port\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: user\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: name\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbHost\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /logs\n          name: logs\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: logs\n        hostPath:\n          path: /opt/kubernetes/logs\n",
    "errors": []
  },
  {
    "id": "03310",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crimson\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crimson\n  template:\n    metadata:\n      labels:\n        app: crimson\n    spec:\n      containers:\n      - name: app\n        image: localhost:32000/crimson:stable\n        env:\n        - name: TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: discord-secrets\n              key: token\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbPassword\n        - name: REST_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: userName\n        - name: REST_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: password\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: port\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: user\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: name\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbHost\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /logs\n          name: logs\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: logs\n        hostPath:\n          path: /opt/kubernetes/logs\n",
    "errors": []
  },
  {
    "id": "03311",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crimson\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crimson\n  template:\n    metadata:\n      labels:\n        app: crimson\n    spec:\n      containers:\n      - name: app\n        image: localhost:32000/crimson:stable\n        env:\n        - name: TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: discord-secrets\n              key: token\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbPassword\n        - name: REST_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: userName\n        - name: REST_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: password\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: port\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: user\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: name\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbHost\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /logs\n          name: logs\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: logs\n        hostPath:\n          path: /opt/kubernetes/logs\n",
    "errors": []
  },
  {
    "id": "03312",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: crimson\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crimson\n  template:\n    metadata:\n      labels:\n        app: crimson\n    spec:\n      containers:\n      - name: app\n        image: localhost:32000/crimson:stable\n        env:\n        - name: TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: discord-secrets\n              key: token\n        - name: DB_PASS\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbPassword\n        - name: REST_USER_NAME\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: userName\n        - name: REST_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: crimson-credentials\n              key: password\n        - name: DB_PORT\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: port\n        - name: DB_USER\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: user\n        - name: DB_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: name\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: db-credentials\n              key: dbHost\n        imagePullPolicy: Always\n        volumeMounts:\n        - mountPath: /logs\n          name: logs\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: logs\n        hostPath:\n          path: /opt/kubernetes/logs\n",
    "errors": []
  },
  {
    "id": "03313",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - image: vladimir44/microservices-demo-frontend:0.0.2\n        name: frontend\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "03314",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - image: vladimir44/microservices-demo-frontend:0.0.2\n        name: frontend\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03315",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - image: vladimir44/microservices-demo-frontend:0.0.2\n        name: frontend\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03316",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n      - image: vladimir44/microservices-demo-frontend:0.0.2\n        name: frontend\n        readinessProbe:\n          initialDelaySeconds: 10\n          httpGet:\n            path: /_healthz\n            port: 8080\n            httpHeaders:\n            - name: Cookie\n              value: shop_session-id=x-readiness-probe\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        - name: ENV_PLATFORM\n          value: gcp\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03317",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: community-operators-catalog-rollout\n  annotations:\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\nspec:\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: catalog-rollout\n          containers:\n          - name: rollout\n            image: CLI_IMAGE:stable\n            imagePullPolicy: IfNotPresent\n            command:\n            - oc\n            - rollout\n            - restart\n            - deployment/community-operators-catalog\n            securityContext:\n              capabilities:\n                drop:\n                - NET_RAW\n                - NET_ADMIN\n                - SYS_ADMIN\n                - SYS_MODULE\n                - SYS_PTRACE\n                - SYS_CHROOT\n              privileged: false\n              allowPrivilegeEscalation: false\n              runAsNonRoot: true\n              readOnlyRootFilesystem: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n          restartPolicy: OnFailure\n  schedule: 0 0 * * *\n",
    "errors": []
  },
  {
    "id": "03318",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: community-operators-catalog-rollout\n  annotations:\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\nspec:\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: catalog-rollout\n          containers:\n          - name: rollout\n            image: CLI_IMAGE:stable\n            imagePullPolicy: IfNotPresent\n            command:\n            - oc\n            - rollout\n            - restart\n            - deployment/community-operators-catalog\n            securityContext:\n              readOnlyRootFilesystem: true\n              privileged: false\n              capabilities:\n                drop:\n                - NET_RAW\n                - NET_ADMIN\n                - SYS_ADMIN\n                - SYS_MODULE\n                - SYS_PTRACE\n                - SYS_CHROOT\n              allowPrivilegeEscalation: false\n              runAsNonRoot: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n          restartPolicy: OnFailure\n  schedule: 0 0 * * *\n",
    "errors": []
  },
  {
    "id": "03319",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: community-operators-catalog-rollout\n  annotations:\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\nspec:\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: catalog-rollout\n          containers:\n          - name: rollout\n            image: CLI_IMAGE:stable\n            imagePullPolicy: IfNotPresent\n            command:\n            - oc\n            - rollout\n            - restart\n            - deployment/community-operators-catalog\n            securityContext:\n              runAsNonRoot: true\n              privileged: false\n              capabilities:\n                drop:\n                - NET_RAW\n                - NET_ADMIN\n                - SYS_ADMIN\n                - SYS_MODULE\n                - SYS_PTRACE\n                - SYS_CHROOT\n              allowPrivilegeEscalation: false\n              readOnlyRootFilesystem: true\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n          restartPolicy: OnFailure\n  schedule: 0 0 * * *\n",
    "errors": []
  },
  {
    "id": "03320",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: community-operators-catalog-rollout\n  annotations:\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\nspec:\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: catalog-rollout\n          containers:\n          - name: rollout\n            image: CLI_IMAGE:stable\n            imagePullPolicy: IfNotPresent\n            command:\n            - oc\n            - rollout\n            - restart\n            - deployment/community-operators-catalog\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n              capabilities:\n                drop:\n                - NET_RAW\n                - NET_ADMIN\n                - SYS_ADMIN\n                - SYS_MODULE\n                - SYS_PTRACE\n                - SYS_CHROOT\n              allowPrivilegeEscalation: false\n              runAsNonRoot: true\n              readOnlyRootFilesystem: true\n          restartPolicy: OnFailure\n  schedule: 0 0 * * *\n",
    "errors": []
  },
  {
    "id": "03321",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: community-operators-catalog-rollout\n  annotations:\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\nspec:\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: catalog-rollout\n          containers:\n          - name: rollout\n            image: CLI_IMAGE:stable\n            imagePullPolicy: IfNotPresent\n            command:\n            - oc\n            - rollout\n            - restart\n            - deployment/community-operators-catalog\n            resources:\n              requests:\n                cpu: 100m\n                memory: 128Mi\n              limits:\n                cpu: 500m\n                memory: 256Mi\n            securityContext:\n              privileged: false\n              capabilities:\n                drop:\n                - NET_RAW\n                - NET_ADMIN\n                - SYS_ADMIN\n                - SYS_MODULE\n                - SYS_PTRACE\n                - SYS_CHROOT\n              allowPrivilegeEscalation: false\n              runAsNonRoot: true\n              readOnlyRootFilesystem: true\n          restartPolicy: OnFailure\n  schedule: 0 0 * * *\n",
    "errors": []
  },
  {
    "id": "03322",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200619-56de83d071\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03323",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200619-56de83d071\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03324",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200619-56de83d071\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03325",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20200619-56de83d071\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "03326",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"orders-view-app\" is invalid: spec.template.spec.containers[0].volumeMounts[1].name: Not found: \"rocksdb\""
    ]
  },
  {
    "id": "03327",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"orders-view-app\" is invalid: spec.template.spec.containers[0].volumeMounts[1].name: Not found: \"rocksdb\""
    ]
  },
  {
    "id": "03328",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"orders-view-app\" is invalid: spec.template.spec.containers[0].volumeMounts[1].name: Not found: \"rocksdb\""
    ]
  },
  {
    "id": "03329",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"orders-view-app\" is invalid: spec.template.spec.containers[0].volumeMounts[1].name: Not found: \"rocksdb\""
    ]
  },
  {
    "id": "03330",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"orders-view-app\" is invalid: spec.template.spec.containers[0].volumeMounts[1].name: Not found: \"rocksdb\""
    ]
  },
  {
    "id": "03331",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:stable\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03332",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:stable\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03333",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:stable\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "03334",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:stable\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03335",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titan-ccp-load-generator\nspec:\n  selector:\n    matchLabels:\n      app: titan-ccp-load-generator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: titan-ccp-load-generator\n    spec:\n      containers:\n      - name: workload-generator\n        image: workload-generator:stable\n        env:\n        - name: NUM_SENSORS\n          value: '25000'\n        - name: INSTANCES\n          value: '1'\n        - name: NUM_NESTED_GROUPS\n          value: '5'\n        - name: ZK_HOST\n          value: my-confluent-cp-zookeeper\n        - name: ZK_PORT\n          value: '2181'\n        - name: KAFKA_BOOTSTRAP_SERVERS\n          value: my-confluent-cp-kafka:9092\n        - name: SCHEMA_REGISTRY_URL\n          value: http://my-confluent-cp-schema-registry:8081\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "03336",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: openvpn-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openvpn-server\n  template:\n    metadata:\n      labels:\n        app: openvpn-server\n    spec:\n      containers:\n      - name: openvpn-server\n        image: quay.io/sjenning/poc:openvpn\n        imagePullPolicy: Always\n        command:\n        - /usr/sbin/openvpn\n        - --config\n        - /etc/openvpn/server/server.conf\n        workingDir: /etc/openvpn/server\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/openvpn/server\n          name: server\n        - mountPath: /etc/openvpn/ccd\n          name: ccd\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - secret:\n          secretName: openvpn-server\n        name: server\n      - secret:\n          secretName: openvpn-ccd\n        name: ccd\n",
    "errors": []
  }
]